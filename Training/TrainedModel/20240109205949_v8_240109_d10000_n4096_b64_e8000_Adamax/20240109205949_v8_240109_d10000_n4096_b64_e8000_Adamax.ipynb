{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v7_240109(評価指標追加)\n",
    "\n",
    "#%%\n",
    "# 必要に応じてpip\n",
    "# !pip install --upgrade pip\n",
    "# !pip install numpy scikit-learn tensorflow matplotlib pillow pandas\n",
    "# !pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\TAKUMI\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 機械学習のライブラリ関連をインポート\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ランダムにシャッフルして，学習・テストに分割するモジュール\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "# 評価指標の計算用\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# 深層学習のライブラリをインポート\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "#表示系のインポートと設定\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ファイル操作\n",
    "import os\n",
    "\n",
    "# 画像操作\n",
    "from PIL import Image\n",
    "\n",
    "# 時間取得\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIRS\n",
    "DATASET_NUM = 10000\n",
    "DIRS_DATASET = \"../Training/Datasets_v0108/Dataset\" + str(DATASET_NUM) + \"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ファイルを取得, 配列に格納, Pythonリスト型をnumpy.ndarray型に変換\n",
    "file_names = []\n",
    "    \n",
    "# フォルダ内のファイルを取得\n",
    "files = os.listdir(DIRS_DATASET)\n",
    "\n",
    "# ファイル名を配列に格納\n",
    "for file in files:\n",
    "    file_names.append(file)\n",
    "\n",
    "# Pythonリスト型をnumpy.ndarray型に変換\n",
    "file_names = np.array(file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['4510016121775.jpeg', '4510040841489.jpeg', '4510041988985.jpeg',\n",
       "       ..., '4999915370062.jpeg', '4999978425181.jpeg',\n",
       "       '4999985455584.jpeg'], dtype='<U18')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_grayscale(numpy_array):\n",
    "    # グレーと言わず2値化\n",
    "    grayscale_array = np.where(numpy_array <= 128, 0, 255)\n",
    "    # plt.imshow(grayscale_array) # こいつらのせいで処理が重かった。出力系は要注意\n",
    "    # print(grayscale_array)\n",
    "    return grayscale_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 画像を配列にしてよしなに\n",
    "X, y = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_name in file_names:\n",
    "    numpy_array = np.array(Image.open(DIRS_DATASET + file_name)) # 画像をnumpy配列にする\n",
    "    # print(numpy_array)\n",
    "    grayscale_array = convert_to_grayscale(numpy_array)\n",
    "    # print(grayscale_array)\n",
    "    for i in range(13):\n",
    "        # grayscale_array1 = np.where(np.all(grayscale_array == 0, axis=-1), 0, 255)\n",
    "        # print(grayscale_array1)\n",
    "        grayscale_array2 = np.where(grayscale_array == 255, i+1, 0)\n",
    "        # print(grayscale_array2)\n",
    "        X.append(grayscale_array2)\n",
    "        y.append(file_name[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, yをPythonリスト型をnumpy.ndarray型に変換\n",
    "X = np.array(X)\n",
    "X = X.squeeze()\n",
    "y = np.array(y, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 5, 1, ..., 5, 8, 4])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ラベルデータをone-hotベクトルに直す\n",
    "def one_hot_vector(y):\n",
    "    labels = {\n",
    "        0: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], \n",
    "        1: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], \n",
    "        2: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], \n",
    "        3: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], \n",
    "        4: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], \n",
    "        5: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], \n",
    "        6: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], \n",
    "        7: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], \n",
    "        8: [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], \n",
    "        9: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], \n",
    "    }\n",
    "\n",
    "    y = np.array(list(map(lambda v : labels[v] , y)))\n",
    "    return y\n",
    "\n",
    "# ラベルデータをone-hotベクトル「から」直す\n",
    "def one_hot_vector_restore(y):\n",
    "    labels = {\n",
    "        (1, 0, 0, 0, 0, 0, 0, 0, 0, 0): 0,\n",
    "        (0, 1, 0, 0, 0, 0, 0, 0, 0, 0): 1,\n",
    "        (0, 0, 1, 0, 0, 0, 0, 0, 0, 0): 2,\n",
    "        (0, 0, 0, 1, 0, 0, 0, 0, 0, 0): 3,\n",
    "        (0, 0, 0, 0, 1, 0, 0, 0, 0, 0): 4,\n",
    "        (0, 0, 0, 0, 0, 1, 0, 0, 0, 0): 5,\n",
    "        (0, 0, 0, 0, 0, 0, 1, 0, 0, 0): 6,\n",
    "        (0, 0, 0, 0, 0, 0, 0, 1, 0, 0): 7,\n",
    "        (0, 0, 0, 0, 0, 0, 0, 0, 1, 0): 8,\n",
    "        (0, 0, 0, 0, 0, 0, 0, 0, 0, 1): 9,\n",
    "    }\n",
    "\n",
    "    y = np.array([labels[tuple(one_hot)] for one_hot in y])\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = one_hot_vector(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 1, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### データの分割\n",
    "ss = ShuffleSplit(n_splits=1,      # 分割を1個生成\n",
    "                  train_size=0.8,  # 学習\n",
    "                  test_size =0.2,  # テスト\n",
    "                  random_state=0)  # 乱数種（再現用）\n",
    "\n",
    "# 学習データとテストデータのインデックスを作成\n",
    "train_index, test_index = next(ss.split(X))\n",
    "\n",
    "X_train, X_test = X[train_index], X[test_index] # 学習データ，テストデータ\n",
    "y_train, y_test = y[train_index], y[test_index] # 学習データのラベル，テストデータのラベル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 1, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104000, 337)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[0], X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ニューラルネットワークの構築\n",
    "\n",
    "# 学習し、テストデータで評価し、スコアを表示する\n",
    "# 引数は、中間層の数、バッチサイズ、epoch数\n",
    "\n",
    "def fit_epoch(neuron, batch, epochs, ckpt_period, optimizer_name):\n",
    "    ver_name = \"v8_240109\"\n",
    "    \n",
    "    # チェックポイントの設定\n",
    "    dt_now = datetime.datetime.now()\n",
    "    checkpoint_path = \"./training_ckpt_\" + dt_now.strftime('%Y%m%d%H%M%S') + \"_\" + ver_name + \"_d\" + str(DATASET_NUM) + \"_n\" + str(neuron)  + \"_b\" + str(batch) + \"_e\" + str(epochs) + \"_c\" + str(ckpt_period) + \"_\" + optimizer_name + \"/cp-{epoch:09d}.ckpt\"\n",
    "    checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "    cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        checkpoint_path,\n",
    "        verbose=1,\n",
    "        save_weights_only=True,\n",
    "        period=ckpt_period  # 重みをckpt_periodエポックごとに保存します\n",
    "    )\n",
    "\n",
    "\n",
    "    # レイヤーのオブジェクトを作成\n",
    "    Dense = keras.layers.Dense\n",
    "\n",
    "    # モデルの構造を定義\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Flatten(input_shape=(337, )))\n",
    "    model.add(Dense(neuron, activation='relu'))\n",
    "    \n",
    "    # 畳み込み層を追加\n",
    "    # model.add(tf.keras.layers.Flatten(tf.keras.layers.Conv2D(filters=neuron, kernel_size=(3, 3), activation='relu', input_shape=(1, 337, 3))))\n",
    "\n",
    "    model.add(Dense(10, activation='softmax')) # 10つのラベルがありsoftmaxで最後の層作る\n",
    "\n",
    "    # モデルを構築\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=optimizer_name,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    # 必要に応じてチェックポイントから再開\n",
    "    model.load_weights(\"./training_ckpt_20240109200453_v7_240109_d10000_n4096_b64_e80000_Adamax/cp-000000200.ckpt\")\n",
    "\n",
    "    # 学習を実行\n",
    "    hist = model.fit(X_train, y_train,\n",
    "        batch_size=batch, # 誤差逆伝播法をするときの1回当たりのデータ数\n",
    "        epochs=epochs,\n",
    "        callbacks=[cp_callback],\n",
    "        verbose=1,\n",
    "        validation_split=0.1)\n",
    "    \n",
    "    # モデルの保存\n",
    "    model.save(\"./TrainedModel/\" + dt_now.strftime('%Y%m%d%H%M%S') + \"_\" + ver_name + \"_d\" + str(DATASET_NUM) + \"_n\" + str(neuron)  + \"_b\" + str(batch) + \"_e\" + str(epochs) + \"_\"+ optimizer_name)\n",
    "    \n",
    "    # モデルを評価\n",
    "    score = model.evaluate(X_test, y_test, verbose=1)\n",
    "    print('正解率(Accuracy)=', score[1], 'loss=', score[0])\n",
    "\n",
    "    # 予測を取得\n",
    "    predictions = model.predict(X_test)\n",
    "    predicted_labels = tf.argmax(predictions, axis=1).numpy()\n",
    "    y_test_restored = one_hot_vector_restore(y_test) # one-hotベクトル「から」直す\n",
    "\n",
    "    print(predicted_labels)\n",
    "\n",
    "    # classification_reportを使用して評価指標を表示\n",
    "    df_report = pd.DataFrame(classification_report(y_test_restored, predicted_labels, output_dict=True)).T\n",
    "    print(df_report)\n",
    "\n",
    "    # seabornのヒートマップ\n",
    "    sns.heatmap(confusion_matrix(y_test_restored, predicted_labels), annot=True)\n",
    "    plt.xlabel(\"pred\")\n",
    "    plt.ylabel('true')\n",
    "    plt.show()\n",
    "    \n",
    "    # 学習の様子をグラフへ描画 \n",
    "    # 正解率の推移をプロット\n",
    "    plt.plot(hist.history['accuracy'])\n",
    "    plt.plot(hist.history['val_accuracy'])\n",
    "    plt.title('Accuracy')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    # ロスの推移をプロット\n",
    "    plt.plot(hist.history['loss'])\n",
    "    plt.plot(hist.history['val_loss'])\n",
    "    plt.title('Loss')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(DATASET_NUM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8000\n",
      "1463/1463 [==============================] - 17s 11ms/step - loss: 0.6929 - accuracy: 0.7097 - val_loss: 1.1861 - val_accuracy: 0.5599\n",
      "Epoch 2/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.6911 - accuracy: 0.7122 - val_loss: 1.1296 - val_accuracy: 0.5789\n",
      "Epoch 3/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.6905 - accuracy: 0.7102 - val_loss: 1.1081 - val_accuracy: 0.5821\n",
      "Epoch 4/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.6860 - accuracy: 0.7129 - val_loss: 1.1306 - val_accuracy: 0.5769\n",
      "Epoch 5/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.6868 - accuracy: 0.7123 - val_loss: 1.1062 - val_accuracy: 0.5865\n",
      "Epoch 6/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.6836 - accuracy: 0.7140 - val_loss: 1.1438 - val_accuracy: 0.5782\n",
      "Epoch 7/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.6842 - accuracy: 0.7138 - val_loss: 1.1432 - val_accuracy: 0.5767\n",
      "Epoch 8/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.6804 - accuracy: 0.7136 - val_loss: 1.1094 - val_accuracy: 0.5853\n",
      "Epoch 9/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.6775 - accuracy: 0.7166 - val_loss: 1.1266 - val_accuracy: 0.5790\n",
      "Epoch 10/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.6775 - accuracy: 0.7172 - val_loss: 1.1456 - val_accuracy: 0.5732\n",
      "Epoch 11/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.6753 - accuracy: 0.7160 - val_loss: 1.1105 - val_accuracy: 0.5777\n",
      "Epoch 12/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.6744 - accuracy: 0.7163 - val_loss: 1.1253 - val_accuracy: 0.5785\n",
      "Epoch 13/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.6734 - accuracy: 0.7171 - val_loss: 1.0989 - val_accuracy: 0.5815\n",
      "Epoch 14/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.6737 - accuracy: 0.7174 - val_loss: 1.1077 - val_accuracy: 0.5854\n",
      "Epoch 15/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.6699 - accuracy: 0.7182 - val_loss: 1.1057 - val_accuracy: 0.5820\n",
      "Epoch 16/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.6678 - accuracy: 0.7191 - val_loss: 1.1095 - val_accuracy: 0.5835\n",
      "Epoch 17/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.6670 - accuracy: 0.7207 - val_loss: 1.1012 - val_accuracy: 0.5906\n",
      "Epoch 18/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.6601 - accuracy: 0.7221 - val_loss: 1.1412 - val_accuracy: 0.5812\n",
      "Epoch 19/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.6625 - accuracy: 0.7208 - val_loss: 1.1531 - val_accuracy: 0.5789\n",
      "Epoch 20/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.6607 - accuracy: 0.7227 - val_loss: 1.1738 - val_accuracy: 0.5711\n",
      "Epoch 21/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.6616 - accuracy: 0.7220 - val_loss: 1.0862 - val_accuracy: 0.5917\n",
      "Epoch 22/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.6583 - accuracy: 0.7231 - val_loss: 1.1109 - val_accuracy: 0.5834\n",
      "Epoch 23/8000\n",
      "1463/1463 [==============================] - 12s 9ms/step - loss: 0.6551 - accuracy: 0.7252 - val_loss: 1.1159 - val_accuracy: 0.5875\n",
      "Epoch 24/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.6571 - accuracy: 0.7254 - val_loss: 1.1080 - val_accuracy: 0.5892\n",
      "Epoch 25/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.6512 - accuracy: 0.7269 - val_loss: 1.1090 - val_accuracy: 0.5855\n",
      "Epoch 26/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.6501 - accuracy: 0.7263 - val_loss: 1.0897 - val_accuracy: 0.5943\n",
      "Epoch 27/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.6506 - accuracy: 0.7272 - val_loss: 1.1189 - val_accuracy: 0.5913\n",
      "Epoch 28/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.6427 - accuracy: 0.7285 - val_loss: 1.1007 - val_accuracy: 0.5912\n",
      "Epoch 29/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.6429 - accuracy: 0.7293 - val_loss: 1.0908 - val_accuracy: 0.5900\n",
      "Epoch 30/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.6473 - accuracy: 0.7292 - val_loss: 1.1068 - val_accuracy: 0.5942\n",
      "Epoch 31/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.6396 - accuracy: 0.7310 - val_loss: 1.0983 - val_accuracy: 0.5889\n",
      "Epoch 32/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.6387 - accuracy: 0.7314 - val_loss: 1.0758 - val_accuracy: 0.6003\n",
      "Epoch 33/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.6393 - accuracy: 0.7311 - val_loss: 1.1143 - val_accuracy: 0.5879\n",
      "Epoch 34/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.6379 - accuracy: 0.7331 - val_loss: 1.0920 - val_accuracy: 0.5947\n",
      "Epoch 35/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.6334 - accuracy: 0.7343 - val_loss: 1.1036 - val_accuracy: 0.5818\n",
      "Epoch 36/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.6337 - accuracy: 0.7347 - val_loss: 1.0728 - val_accuracy: 0.5970\n",
      "Epoch 37/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.6273 - accuracy: 0.7371 - val_loss: 1.0705 - val_accuracy: 0.5959\n",
      "Epoch 38/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.6322 - accuracy: 0.7354 - val_loss: 1.1018 - val_accuracy: 0.5941\n",
      "Epoch 39/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.6326 - accuracy: 0.7342 - val_loss: 1.1161 - val_accuracy: 0.5922\n",
      "Epoch 40/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.6237 - accuracy: 0.7384 - val_loss: 1.0877 - val_accuracy: 0.5979\n",
      "Epoch 41/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.6226 - accuracy: 0.7395 - val_loss: 1.1556 - val_accuracy: 0.5757\n",
      "Epoch 42/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.6241 - accuracy: 0.7391 - val_loss: 1.1011 - val_accuracy: 0.5962\n",
      "Epoch 43/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.6190 - accuracy: 0.7406 - val_loss: 1.1200 - val_accuracy: 0.5821\n",
      "Epoch 44/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.6228 - accuracy: 0.7390 - val_loss: 1.1206 - val_accuracy: 0.5884\n",
      "Epoch 45/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.6203 - accuracy: 0.7410 - val_loss: 1.1300 - val_accuracy: 0.5913\n",
      "Epoch 46/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.6211 - accuracy: 0.7413 - val_loss: 1.1327 - val_accuracy: 0.5884\n",
      "Epoch 47/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.6213 - accuracy: 0.7391 - val_loss: 1.0698 - val_accuracy: 0.5945\n",
      "Epoch 48/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.6170 - accuracy: 0.7420 - val_loss: 1.0804 - val_accuracy: 0.5952\n",
      "Epoch 49/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.6121 - accuracy: 0.7429 - val_loss: 1.0812 - val_accuracy: 0.6032\n",
      "Epoch 50/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.6156 - accuracy: 0.7435 - val_loss: 1.1342 - val_accuracy: 0.5915\n",
      "Epoch 51/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.6178 - accuracy: 0.7410 - val_loss: 1.0937 - val_accuracy: 0.5938\n",
      "Epoch 52/8000\n",
      "1463/1463 [==============================] - 18s 12ms/step - loss: 0.6087 - accuracy: 0.7464 - val_loss: 1.0859 - val_accuracy: 0.5980\n",
      "Epoch 53/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.6084 - accuracy: 0.7454 - val_loss: 1.0967 - val_accuracy: 0.5903\n",
      "Epoch 54/8000\n",
      "1463/1463 [==============================] - 18s 12ms/step - loss: 0.6146 - accuracy: 0.7416 - val_loss: 1.0977 - val_accuracy: 0.5938\n",
      "Epoch 55/8000\n",
      "1463/1463 [==============================] - 17s 11ms/step - loss: 0.6137 - accuracy: 0.7430 - val_loss: 1.0976 - val_accuracy: 0.5878\n",
      "Epoch 56/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.6051 - accuracy: 0.7455 - val_loss: 1.1077 - val_accuracy: 0.5912\n",
      "Epoch 57/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.6062 - accuracy: 0.7462 - val_loss: 1.0991 - val_accuracy: 0.5979\n",
      "Epoch 58/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.6023 - accuracy: 0.7479 - val_loss: 1.0758 - val_accuracy: 0.6086\n",
      "Epoch 59/8000\n",
      "1463/1463 [==============================] - 17s 11ms/step - loss: 0.6032 - accuracy: 0.7484 - val_loss: 1.0877 - val_accuracy: 0.6011\n",
      "Epoch 60/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.6007 - accuracy: 0.7474 - val_loss: 1.1051 - val_accuracy: 0.5975\n",
      "Epoch 61/8000\n",
      "1463/1463 [==============================] - 18s 12ms/step - loss: 0.5993 - accuracy: 0.7481 - val_loss: 1.1045 - val_accuracy: 0.5921\n",
      "Epoch 62/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.5961 - accuracy: 0.7509 - val_loss: 1.1101 - val_accuracy: 0.5932\n",
      "Epoch 63/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.5949 - accuracy: 0.7504 - val_loss: 1.0919 - val_accuracy: 0.5949\n",
      "Epoch 64/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.5960 - accuracy: 0.7485 - val_loss: 1.0644 - val_accuracy: 0.6045\n",
      "Epoch 65/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.5987 - accuracy: 0.7488 - val_loss: 1.0654 - val_accuracy: 0.6067\n",
      "Epoch 66/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.5910 - accuracy: 0.7515 - val_loss: 1.0545 - val_accuracy: 0.6086\n",
      "Epoch 67/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.5962 - accuracy: 0.7499 - val_loss: 1.1366 - val_accuracy: 0.5991\n",
      "Epoch 68/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.6106 - accuracy: 0.7424 - val_loss: 1.0817 - val_accuracy: 0.6048\n",
      "Epoch 69/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.6040 - accuracy: 0.7465 - val_loss: 1.1144 - val_accuracy: 0.5989\n",
      "Epoch 70/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.6021 - accuracy: 0.7468 - val_loss: 1.1118 - val_accuracy: 0.5969\n",
      "Epoch 71/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.5998 - accuracy: 0.7474 - val_loss: 1.1109 - val_accuracy: 0.5959\n",
      "Epoch 72/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.5938 - accuracy: 0.7504 - val_loss: 1.0853 - val_accuracy: 0.5955\n",
      "Epoch 73/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.5954 - accuracy: 0.7509 - val_loss: 1.1150 - val_accuracy: 0.5943\n",
      "Epoch 74/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.5974 - accuracy: 0.7498 - val_loss: 1.0798 - val_accuracy: 0.6036\n",
      "Epoch 75/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.5954 - accuracy: 0.7486 - val_loss: 1.0997 - val_accuracy: 0.6011\n",
      "Epoch 76/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.5965 - accuracy: 0.7499 - val_loss: 1.1160 - val_accuracy: 0.5944\n",
      "Epoch 77/8000\n",
      "1463/1463 [==============================] - 19s 13ms/step - loss: 0.5930 - accuracy: 0.7519 - val_loss: 1.0865 - val_accuracy: 0.6012\n",
      "Epoch 78/8000\n",
      "1463/1463 [==============================] - 19s 13ms/step - loss: 0.5962 - accuracy: 0.7496 - val_loss: 1.1189 - val_accuracy: 0.6015\n",
      "Epoch 79/8000\n",
      "1463/1463 [==============================] - 18s 12ms/step - loss: 0.5924 - accuracy: 0.7522 - val_loss: 1.0731 - val_accuracy: 0.6087\n",
      "Epoch 80/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.5899 - accuracy: 0.7523 - val_loss: 1.1250 - val_accuracy: 0.5966\n",
      "Epoch 81/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.5875 - accuracy: 0.7528 - val_loss: 1.1360 - val_accuracy: 0.5958\n",
      "Epoch 82/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.6035 - accuracy: 0.7476 - val_loss: 1.1387 - val_accuracy: 0.5951\n",
      "Epoch 83/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.6029 - accuracy: 0.7468 - val_loss: 1.1339 - val_accuracy: 0.5880\n",
      "Epoch 84/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.5981 - accuracy: 0.7483 - val_loss: 1.1393 - val_accuracy: 0.5919\n",
      "Epoch 85/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.5940 - accuracy: 0.7497 - val_loss: 1.1571 - val_accuracy: 0.5855\n",
      "Epoch 86/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.5906 - accuracy: 0.7516 - val_loss: 1.1326 - val_accuracy: 0.5956\n",
      "Epoch 87/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.5922 - accuracy: 0.7506 - val_loss: 1.0611 - val_accuracy: 0.6050\n",
      "Epoch 88/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.5905 - accuracy: 0.7513 - val_loss: 1.1313 - val_accuracy: 0.5993\n",
      "Epoch 89/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.5888 - accuracy: 0.7511 - val_loss: 1.0647 - val_accuracy: 0.6063\n",
      "Epoch 90/8000\n",
      "1463/1463 [==============================] - 17s 11ms/step - loss: 0.5870 - accuracy: 0.7518 - val_loss: 1.1209 - val_accuracy: 0.5977\n",
      "Epoch 91/8000\n",
      "1463/1463 [==============================] - 17s 11ms/step - loss: 0.5881 - accuracy: 0.7512 - val_loss: 1.0773 - val_accuracy: 0.6004\n",
      "Epoch 92/8000\n",
      "1463/1463 [==============================] - 20s 14ms/step - loss: 0.5847 - accuracy: 0.7518 - val_loss: 1.1108 - val_accuracy: 0.5969\n",
      "Epoch 93/8000\n",
      "1463/1463 [==============================] - 18s 12ms/step - loss: 0.5869 - accuracy: 0.7531 - val_loss: 1.0812 - val_accuracy: 0.6087\n",
      "Epoch 94/8000\n",
      "1463/1463 [==============================] - 19s 13ms/step - loss: 0.5842 - accuracy: 0.7543 - val_loss: 1.1385 - val_accuracy: 0.5933\n",
      "Epoch 95/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.5833 - accuracy: 0.7529 - val_loss: 1.0690 - val_accuracy: 0.6039\n",
      "Epoch 96/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.5839 - accuracy: 0.7536 - val_loss: 1.0738 - val_accuracy: 0.6097\n",
      "Epoch 97/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.5806 - accuracy: 0.7549 - val_loss: 1.1258 - val_accuracy: 0.5984\n",
      "Epoch 98/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.5851 - accuracy: 0.7523 - val_loss: 1.1189 - val_accuracy: 0.6027\n",
      "Epoch 99/8000\n",
      "1463/1463 [==============================] - 17s 11ms/step - loss: 0.5841 - accuracy: 0.7532 - val_loss: 1.1201 - val_accuracy: 0.5902\n",
      "Epoch 100/8000\n",
      "1460/1463 [============================>.] - ETA: 0s - loss: 0.5771 - accuracy: 0.7560\n",
      "Epoch 100: saving model to ./training_ckpt_20240109205949_v8_240109_d10000_n4096_b64_e8000_c100_Adamax\\cp-000000100.ckpt\n",
      "1463/1463 [==============================] - 17s 11ms/step - loss: 0.5773 - accuracy: 0.7559 - val_loss: 1.0888 - val_accuracy: 0.6039\n",
      "Epoch 101/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.5757 - accuracy: 0.7573 - val_loss: 1.0742 - val_accuracy: 0.6140\n",
      "Epoch 102/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.5776 - accuracy: 0.7558 - val_loss: 1.1035 - val_accuracy: 0.5960\n",
      "Epoch 103/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.5791 - accuracy: 0.7546 - val_loss: 1.1155 - val_accuracy: 0.6063\n",
      "Epoch 104/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.5776 - accuracy: 0.7553 - val_loss: 1.0648 - val_accuracy: 0.6047\n",
      "Epoch 105/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.5758 - accuracy: 0.7560 - val_loss: 1.1151 - val_accuracy: 0.5957\n",
      "Epoch 106/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.5783 - accuracy: 0.7555 - val_loss: 1.0732 - val_accuracy: 0.6101\n",
      "Epoch 107/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.5761 - accuracy: 0.7553 - val_loss: 1.1235 - val_accuracy: 0.5945\n",
      "Epoch 108/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.5693 - accuracy: 0.7597 - val_loss: 1.0870 - val_accuracy: 0.6060\n",
      "Epoch 109/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.5675 - accuracy: 0.7608 - val_loss: 1.1451 - val_accuracy: 0.6019\n",
      "Epoch 110/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.5722 - accuracy: 0.7582 - val_loss: 1.1060 - val_accuracy: 0.5980\n",
      "Epoch 111/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.5674 - accuracy: 0.7610 - val_loss: 1.1052 - val_accuracy: 0.6052\n",
      "Epoch 112/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.5658 - accuracy: 0.7614 - val_loss: 1.0887 - val_accuracy: 0.6059\n",
      "Epoch 113/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.5630 - accuracy: 0.7629 - val_loss: 1.0557 - val_accuracy: 0.6123\n",
      "Epoch 114/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.5606 - accuracy: 0.7637 - val_loss: 1.0554 - val_accuracy: 0.6136\n",
      "Epoch 115/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.5544 - accuracy: 0.7657 - val_loss: 1.0458 - val_accuracy: 0.6121\n",
      "Epoch 116/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.5588 - accuracy: 0.7631 - val_loss: 1.0679 - val_accuracy: 0.6082\n",
      "Epoch 117/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.5583 - accuracy: 0.7656 - val_loss: 1.0806 - val_accuracy: 0.6063\n",
      "Epoch 118/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.5614 - accuracy: 0.7646 - val_loss: 1.1700 - val_accuracy: 0.5936\n",
      "Epoch 119/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.5577 - accuracy: 0.7659 - val_loss: 1.1343 - val_accuracy: 0.5945\n",
      "Epoch 120/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.5532 - accuracy: 0.7675 - val_loss: 1.0579 - val_accuracy: 0.6146\n",
      "Epoch 121/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.5520 - accuracy: 0.7668 - val_loss: 1.1046 - val_accuracy: 0.6021\n",
      "Epoch 122/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.5512 - accuracy: 0.7697 - val_loss: 1.0574 - val_accuracy: 0.6202\n",
      "Epoch 123/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.5476 - accuracy: 0.7700 - val_loss: 1.0758 - val_accuracy: 0.6062\n",
      "Epoch 124/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.5496 - accuracy: 0.7684 - val_loss: 1.0439 - val_accuracy: 0.6165\n",
      "Epoch 125/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.5506 - accuracy: 0.7682 - val_loss: 1.0578 - val_accuracy: 0.6086\n",
      "Epoch 126/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.5464 - accuracy: 0.7708 - val_loss: 1.0480 - val_accuracy: 0.6134\n",
      "Epoch 127/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.5491 - accuracy: 0.7687 - val_loss: 1.0658 - val_accuracy: 0.6088\n",
      "Epoch 128/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.5415 - accuracy: 0.7731 - val_loss: 1.0722 - val_accuracy: 0.6140\n",
      "Epoch 129/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.5407 - accuracy: 0.7730 - val_loss: 1.1730 - val_accuracy: 0.5870\n",
      "Epoch 130/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.5430 - accuracy: 0.7741 - val_loss: 1.0803 - val_accuracy: 0.6109\n",
      "Epoch 131/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.5441 - accuracy: 0.7707 - val_loss: 1.1042 - val_accuracy: 0.6053\n",
      "Epoch 132/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.5371 - accuracy: 0.7735 - val_loss: 1.0694 - val_accuracy: 0.6152\n",
      "Epoch 133/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.5410 - accuracy: 0.7711 - val_loss: 1.0757 - val_accuracy: 0.6116\n",
      "Epoch 134/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.5454 - accuracy: 0.7703 - val_loss: 1.0701 - val_accuracy: 0.6171\n",
      "Epoch 135/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.5377 - accuracy: 0.7735 - val_loss: 1.0707 - val_accuracy: 0.6118\n",
      "Epoch 136/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.5339 - accuracy: 0.7762 - val_loss: 1.0455 - val_accuracy: 0.6153\n",
      "Epoch 137/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.5304 - accuracy: 0.7769 - val_loss: 1.0515 - val_accuracy: 0.6207\n",
      "Epoch 138/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.5385 - accuracy: 0.7741 - val_loss: 1.0991 - val_accuracy: 0.6118\n",
      "Epoch 139/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.5403 - accuracy: 0.7721 - val_loss: 1.0867 - val_accuracy: 0.6062\n",
      "Epoch 140/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.5440 - accuracy: 0.7710 - val_loss: 1.1037 - val_accuracy: 0.6147\n",
      "Epoch 141/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.5422 - accuracy: 0.7718 - val_loss: 1.0766 - val_accuracy: 0.6121\n",
      "Epoch 142/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.5410 - accuracy: 0.7737 - val_loss: 1.0538 - val_accuracy: 0.6172\n",
      "Epoch 143/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.5371 - accuracy: 0.7727 - val_loss: 1.0476 - val_accuracy: 0.6244\n",
      "Epoch 144/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.5410 - accuracy: 0.7719 - val_loss: 1.0639 - val_accuracy: 0.6170\n",
      "Epoch 145/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.5294 - accuracy: 0.7773 - val_loss: 1.0588 - val_accuracy: 0.6225\n",
      "Epoch 146/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.5398 - accuracy: 0.7731 - val_loss: 1.0460 - val_accuracy: 0.6213\n",
      "Epoch 147/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.5336 - accuracy: 0.7776 - val_loss: 1.0704 - val_accuracy: 0.6172\n",
      "Epoch 148/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.5308 - accuracy: 0.7767 - val_loss: 1.0723 - val_accuracy: 0.6202\n",
      "Epoch 149/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.5304 - accuracy: 0.7761 - val_loss: 1.0451 - val_accuracy: 0.6249\n",
      "Epoch 150/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.5241 - accuracy: 0.7788 - val_loss: 1.1007 - val_accuracy: 0.6147\n",
      "Epoch 151/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.5326 - accuracy: 0.7772 - val_loss: 1.0980 - val_accuracy: 0.6078\n",
      "Epoch 152/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.5287 - accuracy: 0.7782 - val_loss: 1.0756 - val_accuracy: 0.6151\n",
      "Epoch 153/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.5269 - accuracy: 0.7780 - val_loss: 1.0939 - val_accuracy: 0.6260\n",
      "Epoch 154/8000\n",
      "1463/1463 [==============================] - 15s 11ms/step - loss: 0.5290 - accuracy: 0.7780 - val_loss: 1.0492 - val_accuracy: 0.6247\n",
      "Epoch 155/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.5332 - accuracy: 0.7780 - val_loss: 1.0529 - val_accuracy: 0.6193\n",
      "Epoch 156/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.5383 - accuracy: 0.7743 - val_loss: 1.1195 - val_accuracy: 0.6004\n",
      "Epoch 157/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.5332 - accuracy: 0.7765 - val_loss: 1.0910 - val_accuracy: 0.6093\n",
      "Epoch 158/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.5253 - accuracy: 0.7802 - val_loss: 1.0524 - val_accuracy: 0.6250\n",
      "Epoch 159/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.5262 - accuracy: 0.7803 - val_loss: 1.0744 - val_accuracy: 0.6150\n",
      "Epoch 160/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.5237 - accuracy: 0.7808 - val_loss: 1.0581 - val_accuracy: 0.6166\n",
      "Epoch 161/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.5241 - accuracy: 0.7804 - val_loss: 1.0414 - val_accuracy: 0.6252\n",
      "Epoch 162/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.5299 - accuracy: 0.7775 - val_loss: 1.0785 - val_accuracy: 0.6068\n",
      "Epoch 163/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.5204 - accuracy: 0.7816 - val_loss: 1.0289 - val_accuracy: 0.6252\n",
      "Epoch 164/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.5210 - accuracy: 0.7819 - val_loss: 1.0871 - val_accuracy: 0.6149\n",
      "Epoch 165/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.5177 - accuracy: 0.7827 - val_loss: 1.0314 - val_accuracy: 0.6300\n",
      "Epoch 166/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.5198 - accuracy: 0.7813 - val_loss: 1.0585 - val_accuracy: 0.6235\n",
      "Epoch 167/8000\n",
      "1463/1463 [==============================] - 18s 12ms/step - loss: 0.5173 - accuracy: 0.7830 - val_loss: 1.0443 - val_accuracy: 0.6208\n",
      "Epoch 168/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.5149 - accuracy: 0.7840 - val_loss: 1.0735 - val_accuracy: 0.6187\n",
      "Epoch 169/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.5162 - accuracy: 0.7832 - val_loss: 1.0879 - val_accuracy: 0.6117\n",
      "Epoch 170/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.5088 - accuracy: 0.7868 - val_loss: 1.0486 - val_accuracy: 0.6245\n",
      "Epoch 171/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.5111 - accuracy: 0.7852 - val_loss: 1.0495 - val_accuracy: 0.6274\n",
      "Epoch 172/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.5153 - accuracy: 0.7840 - val_loss: 1.0404 - val_accuracy: 0.6205\n",
      "Epoch 173/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.5176 - accuracy: 0.7842 - val_loss: 1.0690 - val_accuracy: 0.6173\n",
      "Epoch 174/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.5178 - accuracy: 0.7835 - val_loss: 1.0627 - val_accuracy: 0.6163\n",
      "Epoch 175/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.5197 - accuracy: 0.7818 - val_loss: 1.0422 - val_accuracy: 0.6268\n",
      "Epoch 176/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.5349 - accuracy: 0.7729 - val_loss: 1.1083 - val_accuracy: 0.6205\n",
      "Epoch 177/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.5329 - accuracy: 0.7735 - val_loss: 1.1109 - val_accuracy: 0.6106\n",
      "Epoch 178/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.5263 - accuracy: 0.7784 - val_loss: 1.0604 - val_accuracy: 0.6197\n",
      "Epoch 179/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.5232 - accuracy: 0.7794 - val_loss: 1.0638 - val_accuracy: 0.6223\n",
      "Epoch 180/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.5229 - accuracy: 0.7787 - val_loss: 1.0448 - val_accuracy: 0.6272\n",
      "Epoch 181/8000\n",
      "1463/1463 [==============================] - 17s 11ms/step - loss: 0.5123 - accuracy: 0.7842 - val_loss: 1.0657 - val_accuracy: 0.6217\n",
      "Epoch 182/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.5176 - accuracy: 0.7808 - val_loss: 1.0733 - val_accuracy: 0.6195\n",
      "Epoch 183/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.5170 - accuracy: 0.7806 - val_loss: 1.1364 - val_accuracy: 0.5985\n",
      "Epoch 184/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.5231 - accuracy: 0.7797 - val_loss: 1.0370 - val_accuracy: 0.6291\n",
      "Epoch 185/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.5141 - accuracy: 0.7827 - val_loss: 1.0477 - val_accuracy: 0.6248\n",
      "Epoch 186/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.5178 - accuracy: 0.7823 - val_loss: 1.0876 - val_accuracy: 0.6135\n",
      "Epoch 187/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.5133 - accuracy: 0.7838 - val_loss: 1.0218 - val_accuracy: 0.6348\n",
      "Epoch 188/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.5093 - accuracy: 0.7846 - val_loss: 1.1034 - val_accuracy: 0.6138\n",
      "Epoch 189/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.5127 - accuracy: 0.7854 - val_loss: 1.0540 - val_accuracy: 0.6291\n",
      "Epoch 190/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.5079 - accuracy: 0.7850 - val_loss: 1.0780 - val_accuracy: 0.6189\n",
      "Epoch 191/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.5056 - accuracy: 0.7868 - val_loss: 1.0692 - val_accuracy: 0.6325\n",
      "Epoch 192/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.5113 - accuracy: 0.7833 - val_loss: 1.0340 - val_accuracy: 0.6267\n",
      "Epoch 193/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.5054 - accuracy: 0.7859 - val_loss: 1.1251 - val_accuracy: 0.6121\n",
      "Epoch 194/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.5135 - accuracy: 0.7835 - val_loss: 1.0372 - val_accuracy: 0.6282\n",
      "Epoch 195/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.5095 - accuracy: 0.7850 - val_loss: 1.0390 - val_accuracy: 0.6321\n",
      "Epoch 196/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.5088 - accuracy: 0.7850 - val_loss: 1.0411 - val_accuracy: 0.6347\n",
      "Epoch 197/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.5031 - accuracy: 0.7877 - val_loss: 1.1019 - val_accuracy: 0.6124\n",
      "Epoch 198/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.5071 - accuracy: 0.7842 - val_loss: 1.0454 - val_accuracy: 0.6372\n",
      "Epoch 199/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.5214 - accuracy: 0.7801 - val_loss: 1.0666 - val_accuracy: 0.6125\n",
      "Epoch 200/8000\n",
      "1460/1463 [============================>.] - ETA: 0s - loss: 0.5156 - accuracy: 0.7804\n",
      "Epoch 200: saving model to ./training_ckpt_20240109205949_v8_240109_d10000_n4096_b64_e8000_c100_Adamax\\cp-000000200.ckpt\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.5156 - accuracy: 0.7804 - val_loss: 1.0371 - val_accuracy: 0.6313\n",
      "Epoch 201/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.5116 - accuracy: 0.7831 - val_loss: 1.0766 - val_accuracy: 0.6225\n",
      "Epoch 202/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.5201 - accuracy: 0.7796 - val_loss: 1.0409 - val_accuracy: 0.6263\n",
      "Epoch 203/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.5079 - accuracy: 0.7840 - val_loss: 1.0440 - val_accuracy: 0.6349\n",
      "Epoch 204/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.5071 - accuracy: 0.7852 - val_loss: 1.0351 - val_accuracy: 0.6312\n",
      "Epoch 205/8000\n",
      "1463/1463 [==============================] - 15s 11ms/step - loss: 0.5049 - accuracy: 0.7846 - val_loss: 1.0530 - val_accuracy: 0.6291\n",
      "Epoch 206/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.5090 - accuracy: 0.7843 - val_loss: 1.0346 - val_accuracy: 0.6293\n",
      "Epoch 207/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.4985 - accuracy: 0.7890 - val_loss: 1.0832 - val_accuracy: 0.6210\n",
      "Epoch 208/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.4997 - accuracy: 0.7883 - val_loss: 1.0661 - val_accuracy: 0.6194\n",
      "Epoch 209/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.5017 - accuracy: 0.7882 - val_loss: 1.0411 - val_accuracy: 0.6320\n",
      "Epoch 210/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.4985 - accuracy: 0.7894 - val_loss: 1.1155 - val_accuracy: 0.6209\n",
      "Epoch 211/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.4998 - accuracy: 0.7884 - val_loss: 1.1566 - val_accuracy: 0.6193\n",
      "Epoch 212/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.5170 - accuracy: 0.7798 - val_loss: 1.0317 - val_accuracy: 0.6317\n",
      "Epoch 213/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.5120 - accuracy: 0.7809 - val_loss: 1.0458 - val_accuracy: 0.6315\n",
      "Epoch 214/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.5140 - accuracy: 0.7822 - val_loss: 1.0544 - val_accuracy: 0.6237\n",
      "Epoch 215/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.5090 - accuracy: 0.7835 - val_loss: 1.0605 - val_accuracy: 0.6272\n",
      "Epoch 216/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.5089 - accuracy: 0.7851 - val_loss: 1.0954 - val_accuracy: 0.6164\n",
      "Epoch 217/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.5069 - accuracy: 0.7848 - val_loss: 1.0758 - val_accuracy: 0.6217\n",
      "Epoch 218/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.5044 - accuracy: 0.7848 - val_loss: 1.0238 - val_accuracy: 0.6333\n",
      "Epoch 219/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.5046 - accuracy: 0.7845 - val_loss: 1.0342 - val_accuracy: 0.6305\n",
      "Epoch 220/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.4977 - accuracy: 0.7875 - val_loss: 1.0348 - val_accuracy: 0.6321\n",
      "Epoch 221/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.5076 - accuracy: 0.7823 - val_loss: 1.0519 - val_accuracy: 0.6305\n",
      "Epoch 222/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.5018 - accuracy: 0.7865 - val_loss: 1.1073 - val_accuracy: 0.6204\n",
      "Epoch 223/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.5007 - accuracy: 0.7874 - val_loss: 1.0751 - val_accuracy: 0.6244\n",
      "Epoch 224/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.4992 - accuracy: 0.7876 - val_loss: 1.0744 - val_accuracy: 0.6291\n",
      "Epoch 225/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.5003 - accuracy: 0.7870 - val_loss: 1.0619 - val_accuracy: 0.6286\n",
      "Epoch 226/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.4967 - accuracy: 0.7885 - val_loss: 1.0575 - val_accuracy: 0.6265\n",
      "Epoch 227/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.5024 - accuracy: 0.7871 - val_loss: 1.0255 - val_accuracy: 0.6382\n",
      "Epoch 228/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.4998 - accuracy: 0.7871 - val_loss: 1.0442 - val_accuracy: 0.6343\n",
      "Epoch 229/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.4966 - accuracy: 0.7884 - val_loss: 1.1098 - val_accuracy: 0.6122\n",
      "Epoch 230/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.4954 - accuracy: 0.7891 - val_loss: 1.0701 - val_accuracy: 0.6214\n",
      "Epoch 231/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.4920 - accuracy: 0.7911 - val_loss: 1.0590 - val_accuracy: 0.6289\n",
      "Epoch 232/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.4904 - accuracy: 0.7914 - val_loss: 1.0997 - val_accuracy: 0.6199\n",
      "Epoch 233/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.4931 - accuracy: 0.7896 - val_loss: 1.0909 - val_accuracy: 0.6217\n",
      "Epoch 234/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.4894 - accuracy: 0.7928 - val_loss: 1.0350 - val_accuracy: 0.6340\n",
      "Epoch 235/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.4939 - accuracy: 0.7902 - val_loss: 1.0374 - val_accuracy: 0.6320\n",
      "Epoch 236/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.4897 - accuracy: 0.7912 - val_loss: 1.0913 - val_accuracy: 0.6230\n",
      "Epoch 237/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.4913 - accuracy: 0.7917 - val_loss: 1.0826 - val_accuracy: 0.6178\n",
      "Epoch 238/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.4865 - accuracy: 0.7925 - val_loss: 1.0748 - val_accuracy: 0.6232\n",
      "Epoch 239/8000\n",
      "1463/1463 [==============================] - 15s 11ms/step - loss: 0.4856 - accuracy: 0.7937 - val_loss: 1.0332 - val_accuracy: 0.6327\n",
      "Epoch 240/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.4857 - accuracy: 0.7941 - val_loss: 1.0868 - val_accuracy: 0.6214\n",
      "Epoch 241/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.4867 - accuracy: 0.7934 - val_loss: 1.0675 - val_accuracy: 0.6250\n",
      "Epoch 242/8000\n",
      "1463/1463 [==============================] - 15s 11ms/step - loss: 0.4820 - accuracy: 0.7959 - val_loss: 1.0727 - val_accuracy: 0.6317\n",
      "Epoch 243/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.4821 - accuracy: 0.7959 - val_loss: 1.0406 - val_accuracy: 0.6347\n",
      "Epoch 244/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.4797 - accuracy: 0.7964 - val_loss: 1.0351 - val_accuracy: 0.6353\n",
      "Epoch 245/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.4844 - accuracy: 0.7936 - val_loss: 1.0493 - val_accuracy: 0.6310\n",
      "Epoch 246/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.4850 - accuracy: 0.7937 - val_loss: 1.0304 - val_accuracy: 0.6322\n",
      "Epoch 247/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.4764 - accuracy: 0.7981 - val_loss: 1.0325 - val_accuracy: 0.6384\n",
      "Epoch 248/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.4778 - accuracy: 0.7971 - val_loss: 1.0699 - val_accuracy: 0.6304\n",
      "Epoch 249/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.4756 - accuracy: 0.7987 - val_loss: 1.0765 - val_accuracy: 0.6222\n",
      "Epoch 250/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.4785 - accuracy: 0.7957 - val_loss: 1.0643 - val_accuracy: 0.6256\n",
      "Epoch 251/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.4920 - accuracy: 0.7922 - val_loss: 1.0300 - val_accuracy: 0.6397\n",
      "Epoch 252/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.4755 - accuracy: 0.7991 - val_loss: 1.0419 - val_accuracy: 0.6349\n",
      "Epoch 253/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.4783 - accuracy: 0.7968 - val_loss: 1.0415 - val_accuracy: 0.6292\n",
      "Epoch 254/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.4767 - accuracy: 0.7975 - val_loss: 1.0247 - val_accuracy: 0.6387\n",
      "Epoch 255/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.4741 - accuracy: 0.7989 - val_loss: 1.0732 - val_accuracy: 0.6304\n",
      "Epoch 256/8000\n",
      "1463/1463 [==============================] - 15s 11ms/step - loss: 0.4799 - accuracy: 0.7965 - val_loss: 1.1087 - val_accuracy: 0.6171\n",
      "Epoch 257/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.4749 - accuracy: 0.7980 - val_loss: 1.0482 - val_accuracy: 0.6352\n",
      "Epoch 258/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.4704 - accuracy: 0.8007 - val_loss: 1.0575 - val_accuracy: 0.6297\n",
      "Epoch 259/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.4704 - accuracy: 0.8014 - val_loss: 1.0396 - val_accuracy: 0.6350\n",
      "Epoch 260/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.4690 - accuracy: 0.8006 - val_loss: 1.0172 - val_accuracy: 0.6389\n",
      "Epoch 261/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.4712 - accuracy: 0.7991 - val_loss: 1.0413 - val_accuracy: 0.6413\n",
      "Epoch 262/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.4700 - accuracy: 0.8008 - val_loss: 1.0385 - val_accuracy: 0.6402\n",
      "Epoch 263/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.4729 - accuracy: 0.7991 - val_loss: 1.0763 - val_accuracy: 0.6196\n",
      "Epoch 264/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.4700 - accuracy: 0.8013 - val_loss: 1.0227 - val_accuracy: 0.6368\n",
      "Epoch 265/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.4804 - accuracy: 0.7979 - val_loss: 1.0316 - val_accuracy: 0.6327\n",
      "Epoch 266/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.4679 - accuracy: 0.8026 - val_loss: 1.1135 - val_accuracy: 0.6231\n",
      "Epoch 267/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.4734 - accuracy: 0.7991 - val_loss: 1.0074 - val_accuracy: 0.6427\n",
      "Epoch 268/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.4700 - accuracy: 0.8005 - val_loss: 1.0095 - val_accuracy: 0.6471\n",
      "Epoch 269/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.4651 - accuracy: 0.8020 - val_loss: 1.0512 - val_accuracy: 0.6383\n",
      "Epoch 270/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.4676 - accuracy: 0.8028 - val_loss: 1.0323 - val_accuracy: 0.6365\n",
      "Epoch 271/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.4670 - accuracy: 0.8028 - val_loss: 1.0722 - val_accuracy: 0.6395\n",
      "Epoch 272/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.4635 - accuracy: 0.8028 - val_loss: 1.0542 - val_accuracy: 0.6325\n",
      "Epoch 273/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.4642 - accuracy: 0.8026 - val_loss: 1.0321 - val_accuracy: 0.6409\n",
      "Epoch 274/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.4649 - accuracy: 0.8031 - val_loss: 1.0495 - val_accuracy: 0.6366\n",
      "Epoch 275/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.4695 - accuracy: 0.8029 - val_loss: 1.0844 - val_accuracy: 0.6335\n",
      "Epoch 276/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.4669 - accuracy: 0.8037 - val_loss: 1.0470 - val_accuracy: 0.6360\n",
      "Epoch 277/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.4663 - accuracy: 0.8008 - val_loss: 1.0108 - val_accuracy: 0.6436\n",
      "Epoch 278/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.4656 - accuracy: 0.8030 - val_loss: 1.0698 - val_accuracy: 0.6323\n",
      "Epoch 279/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.4606 - accuracy: 0.8044 - val_loss: 1.0498 - val_accuracy: 0.6359\n",
      "Epoch 280/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.4627 - accuracy: 0.8038 - val_loss: 1.0390 - val_accuracy: 0.6369\n",
      "Epoch 281/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.4564 - accuracy: 0.8063 - val_loss: 1.0637 - val_accuracy: 0.6276\n",
      "Epoch 282/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.4595 - accuracy: 0.8060 - val_loss: 1.0505 - val_accuracy: 0.6426\n",
      "Epoch 283/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.4549 - accuracy: 0.8072 - val_loss: 1.0320 - val_accuracy: 0.6395\n",
      "Epoch 284/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.4544 - accuracy: 0.8068 - val_loss: 1.0239 - val_accuracy: 0.6402\n",
      "Epoch 285/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.4598 - accuracy: 0.8068 - val_loss: 1.0107 - val_accuracy: 0.6463\n",
      "Epoch 286/8000\n",
      "1463/1463 [==============================] - 15s 11ms/step - loss: 0.4620 - accuracy: 0.8044 - val_loss: 1.0550 - val_accuracy: 0.6364\n",
      "Epoch 287/8000\n",
      "1463/1463 [==============================] - 15s 11ms/step - loss: 0.4549 - accuracy: 0.8076 - val_loss: 1.0481 - val_accuracy: 0.6380\n",
      "Epoch 288/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.4549 - accuracy: 0.8065 - val_loss: 1.0265 - val_accuracy: 0.6380\n",
      "Epoch 289/8000\n",
      "1463/1463 [==============================] - 15s 11ms/step - loss: 0.4549 - accuracy: 0.8065 - val_loss: 1.0700 - val_accuracy: 0.6394\n",
      "Epoch 290/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.4505 - accuracy: 0.8096 - val_loss: 1.0244 - val_accuracy: 0.6413\n",
      "Epoch 291/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.4527 - accuracy: 0.8083 - val_loss: 1.0450 - val_accuracy: 0.6388\n",
      "Epoch 292/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.4548 - accuracy: 0.8084 - val_loss: 0.9995 - val_accuracy: 0.6458\n",
      "Epoch 293/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.4552 - accuracy: 0.8070 - val_loss: 1.0547 - val_accuracy: 0.6321\n",
      "Epoch 294/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.4517 - accuracy: 0.8095 - val_loss: 1.0465 - val_accuracy: 0.6312\n",
      "Epoch 295/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.4515 - accuracy: 0.8090 - val_loss: 1.0332 - val_accuracy: 0.6407\n",
      "Epoch 296/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.4454 - accuracy: 0.8119 - val_loss: 1.0219 - val_accuracy: 0.6443\n",
      "Epoch 297/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.4434 - accuracy: 0.8123 - val_loss: 1.0722 - val_accuracy: 0.6323\n",
      "Epoch 298/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.4516 - accuracy: 0.8094 - val_loss: 1.0249 - val_accuracy: 0.6397\n",
      "Epoch 299/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.4398 - accuracy: 0.8135 - val_loss: 1.0324 - val_accuracy: 0.6433\n",
      "Epoch 300/8000\n",
      "1458/1463 [============================>.] - ETA: 0s - loss: 0.4465 - accuracy: 0.8112\n",
      "Epoch 300: saving model to ./training_ckpt_20240109205949_v8_240109_d10000_n4096_b64_e8000_c100_Adamax\\cp-000000300.ckpt\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.4464 - accuracy: 0.8112 - val_loss: 1.0117 - val_accuracy: 0.6510\n",
      "Epoch 301/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.4438 - accuracy: 0.8126 - val_loss: 1.0365 - val_accuracy: 0.6415\n",
      "Epoch 302/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.4415 - accuracy: 0.8137 - val_loss: 1.0483 - val_accuracy: 0.6364\n",
      "Epoch 303/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.4406 - accuracy: 0.8154 - val_loss: 1.0119 - val_accuracy: 0.6485\n",
      "Epoch 304/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.4449 - accuracy: 0.8115 - val_loss: 1.0466 - val_accuracy: 0.6388\n",
      "Epoch 305/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.4483 - accuracy: 0.8103 - val_loss: 1.0224 - val_accuracy: 0.6452\n",
      "Epoch 306/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.4441 - accuracy: 0.8119 - val_loss: 1.0496 - val_accuracy: 0.6307\n",
      "Epoch 307/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.4422 - accuracy: 0.8134 - val_loss: 0.9802 - val_accuracy: 0.6510\n",
      "Epoch 308/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.4354 - accuracy: 0.8160 - val_loss: 1.0047 - val_accuracy: 0.6489\n",
      "Epoch 309/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.4430 - accuracy: 0.8130 - val_loss: 1.0178 - val_accuracy: 0.6467\n",
      "Epoch 310/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.4431 - accuracy: 0.8132 - val_loss: 1.0058 - val_accuracy: 0.6493\n",
      "Epoch 311/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.4342 - accuracy: 0.8164 - val_loss: 1.0394 - val_accuracy: 0.6391\n",
      "Epoch 312/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.4408 - accuracy: 0.8145 - val_loss: 1.0082 - val_accuracy: 0.6467\n",
      "Epoch 313/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.4341 - accuracy: 0.8183 - val_loss: 1.0608 - val_accuracy: 0.6411\n",
      "Epoch 314/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.4387 - accuracy: 0.8136 - val_loss: 1.0107 - val_accuracy: 0.6505\n",
      "Epoch 315/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.4335 - accuracy: 0.8168 - val_loss: 1.0410 - val_accuracy: 0.6342\n",
      "Epoch 316/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.4346 - accuracy: 0.8151 - val_loss: 1.0344 - val_accuracy: 0.6407\n",
      "Epoch 317/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.4332 - accuracy: 0.8171 - val_loss: 1.0579 - val_accuracy: 0.6364\n",
      "Epoch 318/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.4386 - accuracy: 0.8151 - val_loss: 1.0439 - val_accuracy: 0.6413\n",
      "Epoch 319/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.4290 - accuracy: 0.8204 - val_loss: 1.0351 - val_accuracy: 0.6413\n",
      "Epoch 320/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.4481 - accuracy: 0.8125 - val_loss: 1.0038 - val_accuracy: 0.6513\n",
      "Epoch 321/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.4448 - accuracy: 0.8129 - val_loss: 1.0266 - val_accuracy: 0.6471\n",
      "Epoch 322/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.4316 - accuracy: 0.8171 - val_loss: 1.0560 - val_accuracy: 0.6407\n",
      "Epoch 323/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.4351 - accuracy: 0.8158 - val_loss: 1.0139 - val_accuracy: 0.6415\n",
      "Epoch 324/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.4429 - accuracy: 0.8128 - val_loss: 1.0286 - val_accuracy: 0.6475\n",
      "Epoch 325/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.4380 - accuracy: 0.8168 - val_loss: 1.0283 - val_accuracy: 0.6440\n",
      "Epoch 326/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.4396 - accuracy: 0.8137 - val_loss: 1.0351 - val_accuracy: 0.6450\n",
      "Epoch 327/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.4413 - accuracy: 0.8138 - val_loss: 1.0461 - val_accuracy: 0.6356\n",
      "Epoch 328/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.4355 - accuracy: 0.8166 - val_loss: 0.9958 - val_accuracy: 0.6559\n",
      "Epoch 329/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.4373 - accuracy: 0.8156 - val_loss: 1.0057 - val_accuracy: 0.6507\n",
      "Epoch 330/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.4384 - accuracy: 0.8161 - val_loss: 0.9989 - val_accuracy: 0.6489\n",
      "Epoch 331/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.4292 - accuracy: 0.8184 - val_loss: 1.0251 - val_accuracy: 0.6438\n",
      "Epoch 332/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.4334 - accuracy: 0.8157 - val_loss: 1.0088 - val_accuracy: 0.6520\n",
      "Epoch 333/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.4320 - accuracy: 0.8181 - val_loss: 0.9985 - val_accuracy: 0.6514\n",
      "Epoch 334/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.4282 - accuracy: 0.8208 - val_loss: 1.0066 - val_accuracy: 0.6469\n",
      "Epoch 335/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.4327 - accuracy: 0.8179 - val_loss: 1.0001 - val_accuracy: 0.6528\n",
      "Epoch 336/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.4314 - accuracy: 0.8189 - val_loss: 1.0054 - val_accuracy: 0.6482\n",
      "Epoch 337/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.4239 - accuracy: 0.8206 - val_loss: 1.0205 - val_accuracy: 0.6526\n",
      "Epoch 338/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.4304 - accuracy: 0.8168 - val_loss: 1.0422 - val_accuracy: 0.6367\n",
      "Epoch 339/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.4268 - accuracy: 0.8202 - val_loss: 1.0143 - val_accuracy: 0.6478\n",
      "Epoch 340/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.4235 - accuracy: 0.8215 - val_loss: 0.9869 - val_accuracy: 0.6569\n",
      "Epoch 341/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.4293 - accuracy: 0.8202 - val_loss: 1.0086 - val_accuracy: 0.6463\n",
      "Epoch 342/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.4296 - accuracy: 0.8188 - val_loss: 1.0264 - val_accuracy: 0.6442\n",
      "Epoch 343/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.4240 - accuracy: 0.8222 - val_loss: 1.0374 - val_accuracy: 0.6461\n",
      "Epoch 344/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.4271 - accuracy: 0.8193 - val_loss: 0.9919 - val_accuracy: 0.6491\n",
      "Epoch 345/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.4290 - accuracy: 0.8198 - val_loss: 0.9920 - val_accuracy: 0.6568\n",
      "Epoch 346/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.4269 - accuracy: 0.8221 - val_loss: 0.9946 - val_accuracy: 0.6524\n",
      "Epoch 347/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.4304 - accuracy: 0.8178 - val_loss: 1.0172 - val_accuracy: 0.6469\n",
      "Epoch 348/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.4336 - accuracy: 0.8155 - val_loss: 1.0137 - val_accuracy: 0.6413\n",
      "Epoch 349/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.4311 - accuracy: 0.8162 - val_loss: 1.0007 - val_accuracy: 0.6585\n",
      "Epoch 350/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.4353 - accuracy: 0.8174 - val_loss: 1.0356 - val_accuracy: 0.6478\n",
      "Epoch 351/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.4286 - accuracy: 0.8181 - val_loss: 1.0943 - val_accuracy: 0.6394\n",
      "Epoch 352/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.4278 - accuracy: 0.8204 - val_loss: 0.9880 - val_accuracy: 0.6578\n",
      "Epoch 353/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.4299 - accuracy: 0.8176 - val_loss: 1.0726 - val_accuracy: 0.6278\n",
      "Epoch 354/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.4265 - accuracy: 0.8206 - val_loss: 0.9849 - val_accuracy: 0.6604\n",
      "Epoch 355/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.4302 - accuracy: 0.8179 - val_loss: 1.0236 - val_accuracy: 0.6450\n",
      "Epoch 356/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.4271 - accuracy: 0.8197 - val_loss: 1.0184 - val_accuracy: 0.6474\n",
      "Epoch 357/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.4209 - accuracy: 0.8230 - val_loss: 0.9783 - val_accuracy: 0.6617\n",
      "Epoch 358/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.4270 - accuracy: 0.8202 - val_loss: 0.9934 - val_accuracy: 0.6539\n",
      "Epoch 359/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.4253 - accuracy: 0.8217 - val_loss: 1.0203 - val_accuracy: 0.6498\n",
      "Epoch 360/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.4202 - accuracy: 0.8222 - val_loss: 1.0030 - val_accuracy: 0.6561\n",
      "Epoch 361/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.4150 - accuracy: 0.8257 - val_loss: 0.9879 - val_accuracy: 0.6538\n",
      "Epoch 362/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.4124 - accuracy: 0.8271 - val_loss: 0.9850 - val_accuracy: 0.6548\n",
      "Epoch 363/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.4153 - accuracy: 0.8263 - val_loss: 0.9699 - val_accuracy: 0.6625\n",
      "Epoch 364/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.4127 - accuracy: 0.8253 - val_loss: 0.9912 - val_accuracy: 0.6552\n",
      "Epoch 365/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.4153 - accuracy: 0.8247 - val_loss: 1.1144 - val_accuracy: 0.6361\n",
      "Epoch 366/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.4140 - accuracy: 0.8276 - val_loss: 1.0106 - val_accuracy: 0.6504\n",
      "Epoch 367/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.4120 - accuracy: 0.8259 - val_loss: 0.9892 - val_accuracy: 0.6593\n",
      "Epoch 368/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.4122 - accuracy: 0.8269 - val_loss: 0.9791 - val_accuracy: 0.6603\n",
      "Epoch 369/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.4112 - accuracy: 0.8274 - val_loss: 0.9787 - val_accuracy: 0.6599\n",
      "Epoch 370/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.4123 - accuracy: 0.8271 - val_loss: 1.0002 - val_accuracy: 0.6574\n",
      "Epoch 371/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.4102 - accuracy: 0.8273 - val_loss: 0.9859 - val_accuracy: 0.6612\n",
      "Epoch 372/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.4080 - accuracy: 0.8288 - val_loss: 0.9958 - val_accuracy: 0.6592\n",
      "Epoch 373/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.4118 - accuracy: 0.8260 - val_loss: 1.0371 - val_accuracy: 0.6521\n",
      "Epoch 374/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.4246 - accuracy: 0.8233 - val_loss: 0.9791 - val_accuracy: 0.6659\n",
      "Epoch 375/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.4187 - accuracy: 0.8274 - val_loss: 1.0054 - val_accuracy: 0.6568\n",
      "Epoch 376/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.4131 - accuracy: 0.8278 - val_loss: 1.0206 - val_accuracy: 0.6578\n",
      "Epoch 377/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.4088 - accuracy: 0.8291 - val_loss: 1.0062 - val_accuracy: 0.6527\n",
      "Epoch 378/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.4069 - accuracy: 0.8300 - val_loss: 0.9679 - val_accuracy: 0.6706\n",
      "Epoch 379/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.4080 - accuracy: 0.8308 - val_loss: 1.0602 - val_accuracy: 0.6414\n",
      "Epoch 380/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.4006 - accuracy: 0.8325 - val_loss: 0.9639 - val_accuracy: 0.6644\n",
      "Epoch 381/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.4072 - accuracy: 0.8300 - val_loss: 1.0595 - val_accuracy: 0.6546\n",
      "Epoch 382/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.4096 - accuracy: 0.8303 - val_loss: 0.9486 - val_accuracy: 0.6714\n",
      "Epoch 383/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.4025 - accuracy: 0.8335 - val_loss: 0.9693 - val_accuracy: 0.6702\n",
      "Epoch 384/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.4016 - accuracy: 0.8329 - val_loss: 0.9894 - val_accuracy: 0.6649\n",
      "Epoch 385/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.4047 - accuracy: 0.8323 - val_loss: 0.9685 - val_accuracy: 0.6649\n",
      "Epoch 386/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3984 - accuracy: 0.8331 - val_loss: 0.9485 - val_accuracy: 0.6658\n",
      "Epoch 387/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.4030 - accuracy: 0.8313 - val_loss: 1.0115 - val_accuracy: 0.6616\n",
      "Epoch 388/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.4041 - accuracy: 0.8309 - val_loss: 1.0067 - val_accuracy: 0.6604\n",
      "Epoch 389/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.4041 - accuracy: 0.8333 - val_loss: 0.9736 - val_accuracy: 0.6662\n",
      "Epoch 390/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3948 - accuracy: 0.8349 - val_loss: 0.9715 - val_accuracy: 0.6639\n",
      "Epoch 391/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3996 - accuracy: 0.8324 - val_loss: 0.9955 - val_accuracy: 0.6593\n",
      "Epoch 392/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3980 - accuracy: 0.8342 - val_loss: 1.0171 - val_accuracy: 0.6647\n",
      "Epoch 393/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3973 - accuracy: 0.8345 - val_loss: 0.9642 - val_accuracy: 0.6691\n",
      "Epoch 394/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3941 - accuracy: 0.8358 - val_loss: 1.0324 - val_accuracy: 0.6520\n",
      "Epoch 395/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3975 - accuracy: 0.8360 - val_loss: 0.9533 - val_accuracy: 0.6737\n",
      "Epoch 396/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3942 - accuracy: 0.8356 - val_loss: 0.9460 - val_accuracy: 0.6726\n",
      "Epoch 397/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3940 - accuracy: 0.8369 - val_loss: 0.9675 - val_accuracy: 0.6656\n",
      "Epoch 398/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3941 - accuracy: 0.8363 - val_loss: 0.9607 - val_accuracy: 0.6672\n",
      "Epoch 399/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3901 - accuracy: 0.8378 - val_loss: 0.9348 - val_accuracy: 0.6747\n",
      "Epoch 400/8000\n",
      "1459/1463 [============================>.] - ETA: 0s - loss: 0.3928 - accuracy: 0.8372\n",
      "Epoch 400: saving model to ./training_ckpt_20240109205949_v8_240109_d10000_n4096_b64_e8000_c100_Adamax\\cp-000000400.ckpt\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3928 - accuracy: 0.8372 - val_loss: 0.9982 - val_accuracy: 0.6634\n",
      "Epoch 401/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3931 - accuracy: 0.8363 - val_loss: 1.0278 - val_accuracy: 0.6518\n",
      "Epoch 402/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3896 - accuracy: 0.8382 - val_loss: 0.9878 - val_accuracy: 0.6642\n",
      "Epoch 403/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3895 - accuracy: 0.8380 - val_loss: 0.9703 - val_accuracy: 0.6687\n",
      "Epoch 404/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3936 - accuracy: 0.8367 - val_loss: 0.9367 - val_accuracy: 0.6775\n",
      "Epoch 405/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.3899 - accuracy: 0.8383 - val_loss: 0.9941 - val_accuracy: 0.6638\n",
      "Epoch 406/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3930 - accuracy: 0.8369 - val_loss: 0.9793 - val_accuracy: 0.6615\n",
      "Epoch 407/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3870 - accuracy: 0.8394 - val_loss: 0.9512 - val_accuracy: 0.6752\n",
      "Epoch 408/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3928 - accuracy: 0.8381 - val_loss: 0.9878 - val_accuracy: 0.6710\n",
      "Epoch 409/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3900 - accuracy: 0.8388 - val_loss: 0.9807 - val_accuracy: 0.6687\n",
      "Epoch 410/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3839 - accuracy: 0.8416 - val_loss: 0.9743 - val_accuracy: 0.6700\n",
      "Epoch 411/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3872 - accuracy: 0.8395 - val_loss: 0.9561 - val_accuracy: 0.6746\n",
      "Epoch 412/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3904 - accuracy: 0.8379 - val_loss: 0.9388 - val_accuracy: 0.6732\n",
      "Epoch 413/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3885 - accuracy: 0.8381 - val_loss: 1.0096 - val_accuracy: 0.6690\n",
      "Epoch 414/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3889 - accuracy: 0.8390 - val_loss: 0.9493 - val_accuracy: 0.6762\n",
      "Epoch 415/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3902 - accuracy: 0.8388 - val_loss: 0.9489 - val_accuracy: 0.6752\n",
      "Epoch 416/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3852 - accuracy: 0.8413 - val_loss: 0.9989 - val_accuracy: 0.6660\n",
      "Epoch 417/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3826 - accuracy: 0.8416 - val_loss: 0.9563 - val_accuracy: 0.6777\n",
      "Epoch 418/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3846 - accuracy: 0.8411 - val_loss: 0.9691 - val_accuracy: 0.6660\n",
      "Epoch 419/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3862 - accuracy: 0.8393 - val_loss: 0.9329 - val_accuracy: 0.6758\n",
      "Epoch 420/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3831 - accuracy: 0.8406 - val_loss: 0.9184 - val_accuracy: 0.6789\n",
      "Epoch 421/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3849 - accuracy: 0.8404 - val_loss: 0.9403 - val_accuracy: 0.6789\n",
      "Epoch 422/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3822 - accuracy: 0.8427 - val_loss: 0.9622 - val_accuracy: 0.6714\n",
      "Epoch 423/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3832 - accuracy: 0.8420 - val_loss: 1.0282 - val_accuracy: 0.6620\n",
      "Epoch 424/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3800 - accuracy: 0.8421 - val_loss: 0.9596 - val_accuracy: 0.6710\n",
      "Epoch 425/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3797 - accuracy: 0.8423 - val_loss: 0.9826 - val_accuracy: 0.6696\n",
      "Epoch 426/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3750 - accuracy: 0.8446 - val_loss: 0.9778 - val_accuracy: 0.6654\n",
      "Epoch 427/8000\n",
      "1463/1463 [==============================] - 15s 11ms/step - loss: 0.3784 - accuracy: 0.8445 - val_loss: 0.9635 - val_accuracy: 0.6751\n",
      "Epoch 428/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3816 - accuracy: 0.8426 - val_loss: 0.9359 - val_accuracy: 0.6813\n",
      "Epoch 429/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3750 - accuracy: 0.8451 - val_loss: 0.9572 - val_accuracy: 0.6787\n",
      "Epoch 430/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3791 - accuracy: 0.8425 - val_loss: 0.9573 - val_accuracy: 0.6700\n",
      "Epoch 431/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3699 - accuracy: 0.8464 - val_loss: 0.9919 - val_accuracy: 0.6627\n",
      "Epoch 432/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3777 - accuracy: 0.8427 - val_loss: 1.0777 - val_accuracy: 0.6683\n",
      "Epoch 433/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3771 - accuracy: 0.8436 - val_loss: 0.9384 - val_accuracy: 0.6781\n",
      "Epoch 434/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3741 - accuracy: 0.8452 - val_loss: 0.9696 - val_accuracy: 0.6737\n",
      "Epoch 435/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3776 - accuracy: 0.8439 - val_loss: 0.9678 - val_accuracy: 0.6733\n",
      "Epoch 436/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3762 - accuracy: 0.8454 - val_loss: 0.9737 - val_accuracy: 0.6726\n",
      "Epoch 437/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3705 - accuracy: 0.8470 - val_loss: 0.9802 - val_accuracy: 0.6692\n",
      "Epoch 438/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3744 - accuracy: 0.8455 - val_loss: 0.9635 - val_accuracy: 0.6710\n",
      "Epoch 439/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3687 - accuracy: 0.8481 - val_loss: 0.9245 - val_accuracy: 0.6758\n",
      "Epoch 440/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3704 - accuracy: 0.8479 - val_loss: 0.9697 - val_accuracy: 0.6716\n",
      "Epoch 441/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3771 - accuracy: 0.8455 - val_loss: 1.0833 - val_accuracy: 0.6469\n",
      "Epoch 442/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3790 - accuracy: 0.8441 - val_loss: 0.9558 - val_accuracy: 0.6705\n",
      "Epoch 443/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3742 - accuracy: 0.8446 - val_loss: 1.0670 - val_accuracy: 0.6757\n",
      "Epoch 444/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3703 - accuracy: 0.8471 - val_loss: 0.9613 - val_accuracy: 0.6738\n",
      "Epoch 445/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3751 - accuracy: 0.8453 - val_loss: 0.9775 - val_accuracy: 0.6650\n",
      "Epoch 446/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3644 - accuracy: 0.8506 - val_loss: 0.9524 - val_accuracy: 0.6787\n",
      "Epoch 447/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3693 - accuracy: 0.8476 - val_loss: 0.9577 - val_accuracy: 0.6789\n",
      "Epoch 448/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3714 - accuracy: 0.8485 - val_loss: 0.9419 - val_accuracy: 0.6787\n",
      "Epoch 449/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3711 - accuracy: 0.8471 - val_loss: 0.9644 - val_accuracy: 0.6724\n",
      "Epoch 450/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3709 - accuracy: 0.8473 - val_loss: 0.9793 - val_accuracy: 0.6699\n",
      "Epoch 451/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3669 - accuracy: 0.8472 - val_loss: 0.9709 - val_accuracy: 0.6687\n",
      "Epoch 452/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3674 - accuracy: 0.8485 - val_loss: 0.9779 - val_accuracy: 0.6705\n",
      "Epoch 453/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3763 - accuracy: 0.8434 - val_loss: 0.9384 - val_accuracy: 0.6779\n",
      "Epoch 454/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3645 - accuracy: 0.8490 - val_loss: 0.9805 - val_accuracy: 0.6737\n",
      "Epoch 455/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3616 - accuracy: 0.8505 - val_loss: 0.9507 - val_accuracy: 0.6852\n",
      "Epoch 456/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3641 - accuracy: 0.8492 - val_loss: 0.9921 - val_accuracy: 0.6670\n",
      "Epoch 457/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3656 - accuracy: 0.8490 - val_loss: 0.9300 - val_accuracy: 0.6847\n",
      "Epoch 458/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3655 - accuracy: 0.8484 - val_loss: 0.9483 - val_accuracy: 0.6781\n",
      "Epoch 459/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3637 - accuracy: 0.8493 - val_loss: 0.9636 - val_accuracy: 0.6848\n",
      "Epoch 460/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3627 - accuracy: 0.8505 - val_loss: 0.9847 - val_accuracy: 0.6747\n",
      "Epoch 461/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3625 - accuracy: 0.8509 - val_loss: 0.9635 - val_accuracy: 0.6804\n",
      "Epoch 462/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3610 - accuracy: 0.8505 - val_loss: 0.9315 - val_accuracy: 0.6818\n",
      "Epoch 463/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3685 - accuracy: 0.8483 - val_loss: 0.9551 - val_accuracy: 0.6751\n",
      "Epoch 464/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3660 - accuracy: 0.8489 - val_loss: 0.9113 - val_accuracy: 0.6859\n",
      "Epoch 465/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3637 - accuracy: 0.8500 - val_loss: 0.9212 - val_accuracy: 0.6874\n",
      "Epoch 466/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3634 - accuracy: 0.8503 - val_loss: 0.9643 - val_accuracy: 0.6780\n",
      "Epoch 467/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3627 - accuracy: 0.8505 - val_loss: 0.9269 - val_accuracy: 0.6856\n",
      "Epoch 468/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3585 - accuracy: 0.8521 - val_loss: 0.9445 - val_accuracy: 0.6814\n",
      "Epoch 469/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3614 - accuracy: 0.8505 - val_loss: 0.9798 - val_accuracy: 0.6723\n",
      "Epoch 470/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3651 - accuracy: 0.8493 - val_loss: 0.9729 - val_accuracy: 0.6767\n",
      "Epoch 471/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3563 - accuracy: 0.8517 - val_loss: 0.9901 - val_accuracy: 0.6669\n",
      "Epoch 472/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3665 - accuracy: 0.8496 - val_loss: 1.0058 - val_accuracy: 0.6659\n",
      "Epoch 473/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3597 - accuracy: 0.8500 - val_loss: 0.9290 - val_accuracy: 0.6840\n",
      "Epoch 474/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3592 - accuracy: 0.8521 - val_loss: 0.9585 - val_accuracy: 0.6786\n",
      "Epoch 475/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3528 - accuracy: 0.8542 - val_loss: 0.9417 - val_accuracy: 0.6854\n",
      "Epoch 476/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3624 - accuracy: 0.8512 - val_loss: 0.9200 - val_accuracy: 0.6887\n",
      "Epoch 477/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3633 - accuracy: 0.8514 - val_loss: 0.9798 - val_accuracy: 0.6750\n",
      "Epoch 478/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3588 - accuracy: 0.8517 - val_loss: 0.9469 - val_accuracy: 0.6865\n",
      "Epoch 479/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3580 - accuracy: 0.8525 - val_loss: 0.9275 - val_accuracy: 0.6769\n",
      "Epoch 480/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.3533 - accuracy: 0.8545 - val_loss: 0.9775 - val_accuracy: 0.6788\n",
      "Epoch 481/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3603 - accuracy: 0.8510 - val_loss: 0.9400 - val_accuracy: 0.6812\n",
      "Epoch 482/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3552 - accuracy: 0.8526 - val_loss: 0.9577 - val_accuracy: 0.6826\n",
      "Epoch 483/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3576 - accuracy: 0.8522 - val_loss: 0.9397 - val_accuracy: 0.6827\n",
      "Epoch 484/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3520 - accuracy: 0.8545 - val_loss: 0.9600 - val_accuracy: 0.6801\n",
      "Epoch 485/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3541 - accuracy: 0.8542 - val_loss: 0.9359 - val_accuracy: 0.6886\n",
      "Epoch 486/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3536 - accuracy: 0.8538 - val_loss: 0.9966 - val_accuracy: 0.6665\n",
      "Epoch 487/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3577 - accuracy: 0.8529 - val_loss: 0.9901 - val_accuracy: 0.6725\n",
      "Epoch 488/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3579 - accuracy: 0.8539 - val_loss: 0.9512 - val_accuracy: 0.6791\n",
      "Epoch 489/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3509 - accuracy: 0.8540 - val_loss: 1.0468 - val_accuracy: 0.6798\n",
      "Epoch 490/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3499 - accuracy: 0.8561 - val_loss: 0.9465 - val_accuracy: 0.6867\n",
      "Epoch 491/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3576 - accuracy: 0.8534 - val_loss: 0.9280 - val_accuracy: 0.6860\n",
      "Epoch 492/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3504 - accuracy: 0.8551 - val_loss: 0.9565 - val_accuracy: 0.6856\n",
      "Epoch 493/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3477 - accuracy: 0.8573 - val_loss: 0.9821 - val_accuracy: 0.6812\n",
      "Epoch 494/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3678 - accuracy: 0.8484 - val_loss: 0.9563 - val_accuracy: 0.6802\n",
      "Epoch 495/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3585 - accuracy: 0.8519 - val_loss: 1.0968 - val_accuracy: 0.6542\n",
      "Epoch 496/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3607 - accuracy: 0.8520 - val_loss: 0.9908 - val_accuracy: 0.6712\n",
      "Epoch 497/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3533 - accuracy: 0.8530 - val_loss: 0.9358 - val_accuracy: 0.6893\n",
      "Epoch 498/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3531 - accuracy: 0.8539 - val_loss: 0.9581 - val_accuracy: 0.6770\n",
      "Epoch 499/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3581 - accuracy: 0.8521 - val_loss: 0.9505 - val_accuracy: 0.6804\n",
      "Epoch 500/8000\n",
      "1463/1463 [==============================] - ETA: 0s - loss: 0.3579 - accuracy: 0.8525\n",
      "Epoch 500: saving model to ./training_ckpt_20240109205949_v8_240109_d10000_n4096_b64_e8000_c100_Adamax\\cp-000000500.ckpt\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3579 - accuracy: 0.8525 - val_loss: 0.9910 - val_accuracy: 0.6771\n",
      "Epoch 501/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3512 - accuracy: 0.8553 - val_loss: 0.9724 - val_accuracy: 0.6778\n",
      "Epoch 502/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.3536 - accuracy: 0.8539 - val_loss: 0.9823 - val_accuracy: 0.6787\n",
      "Epoch 503/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3602 - accuracy: 0.8517 - val_loss: 0.9263 - val_accuracy: 0.6895\n",
      "Epoch 504/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3508 - accuracy: 0.8550 - val_loss: 0.9944 - val_accuracy: 0.6787\n",
      "Epoch 505/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3525 - accuracy: 0.8539 - val_loss: 0.9387 - val_accuracy: 0.6918\n",
      "Epoch 506/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.3474 - accuracy: 0.8562 - val_loss: 0.9363 - val_accuracy: 0.6872\n",
      "Epoch 507/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3567 - accuracy: 0.8529 - val_loss: 0.9967 - val_accuracy: 0.6772\n",
      "Epoch 508/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3549 - accuracy: 0.8522 - val_loss: 0.9733 - val_accuracy: 0.6809\n",
      "Epoch 509/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3516 - accuracy: 0.8546 - val_loss: 0.9853 - val_accuracy: 0.6783\n",
      "Epoch 510/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3526 - accuracy: 0.8538 - val_loss: 0.9357 - val_accuracy: 0.6869\n",
      "Epoch 511/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3473 - accuracy: 0.8563 - val_loss: 0.9290 - val_accuracy: 0.6833\n",
      "Epoch 512/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3476 - accuracy: 0.8566 - val_loss: 0.9872 - val_accuracy: 0.6762\n",
      "Epoch 513/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3513 - accuracy: 0.8550 - val_loss: 1.0241 - val_accuracy: 0.6669\n",
      "Epoch 514/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3475 - accuracy: 0.8567 - val_loss: 0.9493 - val_accuracy: 0.6828\n",
      "Epoch 515/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3493 - accuracy: 0.8549 - val_loss: 0.9837 - val_accuracy: 0.6756\n",
      "Epoch 516/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3470 - accuracy: 0.8563 - val_loss: 0.9480 - val_accuracy: 0.6826\n",
      "Epoch 517/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3497 - accuracy: 0.8553 - val_loss: 0.9361 - val_accuracy: 0.6870\n",
      "Epoch 518/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3456 - accuracy: 0.8578 - val_loss: 1.0208 - val_accuracy: 0.6729\n",
      "Epoch 519/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3530 - accuracy: 0.8541 - val_loss: 1.0447 - val_accuracy: 0.6674\n",
      "Epoch 520/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3501 - accuracy: 0.8566 - val_loss: 0.9218 - val_accuracy: 0.6911\n",
      "Epoch 521/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3437 - accuracy: 0.8580 - val_loss: 1.0331 - val_accuracy: 0.6663\n",
      "Epoch 522/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3521 - accuracy: 0.8549 - val_loss: 0.9303 - val_accuracy: 0.6883\n",
      "Epoch 523/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3511 - accuracy: 0.8547 - val_loss: 0.9532 - val_accuracy: 0.6822\n",
      "Epoch 524/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3482 - accuracy: 0.8559 - val_loss: 0.9607 - val_accuracy: 0.6816\n",
      "Epoch 525/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3476 - accuracy: 0.8565 - val_loss: 0.9298 - val_accuracy: 0.6932\n",
      "Epoch 526/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3486 - accuracy: 0.8562 - val_loss: 0.9385 - val_accuracy: 0.6901\n",
      "Epoch 527/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3389 - accuracy: 0.8594 - val_loss: 0.9670 - val_accuracy: 0.6840\n",
      "Epoch 528/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3404 - accuracy: 0.8596 - val_loss: 0.9639 - val_accuracy: 0.6775\n",
      "Epoch 529/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3402 - accuracy: 0.8599 - val_loss: 0.9136 - val_accuracy: 0.6935\n",
      "Epoch 530/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3409 - accuracy: 0.8594 - val_loss: 0.9639 - val_accuracy: 0.6867\n",
      "Epoch 531/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3423 - accuracy: 0.8579 - val_loss: 0.9446 - val_accuracy: 0.6837\n",
      "Epoch 532/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3495 - accuracy: 0.8566 - val_loss: 0.9790 - val_accuracy: 0.6777\n",
      "Epoch 533/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3436 - accuracy: 0.8588 - val_loss: 0.9654 - val_accuracy: 0.6845\n",
      "Epoch 534/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3394 - accuracy: 0.8601 - val_loss: 0.9543 - val_accuracy: 0.6883\n",
      "Epoch 535/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3409 - accuracy: 0.8598 - val_loss: 0.9490 - val_accuracy: 0.6862\n",
      "Epoch 536/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3405 - accuracy: 0.8589 - val_loss: 0.9582 - val_accuracy: 0.6875\n",
      "Epoch 537/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3397 - accuracy: 0.8607 - val_loss: 0.9600 - val_accuracy: 0.6849\n",
      "Epoch 538/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3423 - accuracy: 0.8579 - val_loss: 0.9689 - val_accuracy: 0.6769\n",
      "Epoch 539/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3397 - accuracy: 0.8601 - val_loss: 0.9623 - val_accuracy: 0.6920\n",
      "Epoch 540/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3407 - accuracy: 0.8605 - val_loss: 0.9813 - val_accuracy: 0.6795\n",
      "Epoch 541/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3416 - accuracy: 0.8599 - val_loss: 0.9148 - val_accuracy: 0.6956\n",
      "Epoch 542/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3444 - accuracy: 0.8592 - val_loss: 0.9920 - val_accuracy: 0.6822\n",
      "Epoch 543/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3365 - accuracy: 0.8614 - val_loss: 1.0096 - val_accuracy: 0.6793\n",
      "Epoch 544/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3436 - accuracy: 0.8568 - val_loss: 0.9388 - val_accuracy: 0.6904\n",
      "Epoch 545/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3320 - accuracy: 0.8644 - val_loss: 0.9306 - val_accuracy: 0.6910\n",
      "Epoch 546/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3380 - accuracy: 0.8602 - val_loss: 0.9651 - val_accuracy: 0.6841\n",
      "Epoch 547/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3348 - accuracy: 0.8620 - val_loss: 0.9841 - val_accuracy: 0.6823\n",
      "Epoch 548/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3357 - accuracy: 0.8612 - val_loss: 0.9879 - val_accuracy: 0.6738\n",
      "Epoch 549/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3375 - accuracy: 0.8617 - val_loss: 0.9818 - val_accuracy: 0.6791\n",
      "Epoch 550/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3333 - accuracy: 0.8626 - val_loss: 0.9459 - val_accuracy: 0.6911\n",
      "Epoch 551/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3367 - accuracy: 0.8607 - val_loss: 1.0239 - val_accuracy: 0.6701\n",
      "Epoch 552/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3338 - accuracy: 0.8618 - val_loss: 0.9398 - val_accuracy: 0.6845\n",
      "Epoch 553/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3381 - accuracy: 0.8607 - val_loss: 0.9309 - val_accuracy: 0.6848\n",
      "Epoch 554/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3346 - accuracy: 0.8622 - val_loss: 1.1131 - val_accuracy: 0.6520\n",
      "Epoch 555/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3354 - accuracy: 0.8613 - val_loss: 0.9621 - val_accuracy: 0.6900\n",
      "Epoch 556/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3340 - accuracy: 0.8625 - val_loss: 0.9242 - val_accuracy: 0.6911\n",
      "Epoch 557/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3365 - accuracy: 0.8613 - val_loss: 0.9367 - val_accuracy: 0.6925\n",
      "Epoch 558/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3342 - accuracy: 0.8621 - val_loss: 0.9400 - val_accuracy: 0.6900\n",
      "Epoch 559/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3348 - accuracy: 0.8622 - val_loss: 0.9548 - val_accuracy: 0.6851\n",
      "Epoch 560/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3303 - accuracy: 0.8637 - val_loss: 0.9547 - val_accuracy: 0.6884\n",
      "Epoch 561/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3335 - accuracy: 0.8626 - val_loss: 0.9391 - val_accuracy: 0.6853\n",
      "Epoch 562/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3310 - accuracy: 0.8626 - val_loss: 0.9795 - val_accuracy: 0.6868\n",
      "Epoch 563/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3307 - accuracy: 0.8637 - val_loss: 0.9258 - val_accuracy: 0.6913\n",
      "Epoch 564/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3250 - accuracy: 0.8663 - val_loss: 0.9305 - val_accuracy: 0.6924\n",
      "Epoch 565/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3305 - accuracy: 0.8635 - val_loss: 0.9874 - val_accuracy: 0.6800\n",
      "Epoch 566/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3273 - accuracy: 0.8652 - val_loss: 0.9523 - val_accuracy: 0.6905\n",
      "Epoch 567/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3304 - accuracy: 0.8640 - val_loss: 0.9380 - val_accuracy: 0.6928\n",
      "Epoch 568/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3312 - accuracy: 0.8649 - val_loss: 0.9470 - val_accuracy: 0.6920\n",
      "Epoch 569/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3240 - accuracy: 0.8662 - val_loss: 0.9361 - val_accuracy: 0.6917\n",
      "Epoch 570/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3284 - accuracy: 0.8642 - val_loss: 0.9316 - val_accuracy: 0.6947\n",
      "Epoch 571/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3335 - accuracy: 0.8633 - val_loss: 0.9206 - val_accuracy: 0.6952\n",
      "Epoch 572/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3278 - accuracy: 0.8643 - val_loss: 0.9650 - val_accuracy: 0.6869\n",
      "Epoch 573/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3259 - accuracy: 0.8649 - val_loss: 0.9973 - val_accuracy: 0.6785\n",
      "Epoch 574/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3313 - accuracy: 0.8640 - val_loss: 0.9778 - val_accuracy: 0.6925\n",
      "Epoch 575/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3287 - accuracy: 0.8650 - val_loss: 1.0742 - val_accuracy: 0.6636\n",
      "Epoch 576/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3317 - accuracy: 0.8635 - val_loss: 0.9875 - val_accuracy: 0.6785\n",
      "Epoch 577/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3332 - accuracy: 0.8638 - val_loss: 0.9954 - val_accuracy: 0.6835\n",
      "Epoch 578/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3315 - accuracy: 0.8633 - val_loss: 0.9785 - val_accuracy: 0.6861\n",
      "Epoch 579/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3288 - accuracy: 0.8644 - val_loss: 0.9747 - val_accuracy: 0.6874\n",
      "Epoch 580/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3277 - accuracy: 0.8656 - val_loss: 0.9596 - val_accuracy: 0.6878\n",
      "Epoch 581/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3289 - accuracy: 0.8654 - val_loss: 1.0052 - val_accuracy: 0.6729\n",
      "Epoch 582/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3285 - accuracy: 0.8653 - val_loss: 0.9596 - val_accuracy: 0.6822\n",
      "Epoch 583/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3247 - accuracy: 0.8670 - val_loss: 1.0201 - val_accuracy: 0.6811\n",
      "Epoch 584/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3297 - accuracy: 0.8653 - val_loss: 0.9890 - val_accuracy: 0.6784\n",
      "Epoch 585/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3251 - accuracy: 0.8660 - val_loss: 1.0134 - val_accuracy: 0.6727\n",
      "Epoch 586/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3414 - accuracy: 0.8611 - val_loss: 0.9442 - val_accuracy: 0.6938\n",
      "Epoch 587/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3321 - accuracy: 0.8626 - val_loss: 0.9579 - val_accuracy: 0.6844\n",
      "Epoch 588/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3386 - accuracy: 0.8596 - val_loss: 0.9353 - val_accuracy: 0.6962\n",
      "Epoch 589/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3300 - accuracy: 0.8641 - val_loss: 0.9760 - val_accuracy: 0.6862\n",
      "Epoch 590/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3328 - accuracy: 0.8628 - val_loss: 0.9895 - val_accuracy: 0.6801\n",
      "Epoch 591/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3366 - accuracy: 0.8615 - val_loss: 0.9756 - val_accuracy: 0.6841\n",
      "Epoch 592/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3286 - accuracy: 0.8637 - val_loss: 0.9520 - val_accuracy: 0.6935\n",
      "Epoch 593/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3309 - accuracy: 0.8628 - val_loss: 0.9657 - val_accuracy: 0.6901\n",
      "Epoch 594/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3243 - accuracy: 0.8649 - val_loss: 0.9261 - val_accuracy: 0.6928\n",
      "Epoch 595/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3355 - accuracy: 0.8611 - val_loss: 1.0108 - val_accuracy: 0.6807\n",
      "Epoch 596/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3279 - accuracy: 0.8644 - val_loss: 0.9740 - val_accuracy: 0.6922\n",
      "Epoch 597/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3271 - accuracy: 0.8648 - val_loss: 0.9024 - val_accuracy: 0.7046\n",
      "Epoch 598/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3238 - accuracy: 0.8660 - val_loss: 0.9351 - val_accuracy: 0.6997\n",
      "Epoch 599/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3231 - accuracy: 0.8676 - val_loss: 0.9552 - val_accuracy: 0.6910\n",
      "Epoch 600/8000\n",
      "1459/1463 [============================>.] - ETA: 0s - loss: 0.3237 - accuracy: 0.8657\n",
      "Epoch 600: saving model to ./training_ckpt_20240109205949_v8_240109_d10000_n4096_b64_e8000_c100_Adamax\\cp-000000600.ckpt\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3237 - accuracy: 0.8657 - val_loss: 0.9625 - val_accuracy: 0.6925\n",
      "Epoch 601/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3281 - accuracy: 0.8646 - val_loss: 0.9829 - val_accuracy: 0.6868\n",
      "Epoch 602/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3345 - accuracy: 0.8628 - val_loss: 0.9409 - val_accuracy: 0.6956\n",
      "Epoch 603/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3194 - accuracy: 0.8682 - val_loss: 0.9655 - val_accuracy: 0.6878\n",
      "Epoch 604/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3260 - accuracy: 0.8666 - val_loss: 0.9573 - val_accuracy: 0.6960\n",
      "Epoch 605/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3262 - accuracy: 0.8652 - val_loss: 0.9207 - val_accuracy: 0.6951\n",
      "Epoch 606/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3232 - accuracy: 0.8668 - val_loss: 0.9273 - val_accuracy: 0.6925\n",
      "Epoch 607/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3188 - accuracy: 0.8684 - val_loss: 0.9675 - val_accuracy: 0.6909\n",
      "Epoch 608/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3223 - accuracy: 0.8672 - val_loss: 0.9409 - val_accuracy: 0.6923\n",
      "Epoch 609/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3199 - accuracy: 0.8685 - val_loss: 0.9367 - val_accuracy: 0.6957\n",
      "Epoch 610/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3192 - accuracy: 0.8684 - val_loss: 0.9378 - val_accuracy: 0.6951\n",
      "Epoch 611/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3215 - accuracy: 0.8674 - val_loss: 0.9380 - val_accuracy: 0.6939\n",
      "Epoch 612/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3212 - accuracy: 0.8670 - val_loss: 0.9506 - val_accuracy: 0.6948\n",
      "Epoch 613/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3213 - accuracy: 0.8682 - val_loss: 0.9536 - val_accuracy: 0.6941\n",
      "Epoch 614/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3215 - accuracy: 0.8679 - val_loss: 0.9579 - val_accuracy: 0.6892\n",
      "Epoch 615/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3212 - accuracy: 0.8682 - val_loss: 0.9373 - val_accuracy: 0.6897\n",
      "Epoch 616/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3220 - accuracy: 0.8678 - val_loss: 0.9722 - val_accuracy: 0.6934\n",
      "Epoch 617/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3208 - accuracy: 0.8687 - val_loss: 0.9491 - val_accuracy: 0.6921\n",
      "Epoch 618/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3204 - accuracy: 0.8678 - val_loss: 0.9867 - val_accuracy: 0.6849\n",
      "Epoch 619/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3218 - accuracy: 0.8676 - val_loss: 0.9128 - val_accuracy: 0.7022\n",
      "Epoch 620/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.3107 - accuracy: 0.8718 - val_loss: 0.9687 - val_accuracy: 0.6898\n",
      "Epoch 621/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3201 - accuracy: 0.8681 - val_loss: 0.9250 - val_accuracy: 0.6939\n",
      "Epoch 622/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3165 - accuracy: 0.8692 - val_loss: 0.9531 - val_accuracy: 0.6965\n",
      "Epoch 623/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3201 - accuracy: 0.8682 - val_loss: 0.9447 - val_accuracy: 0.6931\n",
      "Epoch 624/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3204 - accuracy: 0.8678 - val_loss: 0.9405 - val_accuracy: 0.6938\n",
      "Epoch 625/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3169 - accuracy: 0.8696 - val_loss: 0.9474 - val_accuracy: 0.6933\n",
      "Epoch 626/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3273 - accuracy: 0.8658 - val_loss: 0.9564 - val_accuracy: 0.6903\n",
      "Epoch 627/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3134 - accuracy: 0.8710 - val_loss: 0.9324 - val_accuracy: 0.6963\n",
      "Epoch 628/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3243 - accuracy: 0.8674 - val_loss: 0.9126 - val_accuracy: 0.6981\n",
      "Epoch 629/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3143 - accuracy: 0.8704 - val_loss: 0.9205 - val_accuracy: 0.7000\n",
      "Epoch 630/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3159 - accuracy: 0.8703 - val_loss: 0.9404 - val_accuracy: 0.6960\n",
      "Epoch 631/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3159 - accuracy: 0.8707 - val_loss: 0.9057 - val_accuracy: 0.7028\n",
      "Epoch 632/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3173 - accuracy: 0.8702 - val_loss: 0.9454 - val_accuracy: 0.7021\n",
      "Epoch 633/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3174 - accuracy: 0.8696 - val_loss: 0.9492 - val_accuracy: 0.6951\n",
      "Epoch 634/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3139 - accuracy: 0.8705 - val_loss: 0.9484 - val_accuracy: 0.6897\n",
      "Epoch 635/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3203 - accuracy: 0.8683 - val_loss: 0.9253 - val_accuracy: 0.7003\n",
      "Epoch 636/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3120 - accuracy: 0.8725 - val_loss: 0.9368 - val_accuracy: 0.6976\n",
      "Epoch 637/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3124 - accuracy: 0.8721 - val_loss: 0.9596 - val_accuracy: 0.6913\n",
      "Epoch 638/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3095 - accuracy: 0.8728 - val_loss: 0.9386 - val_accuracy: 0.6980\n",
      "Epoch 639/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3112 - accuracy: 0.8727 - val_loss: 0.9162 - val_accuracy: 0.7026\n",
      "Epoch 640/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3132 - accuracy: 0.8721 - val_loss: 1.0061 - val_accuracy: 0.6848\n",
      "Epoch 641/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3088 - accuracy: 0.8738 - val_loss: 0.9479 - val_accuracy: 0.6938\n",
      "Epoch 642/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3111 - accuracy: 0.8723 - val_loss: 1.0021 - val_accuracy: 0.6837\n",
      "Epoch 643/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3065 - accuracy: 0.8748 - val_loss: 0.8941 - val_accuracy: 0.7082\n",
      "Epoch 644/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3109 - accuracy: 0.8713 - val_loss: 0.9577 - val_accuracy: 0.6917\n",
      "Epoch 645/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3108 - accuracy: 0.8722 - val_loss: 0.9179 - val_accuracy: 0.6986\n",
      "Epoch 646/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3066 - accuracy: 0.8742 - val_loss: 0.9501 - val_accuracy: 0.6922\n",
      "Epoch 647/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3103 - accuracy: 0.8735 - val_loss: 0.9811 - val_accuracy: 0.6837\n",
      "Epoch 648/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3035 - accuracy: 0.8748 - val_loss: 0.9198 - val_accuracy: 0.7005\n",
      "Epoch 649/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3119 - accuracy: 0.8724 - val_loss: 0.9390 - val_accuracy: 0.6991\n",
      "Epoch 650/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3047 - accuracy: 0.8756 - val_loss: 0.9408 - val_accuracy: 0.7002\n",
      "Epoch 651/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3025 - accuracy: 0.8761 - val_loss: 0.9432 - val_accuracy: 0.6919\n",
      "Epoch 652/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3019 - accuracy: 0.8768 - val_loss: 0.8990 - val_accuracy: 0.7065\n",
      "Epoch 653/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3035 - accuracy: 0.8755 - val_loss: 0.9525 - val_accuracy: 0.6920\n",
      "Epoch 654/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3048 - accuracy: 0.8753 - val_loss: 0.9216 - val_accuracy: 0.7016\n",
      "Epoch 655/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3103 - accuracy: 0.8736 - val_loss: 0.9236 - val_accuracy: 0.7046\n",
      "Epoch 656/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3105 - accuracy: 0.8728 - val_loss: 0.9325 - val_accuracy: 0.7017\n",
      "Epoch 657/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3080 - accuracy: 0.8743 - val_loss: 0.9251 - val_accuracy: 0.7027\n",
      "Epoch 658/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3101 - accuracy: 0.8729 - val_loss: 0.9264 - val_accuracy: 0.7033\n",
      "Epoch 659/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3086 - accuracy: 0.8743 - val_loss: 0.9758 - val_accuracy: 0.6932\n",
      "Epoch 660/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3071 - accuracy: 0.8743 - val_loss: 1.0369 - val_accuracy: 0.6733\n",
      "Epoch 661/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3005 - accuracy: 0.8779 - val_loss: 0.9407 - val_accuracy: 0.7013\n",
      "Epoch 662/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3047 - accuracy: 0.8752 - val_loss: 0.9460 - val_accuracy: 0.6938\n",
      "Epoch 663/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3023 - accuracy: 0.8775 - val_loss: 0.9135 - val_accuracy: 0.7029\n",
      "Epoch 664/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3018 - accuracy: 0.8766 - val_loss: 0.9187 - val_accuracy: 0.7003\n",
      "Epoch 665/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3038 - accuracy: 0.8765 - val_loss: 0.9389 - val_accuracy: 0.7004\n",
      "Epoch 666/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3022 - accuracy: 0.8757 - val_loss: 0.9008 - val_accuracy: 0.7068\n",
      "Epoch 667/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2969 - accuracy: 0.8790 - val_loss: 0.9404 - val_accuracy: 0.6984\n",
      "Epoch 668/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3003 - accuracy: 0.8775 - val_loss: 0.8903 - val_accuracy: 0.7106\n",
      "Epoch 669/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2983 - accuracy: 0.8782 - val_loss: 0.8988 - val_accuracy: 0.7105\n",
      "Epoch 670/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2959 - accuracy: 0.8793 - val_loss: 0.9041 - val_accuracy: 0.7041\n",
      "Epoch 671/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3021 - accuracy: 0.8777 - val_loss: 0.9607 - val_accuracy: 0.6938\n",
      "Epoch 672/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3005 - accuracy: 0.8767 - val_loss: 0.9436 - val_accuracy: 0.7025\n",
      "Epoch 673/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3067 - accuracy: 0.8753 - val_loss: 0.9203 - val_accuracy: 0.7012\n",
      "Epoch 674/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3016 - accuracy: 0.8766 - val_loss: 0.9114 - val_accuracy: 0.7043\n",
      "Epoch 675/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3033 - accuracy: 0.8770 - val_loss: 0.9523 - val_accuracy: 0.6951\n",
      "Epoch 676/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2956 - accuracy: 0.8803 - val_loss: 0.9688 - val_accuracy: 0.6928\n",
      "Epoch 677/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3023 - accuracy: 0.8769 - val_loss: 0.9134 - val_accuracy: 0.7086\n",
      "Epoch 678/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2962 - accuracy: 0.8796 - val_loss: 0.9585 - val_accuracy: 0.6951\n",
      "Epoch 679/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2972 - accuracy: 0.8785 - val_loss: 0.9368 - val_accuracy: 0.7044\n",
      "Epoch 680/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3025 - accuracy: 0.8768 - val_loss: 0.9217 - val_accuracy: 0.7098\n",
      "Epoch 681/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.2916 - accuracy: 0.8817 - val_loss: 0.9213 - val_accuracy: 0.7099\n",
      "Epoch 682/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.2940 - accuracy: 0.8790 - val_loss: 0.9033 - val_accuracy: 0.7075\n",
      "Epoch 683/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3004 - accuracy: 0.8768 - val_loss: 0.9434 - val_accuracy: 0.7000\n",
      "Epoch 684/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.2958 - accuracy: 0.8791 - val_loss: 0.9354 - val_accuracy: 0.7013\n",
      "Epoch 685/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3054 - accuracy: 0.8753 - val_loss: 0.9338 - val_accuracy: 0.7057\n",
      "Epoch 686/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3009 - accuracy: 0.8769 - val_loss: 0.9688 - val_accuracy: 0.6980\n",
      "Epoch 687/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3001 - accuracy: 0.8774 - val_loss: 0.9868 - val_accuracy: 0.6881\n",
      "Epoch 688/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2960 - accuracy: 0.8799 - val_loss: 0.8941 - val_accuracy: 0.7108\n",
      "Epoch 689/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3005 - accuracy: 0.8790 - val_loss: 0.8875 - val_accuracy: 0.7135\n",
      "Epoch 690/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2919 - accuracy: 0.8809 - val_loss: 0.9008 - val_accuracy: 0.7060\n",
      "Epoch 691/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2912 - accuracy: 0.8814 - val_loss: 0.9426 - val_accuracy: 0.6985\n",
      "Epoch 692/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.2898 - accuracy: 0.8820 - val_loss: 0.9232 - val_accuracy: 0.7047\n",
      "Epoch 693/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2944 - accuracy: 0.8803 - val_loss: 0.9571 - val_accuracy: 0.6956\n",
      "Epoch 694/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.2881 - accuracy: 0.8825 - val_loss: 0.8733 - val_accuracy: 0.7203\n",
      "Epoch 695/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.2916 - accuracy: 0.8817 - val_loss: 0.9959 - val_accuracy: 0.6941\n",
      "Epoch 696/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3256 - accuracy: 0.8679 - val_loss: 0.9321 - val_accuracy: 0.7027\n",
      "Epoch 697/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3156 - accuracy: 0.8704 - val_loss: 0.9692 - val_accuracy: 0.6888\n",
      "Epoch 698/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3212 - accuracy: 0.8688 - val_loss: 0.9747 - val_accuracy: 0.6885\n",
      "Epoch 699/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3106 - accuracy: 0.8735 - val_loss: 0.9254 - val_accuracy: 0.7051\n",
      "Epoch 700/8000\n",
      "1458/1463 [============================>.] - ETA: 0s - loss: 0.3132 - accuracy: 0.8726\n",
      "Epoch 700: saving model to ./training_ckpt_20240109205949_v8_240109_d10000_n4096_b64_e8000_c100_Adamax\\cp-000000700.ckpt\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3134 - accuracy: 0.8725 - val_loss: 1.0439 - val_accuracy: 0.6740\n",
      "Epoch 701/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3040 - accuracy: 0.8765 - val_loss: 0.9606 - val_accuracy: 0.6945\n",
      "Epoch 702/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.3051 - accuracy: 0.8763 - val_loss: 0.9472 - val_accuracy: 0.7013\n",
      "Epoch 703/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3034 - accuracy: 0.8762 - val_loss: 0.9505 - val_accuracy: 0.7000\n",
      "Epoch 704/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3167 - accuracy: 0.8729 - val_loss: 0.9249 - val_accuracy: 0.7089\n",
      "Epoch 705/8000\n",
      "1463/1463 [==============================] - 15s 11ms/step - loss: 0.3160 - accuracy: 0.8727 - val_loss: 0.9518 - val_accuracy: 0.7022\n",
      "Epoch 706/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.3212 - accuracy: 0.8689 - val_loss: 0.9034 - val_accuracy: 0.7120\n",
      "Epoch 707/8000\n",
      "1463/1463 [==============================] - 18s 12ms/step - loss: 0.3127 - accuracy: 0.8724 - val_loss: 0.9213 - val_accuracy: 0.7128\n",
      "Epoch 708/8000\n",
      "1463/1463 [==============================] - 20s 14ms/step - loss: 0.3112 - accuracy: 0.8729 - val_loss: 0.8854 - val_accuracy: 0.7144\n",
      "Epoch 709/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.3103 - accuracy: 0.8736 - val_loss: 0.9937 - val_accuracy: 0.6940\n",
      "Epoch 710/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3127 - accuracy: 0.8720 - val_loss: 0.9156 - val_accuracy: 0.7043\n",
      "Epoch 711/8000\n",
      "1463/1463 [==============================] - 15s 11ms/step - loss: 0.3155 - accuracy: 0.8722 - val_loss: 0.9465 - val_accuracy: 0.6983\n",
      "Epoch 712/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.3105 - accuracy: 0.8736 - val_loss: 0.9736 - val_accuracy: 0.6962\n",
      "Epoch 713/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3181 - accuracy: 0.8699 - val_loss: 0.9295 - val_accuracy: 0.7019\n",
      "Epoch 714/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3110 - accuracy: 0.8734 - val_loss: 0.9001 - val_accuracy: 0.7112\n",
      "Epoch 715/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3083 - accuracy: 0.8736 - val_loss: 0.9499 - val_accuracy: 0.7012\n",
      "Epoch 716/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3109 - accuracy: 0.8730 - val_loss: 0.9113 - val_accuracy: 0.7090\n",
      "Epoch 717/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3058 - accuracy: 0.8752 - val_loss: 0.9526 - val_accuracy: 0.6961\n",
      "Epoch 718/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3076 - accuracy: 0.8739 - val_loss: 0.9360 - val_accuracy: 0.7035\n",
      "Epoch 719/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3084 - accuracy: 0.8739 - val_loss: 0.9516 - val_accuracy: 0.7007\n",
      "Epoch 720/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3084 - accuracy: 0.8742 - val_loss: 0.9149 - val_accuracy: 0.7072\n",
      "Epoch 721/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3047 - accuracy: 0.8750 - val_loss: 0.9398 - val_accuracy: 0.6980\n",
      "Epoch 722/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3061 - accuracy: 0.8750 - val_loss: 0.9131 - val_accuracy: 0.7108\n",
      "Epoch 723/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3049 - accuracy: 0.8748 - val_loss: 0.9372 - val_accuracy: 0.7042\n",
      "Epoch 724/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3023 - accuracy: 0.8763 - val_loss: 0.8982 - val_accuracy: 0.7144\n",
      "Epoch 725/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3012 - accuracy: 0.8763 - val_loss: 0.9001 - val_accuracy: 0.7104\n",
      "Epoch 726/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3029 - accuracy: 0.8758 - val_loss: 0.9997 - val_accuracy: 0.6979\n",
      "Epoch 727/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.3032 - accuracy: 0.8763 - val_loss: 0.8813 - val_accuracy: 0.7171\n",
      "Epoch 728/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2981 - accuracy: 0.8774 - val_loss: 0.9393 - val_accuracy: 0.7034\n",
      "Epoch 729/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3001 - accuracy: 0.8773 - val_loss: 0.9520 - val_accuracy: 0.7043\n",
      "Epoch 730/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3021 - accuracy: 0.8759 - val_loss: 0.9146 - val_accuracy: 0.7060\n",
      "Epoch 731/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3017 - accuracy: 0.8772 - val_loss: 0.9407 - val_accuracy: 0.7013\n",
      "Epoch 732/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2994 - accuracy: 0.8772 - val_loss: 0.9249 - val_accuracy: 0.7088\n",
      "Epoch 733/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2998 - accuracy: 0.8778 - val_loss: 0.9847 - val_accuracy: 0.6925\n",
      "Epoch 734/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3019 - accuracy: 0.8765 - val_loss: 0.9527 - val_accuracy: 0.7046\n",
      "Epoch 735/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3002 - accuracy: 0.8776 - val_loss: 0.9634 - val_accuracy: 0.6991\n",
      "Epoch 736/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2969 - accuracy: 0.8785 - val_loss: 0.8999 - val_accuracy: 0.7089\n",
      "Epoch 737/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3045 - accuracy: 0.8770 - val_loss: 1.0011 - val_accuracy: 0.6869\n",
      "Epoch 738/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3005 - accuracy: 0.8777 - val_loss: 0.9020 - val_accuracy: 0.7129\n",
      "Epoch 739/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3006 - accuracy: 0.8781 - val_loss: 0.9298 - val_accuracy: 0.7030\n",
      "Epoch 740/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2963 - accuracy: 0.8783 - val_loss: 0.9336 - val_accuracy: 0.7002\n",
      "Epoch 741/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.3004 - accuracy: 0.8771 - val_loss: 1.0166 - val_accuracy: 0.6926\n",
      "Epoch 742/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2989 - accuracy: 0.8781 - val_loss: 0.9735 - val_accuracy: 0.6934\n",
      "Epoch 743/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2955 - accuracy: 0.8786 - val_loss: 0.8845 - val_accuracy: 0.7152\n",
      "Epoch 744/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2955 - accuracy: 0.8794 - val_loss: 0.9098 - val_accuracy: 0.7068\n",
      "Epoch 745/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2922 - accuracy: 0.8806 - val_loss: 0.9305 - val_accuracy: 0.7088\n",
      "Epoch 746/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2966 - accuracy: 0.8779 - val_loss: 0.9111 - val_accuracy: 0.7100\n",
      "Epoch 747/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2901 - accuracy: 0.8807 - val_loss: 0.8964 - val_accuracy: 0.7127\n",
      "Epoch 748/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2966 - accuracy: 0.8802 - val_loss: 0.9343 - val_accuracy: 0.7031\n",
      "Epoch 749/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2897 - accuracy: 0.8827 - val_loss: 0.8875 - val_accuracy: 0.7174\n",
      "Epoch 750/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2879 - accuracy: 0.8819 - val_loss: 0.9325 - val_accuracy: 0.7032\n",
      "Epoch 751/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2949 - accuracy: 0.8804 - val_loss: 0.9021 - val_accuracy: 0.7167\n",
      "Epoch 752/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.2955 - accuracy: 0.8803 - val_loss: 0.9098 - val_accuracy: 0.7079\n",
      "Epoch 753/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2938 - accuracy: 0.8804 - val_loss: 0.9900 - val_accuracy: 0.6927\n",
      "Epoch 754/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2912 - accuracy: 0.8817 - val_loss: 0.9714 - val_accuracy: 0.6928\n",
      "Epoch 755/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2941 - accuracy: 0.8795 - val_loss: 0.8983 - val_accuracy: 0.7181\n",
      "Epoch 756/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2877 - accuracy: 0.8834 - val_loss: 0.9390 - val_accuracy: 0.7121\n",
      "Epoch 757/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2878 - accuracy: 0.8821 - val_loss: 0.9401 - val_accuracy: 0.7031\n",
      "Epoch 758/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2921 - accuracy: 0.8806 - val_loss: 0.9249 - val_accuracy: 0.7052\n",
      "Epoch 759/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2939 - accuracy: 0.8804 - val_loss: 0.9548 - val_accuracy: 0.7099\n",
      "Epoch 760/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2871 - accuracy: 0.8826 - val_loss: 0.9154 - val_accuracy: 0.7117\n",
      "Epoch 761/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2845 - accuracy: 0.8832 - val_loss: 0.8981 - val_accuracy: 0.7163\n",
      "Epoch 762/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2904 - accuracy: 0.8820 - val_loss: 0.9227 - val_accuracy: 0.7132\n",
      "Epoch 763/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2797 - accuracy: 0.8851 - val_loss: 0.9038 - val_accuracy: 0.7107\n",
      "Epoch 764/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2898 - accuracy: 0.8819 - val_loss: 0.9294 - val_accuracy: 0.7059\n",
      "Epoch 765/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.2848 - accuracy: 0.8843 - val_loss: 0.8977 - val_accuracy: 0.7140\n",
      "Epoch 766/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2788 - accuracy: 0.8867 - val_loss: 0.9254 - val_accuracy: 0.7107\n",
      "Epoch 767/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2893 - accuracy: 0.8831 - val_loss: 0.8761 - val_accuracy: 0.7187\n",
      "Epoch 768/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2812 - accuracy: 0.8852 - val_loss: 0.8981 - val_accuracy: 0.7112\n",
      "Epoch 769/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2853 - accuracy: 0.8839 - val_loss: 0.8645 - val_accuracy: 0.7217\n",
      "Epoch 770/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.2798 - accuracy: 0.8869 - val_loss: 0.9096 - val_accuracy: 0.7099\n",
      "Epoch 771/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2829 - accuracy: 0.8854 - val_loss: 0.8863 - val_accuracy: 0.7176\n",
      "Epoch 772/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2835 - accuracy: 0.8843 - val_loss: 0.8997 - val_accuracy: 0.7134\n",
      "Epoch 773/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2779 - accuracy: 0.8866 - val_loss: 0.9562 - val_accuracy: 0.7027\n",
      "Epoch 774/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2816 - accuracy: 0.8856 - val_loss: 0.9084 - val_accuracy: 0.7143\n",
      "Epoch 775/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.2798 - accuracy: 0.8872 - val_loss: 0.9521 - val_accuracy: 0.7062\n",
      "Epoch 776/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2780 - accuracy: 0.8878 - val_loss: 0.9595 - val_accuracy: 0.7008\n",
      "Epoch 777/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2819 - accuracy: 0.8854 - val_loss: 0.9265 - val_accuracy: 0.7107\n",
      "Epoch 778/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2877 - accuracy: 0.8826 - val_loss: 0.9138 - val_accuracy: 0.7091\n",
      "Epoch 779/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.2763 - accuracy: 0.8880 - val_loss: 0.9261 - val_accuracy: 0.7089\n",
      "Epoch 780/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.2736 - accuracy: 0.8898 - val_loss: 0.8667 - val_accuracy: 0.7220\n",
      "Epoch 781/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.2758 - accuracy: 0.8878 - val_loss: 0.8642 - val_accuracy: 0.7234\n",
      "Epoch 782/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.2815 - accuracy: 0.8860 - val_loss: 0.9191 - val_accuracy: 0.7102\n",
      "Epoch 783/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.2763 - accuracy: 0.8885 - val_loss: 0.8795 - val_accuracy: 0.7182\n",
      "Epoch 784/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2747 - accuracy: 0.8892 - val_loss: 0.9597 - val_accuracy: 0.7052\n",
      "Epoch 785/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.2726 - accuracy: 0.8887 - val_loss: 0.8807 - val_accuracy: 0.7242\n",
      "Epoch 786/8000\n",
      "1463/1463 [==============================] - 15s 11ms/step - loss: 0.2825 - accuracy: 0.8859 - val_loss: 0.9322 - val_accuracy: 0.7125\n",
      "Epoch 787/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2769 - accuracy: 0.8876 - val_loss: 0.9294 - val_accuracy: 0.7112\n",
      "Epoch 788/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2780 - accuracy: 0.8863 - val_loss: 0.9276 - val_accuracy: 0.7082\n",
      "Epoch 789/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.2737 - accuracy: 0.8894 - val_loss: 0.9376 - val_accuracy: 0.7038\n",
      "Epoch 790/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2759 - accuracy: 0.8884 - val_loss: 0.9045 - val_accuracy: 0.7161\n",
      "Epoch 791/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2801 - accuracy: 0.8882 - val_loss: 1.0080 - val_accuracy: 0.6976\n",
      "Epoch 792/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2729 - accuracy: 0.8895 - val_loss: 0.9101 - val_accuracy: 0.7166\n",
      "Epoch 793/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2743 - accuracy: 0.8891 - val_loss: 0.9358 - val_accuracy: 0.7138\n",
      "Epoch 794/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.2702 - accuracy: 0.8909 - val_loss: 0.8987 - val_accuracy: 0.7128\n",
      "Epoch 795/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2710 - accuracy: 0.8899 - val_loss: 0.9796 - val_accuracy: 0.7018\n",
      "Epoch 796/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.2790 - accuracy: 0.8871 - val_loss: 0.9560 - val_accuracy: 0.7075\n",
      "Epoch 797/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2765 - accuracy: 0.8883 - val_loss: 0.9533 - val_accuracy: 0.7027\n",
      "Epoch 798/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2757 - accuracy: 0.8890 - val_loss: 0.8813 - val_accuracy: 0.7188\n",
      "Epoch 799/8000\n",
      "1463/1463 [==============================] - 15s 11ms/step - loss: 0.2702 - accuracy: 0.8904 - val_loss: 0.8847 - val_accuracy: 0.7197\n",
      "Epoch 800/8000\n",
      "1459/1463 [============================>.] - ETA: 0s - loss: 0.2704 - accuracy: 0.8914\n",
      "Epoch 800: saving model to ./training_ckpt_20240109205949_v8_240109_d10000_n4096_b64_e8000_c100_Adamax\\cp-000000800.ckpt\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2704 - accuracy: 0.8913 - val_loss: 0.8664 - val_accuracy: 0.7224\n",
      "Epoch 801/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2654 - accuracy: 0.8927 - val_loss: 0.8862 - val_accuracy: 0.7181\n",
      "Epoch 802/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2718 - accuracy: 0.8904 - val_loss: 0.8996 - val_accuracy: 0.7175\n",
      "Epoch 803/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2767 - accuracy: 0.8882 - val_loss: 0.9248 - val_accuracy: 0.7120\n",
      "Epoch 804/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2747 - accuracy: 0.8888 - val_loss: 0.9254 - val_accuracy: 0.7114\n",
      "Epoch 805/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2680 - accuracy: 0.8919 - val_loss: 0.9464 - val_accuracy: 0.7067\n",
      "Epoch 806/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2729 - accuracy: 0.8895 - val_loss: 0.8923 - val_accuracy: 0.7194\n",
      "Epoch 807/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2767 - accuracy: 0.8889 - val_loss: 0.8918 - val_accuracy: 0.7135\n",
      "Epoch 808/8000\n",
      "1463/1463 [==============================] - 15s 11ms/step - loss: 0.2649 - accuracy: 0.8940 - val_loss: 0.8773 - val_accuracy: 0.7198\n",
      "Epoch 809/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.2653 - accuracy: 0.8927 - val_loss: 0.8497 - val_accuracy: 0.7303\n",
      "Epoch 810/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2661 - accuracy: 0.8923 - val_loss: 0.8880 - val_accuracy: 0.7209\n",
      "Epoch 811/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2695 - accuracy: 0.8909 - val_loss: 0.9352 - val_accuracy: 0.7123\n",
      "Epoch 812/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2667 - accuracy: 0.8927 - val_loss: 0.8720 - val_accuracy: 0.7195\n",
      "Epoch 813/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2675 - accuracy: 0.8921 - val_loss: 0.8417 - val_accuracy: 0.7277\n",
      "Epoch 814/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2639 - accuracy: 0.8931 - val_loss: 0.8854 - val_accuracy: 0.7237\n",
      "Epoch 815/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2656 - accuracy: 0.8927 - val_loss: 0.8537 - val_accuracy: 0.7295\n",
      "Epoch 816/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2659 - accuracy: 0.8922 - val_loss: 0.9380 - val_accuracy: 0.7118\n",
      "Epoch 817/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2710 - accuracy: 0.8918 - val_loss: 1.0106 - val_accuracy: 0.6999\n",
      "Epoch 818/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2663 - accuracy: 0.8923 - val_loss: 0.8924 - val_accuracy: 0.7237\n",
      "Epoch 819/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2625 - accuracy: 0.8939 - val_loss: 0.8779 - val_accuracy: 0.7242\n",
      "Epoch 820/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2580 - accuracy: 0.8946 - val_loss: 0.8755 - val_accuracy: 0.7210\n",
      "Epoch 821/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2609 - accuracy: 0.8944 - val_loss: 0.8848 - val_accuracy: 0.7224\n",
      "Epoch 822/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2692 - accuracy: 0.8911 - val_loss: 0.8788 - val_accuracy: 0.7222\n",
      "Epoch 823/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.2594 - accuracy: 0.8960 - val_loss: 0.8485 - val_accuracy: 0.7337\n",
      "Epoch 824/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.2628 - accuracy: 0.8933 - val_loss: 0.8702 - val_accuracy: 0.7252\n",
      "Epoch 825/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2672 - accuracy: 0.8925 - val_loss: 0.8583 - val_accuracy: 0.7260\n",
      "Epoch 826/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2557 - accuracy: 0.8971 - val_loss: 0.8474 - val_accuracy: 0.7288\n",
      "Epoch 827/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2571 - accuracy: 0.8970 - val_loss: 0.8564 - val_accuracy: 0.7275\n",
      "Epoch 828/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2552 - accuracy: 0.8977 - val_loss: 0.8987 - val_accuracy: 0.7199\n",
      "Epoch 829/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2562 - accuracy: 0.8964 - val_loss: 0.8996 - val_accuracy: 0.7231\n",
      "Epoch 830/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2564 - accuracy: 0.8980 - val_loss: 0.9173 - val_accuracy: 0.7232\n",
      "Epoch 831/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2587 - accuracy: 0.8959 - val_loss: 0.8709 - val_accuracy: 0.7231\n",
      "Epoch 832/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2578 - accuracy: 0.8962 - val_loss: 0.8498 - val_accuracy: 0.7312\n",
      "Epoch 833/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2602 - accuracy: 0.8948 - val_loss: 0.8520 - val_accuracy: 0.7295\n",
      "Epoch 834/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2605 - accuracy: 0.8953 - val_loss: 0.9281 - val_accuracy: 0.7142\n",
      "Epoch 835/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2568 - accuracy: 0.8966 - val_loss: 0.9012 - val_accuracy: 0.7155\n",
      "Epoch 836/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2584 - accuracy: 0.8966 - val_loss: 0.8910 - val_accuracy: 0.7191\n",
      "Epoch 837/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2542 - accuracy: 0.8986 - val_loss: 0.8654 - val_accuracy: 0.7275\n",
      "Epoch 838/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2579 - accuracy: 0.8964 - val_loss: 0.8679 - val_accuracy: 0.7268\n",
      "Epoch 839/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2577 - accuracy: 0.8970 - val_loss: 0.8722 - val_accuracy: 0.7276\n",
      "Epoch 840/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2551 - accuracy: 0.8982 - val_loss: 0.8755 - val_accuracy: 0.7259\n",
      "Epoch 841/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.2603 - accuracy: 0.8959 - val_loss: 0.8746 - val_accuracy: 0.7219\n",
      "Epoch 842/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.2559 - accuracy: 0.8981 - val_loss: 0.9236 - val_accuracy: 0.7117\n",
      "Epoch 843/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2531 - accuracy: 0.8995 - val_loss: 0.9444 - val_accuracy: 0.7166\n",
      "Epoch 844/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.2526 - accuracy: 0.8982 - val_loss: 0.8335 - val_accuracy: 0.7362\n",
      "Epoch 845/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2549 - accuracy: 0.8969 - val_loss: 0.8788 - val_accuracy: 0.7229\n",
      "Epoch 846/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2499 - accuracy: 0.9004 - val_loss: 1.0122 - val_accuracy: 0.7007\n",
      "Epoch 847/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2531 - accuracy: 0.8990 - val_loss: 0.8804 - val_accuracy: 0.7228\n",
      "Epoch 848/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2508 - accuracy: 0.8994 - val_loss: 0.9310 - val_accuracy: 0.7138\n",
      "Epoch 849/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2506 - accuracy: 0.8986 - val_loss: 0.8901 - val_accuracy: 0.7236\n",
      "Epoch 850/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2554 - accuracy: 0.8972 - val_loss: 0.8959 - val_accuracy: 0.7197\n",
      "Epoch 851/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2567 - accuracy: 0.8972 - val_loss: 0.8678 - val_accuracy: 0.7262\n",
      "Epoch 852/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2494 - accuracy: 0.9001 - val_loss: 0.9033 - val_accuracy: 0.7144\n",
      "Epoch 853/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2528 - accuracy: 0.8988 - val_loss: 0.8882 - val_accuracy: 0.7247\n",
      "Epoch 854/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2513 - accuracy: 0.8987 - val_loss: 0.8487 - val_accuracy: 0.7333\n",
      "Epoch 855/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2497 - accuracy: 0.9007 - val_loss: 0.8428 - val_accuracy: 0.7336\n",
      "Epoch 856/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2504 - accuracy: 0.9014 - val_loss: 0.9055 - val_accuracy: 0.7229\n",
      "Epoch 857/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2495 - accuracy: 0.8995 - val_loss: 0.8796 - val_accuracy: 0.7295\n",
      "Epoch 858/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.2459 - accuracy: 0.9013 - val_loss: 0.8903 - val_accuracy: 0.7279\n",
      "Epoch 859/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2506 - accuracy: 0.8995 - val_loss: 0.8561 - val_accuracy: 0.7317\n",
      "Epoch 860/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.2464 - accuracy: 0.9010 - val_loss: 0.8513 - val_accuracy: 0.7330\n",
      "Epoch 861/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.2520 - accuracy: 0.8992 - val_loss: 0.9079 - val_accuracy: 0.7169\n",
      "Epoch 862/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2500 - accuracy: 0.9005 - val_loss: 0.8651 - val_accuracy: 0.7312\n",
      "Epoch 863/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2444 - accuracy: 0.9013 - val_loss: 0.9860 - val_accuracy: 0.7110\n",
      "Epoch 864/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2436 - accuracy: 0.9025 - val_loss: 0.8402 - val_accuracy: 0.7352\n",
      "Epoch 865/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2467 - accuracy: 0.9009 - val_loss: 0.9205 - val_accuracy: 0.7208\n",
      "Epoch 866/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.2501 - accuracy: 0.8992 - val_loss: 0.8464 - val_accuracy: 0.7385\n",
      "Epoch 867/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.2456 - accuracy: 0.9013 - val_loss: 0.8300 - val_accuracy: 0.7360\n",
      "Epoch 868/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2475 - accuracy: 0.9021 - val_loss: 0.8375 - val_accuracy: 0.7378\n",
      "Epoch 869/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2444 - accuracy: 0.9025 - val_loss: 0.9256 - val_accuracy: 0.7212\n",
      "Epoch 870/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2499 - accuracy: 0.8991 - val_loss: 0.8410 - val_accuracy: 0.7356\n",
      "Epoch 871/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2442 - accuracy: 0.9030 - val_loss: 0.8772 - val_accuracy: 0.7291\n",
      "Epoch 872/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.2435 - accuracy: 0.9030 - val_loss: 0.8493 - val_accuracy: 0.7365\n",
      "Epoch 873/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.2482 - accuracy: 0.9015 - val_loss: 0.8992 - val_accuracy: 0.7244\n",
      "Epoch 874/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.2434 - accuracy: 0.9026 - val_loss: 0.9218 - val_accuracy: 0.7198\n",
      "Epoch 875/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.2409 - accuracy: 0.9040 - val_loss: 0.8537 - val_accuracy: 0.7332\n",
      "Epoch 876/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.2454 - accuracy: 0.9021 - val_loss: 0.9409 - val_accuracy: 0.7074\n",
      "Epoch 877/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2426 - accuracy: 0.9030 - val_loss: 0.8685 - val_accuracy: 0.7267\n",
      "Epoch 878/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2438 - accuracy: 0.9027 - val_loss: 0.8496 - val_accuracy: 0.7287\n",
      "Epoch 879/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2444 - accuracy: 0.9030 - val_loss: 0.8458 - val_accuracy: 0.7311\n",
      "Epoch 880/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2452 - accuracy: 0.9022 - val_loss: 0.8479 - val_accuracy: 0.7306\n",
      "Epoch 881/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2410 - accuracy: 0.9032 - val_loss: 0.9561 - val_accuracy: 0.7196\n",
      "Epoch 882/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2437 - accuracy: 0.9022 - val_loss: 0.8912 - val_accuracy: 0.7221\n",
      "Epoch 883/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.2420 - accuracy: 0.9042 - val_loss: 0.8558 - val_accuracy: 0.7289\n",
      "Epoch 884/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.2400 - accuracy: 0.9043 - val_loss: 0.8474 - val_accuracy: 0.7354\n",
      "Epoch 885/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.2446 - accuracy: 0.9015 - val_loss: 0.8281 - val_accuracy: 0.7415\n",
      "Epoch 886/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2352 - accuracy: 0.9065 - val_loss: 1.0295 - val_accuracy: 0.7112\n",
      "Epoch 887/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.2473 - accuracy: 0.9015 - val_loss: 0.8111 - val_accuracy: 0.7454\n",
      "Epoch 888/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2460 - accuracy: 0.9033 - val_loss: 0.8433 - val_accuracy: 0.7309\n",
      "Epoch 889/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2376 - accuracy: 0.9044 - val_loss: 0.8664 - val_accuracy: 0.7315\n",
      "Epoch 890/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2412 - accuracy: 0.9029 - val_loss: 0.8763 - val_accuracy: 0.7292\n",
      "Epoch 891/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2374 - accuracy: 0.9051 - val_loss: 0.8287 - val_accuracy: 0.7387\n",
      "Epoch 892/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2411 - accuracy: 0.9040 - val_loss: 0.8469 - val_accuracy: 0.7350\n",
      "Epoch 893/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2356 - accuracy: 0.9059 - val_loss: 0.8821 - val_accuracy: 0.7280\n",
      "Epoch 894/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2432 - accuracy: 0.9036 - val_loss: 0.8320 - val_accuracy: 0.7457\n",
      "Epoch 895/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2475 - accuracy: 0.9018 - val_loss: 0.8673 - val_accuracy: 0.7303\n",
      "Epoch 896/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2340 - accuracy: 0.9071 - val_loss: 0.8317 - val_accuracy: 0.7400\n",
      "Epoch 897/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2419 - accuracy: 0.9037 - val_loss: 0.8483 - val_accuracy: 0.7368\n",
      "Epoch 898/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2396 - accuracy: 0.9047 - val_loss: 0.8530 - val_accuracy: 0.7331\n",
      "Epoch 899/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.2419 - accuracy: 0.9031 - val_loss: 0.8272 - val_accuracy: 0.7395\n",
      "Epoch 900/8000\n",
      "1460/1463 [============================>.] - ETA: 0s - loss: 0.2346 - accuracy: 0.9066\n",
      "Epoch 900: saving model to ./training_ckpt_20240109205949_v8_240109_d10000_n4096_b64_e8000_c100_Adamax\\cp-000000900.ckpt\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2346 - accuracy: 0.9066 - val_loss: 0.8739 - val_accuracy: 0.7263\n",
      "Epoch 901/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2383 - accuracy: 0.9056 - val_loss: 0.8960 - val_accuracy: 0.7282\n",
      "Epoch 902/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2493 - accuracy: 0.9008 - val_loss: 0.8492 - val_accuracy: 0.7305\n",
      "Epoch 903/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2308 - accuracy: 0.9068 - val_loss: 0.8053 - val_accuracy: 0.7472\n",
      "Epoch 904/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.2384 - accuracy: 0.9046 - val_loss: 0.8442 - val_accuracy: 0.7371\n",
      "Epoch 905/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.2336 - accuracy: 0.9077 - val_loss: 0.8679 - val_accuracy: 0.7336\n",
      "Epoch 906/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.2410 - accuracy: 0.9037 - val_loss: 0.8734 - val_accuracy: 0.7358\n",
      "Epoch 907/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2323 - accuracy: 0.9081 - val_loss: 0.8297 - val_accuracy: 0.7419\n",
      "Epoch 908/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.2355 - accuracy: 0.9062 - val_loss: 0.8833 - val_accuracy: 0.7331\n",
      "Epoch 909/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2352 - accuracy: 0.9059 - val_loss: 0.8118 - val_accuracy: 0.7439\n",
      "Epoch 910/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2324 - accuracy: 0.9075 - val_loss: 0.8422 - val_accuracy: 0.7316\n",
      "Epoch 911/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2339 - accuracy: 0.9065 - val_loss: 0.8835 - val_accuracy: 0.7304\n",
      "Epoch 912/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.2330 - accuracy: 0.9078 - val_loss: 0.8613 - val_accuracy: 0.7335\n",
      "Epoch 913/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2346 - accuracy: 0.9074 - val_loss: 0.8590 - val_accuracy: 0.7313\n",
      "Epoch 914/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2301 - accuracy: 0.9080 - val_loss: 0.8532 - val_accuracy: 0.7332\n",
      "Epoch 915/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2383 - accuracy: 0.9051 - val_loss: 0.8294 - val_accuracy: 0.7441\n",
      "Epoch 916/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2321 - accuracy: 0.9085 - val_loss: 0.9034 - val_accuracy: 0.7241\n",
      "Epoch 917/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2339 - accuracy: 0.9072 - val_loss: 0.8799 - val_accuracy: 0.7251\n",
      "Epoch 918/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2336 - accuracy: 0.9074 - val_loss: 0.8497 - val_accuracy: 0.7291\n",
      "Epoch 919/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2305 - accuracy: 0.9082 - val_loss: 0.8807 - val_accuracy: 0.7293\n",
      "Epoch 920/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2364 - accuracy: 0.9061 - val_loss: 0.8850 - val_accuracy: 0.7322\n",
      "Epoch 921/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2318 - accuracy: 0.9093 - val_loss: 0.8505 - val_accuracy: 0.7321\n",
      "Epoch 922/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.2292 - accuracy: 0.9079 - val_loss: 0.7978 - val_accuracy: 0.7455\n",
      "Epoch 923/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2254 - accuracy: 0.9101 - val_loss: 0.8604 - val_accuracy: 0.7368\n",
      "Epoch 924/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2323 - accuracy: 0.9078 - val_loss: 0.8923 - val_accuracy: 0.7188\n",
      "Epoch 925/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2352 - accuracy: 0.9075 - val_loss: 0.8706 - val_accuracy: 0.7305\n",
      "Epoch 926/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2297 - accuracy: 0.9083 - val_loss: 0.8324 - val_accuracy: 0.7429\n",
      "Epoch 927/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2313 - accuracy: 0.9085 - val_loss: 0.8501 - val_accuracy: 0.7315\n",
      "Epoch 928/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2310 - accuracy: 0.9094 - val_loss: 0.8220 - val_accuracy: 0.7397\n",
      "Epoch 929/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2256 - accuracy: 0.9101 - val_loss: 0.8918 - val_accuracy: 0.7266\n",
      "Epoch 930/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2280 - accuracy: 0.9093 - val_loss: 0.8265 - val_accuracy: 0.7431\n",
      "Epoch 931/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2308 - accuracy: 0.9089 - val_loss: 0.8927 - val_accuracy: 0.7274\n",
      "Epoch 932/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2268 - accuracy: 0.9094 - val_loss: 0.8442 - val_accuracy: 0.7373\n",
      "Epoch 933/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2334 - accuracy: 0.9070 - val_loss: 0.8718 - val_accuracy: 0.7305\n",
      "Epoch 934/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2275 - accuracy: 0.9102 - val_loss: 0.8522 - val_accuracy: 0.7356\n",
      "Epoch 935/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2286 - accuracy: 0.9091 - val_loss: 0.8146 - val_accuracy: 0.7433\n",
      "Epoch 936/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2248 - accuracy: 0.9110 - val_loss: 0.8194 - val_accuracy: 0.7457\n",
      "Epoch 937/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2270 - accuracy: 0.9098 - val_loss: 0.8129 - val_accuracy: 0.7482\n",
      "Epoch 938/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2261 - accuracy: 0.9106 - val_loss: 0.8333 - val_accuracy: 0.7421\n",
      "Epoch 939/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2543 - accuracy: 0.9008 - val_loss: 0.8702 - val_accuracy: 0.7296\n",
      "Epoch 940/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.2588 - accuracy: 0.8975 - val_loss: 0.8884 - val_accuracy: 0.7254\n",
      "Epoch 941/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2567 - accuracy: 0.8966 - val_loss: 0.8885 - val_accuracy: 0.7261\n",
      "Epoch 942/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.2510 - accuracy: 0.8993 - val_loss: 0.8662 - val_accuracy: 0.7328\n",
      "Epoch 943/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.2515 - accuracy: 0.8990 - val_loss: 0.9032 - val_accuracy: 0.7223\n",
      "Epoch 944/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.2494 - accuracy: 0.8992 - val_loss: 0.8575 - val_accuracy: 0.7261\n",
      "Epoch 945/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.2484 - accuracy: 0.9005 - val_loss: 0.8133 - val_accuracy: 0.7428\n",
      "Epoch 946/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.2423 - accuracy: 0.9022 - val_loss: 0.7864 - val_accuracy: 0.7508\n",
      "Epoch 947/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2332 - accuracy: 0.9075 - val_loss: 0.8663 - val_accuracy: 0.7303\n",
      "Epoch 948/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.2262 - accuracy: 0.9108 - val_loss: 0.7975 - val_accuracy: 0.7472\n",
      "Epoch 949/8000\n",
      "1463/1463 [==============================] - 15s 11ms/step - loss: 0.2322 - accuracy: 0.9089 - val_loss: 0.8130 - val_accuracy: 0.7429\n",
      "Epoch 950/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.2335 - accuracy: 0.9083 - val_loss: 0.8241 - val_accuracy: 0.7399\n",
      "Epoch 951/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2227 - accuracy: 0.9110 - val_loss: 0.8392 - val_accuracy: 0.7437\n",
      "Epoch 952/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2211 - accuracy: 0.9119 - val_loss: 0.8349 - val_accuracy: 0.7352\n",
      "Epoch 953/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2274 - accuracy: 0.9101 - val_loss: 0.8183 - val_accuracy: 0.7446\n",
      "Epoch 954/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2285 - accuracy: 0.9098 - val_loss: 0.8767 - val_accuracy: 0.7272\n",
      "Epoch 955/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2254 - accuracy: 0.9104 - val_loss: 0.8843 - val_accuracy: 0.7244\n",
      "Epoch 956/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.2224 - accuracy: 0.9119 - val_loss: 0.8314 - val_accuracy: 0.7455\n",
      "Epoch 957/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2242 - accuracy: 0.9110 - val_loss: 0.7899 - val_accuracy: 0.7538\n",
      "Epoch 958/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.2286 - accuracy: 0.9104 - val_loss: 0.7902 - val_accuracy: 0.7525\n",
      "Epoch 959/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.2210 - accuracy: 0.9122 - val_loss: 0.8027 - val_accuracy: 0.7489\n",
      "Epoch 960/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2245 - accuracy: 0.9114 - val_loss: 0.8489 - val_accuracy: 0.7410\n",
      "Epoch 961/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.2286 - accuracy: 0.9096 - val_loss: 0.8740 - val_accuracy: 0.7341\n",
      "Epoch 962/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2209 - accuracy: 0.9125 - val_loss: 0.8756 - val_accuracy: 0.7306\n",
      "Epoch 963/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2203 - accuracy: 0.9119 - val_loss: 0.8489 - val_accuracy: 0.7366\n",
      "Epoch 964/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2225 - accuracy: 0.9112 - val_loss: 0.8103 - val_accuracy: 0.7437\n",
      "Epoch 965/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.2228 - accuracy: 0.9115 - val_loss: 0.8164 - val_accuracy: 0.7441\n",
      "Epoch 966/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2179 - accuracy: 0.9134 - val_loss: 0.8048 - val_accuracy: 0.7463\n",
      "Epoch 967/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2148 - accuracy: 0.9152 - val_loss: 0.8492 - val_accuracy: 0.7372\n",
      "Epoch 968/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2268 - accuracy: 0.9090 - val_loss: 0.8356 - val_accuracy: 0.7413\n",
      "Epoch 969/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2212 - accuracy: 0.9128 - val_loss: 0.8399 - val_accuracy: 0.7423\n",
      "Epoch 970/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2237 - accuracy: 0.9125 - val_loss: 0.8119 - val_accuracy: 0.7460\n",
      "Epoch 971/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.2191 - accuracy: 0.9143 - val_loss: 0.7869 - val_accuracy: 0.7551\n",
      "Epoch 972/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2263 - accuracy: 0.9115 - val_loss: 0.8299 - val_accuracy: 0.7403\n",
      "Epoch 973/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2215 - accuracy: 0.9119 - val_loss: 0.8243 - val_accuracy: 0.7464\n",
      "Epoch 974/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2216 - accuracy: 0.9132 - val_loss: 0.7735 - val_accuracy: 0.7613\n",
      "Epoch 975/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.2152 - accuracy: 0.9145 - val_loss: 0.8459 - val_accuracy: 0.7452\n",
      "Epoch 976/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2123 - accuracy: 0.9165 - val_loss: 0.8091 - val_accuracy: 0.7480\n",
      "Epoch 977/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2197 - accuracy: 0.9139 - val_loss: 0.8829 - val_accuracy: 0.7303\n",
      "Epoch 978/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2257 - accuracy: 0.9115 - val_loss: 0.8040 - val_accuracy: 0.7462\n",
      "Epoch 979/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2179 - accuracy: 0.9145 - val_loss: 0.8138 - val_accuracy: 0.7434\n",
      "Epoch 980/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2151 - accuracy: 0.9155 - val_loss: 0.8080 - val_accuracy: 0.7501\n",
      "Epoch 981/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2213 - accuracy: 0.9125 - val_loss: 0.8113 - val_accuracy: 0.7479\n",
      "Epoch 982/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2225 - accuracy: 0.9127 - val_loss: 0.8346 - val_accuracy: 0.7444\n",
      "Epoch 983/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2141 - accuracy: 0.9157 - val_loss: 0.8184 - val_accuracy: 0.7501\n",
      "Epoch 984/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2188 - accuracy: 0.9141 - val_loss: 0.8586 - val_accuracy: 0.7358\n",
      "Epoch 985/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2143 - accuracy: 0.9153 - val_loss: 0.7819 - val_accuracy: 0.7536\n",
      "Epoch 986/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2158 - accuracy: 0.9157 - val_loss: 0.8178 - val_accuracy: 0.7464\n",
      "Epoch 987/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2178 - accuracy: 0.9142 - val_loss: 0.8189 - val_accuracy: 0.7482\n",
      "Epoch 988/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2199 - accuracy: 0.9137 - val_loss: 0.9067 - val_accuracy: 0.7273\n",
      "Epoch 989/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2487 - accuracy: 0.9027 - val_loss: 0.8333 - val_accuracy: 0.7390\n",
      "Epoch 990/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2445 - accuracy: 0.9025 - val_loss: 0.8554 - val_accuracy: 0.7351\n",
      "Epoch 991/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2367 - accuracy: 0.9063 - val_loss: 0.8365 - val_accuracy: 0.7443\n",
      "Epoch 992/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2378 - accuracy: 0.9054 - val_loss: 0.8448 - val_accuracy: 0.7389\n",
      "Epoch 993/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2383 - accuracy: 0.9044 - val_loss: 0.8430 - val_accuracy: 0.7371\n",
      "Epoch 994/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.2397 - accuracy: 0.9047 - val_loss: 0.8455 - val_accuracy: 0.7364\n",
      "Epoch 995/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2308 - accuracy: 0.9078 - val_loss: 0.9171 - val_accuracy: 0.7177\n",
      "Epoch 996/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.2361 - accuracy: 0.9056 - val_loss: 0.8416 - val_accuracy: 0.7440\n",
      "Epoch 997/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2501 - accuracy: 0.9009 - val_loss: 0.8552 - val_accuracy: 0.7317\n",
      "Epoch 998/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2335 - accuracy: 0.9073 - val_loss: 0.8517 - val_accuracy: 0.7387\n",
      "Epoch 999/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2346 - accuracy: 0.9065 - val_loss: 0.8662 - val_accuracy: 0.7310\n",
      "Epoch 1000/8000\n",
      "1461/1463 [============================>.] - ETA: 0s - loss: 0.2383 - accuracy: 0.9055\n",
      "Epoch 1000: saving model to ./training_ckpt_20240109205949_v8_240109_d10000_n4096_b64_e8000_c100_Adamax\\cp-000001000.ckpt\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2382 - accuracy: 0.9056 - val_loss: 0.8034 - val_accuracy: 0.7486\n",
      "Epoch 1001/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2364 - accuracy: 0.9039 - val_loss: 0.8121 - val_accuracy: 0.7422\n",
      "Epoch 1002/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2327 - accuracy: 0.9074 - val_loss: 0.8160 - val_accuracy: 0.7473\n",
      "Epoch 1003/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2347 - accuracy: 0.9058 - val_loss: 0.8812 - val_accuracy: 0.7300\n",
      "Epoch 1004/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2344 - accuracy: 0.9061 - val_loss: 0.8825 - val_accuracy: 0.7313\n",
      "Epoch 1005/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2310 - accuracy: 0.9082 - val_loss: 0.8497 - val_accuracy: 0.7355\n",
      "Epoch 1006/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2345 - accuracy: 0.9067 - val_loss: 0.8106 - val_accuracy: 0.7477\n",
      "Epoch 1007/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2331 - accuracy: 0.9078 - val_loss: 0.8439 - val_accuracy: 0.7375\n",
      "Epoch 1008/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2375 - accuracy: 0.9054 - val_loss: 0.8315 - val_accuracy: 0.7448\n",
      "Epoch 1009/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2295 - accuracy: 0.9088 - val_loss: 0.8861 - val_accuracy: 0.7310\n",
      "Epoch 1010/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2340 - accuracy: 0.9064 - val_loss: 0.8218 - val_accuracy: 0.7477\n",
      "Epoch 1011/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2353 - accuracy: 0.9064 - val_loss: 0.8470 - val_accuracy: 0.7371\n",
      "Epoch 1012/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2314 - accuracy: 0.9077 - val_loss: 0.8243 - val_accuracy: 0.7429\n",
      "Epoch 1013/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2311 - accuracy: 0.9079 - val_loss: 0.8164 - val_accuracy: 0.7425\n",
      "Epoch 1014/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.2362 - accuracy: 0.9055 - val_loss: 0.8279 - val_accuracy: 0.7411\n",
      "Epoch 1015/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.2325 - accuracy: 0.9075 - val_loss: 0.8502 - val_accuracy: 0.7323\n",
      "Epoch 1016/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2310 - accuracy: 0.9074 - val_loss: 0.8132 - val_accuracy: 0.7447\n",
      "Epoch 1017/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2270 - accuracy: 0.9099 - val_loss: 0.8551 - val_accuracy: 0.7372\n",
      "Epoch 1018/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2285 - accuracy: 0.9079 - val_loss: 0.9075 - val_accuracy: 0.7281\n",
      "Epoch 1019/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.2311 - accuracy: 0.9082 - val_loss: 0.8734 - val_accuracy: 0.7325\n",
      "Epoch 1020/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2337 - accuracy: 0.9071 - val_loss: 0.8459 - val_accuracy: 0.7431\n",
      "Epoch 1021/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.2301 - accuracy: 0.9078 - val_loss: 0.8375 - val_accuracy: 0.7386\n",
      "Epoch 1022/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2286 - accuracy: 0.9084 - val_loss: 0.8200 - val_accuracy: 0.7487\n",
      "Epoch 1023/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.2275 - accuracy: 0.9084 - val_loss: 0.8182 - val_accuracy: 0.7463\n",
      "Epoch 1024/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2286 - accuracy: 0.9087 - val_loss: 0.9514 - val_accuracy: 0.7156\n",
      "Epoch 1025/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2248 - accuracy: 0.9109 - val_loss: 0.8265 - val_accuracy: 0.7420\n",
      "Epoch 1026/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2263 - accuracy: 0.9096 - val_loss: 0.8208 - val_accuracy: 0.7394\n",
      "Epoch 1027/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2299 - accuracy: 0.9081 - val_loss: 0.8771 - val_accuracy: 0.7311\n",
      "Epoch 1028/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2235 - accuracy: 0.9115 - val_loss: 0.8323 - val_accuracy: 0.7411\n",
      "Epoch 1029/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2234 - accuracy: 0.9110 - val_loss: 0.8370 - val_accuracy: 0.7448\n",
      "Epoch 1030/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2250 - accuracy: 0.9104 - val_loss: 0.8074 - val_accuracy: 0.7490\n",
      "Epoch 1031/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2306 - accuracy: 0.9081 - val_loss: 0.8547 - val_accuracy: 0.7356\n",
      "Epoch 1032/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2234 - accuracy: 0.9117 - val_loss: 0.8551 - val_accuracy: 0.7365\n",
      "Epoch 1033/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2275 - accuracy: 0.9102 - val_loss: 0.7937 - val_accuracy: 0.7521\n",
      "Epoch 1034/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2261 - accuracy: 0.9106 - val_loss: 0.7922 - val_accuracy: 0.7542\n",
      "Epoch 1035/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.2274 - accuracy: 0.9102 - val_loss: 0.9227 - val_accuracy: 0.7243\n",
      "Epoch 1036/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2249 - accuracy: 0.9112 - val_loss: 0.8452 - val_accuracy: 0.7406\n",
      "Epoch 1037/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.2267 - accuracy: 0.9102 - val_loss: 0.8038 - val_accuracy: 0.7519\n",
      "Epoch 1038/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2266 - accuracy: 0.9097 - val_loss: 0.8280 - val_accuracy: 0.7517\n",
      "Epoch 1039/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.2251 - accuracy: 0.9103 - val_loss: 0.8388 - val_accuracy: 0.7461\n",
      "Epoch 1040/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2307 - accuracy: 0.9097 - val_loss: 0.9548 - val_accuracy: 0.7230\n",
      "Epoch 1041/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2270 - accuracy: 0.9099 - val_loss: 0.8456 - val_accuracy: 0.7420\n",
      "Epoch 1042/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2267 - accuracy: 0.9096 - val_loss: 0.8975 - val_accuracy: 0.7289\n",
      "Epoch 1043/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2221 - accuracy: 0.9110 - val_loss: 0.8437 - val_accuracy: 0.7481\n",
      "Epoch 1044/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2230 - accuracy: 0.9110 - val_loss: 0.8505 - val_accuracy: 0.7433\n",
      "Epoch 1045/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.2222 - accuracy: 0.9116 - val_loss: 0.8672 - val_accuracy: 0.7394\n",
      "Epoch 1046/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2223 - accuracy: 0.9120 - val_loss: 0.8531 - val_accuracy: 0.7384\n",
      "Epoch 1047/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2196 - accuracy: 0.9126 - val_loss: 0.8189 - val_accuracy: 0.7447\n",
      "Epoch 1048/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2247 - accuracy: 0.9108 - val_loss: 0.8331 - val_accuracy: 0.7465\n",
      "Epoch 1049/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2205 - accuracy: 0.9118 - val_loss: 0.8318 - val_accuracy: 0.7370\n",
      "Epoch 1050/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2232 - accuracy: 0.9112 - val_loss: 0.8179 - val_accuracy: 0.7423\n",
      "Epoch 1051/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2256 - accuracy: 0.9106 - val_loss: 0.8302 - val_accuracy: 0.7410\n",
      "Epoch 1052/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2198 - accuracy: 0.9123 - val_loss: 0.8814 - val_accuracy: 0.7327\n",
      "Epoch 1053/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2262 - accuracy: 0.9105 - val_loss: 0.8811 - val_accuracy: 0.7334\n",
      "Epoch 1054/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2294 - accuracy: 0.9094 - val_loss: 0.8036 - val_accuracy: 0.7476\n",
      "Epoch 1055/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2198 - accuracy: 0.9139 - val_loss: 0.8526 - val_accuracy: 0.7405\n",
      "Epoch 1056/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2220 - accuracy: 0.9113 - val_loss: 0.8491 - val_accuracy: 0.7449\n",
      "Epoch 1057/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2192 - accuracy: 0.9127 - val_loss: 0.8588 - val_accuracy: 0.7375\n",
      "Epoch 1058/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.2198 - accuracy: 0.9129 - val_loss: 0.8265 - val_accuracy: 0.7401\n",
      "Epoch 1059/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2210 - accuracy: 0.9125 - val_loss: 0.8227 - val_accuracy: 0.7462\n",
      "Epoch 1060/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2217 - accuracy: 0.9123 - val_loss: 0.8085 - val_accuracy: 0.7473\n",
      "Epoch 1061/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2205 - accuracy: 0.9124 - val_loss: 0.8442 - val_accuracy: 0.7434\n",
      "Epoch 1062/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.2153 - accuracy: 0.9151 - val_loss: 0.8281 - val_accuracy: 0.7499\n",
      "Epoch 1063/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2169 - accuracy: 0.9137 - val_loss: 0.8686 - val_accuracy: 0.7350\n",
      "Epoch 1064/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.2174 - accuracy: 0.9135 - val_loss: 0.8513 - val_accuracy: 0.7405\n",
      "Epoch 1065/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2250 - accuracy: 0.9113 - val_loss: 0.8735 - val_accuracy: 0.7388\n",
      "Epoch 1066/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2295 - accuracy: 0.9097 - val_loss: 0.8816 - val_accuracy: 0.7303\n",
      "Epoch 1067/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2178 - accuracy: 0.9133 - val_loss: 0.8290 - val_accuracy: 0.7460\n",
      "Epoch 1068/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2234 - accuracy: 0.9118 - val_loss: 0.8506 - val_accuracy: 0.7431\n",
      "Epoch 1069/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2216 - accuracy: 0.9131 - val_loss: 0.8300 - val_accuracy: 0.7448\n",
      "Epoch 1070/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2176 - accuracy: 0.9134 - val_loss: 0.8488 - val_accuracy: 0.7429\n",
      "Epoch 1071/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2201 - accuracy: 0.9123 - val_loss: 0.8149 - val_accuracy: 0.7507\n",
      "Epoch 1072/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2192 - accuracy: 0.9135 - val_loss: 0.8990 - val_accuracy: 0.7284\n",
      "Epoch 1073/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2153 - accuracy: 0.9154 - val_loss: 0.8771 - val_accuracy: 0.7347\n",
      "Epoch 1074/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2227 - accuracy: 0.9122 - val_loss: 0.8072 - val_accuracy: 0.7483\n",
      "Epoch 1075/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2220 - accuracy: 0.9120 - val_loss: 0.8181 - val_accuracy: 0.7483\n",
      "Epoch 1076/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2213 - accuracy: 0.9122 - val_loss: 0.8198 - val_accuracy: 0.7492\n",
      "Epoch 1077/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2170 - accuracy: 0.9136 - val_loss: 0.8376 - val_accuracy: 0.7428\n",
      "Epoch 1078/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2195 - accuracy: 0.9135 - val_loss: 0.8392 - val_accuracy: 0.7486\n",
      "Epoch 1079/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2200 - accuracy: 0.9128 - val_loss: 0.8265 - val_accuracy: 0.7465\n",
      "Epoch 1080/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2135 - accuracy: 0.9155 - val_loss: 0.7844 - val_accuracy: 0.7556\n",
      "Epoch 1081/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2156 - accuracy: 0.9143 - val_loss: 0.8050 - val_accuracy: 0.7498\n",
      "Epoch 1082/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2149 - accuracy: 0.9164 - val_loss: 0.8427 - val_accuracy: 0.7421\n",
      "Epoch 1083/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2162 - accuracy: 0.9143 - val_loss: 0.8579 - val_accuracy: 0.7381\n",
      "Epoch 1084/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2162 - accuracy: 0.9150 - val_loss: 0.7748 - val_accuracy: 0.7574\n",
      "Epoch 1085/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2161 - accuracy: 0.9155 - val_loss: 0.8141 - val_accuracy: 0.7451\n",
      "Epoch 1086/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2195 - accuracy: 0.9132 - val_loss: 0.8127 - val_accuracy: 0.7493\n",
      "Epoch 1087/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2137 - accuracy: 0.9162 - val_loss: 0.8074 - val_accuracy: 0.7519\n",
      "Epoch 1088/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2100 - accuracy: 0.9175 - val_loss: 0.8523 - val_accuracy: 0.7476\n",
      "Epoch 1089/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2138 - accuracy: 0.9153 - val_loss: 0.7905 - val_accuracy: 0.7538\n",
      "Epoch 1090/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2133 - accuracy: 0.9159 - val_loss: 0.9074 - val_accuracy: 0.7308\n",
      "Epoch 1091/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2097 - accuracy: 0.9173 - val_loss: 0.8370 - val_accuracy: 0.7460\n",
      "Epoch 1092/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2118 - accuracy: 0.9165 - val_loss: 0.8282 - val_accuracy: 0.7462\n",
      "Epoch 1093/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2167 - accuracy: 0.9149 - val_loss: 0.8385 - val_accuracy: 0.7444\n",
      "Epoch 1094/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2185 - accuracy: 0.9136 - val_loss: 0.8170 - val_accuracy: 0.7481\n",
      "Epoch 1095/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2133 - accuracy: 0.9166 - val_loss: 0.7939 - val_accuracy: 0.7529\n",
      "Epoch 1096/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2082 - accuracy: 0.9179 - val_loss: 0.8415 - val_accuracy: 0.7460\n",
      "Epoch 1097/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.2125 - accuracy: 0.9160 - val_loss: 0.8828 - val_accuracy: 0.7347\n",
      "Epoch 1098/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2096 - accuracy: 0.9182 - val_loss: 0.8472 - val_accuracy: 0.7419\n",
      "Epoch 1099/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2147 - accuracy: 0.9155 - val_loss: 0.8682 - val_accuracy: 0.7392\n",
      "Epoch 1100/8000\n",
      "1463/1463 [==============================] - ETA: 0s - loss: 0.2143 - accuracy: 0.9145\n",
      "Epoch 1100: saving model to ./training_ckpt_20240109205949_v8_240109_d10000_n4096_b64_e8000_c100_Adamax\\cp-000001100.ckpt\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.2143 - accuracy: 0.9145 - val_loss: 0.8758 - val_accuracy: 0.7390\n",
      "Epoch 1101/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2180 - accuracy: 0.9139 - val_loss: 0.7870 - val_accuracy: 0.7554\n",
      "Epoch 1102/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2071 - accuracy: 0.9176 - val_loss: 0.8039 - val_accuracy: 0.7474\n",
      "Epoch 1103/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2115 - accuracy: 0.9172 - val_loss: 0.8111 - val_accuracy: 0.7501\n",
      "Epoch 1104/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2121 - accuracy: 0.9162 - val_loss: 0.7841 - val_accuracy: 0.7562\n",
      "Epoch 1105/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2112 - accuracy: 0.9162 - val_loss: 0.7855 - val_accuracy: 0.7585\n",
      "Epoch 1106/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.2077 - accuracy: 0.9187 - val_loss: 0.9693 - val_accuracy: 0.7212\n",
      "Epoch 1107/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2131 - accuracy: 0.9165 - val_loss: 0.7895 - val_accuracy: 0.7563\n",
      "Epoch 1108/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2061 - accuracy: 0.9191 - val_loss: 0.8035 - val_accuracy: 0.7513\n",
      "Epoch 1109/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2118 - accuracy: 0.9166 - val_loss: 0.8114 - val_accuracy: 0.7545\n",
      "Epoch 1110/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2137 - accuracy: 0.9168 - val_loss: 0.7794 - val_accuracy: 0.7588\n",
      "Epoch 1111/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2114 - accuracy: 0.9175 - val_loss: 0.8314 - val_accuracy: 0.7510\n",
      "Epoch 1112/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2106 - accuracy: 0.9164 - val_loss: 0.8212 - val_accuracy: 0.7480\n",
      "Epoch 1113/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2102 - accuracy: 0.9172 - val_loss: 0.8078 - val_accuracy: 0.7466\n",
      "Epoch 1114/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.2113 - accuracy: 0.9175 - val_loss: 0.8172 - val_accuracy: 0.7468\n",
      "Epoch 1115/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2097 - accuracy: 0.9170 - val_loss: 0.7945 - val_accuracy: 0.7547\n",
      "Epoch 1116/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2118 - accuracy: 0.9160 - val_loss: 0.8224 - val_accuracy: 0.7464\n",
      "Epoch 1117/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2080 - accuracy: 0.9184 - val_loss: 0.8067 - val_accuracy: 0.7521\n",
      "Epoch 1118/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2054 - accuracy: 0.9191 - val_loss: 0.9439 - val_accuracy: 0.7258\n",
      "Epoch 1119/8000\n",
      "1463/1463 [==============================] - 19s 13ms/step - loss: 0.2165 - accuracy: 0.9139 - val_loss: 0.8160 - val_accuracy: 0.7513\n",
      "Epoch 1120/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2120 - accuracy: 0.9163 - val_loss: 0.8375 - val_accuracy: 0.7493\n",
      "Epoch 1121/8000\n",
      "1463/1463 [==============================] - 19s 13ms/step - loss: 0.2072 - accuracy: 0.9183 - val_loss: 0.8664 - val_accuracy: 0.7426\n",
      "Epoch 1122/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2109 - accuracy: 0.9169 - val_loss: 0.8565 - val_accuracy: 0.7433\n",
      "Epoch 1123/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.2061 - accuracy: 0.9184 - val_loss: 0.7806 - val_accuracy: 0.7569\n",
      "Epoch 1124/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2143 - accuracy: 0.9165 - val_loss: 0.8278 - val_accuracy: 0.7460\n",
      "Epoch 1125/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.2072 - accuracy: 0.9181 - val_loss: 0.8820 - val_accuracy: 0.7409\n",
      "Epoch 1126/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2165 - accuracy: 0.9137 - val_loss: 0.7908 - val_accuracy: 0.7563\n",
      "Epoch 1127/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2014 - accuracy: 0.9207 - val_loss: 0.8627 - val_accuracy: 0.7430\n",
      "Epoch 1128/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2062 - accuracy: 0.9195 - val_loss: 0.7746 - val_accuracy: 0.7600\n",
      "Epoch 1129/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2028 - accuracy: 0.9212 - val_loss: 0.8614 - val_accuracy: 0.7380\n",
      "Epoch 1130/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.2083 - accuracy: 0.9185 - val_loss: 0.7700 - val_accuracy: 0.7609\n",
      "Epoch 1131/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.2138 - accuracy: 0.9156 - val_loss: 0.8094 - val_accuracy: 0.7529\n",
      "Epoch 1132/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2089 - accuracy: 0.9177 - val_loss: 0.8550 - val_accuracy: 0.7484\n",
      "Epoch 1133/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2091 - accuracy: 0.9180 - val_loss: 0.8014 - val_accuracy: 0.7557\n",
      "Epoch 1134/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.2084 - accuracy: 0.9177 - val_loss: 0.8413 - val_accuracy: 0.7466\n",
      "Epoch 1135/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.2098 - accuracy: 0.9166 - val_loss: 0.8527 - val_accuracy: 0.7475\n",
      "Epoch 1136/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.2125 - accuracy: 0.9166 - val_loss: 0.8545 - val_accuracy: 0.7448\n",
      "Epoch 1137/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.2014 - accuracy: 0.9217 - val_loss: 0.8216 - val_accuracy: 0.7538\n",
      "Epoch 1138/8000\n",
      "1463/1463 [==============================] - 12s 9ms/step - loss: 0.2094 - accuracy: 0.9179 - val_loss: 0.8599 - val_accuracy: 0.7439\n",
      "Epoch 1139/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.2075 - accuracy: 0.9188 - val_loss: 0.7994 - val_accuracy: 0.7584\n",
      "Epoch 1140/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2093 - accuracy: 0.9175 - val_loss: 0.8055 - val_accuracy: 0.7529\n",
      "Epoch 1141/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.2041 - accuracy: 0.9200 - val_loss: 0.8122 - val_accuracy: 0.7525\n",
      "Epoch 1142/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2009 - accuracy: 0.9217 - val_loss: 0.8175 - val_accuracy: 0.7508\n",
      "Epoch 1143/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.2059 - accuracy: 0.9196 - val_loss: 0.8553 - val_accuracy: 0.7445\n",
      "Epoch 1144/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.2105 - accuracy: 0.9181 - val_loss: 0.7835 - val_accuracy: 0.7575\n",
      "Epoch 1145/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.2017 - accuracy: 0.9208 - val_loss: 0.8210 - val_accuracy: 0.7528\n",
      "Epoch 1146/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2058 - accuracy: 0.9189 - val_loss: 0.8498 - val_accuracy: 0.7396\n",
      "Epoch 1147/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.2057 - accuracy: 0.9194 - val_loss: 0.8133 - val_accuracy: 0.7575\n",
      "Epoch 1148/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2071 - accuracy: 0.9194 - val_loss: 0.7857 - val_accuracy: 0.7594\n",
      "Epoch 1149/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.2084 - accuracy: 0.9185 - val_loss: 0.8476 - val_accuracy: 0.7441\n",
      "Epoch 1150/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.1963 - accuracy: 0.9229 - val_loss: 0.7883 - val_accuracy: 0.7563\n",
      "Epoch 1151/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.2043 - accuracy: 0.9196 - val_loss: 0.8007 - val_accuracy: 0.7537\n",
      "Epoch 1152/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.2028 - accuracy: 0.9199 - val_loss: 0.8250 - val_accuracy: 0.7508\n",
      "Epoch 1153/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2052 - accuracy: 0.9191 - val_loss: 0.7987 - val_accuracy: 0.7545\n",
      "Epoch 1154/8000\n",
      "1463/1463 [==============================] - 12s 9ms/step - loss: 0.2017 - accuracy: 0.9227 - val_loss: 0.7964 - val_accuracy: 0.7567\n",
      "Epoch 1155/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.2023 - accuracy: 0.9195 - val_loss: 0.7973 - val_accuracy: 0.7605\n",
      "Epoch 1156/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.2038 - accuracy: 0.9201 - val_loss: 0.8143 - val_accuracy: 0.7531\n",
      "Epoch 1157/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1999 - accuracy: 0.9214 - val_loss: 0.7837 - val_accuracy: 0.7597\n",
      "Epoch 1158/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.2060 - accuracy: 0.9199 - val_loss: 0.8487 - val_accuracy: 0.7420\n",
      "Epoch 1159/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.2218 - accuracy: 0.9127 - val_loss: 0.8521 - val_accuracy: 0.7430\n",
      "Epoch 1160/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.2239 - accuracy: 0.9105 - val_loss: 0.8092 - val_accuracy: 0.7516\n",
      "Epoch 1161/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2180 - accuracy: 0.9135 - val_loss: 0.8464 - val_accuracy: 0.7469\n",
      "Epoch 1162/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2191 - accuracy: 0.9128 - val_loss: 0.8289 - val_accuracy: 0.7460\n",
      "Epoch 1163/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.2141 - accuracy: 0.9149 - val_loss: 0.8283 - val_accuracy: 0.7479\n",
      "Epoch 1164/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.2189 - accuracy: 0.9137 - val_loss: 0.8430 - val_accuracy: 0.7453\n",
      "Epoch 1165/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2099 - accuracy: 0.9168 - val_loss: 0.8419 - val_accuracy: 0.7424\n",
      "Epoch 1166/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.2151 - accuracy: 0.9133 - val_loss: 0.8071 - val_accuracy: 0.7530\n",
      "Epoch 1167/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.2163 - accuracy: 0.9149 - val_loss: 0.9853 - val_accuracy: 0.7172\n",
      "Epoch 1168/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.2123 - accuracy: 0.9146 - val_loss: 0.8355 - val_accuracy: 0.7444\n",
      "Epoch 1169/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.2138 - accuracy: 0.9152 - val_loss: 0.7966 - val_accuracy: 0.7525\n",
      "Epoch 1170/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.2144 - accuracy: 0.9150 - val_loss: 0.8484 - val_accuracy: 0.7443\n",
      "Epoch 1171/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.2153 - accuracy: 0.9142 - val_loss: 0.8038 - val_accuracy: 0.7562\n",
      "Epoch 1172/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2100 - accuracy: 0.9166 - val_loss: 0.8300 - val_accuracy: 0.7499\n",
      "Epoch 1173/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2138 - accuracy: 0.9142 - val_loss: 0.8686 - val_accuracy: 0.7461\n",
      "Epoch 1174/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2152 - accuracy: 0.9146 - val_loss: 0.8293 - val_accuracy: 0.7512\n",
      "Epoch 1175/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2090 - accuracy: 0.9174 - val_loss: 0.8215 - val_accuracy: 0.7517\n",
      "Epoch 1176/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2127 - accuracy: 0.9167 - val_loss: 0.8201 - val_accuracy: 0.7532\n",
      "Epoch 1177/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2109 - accuracy: 0.9162 - val_loss: 0.8088 - val_accuracy: 0.7549\n",
      "Epoch 1178/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2106 - accuracy: 0.9159 - val_loss: 0.8218 - val_accuracy: 0.7533\n",
      "Epoch 1179/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2090 - accuracy: 0.9168 - val_loss: 0.8597 - val_accuracy: 0.7372\n",
      "Epoch 1180/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2127 - accuracy: 0.9156 - val_loss: 0.8357 - val_accuracy: 0.7472\n",
      "Epoch 1181/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2152 - accuracy: 0.9152 - val_loss: 0.8577 - val_accuracy: 0.7419\n",
      "Epoch 1182/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2023 - accuracy: 0.9200 - val_loss: 0.8795 - val_accuracy: 0.7378\n",
      "Epoch 1183/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2055 - accuracy: 0.9193 - val_loss: 0.8395 - val_accuracy: 0.7463\n",
      "Epoch 1184/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2092 - accuracy: 0.9178 - val_loss: 0.8457 - val_accuracy: 0.7468\n",
      "Epoch 1185/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2088 - accuracy: 0.9178 - val_loss: 0.8044 - val_accuracy: 0.7600\n",
      "Epoch 1186/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2054 - accuracy: 0.9189 - val_loss: 0.8453 - val_accuracy: 0.7475\n",
      "Epoch 1187/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2113 - accuracy: 0.9162 - val_loss: 0.8189 - val_accuracy: 0.7545\n",
      "Epoch 1188/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2138 - accuracy: 0.9151 - val_loss: 0.8378 - val_accuracy: 0.7492\n",
      "Epoch 1189/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2134 - accuracy: 0.9158 - val_loss: 0.8290 - val_accuracy: 0.7509\n",
      "Epoch 1190/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2073 - accuracy: 0.9182 - val_loss: 0.8494 - val_accuracy: 0.7416\n",
      "Epoch 1191/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2100 - accuracy: 0.9178 - val_loss: 0.7997 - val_accuracy: 0.7600\n",
      "Epoch 1192/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2135 - accuracy: 0.9165 - val_loss: 0.8638 - val_accuracy: 0.7408\n",
      "Epoch 1193/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2042 - accuracy: 0.9191 - val_loss: 0.7964 - val_accuracy: 0.7538\n",
      "Epoch 1194/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2096 - accuracy: 0.9179 - val_loss: 0.8083 - val_accuracy: 0.7521\n",
      "Epoch 1195/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2061 - accuracy: 0.9193 - val_loss: 0.8021 - val_accuracy: 0.7564\n",
      "Epoch 1196/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2041 - accuracy: 0.9198 - val_loss: 0.8226 - val_accuracy: 0.7497\n",
      "Epoch 1197/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2063 - accuracy: 0.9182 - val_loss: 0.8523 - val_accuracy: 0.7421\n",
      "Epoch 1198/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2064 - accuracy: 0.9183 - val_loss: 0.9041 - val_accuracy: 0.7351\n",
      "Epoch 1199/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2050 - accuracy: 0.9195 - val_loss: 0.8540 - val_accuracy: 0.7422\n",
      "Epoch 1200/8000\n",
      "1462/1463 [============================>.] - ETA: 0s - loss: 0.2077 - accuracy: 0.9182\n",
      "Epoch 1200: saving model to ./training_ckpt_20240109205949_v8_240109_d10000_n4096_b64_e8000_c100_Adamax\\cp-000001200.ckpt\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2078 - accuracy: 0.9182 - val_loss: 0.8897 - val_accuracy: 0.7443\n",
      "Epoch 1201/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2041 - accuracy: 0.9192 - val_loss: 0.8566 - val_accuracy: 0.7493\n",
      "Epoch 1202/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2107 - accuracy: 0.9162 - val_loss: 0.8264 - val_accuracy: 0.7537\n",
      "Epoch 1203/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2039 - accuracy: 0.9199 - val_loss: 0.8510 - val_accuracy: 0.7514\n",
      "Epoch 1204/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2040 - accuracy: 0.9197 - val_loss: 0.7904 - val_accuracy: 0.7579\n",
      "Epoch 1205/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2098 - accuracy: 0.9181 - val_loss: 0.8654 - val_accuracy: 0.7414\n",
      "Epoch 1206/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2051 - accuracy: 0.9191 - val_loss: 0.8205 - val_accuracy: 0.7535\n",
      "Epoch 1207/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2101 - accuracy: 0.9176 - val_loss: 0.7921 - val_accuracy: 0.7553\n",
      "Epoch 1208/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2114 - accuracy: 0.9166 - val_loss: 0.7968 - val_accuracy: 0.7546\n",
      "Epoch 1209/8000\n",
      "1463/1463 [==============================] - 12s 9ms/step - loss: 0.2026 - accuracy: 0.9201 - val_loss: 0.8466 - val_accuracy: 0.7525\n",
      "Epoch 1210/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2015 - accuracy: 0.9205 - val_loss: 0.7680 - val_accuracy: 0.7634\n",
      "Epoch 1211/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2021 - accuracy: 0.9200 - val_loss: 0.8028 - val_accuracy: 0.7595\n",
      "Epoch 1212/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2003 - accuracy: 0.9209 - val_loss: 0.8146 - val_accuracy: 0.7557\n",
      "Epoch 1213/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2027 - accuracy: 0.9207 - val_loss: 0.8073 - val_accuracy: 0.7579\n",
      "Epoch 1214/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2025 - accuracy: 0.9207 - val_loss: 0.8750 - val_accuracy: 0.7410\n",
      "Epoch 1215/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2027 - accuracy: 0.9202 - val_loss: 0.7923 - val_accuracy: 0.7622\n",
      "Epoch 1216/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1999 - accuracy: 0.9221 - val_loss: 0.7987 - val_accuracy: 0.7617\n",
      "Epoch 1217/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2064 - accuracy: 0.9189 - val_loss: 0.8607 - val_accuracy: 0.7438\n",
      "Epoch 1218/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2033 - accuracy: 0.9210 - val_loss: 0.8232 - val_accuracy: 0.7512\n",
      "Epoch 1219/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2029 - accuracy: 0.9210 - val_loss: 0.8530 - val_accuracy: 0.7438\n",
      "Epoch 1220/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2081 - accuracy: 0.9195 - val_loss: 0.8142 - val_accuracy: 0.7598\n",
      "Epoch 1221/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2020 - accuracy: 0.9206 - val_loss: 0.7996 - val_accuracy: 0.7573\n",
      "Epoch 1222/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1982 - accuracy: 0.9210 - val_loss: 0.8383 - val_accuracy: 0.7523\n",
      "Epoch 1223/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2004 - accuracy: 0.9220 - val_loss: 0.8047 - val_accuracy: 0.7622\n",
      "Epoch 1224/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2049 - accuracy: 0.9199 - val_loss: 0.8887 - val_accuracy: 0.7351\n",
      "Epoch 1225/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1968 - accuracy: 0.9215 - val_loss: 0.8162 - val_accuracy: 0.7547\n",
      "Epoch 1226/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2009 - accuracy: 0.9203 - val_loss: 0.8468 - val_accuracy: 0.7403\n",
      "Epoch 1227/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2065 - accuracy: 0.9184 - val_loss: 0.8392 - val_accuracy: 0.7512\n",
      "Epoch 1228/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2022 - accuracy: 0.9202 - val_loss: 0.8437 - val_accuracy: 0.7491\n",
      "Epoch 1229/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1999 - accuracy: 0.9210 - val_loss: 0.7788 - val_accuracy: 0.7610\n",
      "Epoch 1230/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2004 - accuracy: 0.9210 - val_loss: 0.8639 - val_accuracy: 0.7485\n",
      "Epoch 1231/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2055 - accuracy: 0.9192 - val_loss: 0.8108 - val_accuracy: 0.7554\n",
      "Epoch 1232/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2018 - accuracy: 0.9203 - val_loss: 0.8239 - val_accuracy: 0.7553\n",
      "Epoch 1233/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1946 - accuracy: 0.9231 - val_loss: 0.8585 - val_accuracy: 0.7452\n",
      "Epoch 1234/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.2008 - accuracy: 0.9208 - val_loss: 0.7796 - val_accuracy: 0.7637\n",
      "Epoch 1235/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1954 - accuracy: 0.9237 - val_loss: 0.8405 - val_accuracy: 0.7477\n",
      "Epoch 1236/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2026 - accuracy: 0.9204 - val_loss: 0.8044 - val_accuracy: 0.7586\n",
      "Epoch 1237/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1998 - accuracy: 0.9217 - val_loss: 0.8432 - val_accuracy: 0.7481\n",
      "Epoch 1238/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2012 - accuracy: 0.9216 - val_loss: 0.8031 - val_accuracy: 0.7553\n",
      "Epoch 1239/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1982 - accuracy: 0.9225 - val_loss: 0.7838 - val_accuracy: 0.7648\n",
      "Epoch 1240/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1994 - accuracy: 0.9219 - val_loss: 0.8428 - val_accuracy: 0.7436\n",
      "Epoch 1241/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1995 - accuracy: 0.9223 - val_loss: 0.8699 - val_accuracy: 0.7466\n",
      "Epoch 1242/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.2000 - accuracy: 0.9213 - val_loss: 0.7721 - val_accuracy: 0.7640\n",
      "Epoch 1243/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1933 - accuracy: 0.9248 - val_loss: 0.8142 - val_accuracy: 0.7607\n",
      "Epoch 1244/8000\n",
      "1463/1463 [==============================] - 12s 9ms/step - loss: 0.1958 - accuracy: 0.9234 - val_loss: 0.7967 - val_accuracy: 0.7577\n",
      "Epoch 1245/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1938 - accuracy: 0.9243 - val_loss: 0.7969 - val_accuracy: 0.7575\n",
      "Epoch 1246/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1950 - accuracy: 0.9234 - val_loss: 0.8121 - val_accuracy: 0.7568\n",
      "Epoch 1247/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.2026 - accuracy: 0.9213 - val_loss: 0.8586 - val_accuracy: 0.7472\n",
      "Epoch 1248/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1967 - accuracy: 0.9234 - val_loss: 0.8889 - val_accuracy: 0.7403\n",
      "Epoch 1249/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1911 - accuracy: 0.9258 - val_loss: 0.7932 - val_accuracy: 0.7624\n",
      "Epoch 1250/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1976 - accuracy: 0.9225 - val_loss: 0.8613 - val_accuracy: 0.7510\n",
      "Epoch 1251/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1971 - accuracy: 0.9227 - val_loss: 0.8158 - val_accuracy: 0.7556\n",
      "Epoch 1252/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1980 - accuracy: 0.9226 - val_loss: 0.8134 - val_accuracy: 0.7596\n",
      "Epoch 1253/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1979 - accuracy: 0.9226 - val_loss: 0.8109 - val_accuracy: 0.7581\n",
      "Epoch 1254/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.2001 - accuracy: 0.9215 - val_loss: 0.8287 - val_accuracy: 0.7537\n",
      "Epoch 1255/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.1961 - accuracy: 0.9233 - val_loss: 0.8402 - val_accuracy: 0.7510\n",
      "Epoch 1256/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.1973 - accuracy: 0.9228 - val_loss: 0.8317 - val_accuracy: 0.7579\n",
      "Epoch 1257/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1939 - accuracy: 0.9245 - val_loss: 0.8404 - val_accuracy: 0.7514\n",
      "Epoch 1258/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1913 - accuracy: 0.9250 - val_loss: 0.8166 - val_accuracy: 0.7551\n",
      "Epoch 1259/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1948 - accuracy: 0.9242 - val_loss: 0.7596 - val_accuracy: 0.7700\n",
      "Epoch 1260/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1940 - accuracy: 0.9232 - val_loss: 0.8488 - val_accuracy: 0.7523\n",
      "Epoch 1261/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1900 - accuracy: 0.9251 - val_loss: 0.8072 - val_accuracy: 0.7592\n",
      "Epoch 1262/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1990 - accuracy: 0.9221 - val_loss: 0.8985 - val_accuracy: 0.7387\n",
      "Epoch 1263/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1925 - accuracy: 0.9255 - val_loss: 0.7801 - val_accuracy: 0.7668\n",
      "Epoch 1264/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1918 - accuracy: 0.9252 - val_loss: 0.8801 - val_accuracy: 0.7469\n",
      "Epoch 1265/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1916 - accuracy: 0.9246 - val_loss: 0.7838 - val_accuracy: 0.7627\n",
      "Epoch 1266/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1890 - accuracy: 0.9265 - val_loss: 0.8114 - val_accuracy: 0.7585\n",
      "Epoch 1267/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1947 - accuracy: 0.9230 - val_loss: 0.8148 - val_accuracy: 0.7571\n",
      "Epoch 1268/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1973 - accuracy: 0.9229 - val_loss: 0.8153 - val_accuracy: 0.7568\n",
      "Epoch 1269/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1897 - accuracy: 0.9264 - val_loss: 0.8852 - val_accuracy: 0.7469\n",
      "Epoch 1270/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1926 - accuracy: 0.9253 - val_loss: 0.8166 - val_accuracy: 0.7548\n",
      "Epoch 1271/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1968 - accuracy: 0.9232 - val_loss: 0.8153 - val_accuracy: 0.7568\n",
      "Epoch 1272/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1920 - accuracy: 0.9245 - val_loss: 0.8147 - val_accuracy: 0.7566\n",
      "Epoch 1273/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1882 - accuracy: 0.9268 - val_loss: 0.9166 - val_accuracy: 0.7347\n",
      "Epoch 1274/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1973 - accuracy: 0.9226 - val_loss: 0.8099 - val_accuracy: 0.7616\n",
      "Epoch 1275/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1874 - accuracy: 0.9262 - val_loss: 0.8041 - val_accuracy: 0.7591\n",
      "Epoch 1276/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1913 - accuracy: 0.9248 - val_loss: 0.8092 - val_accuracy: 0.7593\n",
      "Epoch 1277/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1911 - accuracy: 0.9257 - val_loss: 0.7952 - val_accuracy: 0.7582\n",
      "Epoch 1278/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1878 - accuracy: 0.9264 - val_loss: 0.7895 - val_accuracy: 0.7623\n",
      "Epoch 1279/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1972 - accuracy: 0.9243 - val_loss: 0.7937 - val_accuracy: 0.7580\n",
      "Epoch 1280/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1928 - accuracy: 0.9255 - val_loss: 0.8049 - val_accuracy: 0.7611\n",
      "Epoch 1281/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1889 - accuracy: 0.9263 - val_loss: 0.8560 - val_accuracy: 0.7546\n",
      "Epoch 1282/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2116 - accuracy: 0.9179 - val_loss: 0.7782 - val_accuracy: 0.7667\n",
      "Epoch 1283/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2051 - accuracy: 0.9196 - val_loss: 0.8718 - val_accuracy: 0.7469\n",
      "Epoch 1284/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2047 - accuracy: 0.9204 - val_loss: 0.8117 - val_accuracy: 0.7579\n",
      "Epoch 1285/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1989 - accuracy: 0.9219 - val_loss: 0.8089 - val_accuracy: 0.7638\n",
      "Epoch 1286/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1995 - accuracy: 0.9209 - val_loss: 0.8202 - val_accuracy: 0.7583\n",
      "Epoch 1287/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2069 - accuracy: 0.9189 - val_loss: 0.8402 - val_accuracy: 0.7540\n",
      "Epoch 1288/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2107 - accuracy: 0.9182 - val_loss: 0.7952 - val_accuracy: 0.7623\n",
      "Epoch 1289/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1978 - accuracy: 0.9225 - val_loss: 0.8590 - val_accuracy: 0.7477\n",
      "Epoch 1290/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2050 - accuracy: 0.9205 - val_loss: 0.7898 - val_accuracy: 0.7635\n",
      "Epoch 1291/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2000 - accuracy: 0.9212 - val_loss: 0.8071 - val_accuracy: 0.7606\n",
      "Epoch 1292/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1942 - accuracy: 0.9244 - val_loss: 0.8335 - val_accuracy: 0.7519\n",
      "Epoch 1293/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2025 - accuracy: 0.9211 - val_loss: 0.8042 - val_accuracy: 0.7591\n",
      "Epoch 1294/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1939 - accuracy: 0.9239 - val_loss: 0.8178 - val_accuracy: 0.7536\n",
      "Epoch 1295/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1971 - accuracy: 0.9233 - val_loss: 0.8143 - val_accuracy: 0.7593\n",
      "Epoch 1296/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1968 - accuracy: 0.9226 - val_loss: 0.8326 - val_accuracy: 0.7528\n",
      "Epoch 1297/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1969 - accuracy: 0.9232 - val_loss: 0.8171 - val_accuracy: 0.7588\n",
      "Epoch 1298/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1978 - accuracy: 0.9237 - val_loss: 0.8130 - val_accuracy: 0.7590\n",
      "Epoch 1299/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1993 - accuracy: 0.9219 - val_loss: 0.7787 - val_accuracy: 0.7672\n",
      "Epoch 1300/8000\n",
      "1457/1463 [============================>.] - ETA: 0s - loss: 0.1956 - accuracy: 0.9238\n",
      "Epoch 1300: saving model to ./training_ckpt_20240109205949_v8_240109_d10000_n4096_b64_e8000_c100_Adamax\\cp-000001300.ckpt\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1956 - accuracy: 0.9238 - val_loss: 0.8536 - val_accuracy: 0.7477\n",
      "Epoch 1301/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1953 - accuracy: 0.9234 - val_loss: 0.8183 - val_accuracy: 0.7587\n",
      "Epoch 1302/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2021 - accuracy: 0.9194 - val_loss: 0.8355 - val_accuracy: 0.7528\n",
      "Epoch 1303/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.2129 - accuracy: 0.9162 - val_loss: 0.8146 - val_accuracy: 0.7588\n",
      "Epoch 1304/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.2017 - accuracy: 0.9190 - val_loss: 0.8537 - val_accuracy: 0.7523\n",
      "Epoch 1305/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2102 - accuracy: 0.9160 - val_loss: 0.8230 - val_accuracy: 0.7588\n",
      "Epoch 1306/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.2125 - accuracy: 0.9157 - val_loss: 0.8595 - val_accuracy: 0.7477\n",
      "Epoch 1307/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2069 - accuracy: 0.9181 - val_loss: 0.8129 - val_accuracy: 0.7606\n",
      "Epoch 1308/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2070 - accuracy: 0.9177 - val_loss: 0.8071 - val_accuracy: 0.7586\n",
      "Epoch 1309/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2057 - accuracy: 0.9189 - val_loss: 0.8462 - val_accuracy: 0.7508\n",
      "Epoch 1310/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2154 - accuracy: 0.9156 - val_loss: 0.8270 - val_accuracy: 0.7562\n",
      "Epoch 1311/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2025 - accuracy: 0.9195 - val_loss: 0.8365 - val_accuracy: 0.7537\n",
      "Epoch 1312/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.2052 - accuracy: 0.9186 - val_loss: 0.8022 - val_accuracy: 0.7615\n",
      "Epoch 1313/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2115 - accuracy: 0.9176 - val_loss: 0.8660 - val_accuracy: 0.7433\n",
      "Epoch 1314/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2063 - accuracy: 0.9184 - val_loss: 0.8372 - val_accuracy: 0.7538\n",
      "Epoch 1315/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2095 - accuracy: 0.9171 - val_loss: 0.8217 - val_accuracy: 0.7573\n",
      "Epoch 1316/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2092 - accuracy: 0.9169 - val_loss: 0.8699 - val_accuracy: 0.7479\n",
      "Epoch 1317/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2076 - accuracy: 0.9176 - val_loss: 0.9074 - val_accuracy: 0.7528\n",
      "Epoch 1318/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2059 - accuracy: 0.9192 - val_loss: 0.8943 - val_accuracy: 0.7427\n",
      "Epoch 1319/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2013 - accuracy: 0.9201 - val_loss: 0.7948 - val_accuracy: 0.7608\n",
      "Epoch 1320/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1975 - accuracy: 0.9214 - val_loss: 0.8021 - val_accuracy: 0.7654\n",
      "Epoch 1321/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2057 - accuracy: 0.9195 - val_loss: 0.8182 - val_accuracy: 0.7591\n",
      "Epoch 1322/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2088 - accuracy: 0.9183 - val_loss: 0.8139 - val_accuracy: 0.7603\n",
      "Epoch 1323/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2045 - accuracy: 0.9187 - val_loss: 0.8077 - val_accuracy: 0.7608\n",
      "Epoch 1324/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2036 - accuracy: 0.9195 - val_loss: 0.9031 - val_accuracy: 0.7386\n",
      "Epoch 1325/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1995 - accuracy: 0.9207 - val_loss: 0.8807 - val_accuracy: 0.7442\n",
      "Epoch 1326/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2110 - accuracy: 0.9171 - val_loss: 0.8280 - val_accuracy: 0.7589\n",
      "Epoch 1327/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2074 - accuracy: 0.9176 - val_loss: 0.8348 - val_accuracy: 0.7529\n",
      "Epoch 1328/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2056 - accuracy: 0.9191 - val_loss: 0.8177 - val_accuracy: 0.7600\n",
      "Epoch 1329/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2050 - accuracy: 0.9190 - val_loss: 0.8593 - val_accuracy: 0.7520\n",
      "Epoch 1330/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2026 - accuracy: 0.9196 - val_loss: 0.8990 - val_accuracy: 0.7428\n",
      "Epoch 1331/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2049 - accuracy: 0.9193 - val_loss: 0.8550 - val_accuracy: 0.7487\n",
      "Epoch 1332/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2020 - accuracy: 0.9200 - val_loss: 0.8223 - val_accuracy: 0.7588\n",
      "Epoch 1333/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2060 - accuracy: 0.9187 - val_loss: 0.8515 - val_accuracy: 0.7534\n",
      "Epoch 1334/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2010 - accuracy: 0.9199 - val_loss: 0.8356 - val_accuracy: 0.7579\n",
      "Epoch 1335/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2014 - accuracy: 0.9205 - val_loss: 0.8970 - val_accuracy: 0.7447\n",
      "Epoch 1336/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2057 - accuracy: 0.9198 - val_loss: 0.8858 - val_accuracy: 0.7509\n",
      "Epoch 1337/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1989 - accuracy: 0.9210 - val_loss: 0.7851 - val_accuracy: 0.7680\n",
      "Epoch 1338/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1987 - accuracy: 0.9219 - val_loss: 0.8435 - val_accuracy: 0.7544\n",
      "Epoch 1339/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1999 - accuracy: 0.9214 - val_loss: 0.8548 - val_accuracy: 0.7503\n",
      "Epoch 1340/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2020 - accuracy: 0.9196 - val_loss: 0.8709 - val_accuracy: 0.7484\n",
      "Epoch 1341/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2006 - accuracy: 0.9200 - val_loss: 0.8210 - val_accuracy: 0.7587\n",
      "Epoch 1342/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2055 - accuracy: 0.9197 - val_loss: 0.8131 - val_accuracy: 0.7613\n",
      "Epoch 1343/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2043 - accuracy: 0.9200 - val_loss: 0.7942 - val_accuracy: 0.7660\n",
      "Epoch 1344/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2050 - accuracy: 0.9196 - val_loss: 0.8991 - val_accuracy: 0.7459\n",
      "Epoch 1345/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.2004 - accuracy: 0.9201 - val_loss: 0.8684 - val_accuracy: 0.7526\n",
      "Epoch 1346/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2040 - accuracy: 0.9188 - val_loss: 0.8385 - val_accuracy: 0.7538\n",
      "Epoch 1347/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2043 - accuracy: 0.9202 - val_loss: 0.8962 - val_accuracy: 0.7412\n",
      "Epoch 1348/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1985 - accuracy: 0.9210 - val_loss: 0.8189 - val_accuracy: 0.7642\n",
      "Epoch 1349/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2022 - accuracy: 0.9200 - val_loss: 0.8005 - val_accuracy: 0.7630\n",
      "Epoch 1350/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2019 - accuracy: 0.9196 - val_loss: 0.8104 - val_accuracy: 0.7577\n",
      "Epoch 1351/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1996 - accuracy: 0.9212 - val_loss: 0.8283 - val_accuracy: 0.7561\n",
      "Epoch 1352/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.2001 - accuracy: 0.9215 - val_loss: 0.8330 - val_accuracy: 0.7611\n",
      "Epoch 1353/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1997 - accuracy: 0.9208 - val_loss: 0.8240 - val_accuracy: 0.7581\n",
      "Epoch 1354/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2020 - accuracy: 0.9206 - val_loss: 0.8291 - val_accuracy: 0.7599\n",
      "Epoch 1355/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1982 - accuracy: 0.9222 - val_loss: 0.8166 - val_accuracy: 0.7623\n",
      "Epoch 1356/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2031 - accuracy: 0.9209 - val_loss: 0.9005 - val_accuracy: 0.7536\n",
      "Epoch 1357/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2056 - accuracy: 0.9188 - val_loss: 0.8834 - val_accuracy: 0.7478\n",
      "Epoch 1358/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2036 - accuracy: 0.9207 - val_loss: 0.8168 - val_accuracy: 0.7622\n",
      "Epoch 1359/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1988 - accuracy: 0.9214 - val_loss: 0.8460 - val_accuracy: 0.7525\n",
      "Epoch 1360/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2010 - accuracy: 0.9215 - val_loss: 0.8406 - val_accuracy: 0.7571\n",
      "Epoch 1361/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1995 - accuracy: 0.9203 - val_loss: 0.8264 - val_accuracy: 0.7586\n",
      "Epoch 1362/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2019 - accuracy: 0.9211 - val_loss: 0.8525 - val_accuracy: 0.7512\n",
      "Epoch 1363/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1961 - accuracy: 0.9226 - val_loss: 0.8625 - val_accuracy: 0.7552\n",
      "Epoch 1364/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1970 - accuracy: 0.9217 - val_loss: 0.9176 - val_accuracy: 0.7450\n",
      "Epoch 1365/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1961 - accuracy: 0.9222 - val_loss: 0.7988 - val_accuracy: 0.7634\n",
      "Epoch 1366/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1921 - accuracy: 0.9236 - val_loss: 0.7846 - val_accuracy: 0.7666\n",
      "Epoch 1367/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1986 - accuracy: 0.9216 - val_loss: 0.8121 - val_accuracy: 0.7626\n",
      "Epoch 1368/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1963 - accuracy: 0.9236 - val_loss: 0.8155 - val_accuracy: 0.7621\n",
      "Epoch 1369/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1954 - accuracy: 0.9229 - val_loss: 0.8240 - val_accuracy: 0.7619\n",
      "Epoch 1370/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1946 - accuracy: 0.9234 - val_loss: 0.8259 - val_accuracy: 0.7577\n",
      "Epoch 1371/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2012 - accuracy: 0.9205 - val_loss: 0.7924 - val_accuracy: 0.7668\n",
      "Epoch 1372/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.1970 - accuracy: 0.9229 - val_loss: 0.8587 - val_accuracy: 0.7507\n",
      "Epoch 1373/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2021 - accuracy: 0.9208 - val_loss: 0.8231 - val_accuracy: 0.7599\n",
      "Epoch 1374/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1992 - accuracy: 0.9215 - val_loss: 0.8360 - val_accuracy: 0.7566\n",
      "Epoch 1375/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1972 - accuracy: 0.9220 - val_loss: 0.7928 - val_accuracy: 0.7693\n",
      "Epoch 1376/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2027 - accuracy: 0.9202 - val_loss: 0.8413 - val_accuracy: 0.7559\n",
      "Epoch 1377/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1955 - accuracy: 0.9231 - val_loss: 0.8470 - val_accuracy: 0.7571\n",
      "Epoch 1378/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1966 - accuracy: 0.9219 - val_loss: 0.9148 - val_accuracy: 0.7479\n",
      "Epoch 1379/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1960 - accuracy: 0.9232 - val_loss: 0.8134 - val_accuracy: 0.7671\n",
      "Epoch 1380/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1969 - accuracy: 0.9224 - val_loss: 0.8259 - val_accuracy: 0.7595\n",
      "Epoch 1381/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1928 - accuracy: 0.9235 - val_loss: 0.8462 - val_accuracy: 0.7561\n",
      "Epoch 1382/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1990 - accuracy: 0.9220 - val_loss: 0.8251 - val_accuracy: 0.7615\n",
      "Epoch 1383/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1924 - accuracy: 0.9245 - val_loss: 0.8194 - val_accuracy: 0.7663\n",
      "Epoch 1384/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1959 - accuracy: 0.9232 - val_loss: 0.8505 - val_accuracy: 0.7575\n",
      "Epoch 1385/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1950 - accuracy: 0.9237 - val_loss: 0.8188 - val_accuracy: 0.7626\n",
      "Epoch 1386/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1891 - accuracy: 0.9258 - val_loss: 0.8360 - val_accuracy: 0.7540\n",
      "Epoch 1387/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1946 - accuracy: 0.9234 - val_loss: 0.9448 - val_accuracy: 0.7399\n",
      "Epoch 1388/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1989 - accuracy: 0.9227 - val_loss: 0.8528 - val_accuracy: 0.7547\n",
      "Epoch 1389/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1929 - accuracy: 0.9235 - val_loss: 0.8590 - val_accuracy: 0.7547\n",
      "Epoch 1390/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1951 - accuracy: 0.9237 - val_loss: 0.8305 - val_accuracy: 0.7615\n",
      "Epoch 1391/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1912 - accuracy: 0.9250 - val_loss: 0.8318 - val_accuracy: 0.7579\n",
      "Epoch 1392/8000\n",
      "1463/1463 [==============================] - 12s 9ms/step - loss: 0.1937 - accuracy: 0.9241 - val_loss: 0.9023 - val_accuracy: 0.7430\n",
      "Epoch 1393/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1960 - accuracy: 0.9234 - val_loss: 0.8454 - val_accuracy: 0.7607\n",
      "Epoch 1394/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1902 - accuracy: 0.9241 - val_loss: 0.7915 - val_accuracy: 0.7677\n",
      "Epoch 1395/8000\n",
      "1463/1463 [==============================] - 12s 9ms/step - loss: 0.2006 - accuracy: 0.9213 - val_loss: 0.8953 - val_accuracy: 0.7457\n",
      "Epoch 1396/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1999 - accuracy: 0.9222 - val_loss: 0.8612 - val_accuracy: 0.7479\n",
      "Epoch 1397/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1995 - accuracy: 0.9212 - val_loss: 0.8417 - val_accuracy: 0.7559\n",
      "Epoch 1398/8000\n",
      "1463/1463 [==============================] - 12s 9ms/step - loss: 0.1960 - accuracy: 0.9234 - val_loss: 0.8164 - val_accuracy: 0.7648\n",
      "Epoch 1399/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1944 - accuracy: 0.9240 - val_loss: 0.8438 - val_accuracy: 0.7604\n",
      "Epoch 1400/8000\n",
      "1463/1463 [==============================] - ETA: 0s - loss: 0.1954 - accuracy: 0.9231\n",
      "Epoch 1400: saving model to ./training_ckpt_20240109205949_v8_240109_d10000_n4096_b64_e8000_c100_Adamax\\cp-000001400.ckpt\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1954 - accuracy: 0.9231 - val_loss: 0.8698 - val_accuracy: 0.7515\n",
      "Epoch 1401/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1954 - accuracy: 0.9235 - val_loss: 0.8289 - val_accuracy: 0.7617\n",
      "Epoch 1402/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1973 - accuracy: 0.9220 - val_loss: 0.8091 - val_accuracy: 0.7614\n",
      "Epoch 1403/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1980 - accuracy: 0.9214 - val_loss: 0.8164 - val_accuracy: 0.7639\n",
      "Epoch 1404/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1969 - accuracy: 0.9228 - val_loss: 0.8681 - val_accuracy: 0.7520\n",
      "Epoch 1405/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1949 - accuracy: 0.9241 - val_loss: 0.8725 - val_accuracy: 0.7505\n",
      "Epoch 1406/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1979 - accuracy: 0.9216 - val_loss: 0.8594 - val_accuracy: 0.7485\n",
      "Epoch 1407/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1917 - accuracy: 0.9239 - val_loss: 0.8775 - val_accuracy: 0.7486\n",
      "Epoch 1408/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1956 - accuracy: 0.9229 - val_loss: 0.8176 - val_accuracy: 0.7626\n",
      "Epoch 1409/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1920 - accuracy: 0.9245 - val_loss: 0.7869 - val_accuracy: 0.7669\n",
      "Epoch 1410/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2018 - accuracy: 0.9205 - val_loss: 0.8029 - val_accuracy: 0.7654\n",
      "Epoch 1411/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.2009 - accuracy: 0.9208 - val_loss: 0.7949 - val_accuracy: 0.7676\n",
      "Epoch 1412/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1947 - accuracy: 0.9231 - val_loss: 0.8834 - val_accuracy: 0.7438\n",
      "Epoch 1413/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1958 - accuracy: 0.9224 - val_loss: 0.8130 - val_accuracy: 0.7649\n",
      "Epoch 1414/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.1958 - accuracy: 0.9230 - val_loss: 0.8008 - val_accuracy: 0.7682\n",
      "Epoch 1415/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1900 - accuracy: 0.9251 - val_loss: 0.8748 - val_accuracy: 0.7509\n",
      "Epoch 1416/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1897 - accuracy: 0.9252 - val_loss: 0.8154 - val_accuracy: 0.7614\n",
      "Epoch 1417/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1921 - accuracy: 0.9246 - val_loss: 0.7893 - val_accuracy: 0.7705\n",
      "Epoch 1418/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1950 - accuracy: 0.9235 - val_loss: 0.8238 - val_accuracy: 0.7607\n",
      "Epoch 1419/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1892 - accuracy: 0.9255 - val_loss: 0.8368 - val_accuracy: 0.7585\n",
      "Epoch 1420/8000\n",
      "1463/1463 [==============================] - 12s 9ms/step - loss: 0.1940 - accuracy: 0.9237 - val_loss: 0.8589 - val_accuracy: 0.7503\n",
      "Epoch 1421/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1965 - accuracy: 0.9229 - val_loss: 0.8125 - val_accuracy: 0.7638\n",
      "Epoch 1422/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1928 - accuracy: 0.9233 - val_loss: 0.8357 - val_accuracy: 0.7573\n",
      "Epoch 1423/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1906 - accuracy: 0.9240 - val_loss: 0.8547 - val_accuracy: 0.7561\n",
      "Epoch 1424/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1966 - accuracy: 0.9226 - val_loss: 0.7958 - val_accuracy: 0.7645\n",
      "Epoch 1425/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1931 - accuracy: 0.9249 - val_loss: 0.8472 - val_accuracy: 0.7549\n",
      "Epoch 1426/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1920 - accuracy: 0.9253 - val_loss: 0.8553 - val_accuracy: 0.7579\n",
      "Epoch 1427/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1918 - accuracy: 0.9257 - val_loss: 0.8150 - val_accuracy: 0.7613\n",
      "Epoch 1428/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1912 - accuracy: 0.9250 - val_loss: 0.8232 - val_accuracy: 0.7629\n",
      "Epoch 1429/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1966 - accuracy: 0.9230 - val_loss: 0.7835 - val_accuracy: 0.7696\n",
      "Epoch 1430/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1903 - accuracy: 0.9249 - val_loss: 0.8053 - val_accuracy: 0.7688\n",
      "Epoch 1431/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1939 - accuracy: 0.9239 - val_loss: 0.8472 - val_accuracy: 0.7567\n",
      "Epoch 1432/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1905 - accuracy: 0.9247 - val_loss: 0.8041 - val_accuracy: 0.7663\n",
      "Epoch 1433/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1908 - accuracy: 0.9249 - val_loss: 0.8309 - val_accuracy: 0.7577\n",
      "Epoch 1434/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1879 - accuracy: 0.9258 - val_loss: 0.8473 - val_accuracy: 0.7528\n",
      "Epoch 1435/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1940 - accuracy: 0.9233 - val_loss: 0.8224 - val_accuracy: 0.7640\n",
      "Epoch 1436/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1879 - accuracy: 0.9257 - val_loss: 0.9761 - val_accuracy: 0.7251\n",
      "Epoch 1437/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1902 - accuracy: 0.9260 - val_loss: 0.7790 - val_accuracy: 0.7715\n",
      "Epoch 1438/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1909 - accuracy: 0.9247 - val_loss: 0.8261 - val_accuracy: 0.7582\n",
      "Epoch 1439/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1879 - accuracy: 0.9259 - val_loss: 0.8476 - val_accuracy: 0.7591\n",
      "Epoch 1440/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1898 - accuracy: 0.9264 - val_loss: 0.8549 - val_accuracy: 0.7591\n",
      "Epoch 1441/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1919 - accuracy: 0.9251 - val_loss: 0.7878 - val_accuracy: 0.7673\n",
      "Epoch 1442/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1862 - accuracy: 0.9265 - val_loss: 0.8700 - val_accuracy: 0.7568\n",
      "Epoch 1443/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1904 - accuracy: 0.9254 - val_loss: 0.8067 - val_accuracy: 0.7647\n",
      "Epoch 1444/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1891 - accuracy: 0.9259 - val_loss: 0.8194 - val_accuracy: 0.7657\n",
      "Epoch 1445/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1907 - accuracy: 0.9254 - val_loss: 0.8221 - val_accuracy: 0.7628\n",
      "Epoch 1446/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1897 - accuracy: 0.9259 - val_loss: 0.8092 - val_accuracy: 0.7658\n",
      "Epoch 1447/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1919 - accuracy: 0.9243 - val_loss: 0.8064 - val_accuracy: 0.7668\n",
      "Epoch 1448/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1908 - accuracy: 0.9250 - val_loss: 0.7990 - val_accuracy: 0.7687\n",
      "Epoch 1449/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1878 - accuracy: 0.9266 - val_loss: 0.8022 - val_accuracy: 0.7660\n",
      "Epoch 1450/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1915 - accuracy: 0.9250 - val_loss: 0.8546 - val_accuracy: 0.7543\n",
      "Epoch 1451/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1893 - accuracy: 0.9249 - val_loss: 0.8952 - val_accuracy: 0.7429\n",
      "Epoch 1452/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1895 - accuracy: 0.9254 - val_loss: 0.8076 - val_accuracy: 0.7650\n",
      "Epoch 1453/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1895 - accuracy: 0.9259 - val_loss: 0.8066 - val_accuracy: 0.7672\n",
      "Epoch 1454/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1905 - accuracy: 0.9254 - val_loss: 0.8296 - val_accuracy: 0.7607\n",
      "Epoch 1455/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1870 - accuracy: 0.9262 - val_loss: 0.8044 - val_accuracy: 0.7649\n",
      "Epoch 1456/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1878 - accuracy: 0.9254 - val_loss: 0.8056 - val_accuracy: 0.7654\n",
      "Epoch 1457/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1912 - accuracy: 0.9251 - val_loss: 0.8041 - val_accuracy: 0.7639\n",
      "Epoch 1458/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1860 - accuracy: 0.9270 - val_loss: 0.8248 - val_accuracy: 0.7611\n",
      "Epoch 1459/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1923 - accuracy: 0.9235 - val_loss: 0.8301 - val_accuracy: 0.7597\n",
      "Epoch 1460/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1885 - accuracy: 0.9262 - val_loss: 0.7990 - val_accuracy: 0.7683\n",
      "Epoch 1461/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1876 - accuracy: 0.9262 - val_loss: 0.7998 - val_accuracy: 0.7675\n",
      "Epoch 1462/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1857 - accuracy: 0.9270 - val_loss: 0.8567 - val_accuracy: 0.7552\n",
      "Epoch 1463/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1866 - accuracy: 0.9272 - val_loss: 0.8285 - val_accuracy: 0.7620\n",
      "Epoch 1464/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1849 - accuracy: 0.9273 - val_loss: 0.8583 - val_accuracy: 0.7597\n",
      "Epoch 1465/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1824 - accuracy: 0.9290 - val_loss: 0.8055 - val_accuracy: 0.7647\n",
      "Epoch 1466/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1874 - accuracy: 0.9269 - val_loss: 0.9344 - val_accuracy: 0.7462\n",
      "Epoch 1467/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1853 - accuracy: 0.9272 - val_loss: 0.7879 - val_accuracy: 0.7670\n",
      "Epoch 1468/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1864 - accuracy: 0.9274 - val_loss: 0.8629 - val_accuracy: 0.7533\n",
      "Epoch 1469/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1913 - accuracy: 0.9254 - val_loss: 0.8123 - val_accuracy: 0.7657\n",
      "Epoch 1470/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1819 - accuracy: 0.9282 - val_loss: 0.8129 - val_accuracy: 0.7652\n",
      "Epoch 1471/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1895 - accuracy: 0.9263 - val_loss: 0.8896 - val_accuracy: 0.7517\n",
      "Epoch 1472/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1946 - accuracy: 0.9242 - val_loss: 0.8275 - val_accuracy: 0.7620\n",
      "Epoch 1473/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1842 - accuracy: 0.9284 - val_loss: 0.9177 - val_accuracy: 0.7490\n",
      "Epoch 1474/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1873 - accuracy: 0.9258 - val_loss: 0.7783 - val_accuracy: 0.7738\n",
      "Epoch 1475/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1880 - accuracy: 0.9259 - val_loss: 0.8511 - val_accuracy: 0.7573\n",
      "Epoch 1476/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1827 - accuracy: 0.9285 - val_loss: 0.8157 - val_accuracy: 0.7643\n",
      "Epoch 1477/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1902 - accuracy: 0.9260 - val_loss: 0.8389 - val_accuracy: 0.7617\n",
      "Epoch 1478/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1848 - accuracy: 0.9273 - val_loss: 0.8156 - val_accuracy: 0.7622\n",
      "Epoch 1479/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1871 - accuracy: 0.9274 - val_loss: 0.7955 - val_accuracy: 0.7704\n",
      "Epoch 1480/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1831 - accuracy: 0.9279 - val_loss: 0.8076 - val_accuracy: 0.7693\n",
      "Epoch 1481/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1836 - accuracy: 0.9296 - val_loss: 0.8450 - val_accuracy: 0.7576\n",
      "Epoch 1482/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1854 - accuracy: 0.9273 - val_loss: 0.8320 - val_accuracy: 0.7684\n",
      "Epoch 1483/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1838 - accuracy: 0.9291 - val_loss: 0.8150 - val_accuracy: 0.7668\n",
      "Epoch 1484/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1836 - accuracy: 0.9277 - val_loss: 0.8185 - val_accuracy: 0.7588\n",
      "Epoch 1485/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1874 - accuracy: 0.9275 - val_loss: 0.8880 - val_accuracy: 0.7517\n",
      "Epoch 1486/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1837 - accuracy: 0.9278 - val_loss: 0.8394 - val_accuracy: 0.7607\n",
      "Epoch 1487/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1884 - accuracy: 0.9272 - val_loss: 0.8120 - val_accuracy: 0.7671\n",
      "Epoch 1488/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1790 - accuracy: 0.9296 - val_loss: 0.8212 - val_accuracy: 0.7669\n",
      "Epoch 1489/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1802 - accuracy: 0.9298 - val_loss: 0.8204 - val_accuracy: 0.7651\n",
      "Epoch 1490/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1786 - accuracy: 0.9300 - val_loss: 0.8365 - val_accuracy: 0.7609\n",
      "Epoch 1491/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1825 - accuracy: 0.9284 - val_loss: 0.8250 - val_accuracy: 0.7643\n",
      "Epoch 1492/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1808 - accuracy: 0.9293 - val_loss: 0.9028 - val_accuracy: 0.7496\n",
      "Epoch 1493/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1808 - accuracy: 0.9296 - val_loss: 0.8384 - val_accuracy: 0.7606\n",
      "Epoch 1494/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1853 - accuracy: 0.9284 - val_loss: 0.7926 - val_accuracy: 0.7702\n",
      "Epoch 1495/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1772 - accuracy: 0.9313 - val_loss: 0.8224 - val_accuracy: 0.7620\n",
      "Epoch 1496/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1851 - accuracy: 0.9270 - val_loss: 0.8162 - val_accuracy: 0.7688\n",
      "Epoch 1497/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1870 - accuracy: 0.9266 - val_loss: 0.9003 - val_accuracy: 0.7518\n",
      "Epoch 1498/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1839 - accuracy: 0.9285 - val_loss: 0.8245 - val_accuracy: 0.7655\n",
      "Epoch 1499/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1813 - accuracy: 0.9297 - val_loss: 0.7984 - val_accuracy: 0.7709\n",
      "Epoch 1500/8000\n",
      "1460/1463 [============================>.] - ETA: 0s - loss: 0.1896 - accuracy: 0.9269\n",
      "Epoch 1500: saving model to ./training_ckpt_20240109205949_v8_240109_d10000_n4096_b64_e8000_c100_Adamax\\cp-000001500.ckpt\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1895 - accuracy: 0.9269 - val_loss: 0.7876 - val_accuracy: 0.7703\n",
      "Epoch 1501/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1798 - accuracy: 0.9301 - val_loss: 0.8322 - val_accuracy: 0.7652\n",
      "Epoch 1502/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1818 - accuracy: 0.9291 - val_loss: 0.8334 - val_accuracy: 0.7620\n",
      "Epoch 1503/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1805 - accuracy: 0.9284 - val_loss: 0.7997 - val_accuracy: 0.7697\n",
      "Epoch 1504/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1891 - accuracy: 0.9255 - val_loss: 0.8741 - val_accuracy: 0.7618\n",
      "Epoch 1505/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1847 - accuracy: 0.9280 - val_loss: 0.8496 - val_accuracy: 0.7647\n",
      "Epoch 1506/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1803 - accuracy: 0.9300 - val_loss: 0.7927 - val_accuracy: 0.7744\n",
      "Epoch 1507/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1791 - accuracy: 0.9305 - val_loss: 0.7880 - val_accuracy: 0.7734\n",
      "Epoch 1508/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1956 - accuracy: 0.9239 - val_loss: 0.7905 - val_accuracy: 0.7717\n",
      "Epoch 1509/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1833 - accuracy: 0.9281 - val_loss: 0.8208 - val_accuracy: 0.7692\n",
      "Epoch 1510/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1844 - accuracy: 0.9280 - val_loss: 0.8478 - val_accuracy: 0.7570\n",
      "Epoch 1511/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1897 - accuracy: 0.9262 - val_loss: 0.8345 - val_accuracy: 0.7628\n",
      "Epoch 1512/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1822 - accuracy: 0.9287 - val_loss: 0.7953 - val_accuracy: 0.7673\n",
      "Epoch 1513/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1833 - accuracy: 0.9280 - val_loss: 0.8567 - val_accuracy: 0.7569\n",
      "Epoch 1514/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1791 - accuracy: 0.9296 - val_loss: 0.7940 - val_accuracy: 0.7683\n",
      "Epoch 1515/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1746 - accuracy: 0.9309 - val_loss: 0.8063 - val_accuracy: 0.7708\n",
      "Epoch 1516/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1845 - accuracy: 0.9274 - val_loss: 0.8207 - val_accuracy: 0.7618\n",
      "Epoch 1517/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1788 - accuracy: 0.9295 - val_loss: 0.7876 - val_accuracy: 0.7730\n",
      "Epoch 1518/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1848 - accuracy: 0.9285 - val_loss: 0.7734 - val_accuracy: 0.7759\n",
      "Epoch 1519/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1766 - accuracy: 0.9306 - val_loss: 0.7945 - val_accuracy: 0.7695\n",
      "Epoch 1520/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1822 - accuracy: 0.9290 - val_loss: 0.8347 - val_accuracy: 0.7641\n",
      "Epoch 1521/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1845 - accuracy: 0.9282 - val_loss: 0.8361 - val_accuracy: 0.7605\n",
      "Epoch 1522/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1737 - accuracy: 0.9333 - val_loss: 0.7966 - val_accuracy: 0.7667\n",
      "Epoch 1523/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1764 - accuracy: 0.9302 - val_loss: 0.8592 - val_accuracy: 0.7601\n",
      "Epoch 1524/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1758 - accuracy: 0.9313 - val_loss: 0.8422 - val_accuracy: 0.7618\n",
      "Epoch 1525/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1707 - accuracy: 0.9331 - val_loss: 0.7973 - val_accuracy: 0.7720\n",
      "Epoch 1526/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1750 - accuracy: 0.9316 - val_loss: 0.8001 - val_accuracy: 0.7695\n",
      "Epoch 1527/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1788 - accuracy: 0.9301 - val_loss: 0.8336 - val_accuracy: 0.7676\n",
      "Epoch 1528/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1748 - accuracy: 0.9318 - val_loss: 0.7772 - val_accuracy: 0.7791\n",
      "Epoch 1529/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1813 - accuracy: 0.9300 - val_loss: 0.8024 - val_accuracy: 0.7643\n",
      "Epoch 1530/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1823 - accuracy: 0.9292 - val_loss: 0.8358 - val_accuracy: 0.7581\n",
      "Epoch 1531/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1779 - accuracy: 0.9305 - val_loss: 0.8236 - val_accuracy: 0.7679\n",
      "Epoch 1532/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1784 - accuracy: 0.9298 - val_loss: 0.7820 - val_accuracy: 0.7753\n",
      "Epoch 1533/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1768 - accuracy: 0.9311 - val_loss: 0.8061 - val_accuracy: 0.7706\n",
      "Epoch 1534/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1783 - accuracy: 0.9309 - val_loss: 0.7934 - val_accuracy: 0.7713\n",
      "Epoch 1535/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1754 - accuracy: 0.9322 - val_loss: 0.7785 - val_accuracy: 0.7729\n",
      "Epoch 1536/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1832 - accuracy: 0.9288 - val_loss: 0.8157 - val_accuracy: 0.7683\n",
      "Epoch 1537/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1772 - accuracy: 0.9310 - val_loss: 0.8368 - val_accuracy: 0.7641\n",
      "Epoch 1538/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1757 - accuracy: 0.9313 - val_loss: 0.8147 - val_accuracy: 0.7689\n",
      "Epoch 1539/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1775 - accuracy: 0.9317 - val_loss: 0.7657 - val_accuracy: 0.7762\n",
      "Epoch 1540/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1746 - accuracy: 0.9325 - val_loss: 0.9158 - val_accuracy: 0.7449\n",
      "Epoch 1541/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1774 - accuracy: 0.9308 - val_loss: 0.8719 - val_accuracy: 0.7538\n",
      "Epoch 1542/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1777 - accuracy: 0.9311 - val_loss: 0.8076 - val_accuracy: 0.7661\n",
      "Epoch 1543/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1785 - accuracy: 0.9311 - val_loss: 0.7893 - val_accuracy: 0.7749\n",
      "Epoch 1544/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1776 - accuracy: 0.9312 - val_loss: 0.8022 - val_accuracy: 0.7698\n",
      "Epoch 1545/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1756 - accuracy: 0.9320 - val_loss: 0.8012 - val_accuracy: 0.7694\n",
      "Epoch 1546/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1792 - accuracy: 0.9303 - val_loss: 0.8078 - val_accuracy: 0.7671\n",
      "Epoch 1547/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1760 - accuracy: 0.9314 - val_loss: 0.8750 - val_accuracy: 0.7633\n",
      "Epoch 1548/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1761 - accuracy: 0.9312 - val_loss: 0.8004 - val_accuracy: 0.7716\n",
      "Epoch 1549/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1815 - accuracy: 0.9298 - val_loss: 0.7938 - val_accuracy: 0.7720\n",
      "Epoch 1550/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1716 - accuracy: 0.9339 - val_loss: 0.8054 - val_accuracy: 0.7686\n",
      "Epoch 1551/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1746 - accuracy: 0.9319 - val_loss: 0.9024 - val_accuracy: 0.7492\n",
      "Epoch 1552/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1785 - accuracy: 0.9321 - val_loss: 0.7876 - val_accuracy: 0.7720\n",
      "Epoch 1553/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1768 - accuracy: 0.9322 - val_loss: 0.8022 - val_accuracy: 0.7670\n",
      "Epoch 1554/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1725 - accuracy: 0.9324 - val_loss: 0.7995 - val_accuracy: 0.7728\n",
      "Epoch 1555/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1748 - accuracy: 0.9319 - val_loss: 0.8024 - val_accuracy: 0.7695\n",
      "Epoch 1556/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1768 - accuracy: 0.9324 - val_loss: 0.7829 - val_accuracy: 0.7755\n",
      "Epoch 1557/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1795 - accuracy: 0.9306 - val_loss: 0.8034 - val_accuracy: 0.7665\n",
      "Epoch 1558/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1779 - accuracy: 0.9311 - val_loss: 0.8279 - val_accuracy: 0.7650\n",
      "Epoch 1559/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1781 - accuracy: 0.9315 - val_loss: 0.8252 - val_accuracy: 0.7703\n",
      "Epoch 1560/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1776 - accuracy: 0.9310 - val_loss: 1.0016 - val_accuracy: 0.7329\n",
      "Epoch 1561/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1707 - accuracy: 0.9340 - val_loss: 0.7578 - val_accuracy: 0.7797\n",
      "Epoch 1562/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1755 - accuracy: 0.9319 - val_loss: 0.7648 - val_accuracy: 0.7810\n",
      "Epoch 1563/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1740 - accuracy: 0.9320 - val_loss: 0.8379 - val_accuracy: 0.7604\n",
      "Epoch 1564/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1829 - accuracy: 0.9290 - val_loss: 0.8976 - val_accuracy: 0.7600\n",
      "Epoch 1565/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1780 - accuracy: 0.9313 - val_loss: 0.7710 - val_accuracy: 0.7785\n",
      "Epoch 1566/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1764 - accuracy: 0.9309 - val_loss: 0.7762 - val_accuracy: 0.7766\n",
      "Epoch 1567/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1807 - accuracy: 0.9305 - val_loss: 0.7987 - val_accuracy: 0.7767\n",
      "Epoch 1568/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1748 - accuracy: 0.9325 - val_loss: 0.7754 - val_accuracy: 0.7763\n",
      "Epoch 1569/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1718 - accuracy: 0.9338 - val_loss: 0.7895 - val_accuracy: 0.7767\n",
      "Epoch 1570/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1732 - accuracy: 0.9321 - val_loss: 0.8648 - val_accuracy: 0.7598\n",
      "Epoch 1571/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1745 - accuracy: 0.9336 - val_loss: 0.7691 - val_accuracy: 0.7784\n",
      "Epoch 1572/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1728 - accuracy: 0.9333 - val_loss: 0.8328 - val_accuracy: 0.7643\n",
      "Epoch 1573/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1739 - accuracy: 0.9331 - val_loss: 0.8365 - val_accuracy: 0.7611\n",
      "Epoch 1574/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1676 - accuracy: 0.9352 - val_loss: 0.7903 - val_accuracy: 0.7781\n",
      "Epoch 1575/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1720 - accuracy: 0.9323 - val_loss: 0.8020 - val_accuracy: 0.7711\n",
      "Epoch 1576/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1736 - accuracy: 0.9321 - val_loss: 0.8420 - val_accuracy: 0.7617\n",
      "Epoch 1577/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1712 - accuracy: 0.9341 - val_loss: 0.7896 - val_accuracy: 0.7731\n",
      "Epoch 1578/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1706 - accuracy: 0.9339 - val_loss: 0.7812 - val_accuracy: 0.7760\n",
      "Epoch 1579/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1726 - accuracy: 0.9328 - val_loss: 0.7902 - val_accuracy: 0.7769\n",
      "Epoch 1580/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1708 - accuracy: 0.9337 - val_loss: 0.7790 - val_accuracy: 0.7791\n",
      "Epoch 1581/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1712 - accuracy: 0.9342 - val_loss: 0.8274 - val_accuracy: 0.7686\n",
      "Epoch 1582/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1684 - accuracy: 0.9348 - val_loss: 0.8229 - val_accuracy: 0.7711\n",
      "Epoch 1583/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1786 - accuracy: 0.9310 - val_loss: 0.8486 - val_accuracy: 0.7613\n",
      "Epoch 1584/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1772 - accuracy: 0.9320 - val_loss: 0.7950 - val_accuracy: 0.7715\n",
      "Epoch 1585/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1722 - accuracy: 0.9337 - val_loss: 0.7822 - val_accuracy: 0.7727\n",
      "Epoch 1586/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1693 - accuracy: 0.9352 - val_loss: 0.8573 - val_accuracy: 0.7663\n",
      "Epoch 1587/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1725 - accuracy: 0.9333 - val_loss: 0.7691 - val_accuracy: 0.7791\n",
      "Epoch 1588/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1687 - accuracy: 0.9344 - val_loss: 0.7831 - val_accuracy: 0.7776\n",
      "Epoch 1589/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1720 - accuracy: 0.9330 - val_loss: 0.8143 - val_accuracy: 0.7679\n",
      "Epoch 1590/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1735 - accuracy: 0.9334 - val_loss: 0.8175 - val_accuracy: 0.7707\n",
      "Epoch 1591/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1694 - accuracy: 0.9342 - val_loss: 0.7886 - val_accuracy: 0.7763\n",
      "Epoch 1592/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1780 - accuracy: 0.9311 - val_loss: 0.7887 - val_accuracy: 0.7765\n",
      "Epoch 1593/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1701 - accuracy: 0.9348 - val_loss: 0.7702 - val_accuracy: 0.7788\n",
      "Epoch 1594/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1704 - accuracy: 0.9343 - val_loss: 0.7722 - val_accuracy: 0.7798\n",
      "Epoch 1595/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1718 - accuracy: 0.9337 - val_loss: 0.7820 - val_accuracy: 0.7751\n",
      "Epoch 1596/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1695 - accuracy: 0.9350 - val_loss: 0.7937 - val_accuracy: 0.7778\n",
      "Epoch 1597/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1699 - accuracy: 0.9346 - val_loss: 0.7884 - val_accuracy: 0.7751\n",
      "Epoch 1598/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1702 - accuracy: 0.9344 - val_loss: 0.8179 - val_accuracy: 0.7641\n",
      "Epoch 1599/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1694 - accuracy: 0.9355 - val_loss: 0.8631 - val_accuracy: 0.7586\n",
      "Epoch 1600/8000\n",
      "1459/1463 [============================>.] - ETA: 0s - loss: 0.1682 - accuracy: 0.9346\n",
      "Epoch 1600: saving model to ./training_ckpt_20240109205949_v8_240109_d10000_n4096_b64_e8000_c100_Adamax\\cp-000001600.ckpt\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1682 - accuracy: 0.9346 - val_loss: 0.9153 - val_accuracy: 0.7542\n",
      "Epoch 1601/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1716 - accuracy: 0.9344 - val_loss: 0.8463 - val_accuracy: 0.7611\n",
      "Epoch 1602/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1633 - accuracy: 0.9370 - val_loss: 0.8479 - val_accuracy: 0.7661\n",
      "Epoch 1603/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1670 - accuracy: 0.9360 - val_loss: 0.7925 - val_accuracy: 0.7706\n",
      "Epoch 1604/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1785 - accuracy: 0.9319 - val_loss: 0.8297 - val_accuracy: 0.7708\n",
      "Epoch 1605/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1709 - accuracy: 0.9344 - val_loss: 0.7732 - val_accuracy: 0.7780\n",
      "Epoch 1606/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1745 - accuracy: 0.9336 - val_loss: 0.7872 - val_accuracy: 0.7812\n",
      "Epoch 1607/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1714 - accuracy: 0.9336 - val_loss: 0.8375 - val_accuracy: 0.7630\n",
      "Epoch 1608/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1693 - accuracy: 0.9349 - val_loss: 0.7928 - val_accuracy: 0.7762\n",
      "Epoch 1609/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1658 - accuracy: 0.9355 - val_loss: 0.7957 - val_accuracy: 0.7789\n",
      "Epoch 1610/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1663 - accuracy: 0.9365 - val_loss: 0.7894 - val_accuracy: 0.7689\n",
      "Epoch 1611/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1726 - accuracy: 0.9334 - val_loss: 0.7696 - val_accuracy: 0.7768\n",
      "Epoch 1612/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1678 - accuracy: 0.9349 - val_loss: 0.8427 - val_accuracy: 0.7704\n",
      "Epoch 1613/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1855 - accuracy: 0.9299 - val_loss: 0.8522 - val_accuracy: 0.7687\n",
      "Epoch 1614/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1766 - accuracy: 0.9332 - val_loss: 0.8185 - val_accuracy: 0.7749\n",
      "Epoch 1615/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1717 - accuracy: 0.9337 - val_loss: 0.7824 - val_accuracy: 0.7783\n",
      "Epoch 1616/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1764 - accuracy: 0.9318 - val_loss: 0.7983 - val_accuracy: 0.7739\n",
      "Epoch 1617/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1778 - accuracy: 0.9320 - val_loss: 0.8032 - val_accuracy: 0.7694\n",
      "Epoch 1618/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1811 - accuracy: 0.9306 - val_loss: 0.7873 - val_accuracy: 0.7761\n",
      "Epoch 1619/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1646 - accuracy: 0.9360 - val_loss: 0.8027 - val_accuracy: 0.7741\n",
      "Epoch 1620/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1735 - accuracy: 0.9321 - val_loss: 0.8427 - val_accuracy: 0.7638\n",
      "Epoch 1621/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1744 - accuracy: 0.9328 - val_loss: 0.8317 - val_accuracy: 0.7666\n",
      "Epoch 1622/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1740 - accuracy: 0.9325 - val_loss: 0.8002 - val_accuracy: 0.7792\n",
      "Epoch 1623/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1857 - accuracy: 0.9288 - val_loss: 0.7834 - val_accuracy: 0.7788\n",
      "Epoch 1624/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1735 - accuracy: 0.9332 - val_loss: 0.8026 - val_accuracy: 0.7757\n",
      "Epoch 1625/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1740 - accuracy: 0.9331 - val_loss: 0.8867 - val_accuracy: 0.7578\n",
      "Epoch 1626/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1722 - accuracy: 0.9337 - val_loss: 0.8970 - val_accuracy: 0.7624\n",
      "Epoch 1627/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1780 - accuracy: 0.9317 - val_loss: 0.7873 - val_accuracy: 0.7764\n",
      "Epoch 1628/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1732 - accuracy: 0.9341 - val_loss: 0.8442 - val_accuracy: 0.7641\n",
      "Epoch 1629/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1740 - accuracy: 0.9328 - val_loss: 0.8372 - val_accuracy: 0.7676\n",
      "Epoch 1630/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1694 - accuracy: 0.9347 - val_loss: 0.7870 - val_accuracy: 0.7740\n",
      "Epoch 1631/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1711 - accuracy: 0.9342 - val_loss: 0.8033 - val_accuracy: 0.7695\n",
      "Epoch 1632/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1734 - accuracy: 0.9332 - val_loss: 0.8476 - val_accuracy: 0.7672\n",
      "Epoch 1633/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1743 - accuracy: 0.9317 - val_loss: 0.8414 - val_accuracy: 0.7608\n",
      "Epoch 1634/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1718 - accuracy: 0.9337 - val_loss: 0.8120 - val_accuracy: 0.7718\n",
      "Epoch 1635/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1696 - accuracy: 0.9348 - val_loss: 0.8303 - val_accuracy: 0.7708\n",
      "Epoch 1636/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1699 - accuracy: 0.9347 - val_loss: 0.7623 - val_accuracy: 0.7830\n",
      "Epoch 1637/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1643 - accuracy: 0.9367 - val_loss: 0.7916 - val_accuracy: 0.7755\n",
      "Epoch 1638/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1684 - accuracy: 0.9347 - val_loss: 0.7810 - val_accuracy: 0.7793\n",
      "Epoch 1639/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1660 - accuracy: 0.9357 - val_loss: 0.8068 - val_accuracy: 0.7696\n",
      "Epoch 1640/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1759 - accuracy: 0.9317 - val_loss: 0.9269 - val_accuracy: 0.7601\n",
      "Epoch 1641/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1748 - accuracy: 0.9321 - val_loss: 1.0050 - val_accuracy: 0.7559\n",
      "Epoch 1642/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1732 - accuracy: 0.9340 - val_loss: 0.7833 - val_accuracy: 0.7733\n",
      "Epoch 1643/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1715 - accuracy: 0.9340 - val_loss: 0.8229 - val_accuracy: 0.7632\n",
      "Epoch 1644/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1757 - accuracy: 0.9321 - val_loss: 0.7624 - val_accuracy: 0.7781\n",
      "Epoch 1645/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1661 - accuracy: 0.9359 - val_loss: 0.7636 - val_accuracy: 0.7855\n",
      "Epoch 1646/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1718 - accuracy: 0.9345 - val_loss: 0.7529 - val_accuracy: 0.7838\n",
      "Epoch 1647/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1653 - accuracy: 0.9363 - val_loss: 0.9725 - val_accuracy: 0.7516\n",
      "Epoch 1648/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1692 - accuracy: 0.9344 - val_loss: 0.7842 - val_accuracy: 0.7733\n",
      "Epoch 1649/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1707 - accuracy: 0.9340 - val_loss: 0.7886 - val_accuracy: 0.7744\n",
      "Epoch 1650/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1707 - accuracy: 0.9348 - val_loss: 0.7961 - val_accuracy: 0.7713\n",
      "Epoch 1651/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1688 - accuracy: 0.9345 - val_loss: 0.7980 - val_accuracy: 0.7706\n",
      "Epoch 1652/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1675 - accuracy: 0.9359 - val_loss: 0.8397 - val_accuracy: 0.7617\n",
      "Epoch 1653/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1666 - accuracy: 0.9361 - val_loss: 0.7733 - val_accuracy: 0.7829\n",
      "Epoch 1654/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1666 - accuracy: 0.9360 - val_loss: 0.7822 - val_accuracy: 0.7752\n",
      "Epoch 1655/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1685 - accuracy: 0.9351 - val_loss: 0.7896 - val_accuracy: 0.7743\n",
      "Epoch 1656/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1636 - accuracy: 0.9373 - val_loss: 0.7520 - val_accuracy: 0.7873\n",
      "Epoch 1657/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1719 - accuracy: 0.9334 - val_loss: 0.7523 - val_accuracy: 0.7825\n",
      "Epoch 1658/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1631 - accuracy: 0.9370 - val_loss: 0.8050 - val_accuracy: 0.7700\n",
      "Epoch 1659/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1709 - accuracy: 0.9344 - val_loss: 0.8072 - val_accuracy: 0.7726\n",
      "Epoch 1660/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1668 - accuracy: 0.9360 - val_loss: 0.7504 - val_accuracy: 0.7801\n",
      "Epoch 1661/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1751 - accuracy: 0.9336 - val_loss: 0.7625 - val_accuracy: 0.7811\n",
      "Epoch 1662/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1690 - accuracy: 0.9346 - val_loss: 0.8182 - val_accuracy: 0.7687\n",
      "Epoch 1663/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1675 - accuracy: 0.9355 - val_loss: 0.8272 - val_accuracy: 0.7648\n",
      "Epoch 1664/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1673 - accuracy: 0.9357 - val_loss: 0.7943 - val_accuracy: 0.7763\n",
      "Epoch 1665/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1677 - accuracy: 0.9355 - val_loss: 0.8259 - val_accuracy: 0.7696\n",
      "Epoch 1666/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1669 - accuracy: 0.9353 - val_loss: 0.8261 - val_accuracy: 0.7648\n",
      "Epoch 1667/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1716 - accuracy: 0.9348 - val_loss: 0.7430 - val_accuracy: 0.7865\n",
      "Epoch 1668/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1633 - accuracy: 0.9376 - val_loss: 0.7887 - val_accuracy: 0.7779\n",
      "Epoch 1669/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1655 - accuracy: 0.9370 - val_loss: 0.7753 - val_accuracy: 0.7766\n",
      "Epoch 1670/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1673 - accuracy: 0.9354 - val_loss: 0.7314 - val_accuracy: 0.7843\n",
      "Epoch 1671/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1668 - accuracy: 0.9363 - val_loss: 0.8321 - val_accuracy: 0.7659\n",
      "Epoch 1672/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1665 - accuracy: 0.9369 - val_loss: 0.8270 - val_accuracy: 0.7719\n",
      "Epoch 1673/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1636 - accuracy: 0.9364 - val_loss: 0.7362 - val_accuracy: 0.7884\n",
      "Epoch 1674/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1709 - accuracy: 0.9344 - val_loss: 0.7624 - val_accuracy: 0.7789\n",
      "Epoch 1675/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1622 - accuracy: 0.9375 - val_loss: 0.8051 - val_accuracy: 0.7753\n",
      "Epoch 1676/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1625 - accuracy: 0.9369 - val_loss: 0.8076 - val_accuracy: 0.7724\n",
      "Epoch 1677/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1683 - accuracy: 0.9353 - val_loss: 0.8378 - val_accuracy: 0.7641\n",
      "Epoch 1678/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1628 - accuracy: 0.9380 - val_loss: 0.8117 - val_accuracy: 0.7671\n",
      "Epoch 1679/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1681 - accuracy: 0.9359 - val_loss: 0.8103 - val_accuracy: 0.7703\n",
      "Epoch 1680/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1657 - accuracy: 0.9362 - val_loss: 0.8529 - val_accuracy: 0.7695\n",
      "Epoch 1681/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1626 - accuracy: 0.9382 - val_loss: 0.8302 - val_accuracy: 0.7702\n",
      "Epoch 1682/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1655 - accuracy: 0.9363 - val_loss: 0.8017 - val_accuracy: 0.7697\n",
      "Epoch 1683/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1665 - accuracy: 0.9358 - val_loss: 0.7629 - val_accuracy: 0.7842\n",
      "Epoch 1684/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1682 - accuracy: 0.9360 - val_loss: 0.7955 - val_accuracy: 0.7774\n",
      "Epoch 1685/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1640 - accuracy: 0.9373 - val_loss: 0.7850 - val_accuracy: 0.7765\n",
      "Epoch 1686/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1662 - accuracy: 0.9369 - val_loss: 0.7483 - val_accuracy: 0.7825\n",
      "Epoch 1687/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1607 - accuracy: 0.9379 - val_loss: 0.8059 - val_accuracy: 0.7779\n",
      "Epoch 1688/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1597 - accuracy: 0.9380 - val_loss: 0.7680 - val_accuracy: 0.7812\n",
      "Epoch 1689/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1598 - accuracy: 0.9385 - val_loss: 0.7611 - val_accuracy: 0.7800\n",
      "Epoch 1690/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1635 - accuracy: 0.9377 - val_loss: 0.7938 - val_accuracy: 0.7755\n",
      "Epoch 1691/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1610 - accuracy: 0.9384 - val_loss: 0.8065 - val_accuracy: 0.7763\n",
      "Epoch 1692/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1662 - accuracy: 0.9357 - val_loss: 0.7893 - val_accuracy: 0.7754\n",
      "Epoch 1693/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1673 - accuracy: 0.9361 - val_loss: 0.7702 - val_accuracy: 0.7836\n",
      "Epoch 1694/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1608 - accuracy: 0.9381 - val_loss: 0.7723 - val_accuracy: 0.7839\n",
      "Epoch 1695/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1620 - accuracy: 0.9383 - val_loss: 0.7891 - val_accuracy: 0.7819\n",
      "Epoch 1696/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1678 - accuracy: 0.9364 - val_loss: 0.7617 - val_accuracy: 0.7782\n",
      "Epoch 1697/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1616 - accuracy: 0.9381 - val_loss: 0.8782 - val_accuracy: 0.7641\n",
      "Epoch 1698/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1624 - accuracy: 0.9384 - val_loss: 0.7939 - val_accuracy: 0.7760\n",
      "Epoch 1699/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1643 - accuracy: 0.9382 - val_loss: 0.8094 - val_accuracy: 0.7761\n",
      "Epoch 1700/8000\n",
      "1460/1463 [============================>.] - ETA: 0s - loss: 0.1588 - accuracy: 0.9391\n",
      "Epoch 1700: saving model to ./training_ckpt_20240109205949_v8_240109_d10000_n4096_b64_e8000_c100_Adamax\\cp-000001700.ckpt\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1590 - accuracy: 0.9390 - val_loss: 0.8252 - val_accuracy: 0.7696\n",
      "Epoch 1701/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1574 - accuracy: 0.9399 - val_loss: 0.8171 - val_accuracy: 0.7722\n",
      "Epoch 1702/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1595 - accuracy: 0.9387 - val_loss: 0.7868 - val_accuracy: 0.7773\n",
      "Epoch 1703/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1567 - accuracy: 0.9402 - val_loss: 0.8104 - val_accuracy: 0.7762\n",
      "Epoch 1704/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1590 - accuracy: 0.9388 - val_loss: 0.7757 - val_accuracy: 0.7801\n",
      "Epoch 1705/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1583 - accuracy: 0.9393 - val_loss: 0.7804 - val_accuracy: 0.7803\n",
      "Epoch 1706/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1636 - accuracy: 0.9374 - val_loss: 0.7500 - val_accuracy: 0.7870\n",
      "Epoch 1707/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1633 - accuracy: 0.9385 - val_loss: 0.7595 - val_accuracy: 0.7815\n",
      "Epoch 1708/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1595 - accuracy: 0.9388 - val_loss: 0.7538 - val_accuracy: 0.7870\n",
      "Epoch 1709/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1634 - accuracy: 0.9380 - val_loss: 0.8360 - val_accuracy: 0.7648\n",
      "Epoch 1710/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1593 - accuracy: 0.9389 - val_loss: 0.8340 - val_accuracy: 0.7700\n",
      "Epoch 1711/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1559 - accuracy: 0.9403 - val_loss: 0.7647 - val_accuracy: 0.7853\n",
      "Epoch 1712/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1593 - accuracy: 0.9394 - val_loss: 0.9424 - val_accuracy: 0.7577\n",
      "Epoch 1713/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1618 - accuracy: 0.9373 - val_loss: 0.7529 - val_accuracy: 0.7877\n",
      "Epoch 1714/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1627 - accuracy: 0.9385 - val_loss: 0.8789 - val_accuracy: 0.7667\n",
      "Epoch 1715/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1616 - accuracy: 0.9383 - val_loss: 0.7726 - val_accuracy: 0.7849\n",
      "Epoch 1716/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1581 - accuracy: 0.9401 - val_loss: 0.7526 - val_accuracy: 0.7857\n",
      "Epoch 1717/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1589 - accuracy: 0.9401 - val_loss: 0.7859 - val_accuracy: 0.7735\n",
      "Epoch 1718/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1563 - accuracy: 0.9402 - val_loss: 0.7935 - val_accuracy: 0.7786\n",
      "Epoch 1719/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1606 - accuracy: 0.9379 - val_loss: 0.8060 - val_accuracy: 0.7777\n",
      "Epoch 1720/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1599 - accuracy: 0.9386 - val_loss: 0.8017 - val_accuracy: 0.7788\n",
      "Epoch 1721/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1611 - accuracy: 0.9383 - val_loss: 0.7687 - val_accuracy: 0.7805\n",
      "Epoch 1722/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1568 - accuracy: 0.9408 - val_loss: 0.8269 - val_accuracy: 0.7692\n",
      "Epoch 1723/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1597 - accuracy: 0.9392 - val_loss: 0.7515 - val_accuracy: 0.7849\n",
      "Epoch 1724/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1583 - accuracy: 0.9385 - val_loss: 0.7573 - val_accuracy: 0.7823\n",
      "Epoch 1725/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1575 - accuracy: 0.9393 - val_loss: 0.7656 - val_accuracy: 0.7815\n",
      "Epoch 1726/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1565 - accuracy: 0.9401 - val_loss: 0.8014 - val_accuracy: 0.7765\n",
      "Epoch 1727/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1610 - accuracy: 0.9379 - val_loss: 0.7600 - val_accuracy: 0.7859\n",
      "Epoch 1728/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1594 - accuracy: 0.9399 - val_loss: 0.7484 - val_accuracy: 0.7844\n",
      "Epoch 1729/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1545 - accuracy: 0.9409 - val_loss: 0.7803 - val_accuracy: 0.7779\n",
      "Epoch 1730/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1552 - accuracy: 0.9411 - val_loss: 0.8095 - val_accuracy: 0.7801\n",
      "Epoch 1731/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1554 - accuracy: 0.9406 - val_loss: 0.7701 - val_accuracy: 0.7844\n",
      "Epoch 1732/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1644 - accuracy: 0.9371 - val_loss: 0.7277 - val_accuracy: 0.7865\n",
      "Epoch 1733/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1600 - accuracy: 0.9395 - val_loss: 0.8483 - val_accuracy: 0.7656\n",
      "Epoch 1734/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1605 - accuracy: 0.9393 - val_loss: 0.8090 - val_accuracy: 0.7743\n",
      "Epoch 1735/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1541 - accuracy: 0.9412 - val_loss: 0.8309 - val_accuracy: 0.7699\n",
      "Epoch 1736/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1565 - accuracy: 0.9402 - val_loss: 0.7426 - val_accuracy: 0.7858\n",
      "Epoch 1737/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1620 - accuracy: 0.9373 - val_loss: 0.7957 - val_accuracy: 0.7794\n",
      "Epoch 1738/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1559 - accuracy: 0.9406 - val_loss: 0.8020 - val_accuracy: 0.7793\n",
      "Epoch 1739/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1565 - accuracy: 0.9407 - val_loss: 0.7667 - val_accuracy: 0.7863\n",
      "Epoch 1740/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1595 - accuracy: 0.9400 - val_loss: 0.7454 - val_accuracy: 0.7855\n",
      "Epoch 1741/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1586 - accuracy: 0.9399 - val_loss: 0.7920 - val_accuracy: 0.7779\n",
      "Epoch 1742/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1588 - accuracy: 0.9404 - val_loss: 0.7590 - val_accuracy: 0.7790\n",
      "Epoch 1743/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1548 - accuracy: 0.9408 - val_loss: 0.8428 - val_accuracy: 0.7684\n",
      "Epoch 1744/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1563 - accuracy: 0.9408 - val_loss: 0.7345 - val_accuracy: 0.7913\n",
      "Epoch 1745/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1613 - accuracy: 0.9377 - val_loss: 0.7700 - val_accuracy: 0.7833\n",
      "Epoch 1746/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1570 - accuracy: 0.9392 - val_loss: 0.7332 - val_accuracy: 0.7891\n",
      "Epoch 1747/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1579 - accuracy: 0.9397 - val_loss: 0.7596 - val_accuracy: 0.7858\n",
      "Epoch 1748/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1560 - accuracy: 0.9413 - val_loss: 0.7512 - val_accuracy: 0.7877\n",
      "Epoch 1749/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1610 - accuracy: 0.9392 - val_loss: 0.7848 - val_accuracy: 0.7821\n",
      "Epoch 1750/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1529 - accuracy: 0.9425 - val_loss: 0.8639 - val_accuracy: 0.7642\n",
      "Epoch 1751/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1630 - accuracy: 0.9386 - val_loss: 0.7499 - val_accuracy: 0.7833\n",
      "Epoch 1752/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1537 - accuracy: 0.9405 - val_loss: 0.7363 - val_accuracy: 0.7924\n",
      "Epoch 1753/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1550 - accuracy: 0.9408 - val_loss: 0.7649 - val_accuracy: 0.7821\n",
      "Epoch 1754/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1547 - accuracy: 0.9415 - val_loss: 0.7797 - val_accuracy: 0.7794\n",
      "Epoch 1755/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1567 - accuracy: 0.9402 - val_loss: 0.8302 - val_accuracy: 0.7742\n",
      "Epoch 1756/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1647 - accuracy: 0.9378 - val_loss: 0.7888 - val_accuracy: 0.7793\n",
      "Epoch 1757/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1578 - accuracy: 0.9397 - val_loss: 0.7466 - val_accuracy: 0.7856\n",
      "Epoch 1758/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1597 - accuracy: 0.9400 - val_loss: 0.8195 - val_accuracy: 0.7701\n",
      "Epoch 1759/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1561 - accuracy: 0.9399 - val_loss: 0.7991 - val_accuracy: 0.7819\n",
      "Epoch 1760/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1550 - accuracy: 0.9414 - val_loss: 0.7505 - val_accuracy: 0.7881\n",
      "Epoch 1761/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1557 - accuracy: 0.9414 - val_loss: 0.8185 - val_accuracy: 0.7739\n",
      "Epoch 1762/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1561 - accuracy: 0.9403 - val_loss: 0.7472 - val_accuracy: 0.7875\n",
      "Epoch 1763/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1630 - accuracy: 0.9386 - val_loss: 0.8128 - val_accuracy: 0.7783\n",
      "Epoch 1764/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1486 - accuracy: 0.9432 - val_loss: 0.7570 - val_accuracy: 0.7884\n",
      "Epoch 1765/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1590 - accuracy: 0.9398 - val_loss: 0.7444 - val_accuracy: 0.7863\n",
      "Epoch 1766/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1583 - accuracy: 0.9403 - val_loss: 0.7621 - val_accuracy: 0.7881\n",
      "Epoch 1767/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1553 - accuracy: 0.9411 - val_loss: 0.7979 - val_accuracy: 0.7862\n",
      "Epoch 1768/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1569 - accuracy: 0.9406 - val_loss: 0.7679 - val_accuracy: 0.7855\n",
      "Epoch 1769/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1511 - accuracy: 0.9424 - val_loss: 0.7765 - val_accuracy: 0.7824\n",
      "Epoch 1770/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1569 - accuracy: 0.9397 - val_loss: 0.7929 - val_accuracy: 0.7760\n",
      "Epoch 1771/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1600 - accuracy: 0.9387 - val_loss: 0.7456 - val_accuracy: 0.7887\n",
      "Epoch 1772/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1555 - accuracy: 0.9407 - val_loss: 0.8273 - val_accuracy: 0.7769\n",
      "Epoch 1773/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1579 - accuracy: 0.9399 - val_loss: 0.8258 - val_accuracy: 0.7743\n",
      "Epoch 1774/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1590 - accuracy: 0.9400 - val_loss: 0.7461 - val_accuracy: 0.7892\n",
      "Epoch 1775/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1512 - accuracy: 0.9434 - val_loss: 0.8318 - val_accuracy: 0.7750\n",
      "Epoch 1776/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1519 - accuracy: 0.9412 - val_loss: 0.7344 - val_accuracy: 0.7898\n",
      "Epoch 1777/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1587 - accuracy: 0.9396 - val_loss: 0.7480 - val_accuracy: 0.7911\n",
      "Epoch 1778/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1566 - accuracy: 0.9402 - val_loss: 0.7512 - val_accuracy: 0.7899\n",
      "Epoch 1779/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1599 - accuracy: 0.9398 - val_loss: 0.7557 - val_accuracy: 0.7880\n",
      "Epoch 1780/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1544 - accuracy: 0.9418 - val_loss: 0.7737 - val_accuracy: 0.7831\n",
      "Epoch 1781/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1577 - accuracy: 0.9413 - val_loss: 0.7704 - val_accuracy: 0.7823\n",
      "Epoch 1782/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1510 - accuracy: 0.9433 - val_loss: 0.7510 - val_accuracy: 0.7898\n",
      "Epoch 1783/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1579 - accuracy: 0.9412 - val_loss: 0.7931 - val_accuracy: 0.7807\n",
      "Epoch 1784/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1517 - accuracy: 0.9423 - val_loss: 0.7630 - val_accuracy: 0.7841\n",
      "Epoch 1785/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1561 - accuracy: 0.9418 - val_loss: 0.7523 - val_accuracy: 0.7896\n",
      "Epoch 1786/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1546 - accuracy: 0.9424 - val_loss: 1.0023 - val_accuracy: 0.7632\n",
      "Epoch 1787/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1568 - accuracy: 0.9421 - val_loss: 0.7981 - val_accuracy: 0.7806\n",
      "Epoch 1788/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1581 - accuracy: 0.9403 - val_loss: 0.7868 - val_accuracy: 0.7766\n",
      "Epoch 1789/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1479 - accuracy: 0.9447 - val_loss: 0.7802 - val_accuracy: 0.7837\n",
      "Epoch 1790/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1488 - accuracy: 0.9438 - val_loss: 0.7598 - val_accuracy: 0.7892\n",
      "Epoch 1791/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1486 - accuracy: 0.9439 - val_loss: 0.7835 - val_accuracy: 0.7829\n",
      "Epoch 1792/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1516 - accuracy: 0.9422 - val_loss: 0.8215 - val_accuracy: 0.7794\n",
      "Epoch 1793/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1600 - accuracy: 0.9401 - val_loss: 0.8023 - val_accuracy: 0.7742\n",
      "Epoch 1794/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1596 - accuracy: 0.9395 - val_loss: 0.7488 - val_accuracy: 0.7866\n",
      "Epoch 1795/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1588 - accuracy: 0.9401 - val_loss: 0.7368 - val_accuracy: 0.7925\n",
      "Epoch 1796/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1515 - accuracy: 0.9430 - val_loss: 0.7425 - val_accuracy: 0.7874\n",
      "Epoch 1797/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1513 - accuracy: 0.9427 - val_loss: 0.7411 - val_accuracy: 0.7894\n",
      "Epoch 1798/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1473 - accuracy: 0.9445 - val_loss: 0.7682 - val_accuracy: 0.7853\n",
      "Epoch 1799/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1495 - accuracy: 0.9437 - val_loss: 0.7903 - val_accuracy: 0.7805\n",
      "Epoch 1800/8000\n",
      "1463/1463 [==============================] - ETA: 0s - loss: 0.1519 - accuracy: 0.9432\n",
      "Epoch 1800: saving model to ./training_ckpt_20240109205949_v8_240109_d10000_n4096_b64_e8000_c100_Adamax\\cp-000001800.ckpt\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1519 - accuracy: 0.9432 - val_loss: 0.7511 - val_accuracy: 0.7894\n",
      "Epoch 1801/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1505 - accuracy: 0.9442 - val_loss: 0.7681 - val_accuracy: 0.7869\n",
      "Epoch 1802/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1519 - accuracy: 0.9423 - val_loss: 0.7882 - val_accuracy: 0.7829\n",
      "Epoch 1803/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1513 - accuracy: 0.9429 - val_loss: 0.7794 - val_accuracy: 0.7858\n",
      "Epoch 1804/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1541 - accuracy: 0.9413 - val_loss: 0.8239 - val_accuracy: 0.7788\n",
      "Epoch 1805/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1532 - accuracy: 0.9428 - val_loss: 0.7376 - val_accuracy: 0.7929\n",
      "Epoch 1806/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1507 - accuracy: 0.9432 - val_loss: 0.7620 - val_accuracy: 0.7872\n",
      "Epoch 1807/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1540 - accuracy: 0.9422 - val_loss: 0.7792 - val_accuracy: 0.7822\n",
      "Epoch 1808/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1501 - accuracy: 0.9435 - val_loss: 0.7318 - val_accuracy: 0.7901\n",
      "Epoch 1809/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1453 - accuracy: 0.9457 - val_loss: 0.8056 - val_accuracy: 0.7757\n",
      "Epoch 1810/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1586 - accuracy: 0.9406 - val_loss: 0.7796 - val_accuracy: 0.7792\n",
      "Epoch 1811/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1479 - accuracy: 0.9442 - val_loss: 0.7297 - val_accuracy: 0.7924\n",
      "Epoch 1812/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1524 - accuracy: 0.9418 - val_loss: 0.8331 - val_accuracy: 0.7767\n",
      "Epoch 1813/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1571 - accuracy: 0.9413 - val_loss: 0.7448 - val_accuracy: 0.7900\n",
      "Epoch 1814/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1503 - accuracy: 0.9432 - val_loss: 0.7876 - val_accuracy: 0.7788\n",
      "Epoch 1815/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1584 - accuracy: 0.9409 - val_loss: 0.7322 - val_accuracy: 0.7910\n",
      "Epoch 1816/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1582 - accuracy: 0.9407 - val_loss: 0.7565 - val_accuracy: 0.7847\n",
      "Epoch 1817/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1635 - accuracy: 0.9388 - val_loss: 0.7572 - val_accuracy: 0.7864\n",
      "Epoch 1818/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1520 - accuracy: 0.9432 - val_loss: 0.7639 - val_accuracy: 0.7865\n",
      "Epoch 1819/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1664 - accuracy: 0.9371 - val_loss: 0.8078 - val_accuracy: 0.7774\n",
      "Epoch 1820/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1539 - accuracy: 0.9418 - val_loss: 0.7634 - val_accuracy: 0.7859\n",
      "Epoch 1821/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1546 - accuracy: 0.9414 - val_loss: 0.7790 - val_accuracy: 0.7807\n",
      "Epoch 1822/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1574 - accuracy: 0.9400 - val_loss: 0.7745 - val_accuracy: 0.7838\n",
      "Epoch 1823/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1565 - accuracy: 0.9418 - val_loss: 0.8223 - val_accuracy: 0.7764\n",
      "Epoch 1824/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1560 - accuracy: 0.9407 - val_loss: 0.8458 - val_accuracy: 0.7760\n",
      "Epoch 1825/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1529 - accuracy: 0.9423 - val_loss: 0.7663 - val_accuracy: 0.7885\n",
      "Epoch 1826/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1598 - accuracy: 0.9393 - val_loss: 0.7965 - val_accuracy: 0.7773\n",
      "Epoch 1827/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1629 - accuracy: 0.9377 - val_loss: 0.8011 - val_accuracy: 0.7780\n",
      "Epoch 1828/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1547 - accuracy: 0.9415 - val_loss: 0.9498 - val_accuracy: 0.7626\n",
      "Epoch 1829/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1532 - accuracy: 0.9421 - val_loss: 0.7365 - val_accuracy: 0.7948\n",
      "Epoch 1830/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1536 - accuracy: 0.9419 - val_loss: 0.7717 - val_accuracy: 0.7815\n",
      "Epoch 1831/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1588 - accuracy: 0.9405 - val_loss: 0.7818 - val_accuracy: 0.7811\n",
      "Epoch 1832/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1548 - accuracy: 0.9414 - val_loss: 0.8044 - val_accuracy: 0.7773\n",
      "Epoch 1833/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1527 - accuracy: 0.9418 - val_loss: 0.7943 - val_accuracy: 0.7809\n",
      "Epoch 1834/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1591 - accuracy: 0.9400 - val_loss: 0.8083 - val_accuracy: 0.7756\n",
      "Epoch 1835/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1577 - accuracy: 0.9405 - val_loss: 0.7629 - val_accuracy: 0.7866\n",
      "Epoch 1836/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1551 - accuracy: 0.9409 - val_loss: 0.7825 - val_accuracy: 0.7848\n",
      "Epoch 1837/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1551 - accuracy: 0.9414 - val_loss: 0.7272 - val_accuracy: 0.7925\n",
      "Epoch 1838/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1484 - accuracy: 0.9450 - val_loss: 0.8283 - val_accuracy: 0.7757\n",
      "Epoch 1839/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1586 - accuracy: 0.9392 - val_loss: 0.7424 - val_accuracy: 0.7907\n",
      "Epoch 1840/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1508 - accuracy: 0.9437 - val_loss: 0.7450 - val_accuracy: 0.7873\n",
      "Epoch 1841/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1506 - accuracy: 0.9436 - val_loss: 0.7764 - val_accuracy: 0.7808\n",
      "Epoch 1842/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1522 - accuracy: 0.9431 - val_loss: 0.7400 - val_accuracy: 0.7900\n",
      "Epoch 1843/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1516 - accuracy: 0.9426 - val_loss: 0.9426 - val_accuracy: 0.7622\n",
      "Epoch 1844/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1511 - accuracy: 0.9431 - val_loss: 0.7485 - val_accuracy: 0.7921\n",
      "Epoch 1845/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1547 - accuracy: 0.9423 - val_loss: 0.7752 - val_accuracy: 0.7811\n",
      "Epoch 1846/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1484 - accuracy: 0.9445 - val_loss: 0.7808 - val_accuracy: 0.7802\n",
      "Epoch 1847/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1512 - accuracy: 0.9431 - val_loss: 0.7757 - val_accuracy: 0.7817\n",
      "Epoch 1848/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1520 - accuracy: 0.9423 - val_loss: 0.7356 - val_accuracy: 0.7968\n",
      "Epoch 1849/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1548 - accuracy: 0.9418 - val_loss: 0.7711 - val_accuracy: 0.7864\n",
      "Epoch 1850/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1512 - accuracy: 0.9435 - val_loss: 0.7807 - val_accuracy: 0.7813\n",
      "Epoch 1851/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1473 - accuracy: 0.9441 - val_loss: 0.7647 - val_accuracy: 0.7852\n",
      "Epoch 1852/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1514 - accuracy: 0.9429 - val_loss: 0.7581 - val_accuracy: 0.7893\n",
      "Epoch 1853/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1538 - accuracy: 0.9417 - val_loss: 0.8482 - val_accuracy: 0.7690\n",
      "Epoch 1854/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1539 - accuracy: 0.9417 - val_loss: 0.7727 - val_accuracy: 0.7881\n",
      "Epoch 1855/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1498 - accuracy: 0.9442 - val_loss: 0.7139 - val_accuracy: 0.7979\n",
      "Epoch 1856/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1473 - accuracy: 0.9446 - val_loss: 0.7335 - val_accuracy: 0.7889\n",
      "Epoch 1857/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1514 - accuracy: 0.9429 - val_loss: 0.7644 - val_accuracy: 0.7859\n",
      "Epoch 1858/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1547 - accuracy: 0.9417 - val_loss: 0.7233 - val_accuracy: 0.7932\n",
      "Epoch 1859/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1472 - accuracy: 0.9441 - val_loss: 0.8632 - val_accuracy: 0.7638\n",
      "Epoch 1860/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1500 - accuracy: 0.9441 - val_loss: 0.7499 - val_accuracy: 0.7893\n",
      "Epoch 1861/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1509 - accuracy: 0.9425 - val_loss: 0.7607 - val_accuracy: 0.7870\n",
      "Epoch 1862/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1445 - accuracy: 0.9456 - val_loss: 0.7282 - val_accuracy: 0.7951\n",
      "Epoch 1863/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1536 - accuracy: 0.9422 - val_loss: 0.7407 - val_accuracy: 0.7919\n",
      "Epoch 1864/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1438 - accuracy: 0.9451 - val_loss: 0.7300 - val_accuracy: 0.7921\n",
      "Epoch 1865/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1498 - accuracy: 0.9436 - val_loss: 0.7415 - val_accuracy: 0.7922\n",
      "Epoch 1866/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1479 - accuracy: 0.9439 - val_loss: 0.8027 - val_accuracy: 0.7815\n",
      "Epoch 1867/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1527 - accuracy: 0.9427 - val_loss: 0.7706 - val_accuracy: 0.7836\n",
      "Epoch 1868/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1474 - accuracy: 0.9445 - val_loss: 0.7468 - val_accuracy: 0.7887\n",
      "Epoch 1869/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1461 - accuracy: 0.9451 - val_loss: 0.7744 - val_accuracy: 0.7927\n",
      "Epoch 1870/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1484 - accuracy: 0.9447 - val_loss: 0.7399 - val_accuracy: 0.7934\n",
      "Epoch 1871/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1499 - accuracy: 0.9435 - val_loss: 0.8659 - val_accuracy: 0.7745\n",
      "Epoch 1872/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1492 - accuracy: 0.9440 - val_loss: 0.7722 - val_accuracy: 0.7852\n",
      "Epoch 1873/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1435 - accuracy: 0.9462 - val_loss: 0.7674 - val_accuracy: 0.7853\n",
      "Epoch 1874/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1515 - accuracy: 0.9427 - val_loss: 0.7956 - val_accuracy: 0.7845\n",
      "Epoch 1875/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1473 - accuracy: 0.9435 - val_loss: 0.8183 - val_accuracy: 0.7796\n",
      "Epoch 1876/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1427 - accuracy: 0.9448 - val_loss: 0.8275 - val_accuracy: 0.7775\n",
      "Epoch 1877/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1494 - accuracy: 0.9433 - val_loss: 0.8128 - val_accuracy: 0.7770\n",
      "Epoch 1878/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1480 - accuracy: 0.9442 - val_loss: 0.8032 - val_accuracy: 0.7807\n",
      "Epoch 1879/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1442 - accuracy: 0.9455 - val_loss: 0.7832 - val_accuracy: 0.7815\n",
      "Epoch 1880/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1517 - accuracy: 0.9437 - val_loss: 0.7384 - val_accuracy: 0.7907\n",
      "Epoch 1881/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1491 - accuracy: 0.9440 - val_loss: 0.7695 - val_accuracy: 0.7853\n",
      "Epoch 1882/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1428 - accuracy: 0.9471 - val_loss: 0.8241 - val_accuracy: 0.7719\n",
      "Epoch 1883/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1492 - accuracy: 0.9437 - val_loss: 0.7985 - val_accuracy: 0.7855\n",
      "Epoch 1884/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1518 - accuracy: 0.9428 - val_loss: 0.7265 - val_accuracy: 0.7961\n",
      "Epoch 1885/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1466 - accuracy: 0.9451 - val_loss: 0.7078 - val_accuracy: 0.7997\n",
      "Epoch 1886/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1452 - accuracy: 0.9453 - val_loss: 0.8421 - val_accuracy: 0.7720\n",
      "Epoch 1887/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1453 - accuracy: 0.9459 - val_loss: 0.7339 - val_accuracy: 0.7913\n",
      "Epoch 1888/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1468 - accuracy: 0.9449 - val_loss: 0.7487 - val_accuracy: 0.7884\n",
      "Epoch 1889/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1429 - accuracy: 0.9460 - val_loss: 0.7997 - val_accuracy: 0.7809\n",
      "Epoch 1890/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1478 - accuracy: 0.9443 - val_loss: 0.7220 - val_accuracy: 0.7958\n",
      "Epoch 1891/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1435 - accuracy: 0.9464 - val_loss: 0.9053 - val_accuracy: 0.7667\n",
      "Epoch 1892/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1477 - accuracy: 0.9455 - val_loss: 0.7997 - val_accuracy: 0.7802\n",
      "Epoch 1893/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1449 - accuracy: 0.9462 - val_loss: 0.7755 - val_accuracy: 0.7843\n",
      "Epoch 1894/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1432 - accuracy: 0.9462 - val_loss: 0.7519 - val_accuracy: 0.7892\n",
      "Epoch 1895/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1490 - accuracy: 0.9443 - val_loss: 0.7909 - val_accuracy: 0.7795\n",
      "Epoch 1896/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1428 - accuracy: 0.9467 - val_loss: 0.7738 - val_accuracy: 0.7840\n",
      "Epoch 1897/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1406 - accuracy: 0.9472 - val_loss: 0.7303 - val_accuracy: 0.7964\n",
      "Epoch 1898/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1466 - accuracy: 0.9457 - val_loss: 0.7559 - val_accuracy: 0.7914\n",
      "Epoch 1899/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1443 - accuracy: 0.9462 - val_loss: 0.7672 - val_accuracy: 0.7926\n",
      "Epoch 1900/8000\n",
      "1461/1463 [============================>.] - ETA: 0s - loss: 0.1426 - accuracy: 0.9472\n",
      "Epoch 1900: saving model to ./training_ckpt_20240109205949_v8_240109_d10000_n4096_b64_e8000_c100_Adamax\\cp-000001900.ckpt\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1427 - accuracy: 0.9472 - val_loss: 0.7962 - val_accuracy: 0.7841\n",
      "Epoch 1901/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1470 - accuracy: 0.9457 - val_loss: 0.7218 - val_accuracy: 0.7976\n",
      "Epoch 1902/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1460 - accuracy: 0.9459 - val_loss: 0.7678 - val_accuracy: 0.7831\n",
      "Epoch 1903/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1420 - accuracy: 0.9468 - val_loss: 0.7166 - val_accuracy: 0.8004\n",
      "Epoch 1904/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1413 - accuracy: 0.9472 - val_loss: 0.7439 - val_accuracy: 0.7965\n",
      "Epoch 1905/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1436 - accuracy: 0.9459 - val_loss: 0.7109 - val_accuracy: 0.7974\n",
      "Epoch 1906/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1429 - accuracy: 0.9465 - val_loss: 0.7157 - val_accuracy: 0.7977\n",
      "Epoch 1907/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1419 - accuracy: 0.9477 - val_loss: 0.7384 - val_accuracy: 0.7949\n",
      "Epoch 1908/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1443 - accuracy: 0.9465 - val_loss: 0.7915 - val_accuracy: 0.7788\n",
      "Epoch 1909/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1444 - accuracy: 0.9465 - val_loss: 0.7412 - val_accuracy: 0.7950\n",
      "Epoch 1910/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1454 - accuracy: 0.9453 - val_loss: 0.7476 - val_accuracy: 0.7908\n",
      "Epoch 1911/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1398 - accuracy: 0.9474 - val_loss: 0.7833 - val_accuracy: 0.7823\n",
      "Epoch 1912/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1518 - accuracy: 0.9435 - val_loss: 0.7657 - val_accuracy: 0.7894\n",
      "Epoch 1913/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1462 - accuracy: 0.9462 - val_loss: 0.7781 - val_accuracy: 0.7874\n",
      "Epoch 1914/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1401 - accuracy: 0.9486 - val_loss: 0.7518 - val_accuracy: 0.7936\n",
      "Epoch 1915/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1386 - accuracy: 0.9484 - val_loss: 0.7669 - val_accuracy: 0.7893\n",
      "Epoch 1916/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1487 - accuracy: 0.9445 - val_loss: 0.7785 - val_accuracy: 0.7852\n",
      "Epoch 1917/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1414 - accuracy: 0.9462 - val_loss: 0.7451 - val_accuracy: 0.7935\n",
      "Epoch 1918/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1420 - accuracy: 0.9484 - val_loss: 0.7628 - val_accuracy: 0.7917\n",
      "Epoch 1919/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1471 - accuracy: 0.9461 - val_loss: 0.7197 - val_accuracy: 0.7960\n",
      "Epoch 1920/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1387 - accuracy: 0.9490 - val_loss: 0.7762 - val_accuracy: 0.7865\n",
      "Epoch 1921/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1415 - accuracy: 0.9487 - val_loss: 0.7261 - val_accuracy: 0.7962\n",
      "Epoch 1922/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1405 - accuracy: 0.9482 - val_loss: 0.7700 - val_accuracy: 0.7865\n",
      "Epoch 1923/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1427 - accuracy: 0.9474 - val_loss: 0.7685 - val_accuracy: 0.7859\n",
      "Epoch 1924/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1464 - accuracy: 0.9457 - val_loss: 0.7300 - val_accuracy: 0.7938\n",
      "Epoch 1925/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1407 - accuracy: 0.9473 - val_loss: 0.7368 - val_accuracy: 0.7950\n",
      "Epoch 1926/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1388 - accuracy: 0.9475 - val_loss: 0.8418 - val_accuracy: 0.7763\n",
      "Epoch 1927/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1405 - accuracy: 0.9477 - val_loss: 0.7493 - val_accuracy: 0.7927\n",
      "Epoch 1928/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1471 - accuracy: 0.9453 - val_loss: 0.7390 - val_accuracy: 0.7947\n",
      "Epoch 1929/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1404 - accuracy: 0.9472 - val_loss: 0.7197 - val_accuracy: 0.7969\n",
      "Epoch 1930/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1394 - accuracy: 0.9477 - val_loss: 0.7725 - val_accuracy: 0.7847\n",
      "Epoch 1931/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1417 - accuracy: 0.9476 - val_loss: 0.7707 - val_accuracy: 0.7850\n",
      "Epoch 1932/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1420 - accuracy: 0.9465 - val_loss: 0.8296 - val_accuracy: 0.7763\n",
      "Epoch 1933/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1474 - accuracy: 0.9453 - val_loss: 0.7536 - val_accuracy: 0.7875\n",
      "Epoch 1934/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1368 - accuracy: 0.9489 - val_loss: 0.7320 - val_accuracy: 0.7964\n",
      "Epoch 1935/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1410 - accuracy: 0.9469 - val_loss: 0.9142 - val_accuracy: 0.7660\n",
      "Epoch 1936/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1440 - accuracy: 0.9472 - val_loss: 0.7579 - val_accuracy: 0.7887\n",
      "Epoch 1937/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1495 - accuracy: 0.9444 - val_loss: 0.7403 - val_accuracy: 0.7932\n",
      "Epoch 1938/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1422 - accuracy: 0.9478 - val_loss: 0.7894 - val_accuracy: 0.7861\n",
      "Epoch 1939/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1412 - accuracy: 0.9479 - val_loss: 0.7139 - val_accuracy: 0.7997\n",
      "Epoch 1940/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1390 - accuracy: 0.9487 - val_loss: 0.8324 - val_accuracy: 0.7790\n",
      "Epoch 1941/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1401 - accuracy: 0.9477 - val_loss: 0.7568 - val_accuracy: 0.7919\n",
      "Epoch 1942/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1386 - accuracy: 0.9484 - val_loss: 0.7549 - val_accuracy: 0.7886\n",
      "Epoch 1943/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1418 - accuracy: 0.9480 - val_loss: 0.7671 - val_accuracy: 0.7910\n",
      "Epoch 1944/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1400 - accuracy: 0.9477 - val_loss: 0.7657 - val_accuracy: 0.7880\n",
      "Epoch 1945/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1440 - accuracy: 0.9468 - val_loss: 0.7639 - val_accuracy: 0.7894\n",
      "Epoch 1946/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1419 - accuracy: 0.9470 - val_loss: 0.7512 - val_accuracy: 0.7913\n",
      "Epoch 1947/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1401 - accuracy: 0.9488 - val_loss: 0.7301 - val_accuracy: 0.7940\n",
      "Epoch 1948/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1387 - accuracy: 0.9477 - val_loss: 0.7640 - val_accuracy: 0.7943\n",
      "Epoch 1949/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1438 - accuracy: 0.9471 - val_loss: 0.7365 - val_accuracy: 0.7924\n",
      "Epoch 1950/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1387 - accuracy: 0.9480 - val_loss: 0.7216 - val_accuracy: 0.7981\n",
      "Epoch 1951/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1372 - accuracy: 0.9487 - val_loss: 0.7746 - val_accuracy: 0.7853\n",
      "Epoch 1952/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1382 - accuracy: 0.9490 - val_loss: 0.7846 - val_accuracy: 0.7836\n",
      "Epoch 1953/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1349 - accuracy: 0.9504 - val_loss: 0.7236 - val_accuracy: 0.7965\n",
      "Epoch 1954/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1342 - accuracy: 0.9497 - val_loss: 0.7317 - val_accuracy: 0.7936\n",
      "Epoch 1955/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1469 - accuracy: 0.9460 - val_loss: 0.7543 - val_accuracy: 0.7902\n",
      "Epoch 1956/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1359 - accuracy: 0.9498 - val_loss: 0.7316 - val_accuracy: 0.7983\n",
      "Epoch 1957/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1384 - accuracy: 0.9490 - val_loss: 0.7504 - val_accuracy: 0.7904\n",
      "Epoch 1958/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1386 - accuracy: 0.9488 - val_loss: 0.7864 - val_accuracy: 0.7827\n",
      "Epoch 1959/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1362 - accuracy: 0.9499 - val_loss: 0.7008 - val_accuracy: 0.8013\n",
      "Epoch 1960/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1361 - accuracy: 0.9500 - val_loss: 0.7701 - val_accuracy: 0.7894\n",
      "Epoch 1961/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1455 - accuracy: 0.9463 - val_loss: 0.7398 - val_accuracy: 0.7894\n",
      "Epoch 1962/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1390 - accuracy: 0.9486 - val_loss: 0.7173 - val_accuracy: 0.7992\n",
      "Epoch 1963/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1313 - accuracy: 0.9517 - val_loss: 0.7484 - val_accuracy: 0.7913\n",
      "Epoch 1964/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1420 - accuracy: 0.9469 - val_loss: 0.7389 - val_accuracy: 0.7918\n",
      "Epoch 1965/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1401 - accuracy: 0.9480 - val_loss: 0.8287 - val_accuracy: 0.7848\n",
      "Epoch 1966/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1404 - accuracy: 0.9482 - val_loss: 0.7346 - val_accuracy: 0.7954\n",
      "Epoch 1967/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1322 - accuracy: 0.9517 - val_loss: 0.7319 - val_accuracy: 0.7952\n",
      "Epoch 1968/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1372 - accuracy: 0.9493 - val_loss: 0.7559 - val_accuracy: 0.7947\n",
      "Epoch 1969/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1401 - accuracy: 0.9492 - val_loss: 0.7058 - val_accuracy: 0.8000\n",
      "Epoch 1970/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1388 - accuracy: 0.9489 - val_loss: 0.7514 - val_accuracy: 0.7922\n",
      "Epoch 1971/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1340 - accuracy: 0.9501 - val_loss: 0.8059 - val_accuracy: 0.7812\n",
      "Epoch 1972/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1386 - accuracy: 0.9487 - val_loss: 0.7151 - val_accuracy: 0.7977\n",
      "Epoch 1973/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1371 - accuracy: 0.9495 - val_loss: 0.7593 - val_accuracy: 0.7862\n",
      "Epoch 1974/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1323 - accuracy: 0.9513 - val_loss: 0.7024 - val_accuracy: 0.8065\n",
      "Epoch 1975/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1398 - accuracy: 0.9488 - val_loss: 0.7366 - val_accuracy: 0.7959\n",
      "Epoch 1976/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1372 - accuracy: 0.9502 - val_loss: 0.7451 - val_accuracy: 0.7938\n",
      "Epoch 1977/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1428 - accuracy: 0.9473 - val_loss: 0.7128 - val_accuracy: 0.7994\n",
      "Epoch 1978/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1372 - accuracy: 0.9491 - val_loss: 0.8041 - val_accuracy: 0.7834\n",
      "Epoch 1979/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1417 - accuracy: 0.9479 - val_loss: 0.7162 - val_accuracy: 0.8023\n",
      "Epoch 1980/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1376 - accuracy: 0.9485 - val_loss: 0.7483 - val_accuracy: 0.7902\n",
      "Epoch 1981/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1392 - accuracy: 0.9485 - val_loss: 0.7145 - val_accuracy: 0.8020\n",
      "Epoch 1982/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1377 - accuracy: 0.9495 - val_loss: 0.7149 - val_accuracy: 0.7995\n",
      "Epoch 1983/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1342 - accuracy: 0.9500 - val_loss: 0.7760 - val_accuracy: 0.7904\n",
      "Epoch 1984/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1392 - accuracy: 0.9478 - val_loss: 0.7196 - val_accuracy: 0.7954\n",
      "Epoch 1985/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1399 - accuracy: 0.9480 - val_loss: 0.7242 - val_accuracy: 0.7973\n",
      "Epoch 1986/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1363 - accuracy: 0.9500 - val_loss: 0.7053 - val_accuracy: 0.8012\n",
      "Epoch 1987/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1312 - accuracy: 0.9518 - val_loss: 0.7354 - val_accuracy: 0.7941\n",
      "Epoch 1988/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1496 - accuracy: 0.9457 - val_loss: 0.7930 - val_accuracy: 0.7884\n",
      "Epoch 1989/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1514 - accuracy: 0.9436 - val_loss: 0.7365 - val_accuracy: 0.7975\n",
      "Epoch 1990/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1459 - accuracy: 0.9455 - val_loss: 0.7353 - val_accuracy: 0.7947\n",
      "Epoch 1991/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1406 - accuracy: 0.9481 - val_loss: 0.7318 - val_accuracy: 0.7969\n",
      "Epoch 1992/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1414 - accuracy: 0.9471 - val_loss: 0.7369 - val_accuracy: 0.7925\n",
      "Epoch 1993/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1450 - accuracy: 0.9462 - val_loss: 0.7212 - val_accuracy: 0.7987\n",
      "Epoch 1994/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1391 - accuracy: 0.9481 - val_loss: 0.7550 - val_accuracy: 0.7904\n",
      "Epoch 1995/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1391 - accuracy: 0.9476 - val_loss: 0.7108 - val_accuracy: 0.7990\n",
      "Epoch 1996/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1413 - accuracy: 0.9479 - val_loss: 0.8357 - val_accuracy: 0.7758\n",
      "Epoch 1997/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1420 - accuracy: 0.9462 - val_loss: 0.7948 - val_accuracy: 0.7860\n",
      "Epoch 1998/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1435 - accuracy: 0.9464 - val_loss: 0.7522 - val_accuracy: 0.7947\n",
      "Epoch 1999/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1402 - accuracy: 0.9475 - val_loss: 0.7080 - val_accuracy: 0.8033\n",
      "Epoch 2000/8000\n",
      "1457/1463 [============================>.] - ETA: 0s - loss: 0.1398 - accuracy: 0.9483\n",
      "Epoch 2000: saving model to ./training_ckpt_20240109205949_v8_240109_d10000_n4096_b64_e8000_c100_Adamax\\cp-000002000.ckpt\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1397 - accuracy: 0.9482 - val_loss: 0.7500 - val_accuracy: 0.7933\n",
      "Epoch 2001/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1416 - accuracy: 0.9474 - val_loss: 0.7488 - val_accuracy: 0.7913\n",
      "Epoch 2002/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1394 - accuracy: 0.9485 - val_loss: 0.8026 - val_accuracy: 0.7823\n",
      "Epoch 2003/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1434 - accuracy: 0.9471 - val_loss: 0.8066 - val_accuracy: 0.7812\n",
      "Epoch 2004/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1369 - accuracy: 0.9492 - val_loss: 0.7584 - val_accuracy: 0.7924\n",
      "Epoch 2005/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1423 - accuracy: 0.9478 - val_loss: 0.7916 - val_accuracy: 0.7842\n",
      "Epoch 2006/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1400 - accuracy: 0.9487 - val_loss: 0.7788 - val_accuracy: 0.7844\n",
      "Epoch 2007/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1381 - accuracy: 0.9486 - val_loss: 0.7135 - val_accuracy: 0.7988\n",
      "Epoch 2008/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1381 - accuracy: 0.9489 - val_loss: 0.7506 - val_accuracy: 0.7929\n",
      "Epoch 2009/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1395 - accuracy: 0.9481 - val_loss: 0.7657 - val_accuracy: 0.7896\n",
      "Epoch 2010/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1450 - accuracy: 0.9465 - val_loss: 0.7539 - val_accuracy: 0.7916\n",
      "Epoch 2011/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1380 - accuracy: 0.9488 - val_loss: 0.7172 - val_accuracy: 0.7983\n",
      "Epoch 2012/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1440 - accuracy: 0.9470 - val_loss: 0.7442 - val_accuracy: 0.7928\n",
      "Epoch 2013/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1357 - accuracy: 0.9495 - val_loss: 0.7234 - val_accuracy: 0.7982\n",
      "Epoch 2014/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1364 - accuracy: 0.9497 - val_loss: 0.7309 - val_accuracy: 0.7935\n",
      "Epoch 2015/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1398 - accuracy: 0.9485 - val_loss: 0.7402 - val_accuracy: 0.7943\n",
      "Epoch 2016/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1413 - accuracy: 0.9474 - val_loss: 0.7295 - val_accuracy: 0.7977\n",
      "Epoch 2017/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1432 - accuracy: 0.9474 - val_loss: 0.7220 - val_accuracy: 0.7959\n",
      "Epoch 2018/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1399 - accuracy: 0.9477 - val_loss: 0.7759 - val_accuracy: 0.7882\n",
      "Epoch 2019/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1372 - accuracy: 0.9489 - val_loss: 0.7193 - val_accuracy: 0.7962\n",
      "Epoch 2020/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1390 - accuracy: 0.9488 - val_loss: 0.7603 - val_accuracy: 0.7882\n",
      "Epoch 2021/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1363 - accuracy: 0.9494 - val_loss: 0.7209 - val_accuracy: 0.8004\n",
      "Epoch 2022/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1372 - accuracy: 0.9492 - val_loss: 0.8059 - val_accuracy: 0.7835\n",
      "Epoch 2023/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1404 - accuracy: 0.9476 - val_loss: 0.6994 - val_accuracy: 0.8010\n",
      "Epoch 2024/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1334 - accuracy: 0.9511 - val_loss: 0.7394 - val_accuracy: 0.7957\n",
      "Epoch 2025/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1362 - accuracy: 0.9493 - val_loss: 0.7456 - val_accuracy: 0.7941\n",
      "Epoch 2026/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1382 - accuracy: 0.9489 - val_loss: 0.7454 - val_accuracy: 0.7965\n",
      "Epoch 2027/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1392 - accuracy: 0.9481 - val_loss: 0.7240 - val_accuracy: 0.7989\n",
      "Epoch 2028/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1312 - accuracy: 0.9515 - val_loss: 0.7211 - val_accuracy: 0.7990\n",
      "Epoch 2029/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1349 - accuracy: 0.9505 - val_loss: 0.7628 - val_accuracy: 0.7921\n",
      "Epoch 2030/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1389 - accuracy: 0.9489 - val_loss: 0.7551 - val_accuracy: 0.7888\n",
      "Epoch 2031/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1343 - accuracy: 0.9508 - val_loss: 0.7482 - val_accuracy: 0.7914\n",
      "Epoch 2032/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1390 - accuracy: 0.9488 - val_loss: 0.7282 - val_accuracy: 0.7962\n",
      "Epoch 2033/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1385 - accuracy: 0.9488 - val_loss: 0.7863 - val_accuracy: 0.7861\n",
      "Epoch 2034/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1381 - accuracy: 0.9490 - val_loss: 0.7615 - val_accuracy: 0.7876\n",
      "Epoch 2035/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1375 - accuracy: 0.9498 - val_loss: 0.7496 - val_accuracy: 0.7907\n",
      "Epoch 2036/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1340 - accuracy: 0.9511 - val_loss: 0.7616 - val_accuracy: 0.7870\n",
      "Epoch 2037/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1400 - accuracy: 0.9486 - val_loss: 0.7739 - val_accuracy: 0.7906\n",
      "Epoch 2038/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1366 - accuracy: 0.9502 - val_loss: 0.7470 - val_accuracy: 0.7923\n",
      "Epoch 2039/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1337 - accuracy: 0.9502 - val_loss: 0.7265 - val_accuracy: 0.8024\n",
      "Epoch 2040/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1331 - accuracy: 0.9509 - val_loss: 0.7144 - val_accuracy: 0.7987\n",
      "Epoch 2041/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1389 - accuracy: 0.9489 - val_loss: 0.7190 - val_accuracy: 0.7989\n",
      "Epoch 2042/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1329 - accuracy: 0.9512 - val_loss: 0.7274 - val_accuracy: 0.7984\n",
      "Epoch 2043/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1340 - accuracy: 0.9506 - val_loss: 0.7204 - val_accuracy: 0.7989\n",
      "Epoch 2044/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1356 - accuracy: 0.9499 - val_loss: 0.7626 - val_accuracy: 0.7900\n",
      "Epoch 2045/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1369 - accuracy: 0.9499 - val_loss: 0.7290 - val_accuracy: 0.7931\n",
      "Epoch 2046/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1343 - accuracy: 0.9503 - val_loss: 0.7247 - val_accuracy: 0.8003\n",
      "Epoch 2047/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1330 - accuracy: 0.9513 - val_loss: 0.7475 - val_accuracy: 0.7932\n",
      "Epoch 2048/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1365 - accuracy: 0.9497 - val_loss: 0.7576 - val_accuracy: 0.7922\n",
      "Epoch 2049/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1370 - accuracy: 0.9501 - val_loss: 0.7107 - val_accuracy: 0.8010\n",
      "Epoch 2050/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1321 - accuracy: 0.9517 - val_loss: 0.7829 - val_accuracy: 0.7907\n",
      "Epoch 2051/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1288 - accuracy: 0.9530 - val_loss: 0.7406 - val_accuracy: 0.7913\n",
      "Epoch 2052/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1359 - accuracy: 0.9497 - val_loss: 0.7243 - val_accuracy: 0.7983\n",
      "Epoch 2053/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1377 - accuracy: 0.9487 - val_loss: 0.8475 - val_accuracy: 0.7721\n",
      "Epoch 2054/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1350 - accuracy: 0.9508 - val_loss: 0.7411 - val_accuracy: 0.7916\n",
      "Epoch 2055/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1401 - accuracy: 0.9489 - val_loss: 0.7749 - val_accuracy: 0.7912\n",
      "Epoch 2056/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1295 - accuracy: 0.9522 - val_loss: 0.7866 - val_accuracy: 0.7901\n",
      "Epoch 2057/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1354 - accuracy: 0.9513 - val_loss: 0.7186 - val_accuracy: 0.7966\n",
      "Epoch 2058/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1322 - accuracy: 0.9528 - val_loss: 0.7279 - val_accuracy: 0.8008\n",
      "Epoch 2059/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1336 - accuracy: 0.9515 - val_loss: 0.7912 - val_accuracy: 0.7851\n",
      "Epoch 2060/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1346 - accuracy: 0.9505 - val_loss: 0.7343 - val_accuracy: 0.7958\n",
      "Epoch 2061/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1324 - accuracy: 0.9509 - val_loss: 0.7209 - val_accuracy: 0.7947\n",
      "Epoch 2062/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1295 - accuracy: 0.9529 - val_loss: 0.7051 - val_accuracy: 0.8061\n",
      "Epoch 2063/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1328 - accuracy: 0.9516 - val_loss: 0.7327 - val_accuracy: 0.7993\n",
      "Epoch 2064/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1351 - accuracy: 0.9505 - val_loss: 0.7215 - val_accuracy: 0.7970\n",
      "Epoch 2065/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1345 - accuracy: 0.9512 - val_loss: 0.7262 - val_accuracy: 0.7996\n",
      "Epoch 2066/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1341 - accuracy: 0.9513 - val_loss: 0.8863 - val_accuracy: 0.7663\n",
      "Epoch 2067/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1339 - accuracy: 0.9497 - val_loss: 0.7131 - val_accuracy: 0.8039\n",
      "Epoch 2068/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1315 - accuracy: 0.9525 - val_loss: 0.7334 - val_accuracy: 0.7993\n",
      "Epoch 2069/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1304 - accuracy: 0.9524 - val_loss: 0.9256 - val_accuracy: 0.7737\n",
      "Epoch 2070/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1336 - accuracy: 0.9512 - val_loss: 0.7498 - val_accuracy: 0.7932\n",
      "Epoch 2071/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1299 - accuracy: 0.9522 - val_loss: 0.7124 - val_accuracy: 0.8019\n",
      "Epoch 2072/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1303 - accuracy: 0.9513 - val_loss: 0.7894 - val_accuracy: 0.7886\n",
      "Epoch 2073/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1317 - accuracy: 0.9505 - val_loss: 0.7175 - val_accuracy: 0.8001\n",
      "Epoch 2074/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1288 - accuracy: 0.9527 - val_loss: 0.7260 - val_accuracy: 0.7973\n",
      "Epoch 2075/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1332 - accuracy: 0.9517 - val_loss: 0.7262 - val_accuracy: 0.7974\n",
      "Epoch 2076/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1284 - accuracy: 0.9527 - val_loss: 0.7432 - val_accuracy: 0.7961\n",
      "Epoch 2077/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1307 - accuracy: 0.9528 - val_loss: 0.7387 - val_accuracy: 0.7912\n",
      "Epoch 2078/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1252 - accuracy: 0.9551 - val_loss: 0.7068 - val_accuracy: 0.8041\n",
      "Epoch 2079/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1320 - accuracy: 0.9526 - val_loss: 0.7497 - val_accuracy: 0.7984\n",
      "Epoch 2080/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1289 - accuracy: 0.9532 - val_loss: 0.7128 - val_accuracy: 0.8012\n",
      "Epoch 2081/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1381 - accuracy: 0.9492 - val_loss: 0.7190 - val_accuracy: 0.7989\n",
      "Epoch 2082/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1331 - accuracy: 0.9518 - val_loss: 0.7298 - val_accuracy: 0.7980\n",
      "Epoch 2083/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1331 - accuracy: 0.9512 - val_loss: 0.7995 - val_accuracy: 0.7860\n",
      "Epoch 2084/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1355 - accuracy: 0.9499 - val_loss: 0.8286 - val_accuracy: 0.7787\n",
      "Epoch 2085/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1265 - accuracy: 0.9537 - val_loss: 0.7075 - val_accuracy: 0.8005\n",
      "Epoch 2086/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1334 - accuracy: 0.9511 - val_loss: 0.7657 - val_accuracy: 0.7891\n",
      "Epoch 2087/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1273 - accuracy: 0.9535 - val_loss: 0.7645 - val_accuracy: 0.7870\n",
      "Epoch 2088/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1300 - accuracy: 0.9520 - val_loss: 0.7705 - val_accuracy: 0.7919\n",
      "Epoch 2089/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1256 - accuracy: 0.9542 - val_loss: 0.7808 - val_accuracy: 0.7883\n",
      "Epoch 2090/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1290 - accuracy: 0.9528 - val_loss: 0.6978 - val_accuracy: 0.8047\n",
      "Epoch 2091/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1326 - accuracy: 0.9511 - val_loss: 0.7225 - val_accuracy: 0.7984\n",
      "Epoch 2092/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1293 - accuracy: 0.9524 - val_loss: 0.7119 - val_accuracy: 0.8011\n",
      "Epoch 2093/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1370 - accuracy: 0.9500 - val_loss: 0.7251 - val_accuracy: 0.7995\n",
      "Epoch 2094/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1276 - accuracy: 0.9534 - val_loss: 0.7683 - val_accuracy: 0.7900\n",
      "Epoch 2095/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1348 - accuracy: 0.9508 - val_loss: 0.7224 - val_accuracy: 0.7969\n",
      "Epoch 2096/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1315 - accuracy: 0.9527 - val_loss: 0.7293 - val_accuracy: 0.7964\n",
      "Epoch 2097/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1420 - accuracy: 0.9485 - val_loss: 0.7009 - val_accuracy: 0.8041\n",
      "Epoch 2098/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1383 - accuracy: 0.9496 - val_loss: 0.8263 - val_accuracy: 0.7828\n",
      "Epoch 2099/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1383 - accuracy: 0.9495 - val_loss: 0.7066 - val_accuracy: 0.8012\n",
      "Epoch 2100/8000\n",
      "1459/1463 [============================>.] - ETA: 0s - loss: 0.1359 - accuracy: 0.9509\n",
      "Epoch 2100: saving model to ./training_ckpt_20240109205949_v8_240109_d10000_n4096_b64_e8000_c100_Adamax\\cp-000002100.ckpt\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1358 - accuracy: 0.9510 - val_loss: 0.6959 - val_accuracy: 0.8084\n",
      "Epoch 2101/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1268 - accuracy: 0.9532 - val_loss: 0.8079 - val_accuracy: 0.7917\n",
      "Epoch 2102/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1264 - accuracy: 0.9542 - val_loss: 0.7564 - val_accuracy: 0.7924\n",
      "Epoch 2103/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1348 - accuracy: 0.9512 - val_loss: 0.7329 - val_accuracy: 0.8014\n",
      "Epoch 2104/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1293 - accuracy: 0.9533 - val_loss: 0.7720 - val_accuracy: 0.7941\n",
      "Epoch 2105/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1272 - accuracy: 0.9529 - val_loss: 0.6915 - val_accuracy: 0.8075\n",
      "Epoch 2106/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1265 - accuracy: 0.9539 - val_loss: 0.7086 - val_accuracy: 0.8048\n",
      "Epoch 2107/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1244 - accuracy: 0.9543 - val_loss: 0.7621 - val_accuracy: 0.7905\n",
      "Epoch 2108/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1308 - accuracy: 0.9521 - val_loss: 0.7169 - val_accuracy: 0.8007\n",
      "Epoch 2109/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1282 - accuracy: 0.9522 - val_loss: 0.7126 - val_accuracy: 0.8012\n",
      "Epoch 2110/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1266 - accuracy: 0.9547 - val_loss: 0.8349 - val_accuracy: 0.7891\n",
      "Epoch 2111/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1327 - accuracy: 0.9519 - val_loss: 0.7081 - val_accuracy: 0.8046\n",
      "Epoch 2112/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1259 - accuracy: 0.9538 - val_loss: 0.7420 - val_accuracy: 0.7952\n",
      "Epoch 2113/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1261 - accuracy: 0.9543 - val_loss: 0.6956 - val_accuracy: 0.8068\n",
      "Epoch 2114/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1229 - accuracy: 0.9554 - val_loss: 0.7030 - val_accuracy: 0.8062\n",
      "Epoch 2115/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1273 - accuracy: 0.9536 - val_loss: 0.7828 - val_accuracy: 0.7905\n",
      "Epoch 2116/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1226 - accuracy: 0.9550 - val_loss: 0.7189 - val_accuracy: 0.8031\n",
      "Epoch 2117/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1245 - accuracy: 0.9543 - val_loss: 0.7359 - val_accuracy: 0.7985\n",
      "Epoch 2118/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1267 - accuracy: 0.9541 - val_loss: 0.7424 - val_accuracy: 0.7937\n",
      "Epoch 2119/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1251 - accuracy: 0.9550 - val_loss: 0.7453 - val_accuracy: 0.7973\n",
      "Epoch 2120/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1289 - accuracy: 0.9532 - val_loss: 0.7837 - val_accuracy: 0.7907\n",
      "Epoch 2121/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1325 - accuracy: 0.9519 - val_loss: 0.8181 - val_accuracy: 0.7907\n",
      "Epoch 2122/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1236 - accuracy: 0.9546 - val_loss: 0.7253 - val_accuracy: 0.7970\n",
      "Epoch 2123/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1262 - accuracy: 0.9538 - val_loss: 0.7138 - val_accuracy: 0.8005\n",
      "Epoch 2124/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1292 - accuracy: 0.9535 - val_loss: 0.6982 - val_accuracy: 0.8061\n",
      "Epoch 2125/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1293 - accuracy: 0.9533 - val_loss: 0.7510 - val_accuracy: 0.7959\n",
      "Epoch 2126/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1297 - accuracy: 0.9534 - val_loss: 0.6714 - val_accuracy: 0.8088\n",
      "Epoch 2127/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1315 - accuracy: 0.9521 - val_loss: 0.7456 - val_accuracy: 0.7917\n",
      "Epoch 2128/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1263 - accuracy: 0.9535 - val_loss: 0.7315 - val_accuracy: 0.7953\n",
      "Epoch 2129/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1250 - accuracy: 0.9540 - val_loss: 0.6937 - val_accuracy: 0.8069\n",
      "Epoch 2130/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1224 - accuracy: 0.9552 - val_loss: 0.6850 - val_accuracy: 0.8077\n",
      "Epoch 2131/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1266 - accuracy: 0.9547 - val_loss: 0.6933 - val_accuracy: 0.8079\n",
      "Epoch 2132/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1214 - accuracy: 0.9559 - val_loss: 0.6871 - val_accuracy: 0.8087\n",
      "Epoch 2133/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1235 - accuracy: 0.9544 - val_loss: 0.6947 - val_accuracy: 0.8078\n",
      "Epoch 2134/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1290 - accuracy: 0.9529 - val_loss: 0.7647 - val_accuracy: 0.7972\n",
      "Epoch 2135/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1257 - accuracy: 0.9549 - val_loss: 0.7247 - val_accuracy: 0.7991\n",
      "Epoch 2136/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1258 - accuracy: 0.9538 - val_loss: 0.7126 - val_accuracy: 0.8020\n",
      "Epoch 2137/8000\n",
      "1463/1463 [==============================] - 12s 9ms/step - loss: 0.1259 - accuracy: 0.9540 - val_loss: 0.7652 - val_accuracy: 0.7867\n",
      "Epoch 2138/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1280 - accuracy: 0.9539 - val_loss: 0.7114 - val_accuracy: 0.8059\n",
      "Epoch 2139/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1251 - accuracy: 0.9544 - val_loss: 0.7751 - val_accuracy: 0.7924\n",
      "Epoch 2140/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1237 - accuracy: 0.9560 - val_loss: 0.7892 - val_accuracy: 0.7899\n",
      "Epoch 2141/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1226 - accuracy: 0.9557 - val_loss: 0.7547 - val_accuracy: 0.7941\n",
      "Epoch 2142/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1228 - accuracy: 0.9559 - val_loss: 0.7375 - val_accuracy: 0.7984\n",
      "Epoch 2143/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1232 - accuracy: 0.9550 - val_loss: 0.7624 - val_accuracy: 0.7906\n",
      "Epoch 2144/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1267 - accuracy: 0.9545 - val_loss: 0.7438 - val_accuracy: 0.7947\n",
      "Epoch 2145/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1285 - accuracy: 0.9534 - val_loss: 0.6815 - val_accuracy: 0.8058\n",
      "Epoch 2146/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1280 - accuracy: 0.9534 - val_loss: 0.7787 - val_accuracy: 0.7921\n",
      "Epoch 2147/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1243 - accuracy: 0.9548 - val_loss: 0.7204 - val_accuracy: 0.8046\n",
      "Epoch 2148/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1255 - accuracy: 0.9548 - val_loss: 0.7382 - val_accuracy: 0.7973\n",
      "Epoch 2149/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1248 - accuracy: 0.9554 - val_loss: 0.7298 - val_accuracy: 0.7981\n",
      "Epoch 2150/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1266 - accuracy: 0.9536 - val_loss: 0.7456 - val_accuracy: 0.7972\n",
      "Epoch 2151/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1262 - accuracy: 0.9542 - val_loss: 0.6879 - val_accuracy: 0.8056\n",
      "Epoch 2152/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1222 - accuracy: 0.9557 - val_loss: 0.7201 - val_accuracy: 0.7997\n",
      "Epoch 2153/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1230 - accuracy: 0.9552 - val_loss: 0.7269 - val_accuracy: 0.8000\n",
      "Epoch 2154/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1234 - accuracy: 0.9555 - val_loss: 0.7071 - val_accuracy: 0.8049\n",
      "Epoch 2155/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1272 - accuracy: 0.9535 - val_loss: 0.7237 - val_accuracy: 0.8054\n",
      "Epoch 2156/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1229 - accuracy: 0.9551 - val_loss: 0.7031 - val_accuracy: 0.8037\n",
      "Epoch 2157/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1215 - accuracy: 0.9560 - val_loss: 0.7120 - val_accuracy: 0.8063\n",
      "Epoch 2158/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1259 - accuracy: 0.9543 - val_loss: 0.8724 - val_accuracy: 0.7839\n",
      "Epoch 2159/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1261 - accuracy: 0.9541 - val_loss: 0.7918 - val_accuracy: 0.7914\n",
      "Epoch 2160/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1206 - accuracy: 0.9570 - val_loss: 0.7796 - val_accuracy: 0.7862\n",
      "Epoch 2161/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1209 - accuracy: 0.9564 - val_loss: 0.7242 - val_accuracy: 0.8014\n",
      "Epoch 2162/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1215 - accuracy: 0.9563 - val_loss: 0.7112 - val_accuracy: 0.8010\n",
      "Epoch 2163/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1227 - accuracy: 0.9564 - val_loss: 0.7030 - val_accuracy: 0.8023\n",
      "Epoch 2164/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1217 - accuracy: 0.9557 - val_loss: 0.7373 - val_accuracy: 0.7977\n",
      "Epoch 2165/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1214 - accuracy: 0.9558 - val_loss: 0.7204 - val_accuracy: 0.7997\n",
      "Epoch 2166/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1270 - accuracy: 0.9537 - val_loss: 0.7211 - val_accuracy: 0.8055\n",
      "Epoch 2167/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1207 - accuracy: 0.9571 - val_loss: 0.7581 - val_accuracy: 0.7979\n",
      "Epoch 2168/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1267 - accuracy: 0.9545 - val_loss: 0.7283 - val_accuracy: 0.8010\n",
      "Epoch 2169/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1250 - accuracy: 0.9552 - val_loss: 0.7686 - val_accuracy: 0.7900\n",
      "Epoch 2170/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1226 - accuracy: 0.9559 - val_loss: 0.6905 - val_accuracy: 0.8067\n",
      "Epoch 2171/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1223 - accuracy: 0.9555 - val_loss: 0.8276 - val_accuracy: 0.7819\n",
      "Epoch 2172/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1247 - accuracy: 0.9544 - val_loss: 0.7338 - val_accuracy: 0.8001\n",
      "Epoch 2173/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1221 - accuracy: 0.9560 - val_loss: 0.7490 - val_accuracy: 0.7957\n",
      "Epoch 2174/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1305 - accuracy: 0.9529 - val_loss: 0.7184 - val_accuracy: 0.8026\n",
      "Epoch 2175/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1202 - accuracy: 0.9574 - val_loss: 0.7548 - val_accuracy: 0.7943\n",
      "Epoch 2176/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1251 - accuracy: 0.9540 - val_loss: 0.7061 - val_accuracy: 0.8055\n",
      "Epoch 2177/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1251 - accuracy: 0.9549 - val_loss: 0.7223 - val_accuracy: 0.8053\n",
      "Epoch 2178/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1248 - accuracy: 0.9549 - val_loss: 0.7458 - val_accuracy: 0.7990\n",
      "Epoch 2179/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1225 - accuracy: 0.9555 - val_loss: 0.7063 - val_accuracy: 0.8020\n",
      "Epoch 2180/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1206 - accuracy: 0.9560 - val_loss: 0.7617 - val_accuracy: 0.7935\n",
      "Epoch 2181/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1253 - accuracy: 0.9544 - val_loss: 0.7498 - val_accuracy: 0.7996\n",
      "Epoch 2182/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1221 - accuracy: 0.9560 - val_loss: 0.7875 - val_accuracy: 0.7881\n",
      "Epoch 2183/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1253 - accuracy: 0.9543 - val_loss: 0.7251 - val_accuracy: 0.8042\n",
      "Epoch 2184/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1254 - accuracy: 0.9545 - val_loss: 0.6961 - val_accuracy: 0.8080\n",
      "Epoch 2185/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1233 - accuracy: 0.9558 - val_loss: 0.7277 - val_accuracy: 0.7999\n",
      "Epoch 2186/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1213 - accuracy: 0.9563 - val_loss: 0.7746 - val_accuracy: 0.7942\n",
      "Epoch 2187/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1184 - accuracy: 0.9571 - val_loss: 0.7165 - val_accuracy: 0.8058\n",
      "Epoch 2188/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1243 - accuracy: 0.9542 - val_loss: 0.6941 - val_accuracy: 0.8073\n",
      "Epoch 2189/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1179 - accuracy: 0.9581 - val_loss: 0.7215 - val_accuracy: 0.8021\n",
      "Epoch 2190/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1208 - accuracy: 0.9560 - val_loss: 0.7253 - val_accuracy: 0.8009\n",
      "Epoch 2191/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1232 - accuracy: 0.9558 - val_loss: 0.7412 - val_accuracy: 0.8032\n",
      "Epoch 2192/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1259 - accuracy: 0.9548 - val_loss: 0.7012 - val_accuracy: 0.8038\n",
      "Epoch 2193/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1189 - accuracy: 0.9576 - val_loss: 0.7314 - val_accuracy: 0.8012\n",
      "Epoch 2194/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1259 - accuracy: 0.9550 - val_loss: 0.6860 - val_accuracy: 0.8120\n",
      "Epoch 2195/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1200 - accuracy: 0.9565 - val_loss: 0.7380 - val_accuracy: 0.7937\n",
      "Epoch 2196/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1269 - accuracy: 0.9545 - val_loss: 0.7177 - val_accuracy: 0.7992\n",
      "Epoch 2197/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1230 - accuracy: 0.9553 - val_loss: 0.7606 - val_accuracy: 0.7936\n",
      "Epoch 2198/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1262 - accuracy: 0.9545 - val_loss: 0.7051 - val_accuracy: 0.8037\n",
      "Epoch 2199/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1210 - accuracy: 0.9555 - val_loss: 0.6893 - val_accuracy: 0.8072\n",
      "Epoch 2200/8000\n",
      "1457/1463 [============================>.] - ETA: 0s - loss: 0.1198 - accuracy: 0.9568\n",
      "Epoch 2200: saving model to ./training_ckpt_20240109205949_v8_240109_d10000_n4096_b64_e8000_c100_Adamax\\cp-000002200.ckpt\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1201 - accuracy: 0.9567 - val_loss: 0.7662 - val_accuracy: 0.7944\n",
      "Epoch 2201/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1220 - accuracy: 0.9551 - val_loss: 0.7589 - val_accuracy: 0.7971\n",
      "Epoch 2202/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1244 - accuracy: 0.9549 - val_loss: 0.7951 - val_accuracy: 0.7928\n",
      "Epoch 2203/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1263 - accuracy: 0.9543 - val_loss: 0.7519 - val_accuracy: 0.7980\n",
      "Epoch 2204/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1212 - accuracy: 0.9550 - val_loss: 0.7610 - val_accuracy: 0.7938\n",
      "Epoch 2205/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1250 - accuracy: 0.9546 - val_loss: 0.7608 - val_accuracy: 0.7960\n",
      "Epoch 2206/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1173 - accuracy: 0.9576 - val_loss: 0.7801 - val_accuracy: 0.7973\n",
      "Epoch 2207/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1197 - accuracy: 0.9568 - val_loss: 0.7199 - val_accuracy: 0.8051\n",
      "Epoch 2208/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1196 - accuracy: 0.9570 - val_loss: 0.7232 - val_accuracy: 0.8050\n",
      "Epoch 2209/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1228 - accuracy: 0.9552 - val_loss: 0.6713 - val_accuracy: 0.8136\n",
      "Epoch 2210/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1209 - accuracy: 0.9571 - val_loss: 0.7196 - val_accuracy: 0.8034\n",
      "Epoch 2211/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1198 - accuracy: 0.9572 - val_loss: 0.7187 - val_accuracy: 0.8018\n",
      "Epoch 2212/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1233 - accuracy: 0.9556 - val_loss: 0.6974 - val_accuracy: 0.8055\n",
      "Epoch 2213/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1198 - accuracy: 0.9564 - val_loss: 0.7119 - val_accuracy: 0.8021\n",
      "Epoch 2214/8000\n",
      "1463/1463 [==============================] - 12s 9ms/step - loss: 0.1213 - accuracy: 0.9558 - val_loss: 0.6812 - val_accuracy: 0.8100\n",
      "Epoch 2215/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1217 - accuracy: 0.9562 - val_loss: 0.6794 - val_accuracy: 0.8131\n",
      "Epoch 2216/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1171 - accuracy: 0.9582 - val_loss: 0.7502 - val_accuracy: 0.7962\n",
      "Epoch 2217/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1181 - accuracy: 0.9580 - val_loss: 0.6909 - val_accuracy: 0.8049\n",
      "Epoch 2218/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1215 - accuracy: 0.9564 - val_loss: 0.6896 - val_accuracy: 0.8091\n",
      "Epoch 2219/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1186 - accuracy: 0.9574 - val_loss: 0.7357 - val_accuracy: 0.8051\n",
      "Epoch 2220/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1154 - accuracy: 0.9582 - val_loss: 0.7315 - val_accuracy: 0.8006\n",
      "Epoch 2221/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1193 - accuracy: 0.9570 - val_loss: 0.6946 - val_accuracy: 0.8061\n",
      "Epoch 2222/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1181 - accuracy: 0.9580 - val_loss: 0.7271 - val_accuracy: 0.8017\n",
      "Epoch 2223/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1173 - accuracy: 0.9571 - val_loss: 0.7395 - val_accuracy: 0.8022\n",
      "Epoch 2224/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1285 - accuracy: 0.9542 - val_loss: 0.7407 - val_accuracy: 0.8015\n",
      "Epoch 2225/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1225 - accuracy: 0.9563 - val_loss: 0.6783 - val_accuracy: 0.8147\n",
      "Epoch 2226/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1164 - accuracy: 0.9585 - val_loss: 0.7063 - val_accuracy: 0.8070\n",
      "Epoch 2227/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1203 - accuracy: 0.9566 - val_loss: 0.7914 - val_accuracy: 0.7897\n",
      "Epoch 2228/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1347 - accuracy: 0.9511 - val_loss: 0.6981 - val_accuracy: 0.8106\n",
      "Epoch 2229/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1306 - accuracy: 0.9520 - val_loss: 0.8342 - val_accuracy: 0.7821\n",
      "Epoch 2230/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1276 - accuracy: 0.9538 - val_loss: 0.7353 - val_accuracy: 0.7967\n",
      "Epoch 2231/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1287 - accuracy: 0.9533 - val_loss: 0.7300 - val_accuracy: 0.7952\n",
      "Epoch 2232/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1282 - accuracy: 0.9532 - val_loss: 0.7267 - val_accuracy: 0.8039\n",
      "Epoch 2233/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1306 - accuracy: 0.9523 - val_loss: 0.7418 - val_accuracy: 0.7998\n",
      "Epoch 2234/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1238 - accuracy: 0.9547 - val_loss: 0.8037 - val_accuracy: 0.7901\n",
      "Epoch 2235/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1361 - accuracy: 0.9501 - val_loss: 0.7063 - val_accuracy: 0.8037\n",
      "Epoch 2236/8000\n",
      "1463/1463 [==============================] - 12s 9ms/step - loss: 0.1249 - accuracy: 0.9537 - val_loss: 0.8019 - val_accuracy: 0.7858\n",
      "Epoch 2237/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1334 - accuracy: 0.9503 - val_loss: 0.7374 - val_accuracy: 0.7986\n",
      "Epoch 2238/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1271 - accuracy: 0.9527 - val_loss: 0.6986 - val_accuracy: 0.8073\n",
      "Epoch 2239/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1304 - accuracy: 0.9522 - val_loss: 0.7971 - val_accuracy: 0.7908\n",
      "Epoch 2240/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1255 - accuracy: 0.9539 - val_loss: 0.6972 - val_accuracy: 0.8052\n",
      "Epoch 2241/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1323 - accuracy: 0.9520 - val_loss: 0.7331 - val_accuracy: 0.8006\n",
      "Epoch 2242/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1272 - accuracy: 0.9528 - val_loss: 0.6900 - val_accuracy: 0.8063\n",
      "Epoch 2243/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1214 - accuracy: 0.9553 - val_loss: 0.7498 - val_accuracy: 0.7997\n",
      "Epoch 2244/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1275 - accuracy: 0.9529 - val_loss: 0.8654 - val_accuracy: 0.7862\n",
      "Epoch 2245/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1279 - accuracy: 0.9531 - val_loss: 0.6632 - val_accuracy: 0.8143\n",
      "Epoch 2246/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1246 - accuracy: 0.9542 - val_loss: 0.7330 - val_accuracy: 0.8022\n",
      "Epoch 2247/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1229 - accuracy: 0.9553 - val_loss: 0.7941 - val_accuracy: 0.7926\n",
      "Epoch 2248/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1308 - accuracy: 0.9516 - val_loss: 0.6833 - val_accuracy: 0.8122\n",
      "Epoch 2249/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1247 - accuracy: 0.9547 - val_loss: 0.7499 - val_accuracy: 0.7974\n",
      "Epoch 2250/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1301 - accuracy: 0.9527 - val_loss: 0.7079 - val_accuracy: 0.8035\n",
      "Epoch 2251/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1231 - accuracy: 0.9552 - val_loss: 0.7204 - val_accuracy: 0.8063\n",
      "Epoch 2252/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1259 - accuracy: 0.9536 - val_loss: 0.6881 - val_accuracy: 0.8103\n",
      "Epoch 2253/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1256 - accuracy: 0.9547 - val_loss: 0.7501 - val_accuracy: 0.7982\n",
      "Epoch 2254/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1250 - accuracy: 0.9546 - val_loss: 0.7714 - val_accuracy: 0.7914\n",
      "Epoch 2255/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1261 - accuracy: 0.9542 - val_loss: 0.6890 - val_accuracy: 0.8085\n",
      "Epoch 2256/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1288 - accuracy: 0.9535 - val_loss: 0.8534 - val_accuracy: 0.7763\n",
      "Epoch 2257/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1207 - accuracy: 0.9554 - val_loss: 0.7382 - val_accuracy: 0.8020\n",
      "Epoch 2258/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1240 - accuracy: 0.9541 - val_loss: 0.7172 - val_accuracy: 0.8029\n",
      "Epoch 2259/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1214 - accuracy: 0.9562 - val_loss: 0.6716 - val_accuracy: 0.8153\n",
      "Epoch 2260/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1204 - accuracy: 0.9551 - val_loss: 0.7419 - val_accuracy: 0.8026\n",
      "Epoch 2261/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1225 - accuracy: 0.9553 - val_loss: 0.7133 - val_accuracy: 0.8037\n",
      "Epoch 2262/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1287 - accuracy: 0.9528 - val_loss: 0.7502 - val_accuracy: 0.8016\n",
      "Epoch 2263/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1222 - accuracy: 0.9555 - val_loss: 0.7673 - val_accuracy: 0.7940\n",
      "Epoch 2264/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1199 - accuracy: 0.9559 - val_loss: 0.7436 - val_accuracy: 0.8053\n",
      "Epoch 2265/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1228 - accuracy: 0.9552 - val_loss: 0.7119 - val_accuracy: 0.7998\n",
      "Epoch 2266/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1230 - accuracy: 0.9550 - val_loss: 0.7270 - val_accuracy: 0.8036\n",
      "Epoch 2267/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1198 - accuracy: 0.9563 - val_loss: 0.8233 - val_accuracy: 0.7843\n",
      "Epoch 2268/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1253 - accuracy: 0.9543 - val_loss: 0.7238 - val_accuracy: 0.8046\n",
      "Epoch 2269/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1311 - accuracy: 0.9525 - val_loss: 0.6741 - val_accuracy: 0.8143\n",
      "Epoch 2270/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1245 - accuracy: 0.9545 - val_loss: 0.7289 - val_accuracy: 0.8004\n",
      "Epoch 2271/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1199 - accuracy: 0.9558 - val_loss: 0.7925 - val_accuracy: 0.7955\n",
      "Epoch 2272/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1255 - accuracy: 0.9530 - val_loss: 0.7320 - val_accuracy: 0.8022\n",
      "Epoch 2273/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1196 - accuracy: 0.9564 - val_loss: 0.7106 - val_accuracy: 0.8080\n",
      "Epoch 2274/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1182 - accuracy: 0.9568 - val_loss: 0.6800 - val_accuracy: 0.8135\n",
      "Epoch 2275/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1210 - accuracy: 0.9565 - val_loss: 0.7179 - val_accuracy: 0.8059\n",
      "Epoch 2276/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1247 - accuracy: 0.9549 - val_loss: 0.6766 - val_accuracy: 0.8138\n",
      "Epoch 2277/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1205 - accuracy: 0.9557 - val_loss: 0.7046 - val_accuracy: 0.8108\n",
      "Epoch 2278/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1191 - accuracy: 0.9569 - val_loss: 0.8001 - val_accuracy: 0.7929\n",
      "Epoch 2279/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1217 - accuracy: 0.9561 - val_loss: 0.7354 - val_accuracy: 0.7956\n",
      "Epoch 2280/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1229 - accuracy: 0.9551 - val_loss: 0.7103 - val_accuracy: 0.8067\n",
      "Epoch 2281/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1248 - accuracy: 0.9556 - val_loss: 0.7053 - val_accuracy: 0.8079\n",
      "Epoch 2282/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1240 - accuracy: 0.9540 - val_loss: 0.6993 - val_accuracy: 0.8080\n",
      "Epoch 2283/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1238 - accuracy: 0.9548 - val_loss: 0.7873 - val_accuracy: 0.7921\n",
      "Epoch 2284/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1305 - accuracy: 0.9527 - val_loss: 0.7208 - val_accuracy: 0.8031\n",
      "Epoch 2285/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1202 - accuracy: 0.9562 - val_loss: 0.6793 - val_accuracy: 0.8154\n",
      "Epoch 2286/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1241 - accuracy: 0.9543 - val_loss: 0.6939 - val_accuracy: 0.8111\n",
      "Epoch 2287/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1189 - accuracy: 0.9560 - val_loss: 0.7398 - val_accuracy: 0.7992\n",
      "Epoch 2288/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1211 - accuracy: 0.9569 - val_loss: 0.8425 - val_accuracy: 0.7775\n",
      "Epoch 2289/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1208 - accuracy: 0.9559 - val_loss: 0.6915 - val_accuracy: 0.8069\n",
      "Epoch 2290/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1221 - accuracy: 0.9561 - val_loss: 0.7136 - val_accuracy: 0.8046\n",
      "Epoch 2291/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1223 - accuracy: 0.9550 - val_loss: 0.7427 - val_accuracy: 0.8040\n",
      "Epoch 2292/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1247 - accuracy: 0.9546 - val_loss: 0.7302 - val_accuracy: 0.8020\n",
      "Epoch 2293/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1261 - accuracy: 0.9537 - val_loss: 0.6741 - val_accuracy: 0.8115\n",
      "Epoch 2294/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1182 - accuracy: 0.9574 - val_loss: 0.7105 - val_accuracy: 0.8048\n",
      "Epoch 2295/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1209 - accuracy: 0.9562 - val_loss: 0.7901 - val_accuracy: 0.7950\n",
      "Epoch 2296/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1214 - accuracy: 0.9550 - val_loss: 0.7209 - val_accuracy: 0.8014\n",
      "Epoch 2297/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1239 - accuracy: 0.9547 - val_loss: 0.7809 - val_accuracy: 0.7862\n",
      "Epoch 2298/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1258 - accuracy: 0.9539 - val_loss: 0.6838 - val_accuracy: 0.8133\n",
      "Epoch 2299/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1205 - accuracy: 0.9566 - val_loss: 0.7358 - val_accuracy: 0.8044\n",
      "Epoch 2300/8000\n",
      "1461/1463 [============================>.] - ETA: 0s - loss: 0.1183 - accuracy: 0.9572\n",
      "Epoch 2300: saving model to ./training_ckpt_20240109205949_v8_240109_d10000_n4096_b64_e8000_c100_Adamax\\cp-000002300.ckpt\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1183 - accuracy: 0.9572 - val_loss: 0.6946 - val_accuracy: 0.8077\n",
      "Epoch 2301/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1224 - accuracy: 0.9554 - val_loss: 0.7058 - val_accuracy: 0.8091\n",
      "Epoch 2302/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1213 - accuracy: 0.9556 - val_loss: 0.6762 - val_accuracy: 0.8157\n",
      "Epoch 2303/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1239 - accuracy: 0.9556 - val_loss: 0.7165 - val_accuracy: 0.8019\n",
      "Epoch 2304/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1181 - accuracy: 0.9574 - val_loss: 0.7053 - val_accuracy: 0.8081\n",
      "Epoch 2305/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1206 - accuracy: 0.9556 - val_loss: 0.6877 - val_accuracy: 0.8115\n",
      "Epoch 2306/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1223 - accuracy: 0.9551 - val_loss: 0.7430 - val_accuracy: 0.8018\n",
      "Epoch 2307/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1153 - accuracy: 0.9581 - val_loss: 0.7206 - val_accuracy: 0.8048\n",
      "Epoch 2308/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1216 - accuracy: 0.9557 - val_loss: 0.7557 - val_accuracy: 0.7961\n",
      "Epoch 2309/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1199 - accuracy: 0.9566 - val_loss: 0.7363 - val_accuracy: 0.8011\n",
      "Epoch 2310/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1175 - accuracy: 0.9578 - val_loss: 0.7768 - val_accuracy: 0.7998\n",
      "Epoch 2311/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1238 - accuracy: 0.9542 - val_loss: 0.7782 - val_accuracy: 0.7939\n",
      "Epoch 2312/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1237 - accuracy: 0.9557 - val_loss: 0.7085 - val_accuracy: 0.8067\n",
      "Epoch 2313/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1206 - accuracy: 0.9562 - val_loss: 0.6862 - val_accuracy: 0.8066\n",
      "Epoch 2314/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1185 - accuracy: 0.9563 - val_loss: 0.6896 - val_accuracy: 0.8089\n",
      "Epoch 2315/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1217 - accuracy: 0.9564 - val_loss: 0.7359 - val_accuracy: 0.8006\n",
      "Epoch 2316/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1222 - accuracy: 0.9556 - val_loss: 0.6898 - val_accuracy: 0.8130\n",
      "Epoch 2317/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1176 - accuracy: 0.9566 - val_loss: 0.7460 - val_accuracy: 0.7973\n",
      "Epoch 2318/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1241 - accuracy: 0.9550 - val_loss: 0.7459 - val_accuracy: 0.7958\n",
      "Epoch 2319/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1180 - accuracy: 0.9568 - val_loss: 0.7513 - val_accuracy: 0.8042\n",
      "Epoch 2320/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1177 - accuracy: 0.9570 - val_loss: 0.7497 - val_accuracy: 0.7990\n",
      "Epoch 2321/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1225 - accuracy: 0.9556 - val_loss: 0.7427 - val_accuracy: 0.8022\n",
      "Epoch 2322/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1210 - accuracy: 0.9560 - val_loss: 0.7192 - val_accuracy: 0.8041\n",
      "Epoch 2323/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1198 - accuracy: 0.9559 - val_loss: 0.7222 - val_accuracy: 0.8060\n",
      "Epoch 2324/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1245 - accuracy: 0.9549 - val_loss: 0.7007 - val_accuracy: 0.8081\n",
      "Epoch 2325/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1171 - accuracy: 0.9579 - val_loss: 0.7450 - val_accuracy: 0.8006\n",
      "Epoch 2326/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1216 - accuracy: 0.9552 - val_loss: 0.6867 - val_accuracy: 0.8095\n",
      "Epoch 2327/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1173 - accuracy: 0.9569 - val_loss: 0.7813 - val_accuracy: 0.7932\n",
      "Epoch 2328/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1155 - accuracy: 0.9578 - val_loss: 0.7134 - val_accuracy: 0.8077\n",
      "Epoch 2329/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1195 - accuracy: 0.9572 - val_loss: 0.7250 - val_accuracy: 0.8064\n",
      "Epoch 2330/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1174 - accuracy: 0.9573 - val_loss: 0.7174 - val_accuracy: 0.8058\n",
      "Epoch 2331/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1169 - accuracy: 0.9576 - val_loss: 0.7438 - val_accuracy: 0.8029\n",
      "Epoch 2332/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1185 - accuracy: 0.9564 - val_loss: 0.6734 - val_accuracy: 0.8132\n",
      "Epoch 2333/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1165 - accuracy: 0.9572 - val_loss: 0.7125 - val_accuracy: 0.8037\n",
      "Epoch 2334/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1157 - accuracy: 0.9576 - val_loss: 0.7047 - val_accuracy: 0.8089\n",
      "Epoch 2335/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1167 - accuracy: 0.9572 - val_loss: 0.6985 - val_accuracy: 0.8094\n",
      "Epoch 2336/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1155 - accuracy: 0.9584 - val_loss: 0.6769 - val_accuracy: 0.8105\n",
      "Epoch 2337/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1188 - accuracy: 0.9573 - val_loss: 0.7557 - val_accuracy: 0.8012\n",
      "Epoch 2338/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1214 - accuracy: 0.9558 - val_loss: 0.7271 - val_accuracy: 0.8068\n",
      "Epoch 2339/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1171 - accuracy: 0.9574 - val_loss: 0.6817 - val_accuracy: 0.8130\n",
      "Epoch 2340/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1202 - accuracy: 0.9568 - val_loss: 0.7300 - val_accuracy: 0.8002\n",
      "Epoch 2341/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1188 - accuracy: 0.9561 - val_loss: 0.7033 - val_accuracy: 0.8091\n",
      "Epoch 2342/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1168 - accuracy: 0.9580 - val_loss: 0.7686 - val_accuracy: 0.7956\n",
      "Epoch 2343/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1253 - accuracy: 0.9551 - val_loss: 0.7299 - val_accuracy: 0.8038\n",
      "Epoch 2344/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1191 - accuracy: 0.9563 - val_loss: 0.7042 - val_accuracy: 0.8088\n",
      "Epoch 2345/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1191 - accuracy: 0.9568 - val_loss: 0.7272 - val_accuracy: 0.8037\n",
      "Epoch 2346/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1172 - accuracy: 0.9572 - val_loss: 0.7237 - val_accuracy: 0.8059\n",
      "Epoch 2347/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1177 - accuracy: 0.9575 - val_loss: 0.7106 - val_accuracy: 0.8062\n",
      "Epoch 2348/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1201 - accuracy: 0.9568 - val_loss: 0.7012 - val_accuracy: 0.8092\n",
      "Epoch 2349/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1146 - accuracy: 0.9578 - val_loss: 0.7141 - val_accuracy: 0.8063\n",
      "Epoch 2350/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1132 - accuracy: 0.9583 - val_loss: 0.7284 - val_accuracy: 0.8051\n",
      "Epoch 2351/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1147 - accuracy: 0.9577 - val_loss: 0.7363 - val_accuracy: 0.8011\n",
      "Epoch 2352/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1223 - accuracy: 0.9560 - val_loss: 0.7778 - val_accuracy: 0.7901\n",
      "Epoch 2353/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1136 - accuracy: 0.9589 - val_loss: 0.7074 - val_accuracy: 0.8062\n",
      "Epoch 2354/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1161 - accuracy: 0.9578 - val_loss: 0.7915 - val_accuracy: 0.7940\n",
      "Epoch 2355/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1234 - accuracy: 0.9549 - val_loss: 0.7033 - val_accuracy: 0.8093\n",
      "Epoch 2356/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1180 - accuracy: 0.9572 - val_loss: 0.6826 - val_accuracy: 0.8115\n",
      "Epoch 2357/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1187 - accuracy: 0.9570 - val_loss: 0.7357 - val_accuracy: 0.8048\n",
      "Epoch 2358/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1198 - accuracy: 0.9563 - val_loss: 0.8060 - val_accuracy: 0.7949\n",
      "Epoch 2359/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1159 - accuracy: 0.9579 - val_loss: 0.6919 - val_accuracy: 0.8118\n",
      "Epoch 2360/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1187 - accuracy: 0.9568 - val_loss: 0.7331 - val_accuracy: 0.8057\n",
      "Epoch 2361/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1120 - accuracy: 0.9585 - val_loss: 0.7294 - val_accuracy: 0.7998\n",
      "Epoch 2362/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1179 - accuracy: 0.9583 - val_loss: 0.6995 - val_accuracy: 0.8063\n",
      "Epoch 2363/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1166 - accuracy: 0.9575 - val_loss: 0.8577 - val_accuracy: 0.7883\n",
      "Epoch 2364/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1215 - accuracy: 0.9561 - val_loss: 0.7497 - val_accuracy: 0.7993\n",
      "Epoch 2365/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1164 - accuracy: 0.9577 - val_loss: 0.6805 - val_accuracy: 0.8152\n",
      "Epoch 2366/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1159 - accuracy: 0.9578 - val_loss: 0.7557 - val_accuracy: 0.8033\n",
      "Epoch 2367/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1167 - accuracy: 0.9579 - val_loss: 0.8388 - val_accuracy: 0.7900\n",
      "Epoch 2368/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1194 - accuracy: 0.9566 - val_loss: 0.6841 - val_accuracy: 0.8099\n",
      "Epoch 2369/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1166 - accuracy: 0.9578 - val_loss: 0.7027 - val_accuracy: 0.8093\n",
      "Epoch 2370/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1174 - accuracy: 0.9566 - val_loss: 0.7018 - val_accuracy: 0.8058\n",
      "Epoch 2371/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1201 - accuracy: 0.9560 - val_loss: 0.6918 - val_accuracy: 0.8141\n",
      "Epoch 2372/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1150 - accuracy: 0.9584 - val_loss: 0.7370 - val_accuracy: 0.8051\n",
      "Epoch 2373/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1164 - accuracy: 0.9576 - val_loss: 0.6971 - val_accuracy: 0.8071\n",
      "Epoch 2374/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1176 - accuracy: 0.9575 - val_loss: 0.7866 - val_accuracy: 0.7993\n",
      "Epoch 2375/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1209 - accuracy: 0.9558 - val_loss: 0.7366 - val_accuracy: 0.7997\n",
      "Epoch 2376/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1184 - accuracy: 0.9570 - val_loss: 0.7321 - val_accuracy: 0.8033\n",
      "Epoch 2377/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1179 - accuracy: 0.9572 - val_loss: 0.6879 - val_accuracy: 0.8127\n",
      "Epoch 2378/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1171 - accuracy: 0.9574 - val_loss: 0.6893 - val_accuracy: 0.8091\n",
      "Epoch 2379/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1186 - accuracy: 0.9561 - val_loss: 0.8018 - val_accuracy: 0.7969\n",
      "Epoch 2380/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1190 - accuracy: 0.9573 - val_loss: 0.6791 - val_accuracy: 0.8117\n",
      "Epoch 2381/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1180 - accuracy: 0.9576 - val_loss: 0.7639 - val_accuracy: 0.8001\n",
      "Epoch 2382/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1175 - accuracy: 0.9571 - val_loss: 0.8151 - val_accuracy: 0.7973\n",
      "Epoch 2383/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1152 - accuracy: 0.9580 - val_loss: 0.6777 - val_accuracy: 0.8168\n",
      "Epoch 2384/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1186 - accuracy: 0.9575 - val_loss: 0.6737 - val_accuracy: 0.8163\n",
      "Epoch 2385/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1130 - accuracy: 0.9588 - val_loss: 0.6862 - val_accuracy: 0.8147\n",
      "Epoch 2386/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1176 - accuracy: 0.9574 - val_loss: 0.7423 - val_accuracy: 0.7990\n",
      "Epoch 2387/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1151 - accuracy: 0.9587 - val_loss: 0.6868 - val_accuracy: 0.8098\n",
      "Epoch 2388/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1121 - accuracy: 0.9598 - val_loss: 0.7782 - val_accuracy: 0.7987\n",
      "Epoch 2389/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1179 - accuracy: 0.9571 - val_loss: 0.7289 - val_accuracy: 0.8037\n",
      "Epoch 2390/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1177 - accuracy: 0.9581 - val_loss: 0.7539 - val_accuracy: 0.8026\n",
      "Epoch 2391/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1149 - accuracy: 0.9589 - val_loss: 0.7464 - val_accuracy: 0.8061\n",
      "Epoch 2392/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1157 - accuracy: 0.9578 - val_loss: 0.7299 - val_accuracy: 0.8035\n",
      "Epoch 2393/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1189 - accuracy: 0.9573 - val_loss: 0.7183 - val_accuracy: 0.8075\n",
      "Epoch 2394/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1132 - accuracy: 0.9586 - val_loss: 0.7289 - val_accuracy: 0.8066\n",
      "Epoch 2395/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1148 - accuracy: 0.9578 - val_loss: 0.7084 - val_accuracy: 0.8052\n",
      "Epoch 2396/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1136 - accuracy: 0.9579 - val_loss: 0.7391 - val_accuracy: 0.8048\n",
      "Epoch 2397/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1094 - accuracy: 0.9605 - val_loss: 0.7424 - val_accuracy: 0.8068\n",
      "Epoch 2398/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1129 - accuracy: 0.9592 - val_loss: 0.7762 - val_accuracy: 0.7954\n",
      "Epoch 2399/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1181 - accuracy: 0.9572 - val_loss: 0.7784 - val_accuracy: 0.7958\n",
      "Epoch 2400/8000\n",
      "1462/1463 [============================>.] - ETA: 0s - loss: 0.1175 - accuracy: 0.9578\n",
      "Epoch 2400: saving model to ./training_ckpt_20240109205949_v8_240109_d10000_n4096_b64_e8000_c100_Adamax\\cp-000002400.ckpt\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1175 - accuracy: 0.9578 - val_loss: 0.7234 - val_accuracy: 0.8089\n",
      "Epoch 2401/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1159 - accuracy: 0.9575 - val_loss: 0.7330 - val_accuracy: 0.8037\n",
      "Epoch 2402/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1131 - accuracy: 0.9596 - val_loss: 0.6949 - val_accuracy: 0.8133\n",
      "Epoch 2403/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1098 - accuracy: 0.9598 - val_loss: 0.8394 - val_accuracy: 0.7891\n",
      "Epoch 2404/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1187 - accuracy: 0.9575 - val_loss: 0.7298 - val_accuracy: 0.8061\n",
      "Epoch 2405/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1197 - accuracy: 0.9574 - val_loss: 0.7655 - val_accuracy: 0.7951\n",
      "Epoch 2406/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1155 - accuracy: 0.9589 - val_loss: 0.7309 - val_accuracy: 0.8067\n",
      "Epoch 2407/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1177 - accuracy: 0.9575 - val_loss: 0.7298 - val_accuracy: 0.8039\n",
      "Epoch 2408/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1105 - accuracy: 0.9601 - val_loss: 0.6942 - val_accuracy: 0.8154\n",
      "Epoch 2409/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1156 - accuracy: 0.9590 - val_loss: 0.7194 - val_accuracy: 0.8077\n",
      "Epoch 2410/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1127 - accuracy: 0.9590 - val_loss: 0.7298 - val_accuracy: 0.8057\n",
      "Epoch 2411/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1161 - accuracy: 0.9592 - val_loss: 0.7448 - val_accuracy: 0.8047\n",
      "Epoch 2412/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1128 - accuracy: 0.9584 - val_loss: 0.6813 - val_accuracy: 0.8162\n",
      "Epoch 2413/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1091 - accuracy: 0.9602 - val_loss: 0.8319 - val_accuracy: 0.7896\n",
      "Epoch 2414/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1186 - accuracy: 0.9567 - val_loss: 0.7223 - val_accuracy: 0.8100\n",
      "Epoch 2415/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1157 - accuracy: 0.9571 - val_loss: 0.7238 - val_accuracy: 0.8074\n",
      "Epoch 2416/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1185 - accuracy: 0.9565 - val_loss: 0.7657 - val_accuracy: 0.7995\n",
      "Epoch 2417/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1100 - accuracy: 0.9606 - val_loss: 0.7373 - val_accuracy: 0.7999\n",
      "Epoch 2418/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1149 - accuracy: 0.9584 - val_loss: 0.7390 - val_accuracy: 0.8022\n",
      "Epoch 2419/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1140 - accuracy: 0.9584 - val_loss: 0.7069 - val_accuracy: 0.8086\n",
      "Epoch 2420/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1174 - accuracy: 0.9571 - val_loss: 0.8261 - val_accuracy: 0.7860\n",
      "Epoch 2421/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1143 - accuracy: 0.9583 - val_loss: 0.7067 - val_accuracy: 0.8119\n",
      "Epoch 2422/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1225 - accuracy: 0.9558 - val_loss: 0.7200 - val_accuracy: 0.8089\n",
      "Epoch 2423/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1055 - accuracy: 0.9627 - val_loss: 0.6793 - val_accuracy: 0.8170\n",
      "Epoch 2424/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1150 - accuracy: 0.9581 - val_loss: 0.6691 - val_accuracy: 0.8178\n",
      "Epoch 2425/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1114 - accuracy: 0.9599 - val_loss: 0.7519 - val_accuracy: 0.8019\n",
      "Epoch 2426/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1163 - accuracy: 0.9588 - val_loss: 0.8184 - val_accuracy: 0.7888\n",
      "Epoch 2427/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1133 - accuracy: 0.9594 - val_loss: 0.6918 - val_accuracy: 0.8136\n",
      "Epoch 2428/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1167 - accuracy: 0.9582 - val_loss: 0.6710 - val_accuracy: 0.8164\n",
      "Epoch 2429/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1134 - accuracy: 0.9585 - val_loss: 0.7058 - val_accuracy: 0.8068\n",
      "Epoch 2430/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1108 - accuracy: 0.9598 - val_loss: 0.8091 - val_accuracy: 0.7965\n",
      "Epoch 2431/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1195 - accuracy: 0.9562 - val_loss: 0.6990 - val_accuracy: 0.8113\n",
      "Epoch 2432/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1138 - accuracy: 0.9585 - val_loss: 0.7000 - val_accuracy: 0.8105\n",
      "Epoch 2433/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1132 - accuracy: 0.9591 - val_loss: 0.6711 - val_accuracy: 0.8162\n",
      "Epoch 2434/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1157 - accuracy: 0.9580 - val_loss: 0.7372 - val_accuracy: 0.8012\n",
      "Epoch 2435/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1144 - accuracy: 0.9585 - val_loss: 0.7144 - val_accuracy: 0.8076\n",
      "Epoch 2436/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1163 - accuracy: 0.9585 - val_loss: 0.7253 - val_accuracy: 0.8060\n",
      "Epoch 2437/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1167 - accuracy: 0.9572 - val_loss: 0.8003 - val_accuracy: 0.7916\n",
      "Epoch 2438/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1136 - accuracy: 0.9590 - val_loss: 0.7415 - val_accuracy: 0.8067\n",
      "Epoch 2439/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1171 - accuracy: 0.9579 - val_loss: 0.7195 - val_accuracy: 0.8091\n",
      "Epoch 2440/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1122 - accuracy: 0.9602 - val_loss: 0.7358 - val_accuracy: 0.8037\n",
      "Epoch 2441/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1114 - accuracy: 0.9603 - val_loss: 0.7292 - val_accuracy: 0.8055\n",
      "Epoch 2442/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1147 - accuracy: 0.9579 - val_loss: 0.6615 - val_accuracy: 0.8194\n",
      "Epoch 2443/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1132 - accuracy: 0.9593 - val_loss: 0.7128 - val_accuracy: 0.8092\n",
      "Epoch 2444/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1101 - accuracy: 0.9604 - val_loss: 0.6990 - val_accuracy: 0.8132\n",
      "Epoch 2445/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1189 - accuracy: 0.9569 - val_loss: 0.7603 - val_accuracy: 0.8012\n",
      "Epoch 2446/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1153 - accuracy: 0.9579 - val_loss: 0.7167 - val_accuracy: 0.8099\n",
      "Epoch 2447/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1099 - accuracy: 0.9603 - val_loss: 0.6971 - val_accuracy: 0.8115\n",
      "Epoch 2448/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1093 - accuracy: 0.9604 - val_loss: 0.7187 - val_accuracy: 0.8116\n",
      "Epoch 2449/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1145 - accuracy: 0.9594 - val_loss: 0.7179 - val_accuracy: 0.8079\n",
      "Epoch 2450/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1090 - accuracy: 0.9605 - val_loss: 0.6674 - val_accuracy: 0.8182\n",
      "Epoch 2451/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1177 - accuracy: 0.9567 - val_loss: 0.6818 - val_accuracy: 0.8157\n",
      "Epoch 2452/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1087 - accuracy: 0.9610 - val_loss: 0.7158 - val_accuracy: 0.8077\n",
      "Epoch 2453/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1135 - accuracy: 0.9589 - val_loss: 0.7491 - val_accuracy: 0.8048\n",
      "Epoch 2454/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1146 - accuracy: 0.9590 - val_loss: 0.7104 - val_accuracy: 0.8117\n",
      "Epoch 2455/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1107 - accuracy: 0.9601 - val_loss: 0.6679 - val_accuracy: 0.8204\n",
      "Epoch 2456/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1147 - accuracy: 0.9582 - val_loss: 0.7175 - val_accuracy: 0.8062\n",
      "Epoch 2457/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1122 - accuracy: 0.9598 - val_loss: 0.8406 - val_accuracy: 0.7904\n",
      "Epoch 2458/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1163 - accuracy: 0.9582 - val_loss: 0.6997 - val_accuracy: 0.8142\n",
      "Epoch 2459/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1114 - accuracy: 0.9602 - val_loss: 0.6880 - val_accuracy: 0.8150\n",
      "Epoch 2460/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1185 - accuracy: 0.9580 - val_loss: 0.7155 - val_accuracy: 0.8111\n",
      "Epoch 2461/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1123 - accuracy: 0.9594 - val_loss: 0.7237 - val_accuracy: 0.8035\n",
      "Epoch 2462/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1206 - accuracy: 0.9567 - val_loss: 0.7039 - val_accuracy: 0.8112\n",
      "Epoch 2463/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1117 - accuracy: 0.9601 - val_loss: 0.6959 - val_accuracy: 0.8116\n",
      "Epoch 2464/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1093 - accuracy: 0.9607 - val_loss: 0.6920 - val_accuracy: 0.8117\n",
      "Epoch 2465/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1090 - accuracy: 0.9605 - val_loss: 0.7026 - val_accuracy: 0.8101\n",
      "Epoch 2466/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1171 - accuracy: 0.9582 - val_loss: 0.7245 - val_accuracy: 0.8130\n",
      "Epoch 2467/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1176 - accuracy: 0.9581 - val_loss: 0.8908 - val_accuracy: 0.7959\n",
      "Epoch 2468/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1132 - accuracy: 0.9588 - val_loss: 0.6977 - val_accuracy: 0.8128\n",
      "Epoch 2469/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1112 - accuracy: 0.9602 - val_loss: 0.7093 - val_accuracy: 0.8106\n",
      "Epoch 2470/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1086 - accuracy: 0.9609 - val_loss: 0.7416 - val_accuracy: 0.8049\n",
      "Epoch 2471/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1109 - accuracy: 0.9595 - val_loss: 0.7746 - val_accuracy: 0.8004\n",
      "Epoch 2472/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1165 - accuracy: 0.9581 - val_loss: 0.6987 - val_accuracy: 0.8112\n",
      "Epoch 2473/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1112 - accuracy: 0.9597 - val_loss: 0.6896 - val_accuracy: 0.8151\n",
      "Epoch 2474/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1102 - accuracy: 0.9603 - val_loss: 0.7883 - val_accuracy: 0.7962\n",
      "Epoch 2475/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1165 - accuracy: 0.9583 - val_loss: 0.7057 - val_accuracy: 0.8100\n",
      "Epoch 2476/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1102 - accuracy: 0.9600 - val_loss: 0.6897 - val_accuracy: 0.8159\n",
      "Epoch 2477/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1095 - accuracy: 0.9616 - val_loss: 0.7396 - val_accuracy: 0.8024\n",
      "Epoch 2478/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1075 - accuracy: 0.9615 - val_loss: 0.7075 - val_accuracy: 0.8086\n",
      "Epoch 2479/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1141 - accuracy: 0.9582 - val_loss: 0.7229 - val_accuracy: 0.8083\n",
      "Epoch 2480/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1127 - accuracy: 0.9590 - val_loss: 0.7625 - val_accuracy: 0.8060\n",
      "Epoch 2481/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1094 - accuracy: 0.9612 - val_loss: 0.6815 - val_accuracy: 0.8163\n",
      "Epoch 2482/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1107 - accuracy: 0.9603 - val_loss: 0.7057 - val_accuracy: 0.8113\n",
      "Epoch 2483/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1123 - accuracy: 0.9602 - val_loss: 0.7870 - val_accuracy: 0.7953\n",
      "Epoch 2484/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1095 - accuracy: 0.9605 - val_loss: 0.8462 - val_accuracy: 0.7919\n",
      "Epoch 2485/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1171 - accuracy: 0.9577 - val_loss: 0.7458 - val_accuracy: 0.8064\n",
      "Epoch 2486/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1109 - accuracy: 0.9604 - val_loss: 0.7069 - val_accuracy: 0.8147\n",
      "Epoch 2487/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1097 - accuracy: 0.9606 - val_loss: 0.7184 - val_accuracy: 0.8123\n",
      "Epoch 2488/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1092 - accuracy: 0.9610 - val_loss: 0.7041 - val_accuracy: 0.8106\n",
      "Epoch 2489/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1148 - accuracy: 0.9587 - val_loss: 0.7369 - val_accuracy: 0.8052\n",
      "Epoch 2490/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1129 - accuracy: 0.9595 - val_loss: 0.6847 - val_accuracy: 0.8152\n",
      "Epoch 2491/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1141 - accuracy: 0.9590 - val_loss: 0.7276 - val_accuracy: 0.8121\n",
      "Epoch 2492/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1136 - accuracy: 0.9580 - val_loss: 0.7041 - val_accuracy: 0.8133\n",
      "Epoch 2493/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1092 - accuracy: 0.9603 - val_loss: 0.7505 - val_accuracy: 0.8072\n",
      "Epoch 2494/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1096 - accuracy: 0.9607 - val_loss: 0.7417 - val_accuracy: 0.8054\n",
      "Epoch 2495/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1173 - accuracy: 0.9574 - val_loss: 0.7648 - val_accuracy: 0.7988\n",
      "Epoch 2496/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1105 - accuracy: 0.9597 - val_loss: 0.7116 - val_accuracy: 0.8107\n",
      "Epoch 2497/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1128 - accuracy: 0.9592 - val_loss: 0.7177 - val_accuracy: 0.8098\n",
      "Epoch 2498/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1119 - accuracy: 0.9593 - val_loss: 0.7890 - val_accuracy: 0.8003\n",
      "Epoch 2499/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1111 - accuracy: 0.9609 - val_loss: 0.7122 - val_accuracy: 0.8109\n",
      "Epoch 2500/8000\n",
      "1458/1463 [============================>.] - ETA: 0s - loss: 0.1121 - accuracy: 0.9601\n",
      "Epoch 2500: saving model to ./training_ckpt_20240109205949_v8_240109_d10000_n4096_b64_e8000_c100_Adamax\\cp-000002500.ckpt\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1121 - accuracy: 0.9601 - val_loss: 0.6451 - val_accuracy: 0.8205\n",
      "Epoch 2501/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1096 - accuracy: 0.9601 - val_loss: 0.7263 - val_accuracy: 0.8112\n",
      "Epoch 2502/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1122 - accuracy: 0.9599 - val_loss: 0.6977 - val_accuracy: 0.8141\n",
      "Epoch 2503/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1110 - accuracy: 0.9596 - val_loss: 0.7053 - val_accuracy: 0.8101\n",
      "Epoch 2504/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1123 - accuracy: 0.9599 - val_loss: 0.7361 - val_accuracy: 0.8035\n",
      "Epoch 2505/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1164 - accuracy: 0.9585 - val_loss: 0.7260 - val_accuracy: 0.8074\n",
      "Epoch 2506/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1050 - accuracy: 0.9625 - val_loss: 0.7136 - val_accuracy: 0.8108\n",
      "Epoch 2507/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1117 - accuracy: 0.9601 - val_loss: 0.6713 - val_accuracy: 0.8179\n",
      "Epoch 2508/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1137 - accuracy: 0.9596 - val_loss: 0.7088 - val_accuracy: 0.8129\n",
      "Epoch 2509/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1094 - accuracy: 0.9610 - val_loss: 0.7306 - val_accuracy: 0.8072\n",
      "Epoch 2510/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1146 - accuracy: 0.9599 - val_loss: 0.7011 - val_accuracy: 0.8149\n",
      "Epoch 2511/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1056 - accuracy: 0.9621 - val_loss: 0.6948 - val_accuracy: 0.8172\n",
      "Epoch 2512/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1089 - accuracy: 0.9610 - val_loss: 0.7255 - val_accuracy: 0.8093\n",
      "Epoch 2513/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1116 - accuracy: 0.9599 - val_loss: 0.7224 - val_accuracy: 0.8062\n",
      "Epoch 2514/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1050 - accuracy: 0.9628 - val_loss: 0.6760 - val_accuracy: 0.8182\n",
      "Epoch 2515/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1095 - accuracy: 0.9609 - val_loss: 0.7167 - val_accuracy: 0.8117\n",
      "Epoch 2516/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1082 - accuracy: 0.9610 - val_loss: 0.7046 - val_accuracy: 0.8135\n",
      "Epoch 2517/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1057 - accuracy: 0.9621 - val_loss: 0.7016 - val_accuracy: 0.8128\n",
      "Epoch 2518/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1076 - accuracy: 0.9616 - val_loss: 0.7505 - val_accuracy: 0.8062\n",
      "Epoch 2519/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1107 - accuracy: 0.9604 - val_loss: 0.7610 - val_accuracy: 0.8015\n",
      "Epoch 2520/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1118 - accuracy: 0.9600 - val_loss: 0.7394 - val_accuracy: 0.8063\n",
      "Epoch 2521/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1141 - accuracy: 0.9588 - val_loss: 0.7747 - val_accuracy: 0.8017\n",
      "Epoch 2522/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1130 - accuracy: 0.9601 - val_loss: 0.8106 - val_accuracy: 0.7889\n",
      "Epoch 2523/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1123 - accuracy: 0.9598 - val_loss: 0.8403 - val_accuracy: 0.7898\n",
      "Epoch 2524/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1079 - accuracy: 0.9614 - val_loss: 0.7430 - val_accuracy: 0.8079\n",
      "Epoch 2525/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1079 - accuracy: 0.9617 - val_loss: 0.7899 - val_accuracy: 0.8011\n",
      "Epoch 2526/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1104 - accuracy: 0.9606 - val_loss: 0.7012 - val_accuracy: 0.8133\n",
      "Epoch 2527/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1129 - accuracy: 0.9603 - val_loss: 0.6688 - val_accuracy: 0.8181\n",
      "Epoch 2528/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1088 - accuracy: 0.9615 - val_loss: 0.6867 - val_accuracy: 0.8196\n",
      "Epoch 2529/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1038 - accuracy: 0.9630 - val_loss: 0.7829 - val_accuracy: 0.7975\n",
      "Epoch 2530/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1111 - accuracy: 0.9610 - val_loss: 0.7617 - val_accuracy: 0.8019\n",
      "Epoch 2531/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1059 - accuracy: 0.9613 - val_loss: 0.7922 - val_accuracy: 0.7920\n",
      "Epoch 2532/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1080 - accuracy: 0.9612 - val_loss: 0.7201 - val_accuracy: 0.8086\n",
      "Epoch 2533/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1057 - accuracy: 0.9625 - val_loss: 0.7533 - val_accuracy: 0.8062\n",
      "Epoch 2534/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1098 - accuracy: 0.9611 - val_loss: 0.7046 - val_accuracy: 0.8133\n",
      "Epoch 2535/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1133 - accuracy: 0.9594 - val_loss: 0.7889 - val_accuracy: 0.7967\n",
      "Epoch 2536/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1108 - accuracy: 0.9608 - val_loss: 0.7510 - val_accuracy: 0.8070\n",
      "Epoch 2537/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1074 - accuracy: 0.9611 - val_loss: 0.7800 - val_accuracy: 0.8054\n",
      "Epoch 2538/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1020 - accuracy: 0.9634 - val_loss: 0.6771 - val_accuracy: 0.8185\n",
      "Epoch 2539/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1128 - accuracy: 0.9593 - val_loss: 0.7503 - val_accuracy: 0.8034\n",
      "Epoch 2540/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1125 - accuracy: 0.9602 - val_loss: 0.6884 - val_accuracy: 0.8148\n",
      "Epoch 2541/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1085 - accuracy: 0.9612 - val_loss: 0.7039 - val_accuracy: 0.8114\n",
      "Epoch 2542/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1080 - accuracy: 0.9612 - val_loss: 0.7058 - val_accuracy: 0.8141\n",
      "Epoch 2543/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1120 - accuracy: 0.9598 - val_loss: 0.7161 - val_accuracy: 0.8110\n",
      "Epoch 2544/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1084 - accuracy: 0.9615 - val_loss: 0.7220 - val_accuracy: 0.8052\n",
      "Epoch 2545/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1063 - accuracy: 0.9617 - val_loss: 0.7711 - val_accuracy: 0.8042\n",
      "Epoch 2546/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1013 - accuracy: 0.9637 - val_loss: 0.7292 - val_accuracy: 0.8096\n",
      "Epoch 2547/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1064 - accuracy: 0.9621 - val_loss: 0.7293 - val_accuracy: 0.8081\n",
      "Epoch 2548/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1064 - accuracy: 0.9620 - val_loss: 0.7607 - val_accuracy: 0.7991\n",
      "Epoch 2549/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1057 - accuracy: 0.9626 - val_loss: 0.8071 - val_accuracy: 0.7989\n",
      "Epoch 2550/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1039 - accuracy: 0.9628 - val_loss: 0.6705 - val_accuracy: 0.8171\n",
      "Epoch 2551/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1122 - accuracy: 0.9609 - val_loss: 0.7076 - val_accuracy: 0.8109\n",
      "Epoch 2552/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1109 - accuracy: 0.9597 - val_loss: 0.7431 - val_accuracy: 0.8074\n",
      "Epoch 2553/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1108 - accuracy: 0.9610 - val_loss: 0.7504 - val_accuracy: 0.8030\n",
      "Epoch 2554/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1036 - accuracy: 0.9626 - val_loss: 0.7530 - val_accuracy: 0.7995\n",
      "Epoch 2555/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1049 - accuracy: 0.9622 - val_loss: 0.6642 - val_accuracy: 0.8216\n",
      "Epoch 2556/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1013 - accuracy: 0.9638 - val_loss: 0.7015 - val_accuracy: 0.8182\n",
      "Epoch 2557/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1098 - accuracy: 0.9604 - val_loss: 0.6877 - val_accuracy: 0.8166\n",
      "Epoch 2558/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1059 - accuracy: 0.9621 - val_loss: 0.7051 - val_accuracy: 0.8124\n",
      "Epoch 2559/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1095 - accuracy: 0.9603 - val_loss: 0.6870 - val_accuracy: 0.8126\n",
      "Epoch 2560/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1046 - accuracy: 0.9625 - val_loss: 0.7167 - val_accuracy: 0.8080\n",
      "Epoch 2561/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1069 - accuracy: 0.9614 - val_loss: 0.7117 - val_accuracy: 0.8159\n",
      "Epoch 2562/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1094 - accuracy: 0.9613 - val_loss: 0.7387 - val_accuracy: 0.8062\n",
      "Epoch 2563/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1057 - accuracy: 0.9621 - val_loss: 0.7136 - val_accuracy: 0.8143\n",
      "Epoch 2564/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1072 - accuracy: 0.9612 - val_loss: 0.7386 - val_accuracy: 0.8115\n",
      "Epoch 2565/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1125 - accuracy: 0.9601 - val_loss: 0.7387 - val_accuracy: 0.8063\n",
      "Epoch 2566/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1105 - accuracy: 0.9603 - val_loss: 0.7386 - val_accuracy: 0.8071\n",
      "Epoch 2567/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1040 - accuracy: 0.9631 - val_loss: 0.7139 - val_accuracy: 0.8160\n",
      "Epoch 2568/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1100 - accuracy: 0.9605 - val_loss: 0.6945 - val_accuracy: 0.8163\n",
      "Epoch 2569/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1144 - accuracy: 0.9593 - val_loss: 0.6777 - val_accuracy: 0.8218\n",
      "Epoch 2570/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1021 - accuracy: 0.9627 - val_loss: 0.7030 - val_accuracy: 0.8163\n",
      "Epoch 2571/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1039 - accuracy: 0.9633 - val_loss: 0.7931 - val_accuracy: 0.7994\n",
      "Epoch 2572/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1104 - accuracy: 0.9607 - val_loss: 0.7235 - val_accuracy: 0.8107\n",
      "Epoch 2573/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1041 - accuracy: 0.9639 - val_loss: 0.7078 - val_accuracy: 0.8134\n",
      "Epoch 2574/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1114 - accuracy: 0.9604 - val_loss: 0.7172 - val_accuracy: 0.8130\n",
      "Epoch 2575/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1046 - accuracy: 0.9630 - val_loss: 0.7196 - val_accuracy: 0.8102\n",
      "Epoch 2576/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0997 - accuracy: 0.9646 - val_loss: 0.6856 - val_accuracy: 0.8154\n",
      "Epoch 2577/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1080 - accuracy: 0.9613 - val_loss: 0.7164 - val_accuracy: 0.8126\n",
      "Epoch 2578/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1055 - accuracy: 0.9615 - val_loss: 0.6807 - val_accuracy: 0.8186\n",
      "Epoch 2579/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1063 - accuracy: 0.9626 - val_loss: 0.7654 - val_accuracy: 0.8015\n",
      "Epoch 2580/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1092 - accuracy: 0.9614 - val_loss: 0.7691 - val_accuracy: 0.8034\n",
      "Epoch 2581/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1016 - accuracy: 0.9639 - val_loss: 0.7367 - val_accuracy: 0.8089\n",
      "Epoch 2582/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1145 - accuracy: 0.9596 - val_loss: 0.6937 - val_accuracy: 0.8213\n",
      "Epoch 2583/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1093 - accuracy: 0.9612 - val_loss: 0.7547 - val_accuracy: 0.8097\n",
      "Epoch 2584/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1023 - accuracy: 0.9636 - val_loss: 0.7451 - val_accuracy: 0.8005\n",
      "Epoch 2585/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1061 - accuracy: 0.9614 - val_loss: 0.7329 - val_accuracy: 0.8106\n",
      "Epoch 2586/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1042 - accuracy: 0.9629 - val_loss: 0.7201 - val_accuracy: 0.8130\n",
      "Epoch 2587/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1039 - accuracy: 0.9631 - val_loss: 0.7158 - val_accuracy: 0.8094\n",
      "Epoch 2588/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1047 - accuracy: 0.9628 - val_loss: 0.7592 - val_accuracy: 0.8075\n",
      "Epoch 2589/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1056 - accuracy: 0.9628 - val_loss: 0.6995 - val_accuracy: 0.8120\n",
      "Epoch 2590/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1050 - accuracy: 0.9618 - val_loss: 0.7383 - val_accuracy: 0.8061\n",
      "Epoch 2591/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1097 - accuracy: 0.9618 - val_loss: 0.6807 - val_accuracy: 0.8206\n",
      "Epoch 2592/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1041 - accuracy: 0.9628 - val_loss: 0.6712 - val_accuracy: 0.8167\n",
      "Epoch 2593/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1078 - accuracy: 0.9622 - val_loss: 0.6778 - val_accuracy: 0.8203\n",
      "Epoch 2594/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1052 - accuracy: 0.9626 - val_loss: 0.7142 - val_accuracy: 0.8128\n",
      "Epoch 2595/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1071 - accuracy: 0.9621 - val_loss: 0.7328 - val_accuracy: 0.8090\n",
      "Epoch 2596/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1055 - accuracy: 0.9628 - val_loss: 0.7028 - val_accuracy: 0.8134\n",
      "Epoch 2597/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1022 - accuracy: 0.9634 - val_loss: 0.6969 - val_accuracy: 0.8123\n",
      "Epoch 2598/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1118 - accuracy: 0.9604 - val_loss: 0.7928 - val_accuracy: 0.8010\n",
      "Epoch 2599/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1046 - accuracy: 0.9621 - val_loss: 0.7005 - val_accuracy: 0.8135\n",
      "Epoch 2600/8000\n",
      "1462/1463 [============================>.] - ETA: 0s - loss: 0.0990 - accuracy: 0.9651\n",
      "Epoch 2600: saving model to ./training_ckpt_20240109205949_v8_240109_d10000_n4096_b64_e8000_c100_Adamax\\cp-000002600.ckpt\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0990 - accuracy: 0.9651 - val_loss: 0.7014 - val_accuracy: 0.8181\n",
      "Epoch 2601/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1040 - accuracy: 0.9621 - val_loss: 0.6735 - val_accuracy: 0.8206\n",
      "Epoch 2602/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1069 - accuracy: 0.9617 - val_loss: 0.6950 - val_accuracy: 0.8145\n",
      "Epoch 2603/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1149 - accuracy: 0.9591 - val_loss: 0.7258 - val_accuracy: 0.8133\n",
      "Epoch 2604/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1058 - accuracy: 0.9618 - val_loss: 0.6804 - val_accuracy: 0.8163\n",
      "Epoch 2605/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1089 - accuracy: 0.9608 - val_loss: 0.7086 - val_accuracy: 0.8134\n",
      "Epoch 2606/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1039 - accuracy: 0.9630 - val_loss: 0.7121 - val_accuracy: 0.8119\n",
      "Epoch 2607/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1085 - accuracy: 0.9610 - val_loss: 0.7032 - val_accuracy: 0.8090\n",
      "Epoch 2608/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1007 - accuracy: 0.9639 - val_loss: 0.6794 - val_accuracy: 0.8194\n",
      "Epoch 2609/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1094 - accuracy: 0.9610 - val_loss: 0.7840 - val_accuracy: 0.8020\n",
      "Epoch 2610/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1048 - accuracy: 0.9627 - val_loss: 0.7822 - val_accuracy: 0.7967\n",
      "Epoch 2611/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1050 - accuracy: 0.9628 - val_loss: 0.7263 - val_accuracy: 0.8085\n",
      "Epoch 2612/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1015 - accuracy: 0.9640 - val_loss: 0.7040 - val_accuracy: 0.8144\n",
      "Epoch 2613/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1112 - accuracy: 0.9609 - val_loss: 0.6879 - val_accuracy: 0.8180\n",
      "Epoch 2614/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1018 - accuracy: 0.9641 - val_loss: 0.7153 - val_accuracy: 0.8101\n",
      "Epoch 2615/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1044 - accuracy: 0.9629 - val_loss: 0.7461 - val_accuracy: 0.8062\n",
      "Epoch 2616/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1093 - accuracy: 0.9613 - val_loss: 0.7780 - val_accuracy: 0.7939\n",
      "Epoch 2617/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1003 - accuracy: 0.9639 - val_loss: 0.7087 - val_accuracy: 0.8139\n",
      "Epoch 2618/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1071 - accuracy: 0.9615 - val_loss: 0.7351 - val_accuracy: 0.8106\n",
      "Epoch 2619/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0996 - accuracy: 0.9634 - val_loss: 0.7184 - val_accuracy: 0.8085\n",
      "Epoch 2620/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1042 - accuracy: 0.9629 - val_loss: 0.6880 - val_accuracy: 0.8183\n",
      "Epoch 2621/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1036 - accuracy: 0.9628 - val_loss: 0.7422 - val_accuracy: 0.8052\n",
      "Epoch 2622/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1091 - accuracy: 0.9611 - val_loss: 0.7104 - val_accuracy: 0.8142\n",
      "Epoch 2623/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1058 - accuracy: 0.9620 - val_loss: 0.6664 - val_accuracy: 0.8197\n",
      "Epoch 2624/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1066 - accuracy: 0.9634 - val_loss: 0.6837 - val_accuracy: 0.8179\n",
      "Epoch 2625/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1039 - accuracy: 0.9635 - val_loss: 0.7048 - val_accuracy: 0.8131\n",
      "Epoch 2626/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0985 - accuracy: 0.9652 - val_loss: 0.6481 - val_accuracy: 0.8275\n",
      "Epoch 2627/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1158 - accuracy: 0.9599 - val_loss: 0.7235 - val_accuracy: 0.8110\n",
      "Epoch 2628/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1020 - accuracy: 0.9635 - val_loss: 0.7534 - val_accuracy: 0.8055\n",
      "Epoch 2629/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1034 - accuracy: 0.9633 - val_loss: 0.6846 - val_accuracy: 0.8147\n",
      "Epoch 2630/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1046 - accuracy: 0.9632 - val_loss: 0.7424 - val_accuracy: 0.8060\n",
      "Epoch 2631/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1055 - accuracy: 0.9630 - val_loss: 0.6832 - val_accuracy: 0.8200\n",
      "Epoch 2632/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1093 - accuracy: 0.9614 - val_loss: 0.6893 - val_accuracy: 0.8145\n",
      "Epoch 2633/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1035 - accuracy: 0.9635 - val_loss: 0.7126 - val_accuracy: 0.8119\n",
      "Epoch 2634/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1042 - accuracy: 0.9626 - val_loss: 0.7035 - val_accuracy: 0.8171\n",
      "Epoch 2635/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1040 - accuracy: 0.9634 - val_loss: 0.6741 - val_accuracy: 0.8197\n",
      "Epoch 2636/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1079 - accuracy: 0.9611 - val_loss: 0.7690 - val_accuracy: 0.8027\n",
      "Epoch 2637/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1051 - accuracy: 0.9630 - val_loss: 0.7855 - val_accuracy: 0.8000\n",
      "Epoch 2638/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1035 - accuracy: 0.9635 - val_loss: 0.7222 - val_accuracy: 0.8157\n",
      "Epoch 2639/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1098 - accuracy: 0.9619 - val_loss: 0.6840 - val_accuracy: 0.8183\n",
      "Epoch 2640/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1080 - accuracy: 0.9616 - val_loss: 0.7813 - val_accuracy: 0.8042\n",
      "Epoch 2641/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1055 - accuracy: 0.9631 - val_loss: 0.7281 - val_accuracy: 0.8092\n",
      "Epoch 2642/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1052 - accuracy: 0.9633 - val_loss: 0.7750 - val_accuracy: 0.8046\n",
      "Epoch 2643/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1027 - accuracy: 0.9636 - val_loss: 0.6964 - val_accuracy: 0.8191\n",
      "Epoch 2644/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1114 - accuracy: 0.9611 - val_loss: 0.7189 - val_accuracy: 0.8105\n",
      "Epoch 2645/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1069 - accuracy: 0.9617 - val_loss: 0.7721 - val_accuracy: 0.8047\n",
      "Epoch 2646/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1066 - accuracy: 0.9620 - val_loss: 0.7518 - val_accuracy: 0.8077\n",
      "Epoch 2647/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0993 - accuracy: 0.9654 - val_loss: 0.6809 - val_accuracy: 0.8183\n",
      "Epoch 2648/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1042 - accuracy: 0.9635 - val_loss: 0.7702 - val_accuracy: 0.8020\n",
      "Epoch 2649/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1032 - accuracy: 0.9635 - val_loss: 0.7179 - val_accuracy: 0.8124\n",
      "Epoch 2650/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1018 - accuracy: 0.9635 - val_loss: 0.8222 - val_accuracy: 0.7940\n",
      "Epoch 2651/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1065 - accuracy: 0.9622 - val_loss: 0.7292 - val_accuracy: 0.8109\n",
      "Epoch 2652/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1021 - accuracy: 0.9638 - val_loss: 0.7126 - val_accuracy: 0.8111\n",
      "Epoch 2653/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1040 - accuracy: 0.9636 - val_loss: 0.7336 - val_accuracy: 0.8104\n",
      "Epoch 2654/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1060 - accuracy: 0.9618 - val_loss: 0.7373 - val_accuracy: 0.8121\n",
      "Epoch 2655/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1003 - accuracy: 0.9644 - val_loss: 0.7246 - val_accuracy: 0.8155\n",
      "Epoch 2656/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1016 - accuracy: 0.9638 - val_loss: 0.6651 - val_accuracy: 0.8230\n",
      "Epoch 2657/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1101 - accuracy: 0.9609 - val_loss: 0.7165 - val_accuracy: 0.8152\n",
      "Epoch 2658/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1013 - accuracy: 0.9638 - val_loss: 0.7333 - val_accuracy: 0.8072\n",
      "Epoch 2659/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1044 - accuracy: 0.9635 - val_loss: 0.7422 - val_accuracy: 0.8109\n",
      "Epoch 2660/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1017 - accuracy: 0.9638 - val_loss: 0.7575 - val_accuracy: 0.8040\n",
      "Epoch 2661/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1054 - accuracy: 0.9628 - val_loss: 0.6830 - val_accuracy: 0.8189\n",
      "Epoch 2662/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1036 - accuracy: 0.9625 - val_loss: 0.7264 - val_accuracy: 0.8103\n",
      "Epoch 2663/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1105 - accuracy: 0.9609 - val_loss: 0.7327 - val_accuracy: 0.8100\n",
      "Epoch 2664/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0977 - accuracy: 0.9658 - val_loss: 0.6720 - val_accuracy: 0.8185\n",
      "Epoch 2665/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1045 - accuracy: 0.9626 - val_loss: 0.7233 - val_accuracy: 0.8112\n",
      "Epoch 2666/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1026 - accuracy: 0.9638 - val_loss: 0.7289 - val_accuracy: 0.8117\n",
      "Epoch 2667/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0991 - accuracy: 0.9648 - val_loss: 0.7385 - val_accuracy: 0.8107\n",
      "Epoch 2668/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1031 - accuracy: 0.9632 - val_loss: 0.6961 - val_accuracy: 0.8134\n",
      "Epoch 2669/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1054 - accuracy: 0.9627 - val_loss: 0.7098 - val_accuracy: 0.8197\n",
      "Epoch 2670/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1093 - accuracy: 0.9626 - val_loss: 0.6528 - val_accuracy: 0.8254\n",
      "Epoch 2671/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1018 - accuracy: 0.9641 - val_loss: 0.7811 - val_accuracy: 0.8033\n",
      "Epoch 2672/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1091 - accuracy: 0.9617 - val_loss: 0.6952 - val_accuracy: 0.8139\n",
      "Epoch 2673/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1036 - accuracy: 0.9638 - val_loss: 0.6766 - val_accuracy: 0.8202\n",
      "Epoch 2674/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1077 - accuracy: 0.9624 - val_loss: 0.6837 - val_accuracy: 0.8196\n",
      "Epoch 2675/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1007 - accuracy: 0.9646 - val_loss: 0.7656 - val_accuracy: 0.8028\n",
      "Epoch 2676/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1037 - accuracy: 0.9638 - val_loss: 0.7281 - val_accuracy: 0.8114\n",
      "Epoch 2677/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0995 - accuracy: 0.9655 - val_loss: 0.6834 - val_accuracy: 0.8179\n",
      "Epoch 2678/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1034 - accuracy: 0.9638 - val_loss: 0.6971 - val_accuracy: 0.8159\n",
      "Epoch 2679/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1045 - accuracy: 0.9629 - val_loss: 0.7278 - val_accuracy: 0.8091\n",
      "Epoch 2680/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1011 - accuracy: 0.9642 - val_loss: 0.7250 - val_accuracy: 0.8135\n",
      "Epoch 2681/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1001 - accuracy: 0.9646 - val_loss: 0.7439 - val_accuracy: 0.8093\n",
      "Epoch 2682/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1060 - accuracy: 0.9628 - val_loss: 0.7611 - val_accuracy: 0.8041\n",
      "Epoch 2683/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0970 - accuracy: 0.9656 - val_loss: 0.7803 - val_accuracy: 0.7981\n",
      "Epoch 2684/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1039 - accuracy: 0.9637 - val_loss: 0.8376 - val_accuracy: 0.7883\n",
      "Epoch 2685/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1039 - accuracy: 0.9630 - val_loss: 0.6769 - val_accuracy: 0.8237\n",
      "Epoch 2686/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1064 - accuracy: 0.9630 - val_loss: 0.7211 - val_accuracy: 0.8149\n",
      "Epoch 2687/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1003 - accuracy: 0.9656 - val_loss: 0.7021 - val_accuracy: 0.8128\n",
      "Epoch 2688/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1021 - accuracy: 0.9636 - val_loss: 0.6645 - val_accuracy: 0.8203\n",
      "Epoch 2689/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1041 - accuracy: 0.9635 - val_loss: 0.9456 - val_accuracy: 0.7920\n",
      "Epoch 2690/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1015 - accuracy: 0.9650 - val_loss: 0.7556 - val_accuracy: 0.8071\n",
      "Epoch 2691/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0988 - accuracy: 0.9657 - val_loss: 0.6942 - val_accuracy: 0.8188\n",
      "Epoch 2692/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1041 - accuracy: 0.9628 - val_loss: 0.7653 - val_accuracy: 0.8074\n",
      "Epoch 2693/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1058 - accuracy: 0.9624 - val_loss: 0.7129 - val_accuracy: 0.8175\n",
      "Epoch 2694/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0988 - accuracy: 0.9645 - val_loss: 0.7088 - val_accuracy: 0.8174\n",
      "Epoch 2695/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0999 - accuracy: 0.9651 - val_loss: 0.7354 - val_accuracy: 0.8122\n",
      "Epoch 2696/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0999 - accuracy: 0.9641 - val_loss: 0.6889 - val_accuracy: 0.8201\n",
      "Epoch 2697/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1031 - accuracy: 0.9644 - val_loss: 0.8531 - val_accuracy: 0.7973\n",
      "Epoch 2698/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1048 - accuracy: 0.9628 - val_loss: 0.6844 - val_accuracy: 0.8213\n",
      "Epoch 2699/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1033 - accuracy: 0.9639 - val_loss: 0.7493 - val_accuracy: 0.8063\n",
      "Epoch 2700/8000\n",
      "1463/1463 [==============================] - ETA: 0s - loss: 0.1008 - accuracy: 0.9647\n",
      "Epoch 2700: saving model to ./training_ckpt_20240109205949_v8_240109_d10000_n4096_b64_e8000_c100_Adamax\\cp-000002700.ckpt\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1008 - accuracy: 0.9647 - val_loss: 0.6554 - val_accuracy: 0.8236\n",
      "Epoch 2701/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0996 - accuracy: 0.9649 - val_loss: 0.7193 - val_accuracy: 0.8160\n",
      "Epoch 2702/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1010 - accuracy: 0.9644 - val_loss: 0.6678 - val_accuracy: 0.8230\n",
      "Epoch 2703/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1012 - accuracy: 0.9650 - val_loss: 0.6578 - val_accuracy: 0.8269\n",
      "Epoch 2704/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0999 - accuracy: 0.9643 - val_loss: 0.7261 - val_accuracy: 0.8070\n",
      "Epoch 2705/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1093 - accuracy: 0.9622 - val_loss: 0.6683 - val_accuracy: 0.8239\n",
      "Epoch 2706/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1028 - accuracy: 0.9641 - val_loss: 0.6723 - val_accuracy: 0.8221\n",
      "Epoch 2707/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1019 - accuracy: 0.9640 - val_loss: 0.7510 - val_accuracy: 0.8064\n",
      "Epoch 2708/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0998 - accuracy: 0.9649 - val_loss: 0.7145 - val_accuracy: 0.8148\n",
      "Epoch 2709/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0981 - accuracy: 0.9656 - val_loss: 0.7944 - val_accuracy: 0.8008\n",
      "Epoch 2710/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1016 - accuracy: 0.9641 - val_loss: 0.7353 - val_accuracy: 0.8098\n",
      "Epoch 2711/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1066 - accuracy: 0.9622 - val_loss: 0.7199 - val_accuracy: 0.8144\n",
      "Epoch 2712/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1007 - accuracy: 0.9650 - val_loss: 0.6996 - val_accuracy: 0.8156\n",
      "Epoch 2713/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0982 - accuracy: 0.9655 - val_loss: 0.7416 - val_accuracy: 0.8080\n",
      "Epoch 2714/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1053 - accuracy: 0.9633 - val_loss: 0.6722 - val_accuracy: 0.8231\n",
      "Epoch 2715/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0971 - accuracy: 0.9653 - val_loss: 0.7122 - val_accuracy: 0.8138\n",
      "Epoch 2716/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0968 - accuracy: 0.9659 - val_loss: 0.6991 - val_accuracy: 0.8202\n",
      "Epoch 2717/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1028 - accuracy: 0.9643 - val_loss: 0.6993 - val_accuracy: 0.8166\n",
      "Epoch 2718/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0997 - accuracy: 0.9643 - val_loss: 0.7345 - val_accuracy: 0.8076\n",
      "Epoch 2719/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1025 - accuracy: 0.9627 - val_loss: 0.6991 - val_accuracy: 0.8166\n",
      "Epoch 2720/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1072 - accuracy: 0.9628 - val_loss: 0.6946 - val_accuracy: 0.8192\n",
      "Epoch 2721/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1027 - accuracy: 0.9642 - val_loss: 0.6967 - val_accuracy: 0.8165\n",
      "Epoch 2722/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0977 - accuracy: 0.9660 - val_loss: 0.7062 - val_accuracy: 0.8141\n",
      "Epoch 2723/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1025 - accuracy: 0.9638 - val_loss: 0.7315 - val_accuracy: 0.8120\n",
      "Epoch 2724/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1028 - accuracy: 0.9637 - val_loss: 0.7135 - val_accuracy: 0.8165\n",
      "Epoch 2725/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1045 - accuracy: 0.9632 - val_loss: 0.6567 - val_accuracy: 0.8273\n",
      "Epoch 2726/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1045 - accuracy: 0.9622 - val_loss: 0.6827 - val_accuracy: 0.8212\n",
      "Epoch 2727/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1009 - accuracy: 0.9647 - val_loss: 0.6982 - val_accuracy: 0.8182\n",
      "Epoch 2728/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0955 - accuracy: 0.9664 - val_loss: 0.6851 - val_accuracy: 0.8209\n",
      "Epoch 2729/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1037 - accuracy: 0.9638 - val_loss: 0.6749 - val_accuracy: 0.8240\n",
      "Epoch 2730/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0999 - accuracy: 0.9654 - val_loss: 0.6687 - val_accuracy: 0.8229\n",
      "Epoch 2731/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1014 - accuracy: 0.9650 - val_loss: 0.7046 - val_accuracy: 0.8208\n",
      "Epoch 2732/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1001 - accuracy: 0.9655 - val_loss: 0.6914 - val_accuracy: 0.8179\n",
      "Epoch 2733/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0980 - accuracy: 0.9654 - val_loss: 0.7211 - val_accuracy: 0.8079\n",
      "Epoch 2734/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1033 - accuracy: 0.9642 - val_loss: 0.6955 - val_accuracy: 0.8162\n",
      "Epoch 2735/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0997 - accuracy: 0.9656 - val_loss: 0.7162 - val_accuracy: 0.8173\n",
      "Epoch 2736/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0963 - accuracy: 0.9665 - val_loss: 0.6943 - val_accuracy: 0.8181\n",
      "Epoch 2737/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1027 - accuracy: 0.9634 - val_loss: 0.7327 - val_accuracy: 0.8123\n",
      "Epoch 2738/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0974 - accuracy: 0.9652 - val_loss: 0.6605 - val_accuracy: 0.8284\n",
      "Epoch 2739/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1098 - accuracy: 0.9606 - val_loss: 0.7092 - val_accuracy: 0.8125\n",
      "Epoch 2740/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1029 - accuracy: 0.9634 - val_loss: 0.7313 - val_accuracy: 0.8079\n",
      "Epoch 2741/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0990 - accuracy: 0.9649 - val_loss: 0.8006 - val_accuracy: 0.7998\n",
      "Epoch 2742/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1033 - accuracy: 0.9636 - val_loss: 0.7260 - val_accuracy: 0.8146\n",
      "Epoch 2743/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1033 - accuracy: 0.9637 - val_loss: 0.7216 - val_accuracy: 0.8140\n",
      "Epoch 2744/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0984 - accuracy: 0.9652 - val_loss: 0.7262 - val_accuracy: 0.8139\n",
      "Epoch 2745/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0986 - accuracy: 0.9656 - val_loss: 0.6799 - val_accuracy: 0.8211\n",
      "Epoch 2746/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1011 - accuracy: 0.9642 - val_loss: 0.7064 - val_accuracy: 0.8175\n",
      "Epoch 2747/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.1024 - accuracy: 0.9645 - val_loss: 0.7223 - val_accuracy: 0.8108\n",
      "Epoch 2748/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0988 - accuracy: 0.9651 - val_loss: 0.7328 - val_accuracy: 0.8134\n",
      "Epoch 2749/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1056 - accuracy: 0.9629 - val_loss: 0.7101 - val_accuracy: 0.8164\n",
      "Epoch 2750/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0988 - accuracy: 0.9653 - val_loss: 0.7003 - val_accuracy: 0.8189\n",
      "Epoch 2751/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0971 - accuracy: 0.9662 - val_loss: 0.6935 - val_accuracy: 0.8231\n",
      "Epoch 2752/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0986 - accuracy: 0.9656 - val_loss: 0.6582 - val_accuracy: 0.8253\n",
      "Epoch 2753/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0977 - accuracy: 0.9651 - val_loss: 0.6990 - val_accuracy: 0.8171\n",
      "Epoch 2754/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1007 - accuracy: 0.9642 - val_loss: 0.7082 - val_accuracy: 0.8179\n",
      "Epoch 2755/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0960 - accuracy: 0.9658 - val_loss: 0.7274 - val_accuracy: 0.8108\n",
      "Epoch 2756/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0996 - accuracy: 0.9645 - val_loss: 0.7688 - val_accuracy: 0.8052\n",
      "Epoch 2757/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1052 - accuracy: 0.9637 - val_loss: 0.7058 - val_accuracy: 0.8193\n",
      "Epoch 2758/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0984 - accuracy: 0.9653 - val_loss: 0.6874 - val_accuracy: 0.8188\n",
      "Epoch 2759/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1018 - accuracy: 0.9633 - val_loss: 0.6933 - val_accuracy: 0.8145\n",
      "Epoch 2760/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0945 - accuracy: 0.9667 - val_loss: 0.7233 - val_accuracy: 0.8127\n",
      "Epoch 2761/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0979 - accuracy: 0.9662 - val_loss: 0.8841 - val_accuracy: 0.7992\n",
      "Epoch 2762/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0948 - accuracy: 0.9668 - val_loss: 0.6590 - val_accuracy: 0.8287\n",
      "Epoch 2763/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1007 - accuracy: 0.9644 - val_loss: 0.7569 - val_accuracy: 0.8045\n",
      "Epoch 2764/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0941 - accuracy: 0.9669 - val_loss: 0.7455 - val_accuracy: 0.8127\n",
      "Epoch 2765/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0989 - accuracy: 0.9654 - val_loss: 0.7041 - val_accuracy: 0.8189\n",
      "Epoch 2766/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1025 - accuracy: 0.9639 - val_loss: 0.6880 - val_accuracy: 0.8208\n",
      "Epoch 2767/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1042 - accuracy: 0.9636 - val_loss: 0.7009 - val_accuracy: 0.8166\n",
      "Epoch 2768/8000\n",
      "1463/1463 [==============================] - 12s 9ms/step - loss: 0.0965 - accuracy: 0.9657 - val_loss: 0.7231 - val_accuracy: 0.8139\n",
      "Epoch 2769/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1017 - accuracy: 0.9642 - val_loss: 0.7414 - val_accuracy: 0.8099\n",
      "Epoch 2770/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0989 - accuracy: 0.9655 - val_loss: 0.6912 - val_accuracy: 0.8219\n",
      "Epoch 2771/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0932 - accuracy: 0.9675 - val_loss: 0.7409 - val_accuracy: 0.8088\n",
      "Epoch 2772/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1012 - accuracy: 0.9650 - val_loss: 0.6609 - val_accuracy: 0.8243\n",
      "Epoch 2773/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0904 - accuracy: 0.9681 - val_loss: 0.6738 - val_accuracy: 0.8180\n",
      "Epoch 2774/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0965 - accuracy: 0.9657 - val_loss: 0.7196 - val_accuracy: 0.8137\n",
      "Epoch 2775/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1041 - accuracy: 0.9638 - val_loss: 0.6805 - val_accuracy: 0.8209\n",
      "Epoch 2776/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1008 - accuracy: 0.9646 - val_loss: 0.7251 - val_accuracy: 0.8134\n",
      "Epoch 2777/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0915 - accuracy: 0.9682 - val_loss: 0.6714 - val_accuracy: 0.8254\n",
      "Epoch 2778/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0997 - accuracy: 0.9647 - val_loss: 0.7148 - val_accuracy: 0.8182\n",
      "Epoch 2779/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0965 - accuracy: 0.9662 - val_loss: 0.6864 - val_accuracy: 0.8190\n",
      "Epoch 2780/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0959 - accuracy: 0.9664 - val_loss: 0.7235 - val_accuracy: 0.8181\n",
      "Epoch 2781/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0973 - accuracy: 0.9660 - val_loss: 0.6618 - val_accuracy: 0.8268\n",
      "Epoch 2782/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0998 - accuracy: 0.9653 - val_loss: 0.7213 - val_accuracy: 0.8156\n",
      "Epoch 2783/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1006 - accuracy: 0.9641 - val_loss: 0.7169 - val_accuracy: 0.8145\n",
      "Epoch 2784/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0949 - accuracy: 0.9666 - val_loss: 0.7003 - val_accuracy: 0.8154\n",
      "Epoch 2785/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0956 - accuracy: 0.9677 - val_loss: 0.6792 - val_accuracy: 0.8237\n",
      "Epoch 2786/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0990 - accuracy: 0.9648 - val_loss: 0.7218 - val_accuracy: 0.8163\n",
      "Epoch 2787/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0978 - accuracy: 0.9656 - val_loss: 0.6829 - val_accuracy: 0.8225\n",
      "Epoch 2788/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0991 - accuracy: 0.9658 - val_loss: 0.7414 - val_accuracy: 0.8132\n",
      "Epoch 2789/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0954 - accuracy: 0.9664 - val_loss: 0.7410 - val_accuracy: 0.8096\n",
      "Epoch 2790/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0992 - accuracy: 0.9655 - val_loss: 0.7342 - val_accuracy: 0.8093\n",
      "Epoch 2791/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0967 - accuracy: 0.9664 - val_loss: 0.7026 - val_accuracy: 0.8187\n",
      "Epoch 2792/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0962 - accuracy: 0.9657 - val_loss: 0.6746 - val_accuracy: 0.8201\n",
      "Epoch 2793/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0961 - accuracy: 0.9662 - val_loss: 0.6804 - val_accuracy: 0.8210\n",
      "Epoch 2794/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0956 - accuracy: 0.9668 - val_loss: 0.6526 - val_accuracy: 0.8265\n",
      "Epoch 2795/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0941 - accuracy: 0.9670 - val_loss: 0.6859 - val_accuracy: 0.8209\n",
      "Epoch 2796/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0964 - accuracy: 0.9664 - val_loss: 0.6838 - val_accuracy: 0.8204\n",
      "Epoch 2797/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0934 - accuracy: 0.9678 - val_loss: 0.7474 - val_accuracy: 0.8109\n",
      "Epoch 2798/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0937 - accuracy: 0.9668 - val_loss: 0.6900 - val_accuracy: 0.8219\n",
      "Epoch 2799/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1016 - accuracy: 0.9643 - val_loss: 0.7841 - val_accuracy: 0.8033\n",
      "Epoch 2800/8000\n",
      "1462/1463 [============================>.] - ETA: 0s - loss: 0.1001 - accuracy: 0.9646\n",
      "Epoch 2800: saving model to ./training_ckpt_20240109205949_v8_240109_d10000_n4096_b64_e8000_c100_Adamax\\cp-000002800.ckpt\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1001 - accuracy: 0.9646 - val_loss: 0.7361 - val_accuracy: 0.8111\n",
      "Epoch 2801/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0983 - accuracy: 0.9655 - val_loss: 0.6966 - val_accuracy: 0.8204\n",
      "Epoch 2802/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0958 - accuracy: 0.9662 - val_loss: 0.6965 - val_accuracy: 0.8152\n",
      "Epoch 2803/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0961 - accuracy: 0.9666 - val_loss: 0.7141 - val_accuracy: 0.8205\n",
      "Epoch 2804/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1002 - accuracy: 0.9642 - val_loss: 0.7259 - val_accuracy: 0.8121\n",
      "Epoch 2805/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0967 - accuracy: 0.9671 - val_loss: 0.6746 - val_accuracy: 0.8213\n",
      "Epoch 2806/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0963 - accuracy: 0.9669 - val_loss: 0.6821 - val_accuracy: 0.8214\n",
      "Epoch 2807/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0998 - accuracy: 0.9655 - val_loss: 0.6777 - val_accuracy: 0.8223\n",
      "Epoch 2808/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0934 - accuracy: 0.9668 - val_loss: 0.7287 - val_accuracy: 0.8116\n",
      "Epoch 2809/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0932 - accuracy: 0.9678 - val_loss: 0.7337 - val_accuracy: 0.8150\n",
      "Epoch 2810/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0996 - accuracy: 0.9652 - val_loss: 0.6890 - val_accuracy: 0.8197\n",
      "Epoch 2811/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0969 - accuracy: 0.9660 - val_loss: 0.6947 - val_accuracy: 0.8191\n",
      "Epoch 2812/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0957 - accuracy: 0.9671 - val_loss: 0.6593 - val_accuracy: 0.8257\n",
      "Epoch 2813/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0888 - accuracy: 0.9687 - val_loss: 0.7128 - val_accuracy: 0.8160\n",
      "Epoch 2814/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0976 - accuracy: 0.9656 - val_loss: 0.7119 - val_accuracy: 0.8152\n",
      "Epoch 2815/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0942 - accuracy: 0.9662 - val_loss: 0.7419 - val_accuracy: 0.8081\n",
      "Epoch 2816/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0949 - accuracy: 0.9665 - val_loss: 0.7127 - val_accuracy: 0.8174\n",
      "Epoch 2817/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0958 - accuracy: 0.9661 - val_loss: 0.7011 - val_accuracy: 0.8193\n",
      "Epoch 2818/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0946 - accuracy: 0.9675 - val_loss: 0.6785 - val_accuracy: 0.8205\n",
      "Epoch 2819/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0911 - accuracy: 0.9683 - val_loss: 0.7187 - val_accuracy: 0.8147\n",
      "Epoch 2820/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0988 - accuracy: 0.9654 - val_loss: 0.7250 - val_accuracy: 0.8132\n",
      "Epoch 2821/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0970 - accuracy: 0.9666 - val_loss: 0.7547 - val_accuracy: 0.8100\n",
      "Epoch 2822/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0927 - accuracy: 0.9674 - val_loss: 0.7050 - val_accuracy: 0.8204\n",
      "Epoch 2823/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1013 - accuracy: 0.9655 - val_loss: 0.6753 - val_accuracy: 0.8253\n",
      "Epoch 2824/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0999 - accuracy: 0.9653 - val_loss: 0.6945 - val_accuracy: 0.8176\n",
      "Epoch 2825/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1075 - accuracy: 0.9633 - val_loss: 0.6793 - val_accuracy: 0.8217\n",
      "Epoch 2826/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0902 - accuracy: 0.9690 - val_loss: 0.7165 - val_accuracy: 0.8175\n",
      "Epoch 2827/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0916 - accuracy: 0.9677 - val_loss: 0.7011 - val_accuracy: 0.8197\n",
      "Epoch 2828/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0945 - accuracy: 0.9671 - val_loss: 0.7599 - val_accuracy: 0.8067\n",
      "Epoch 2829/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1061 - accuracy: 0.9641 - val_loss: 0.6946 - val_accuracy: 0.8218\n",
      "Epoch 2830/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0909 - accuracy: 0.9678 - val_loss: 0.6457 - val_accuracy: 0.8302\n",
      "Epoch 2831/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0981 - accuracy: 0.9663 - val_loss: 0.6988 - val_accuracy: 0.8212\n",
      "Epoch 2832/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0985 - accuracy: 0.9656 - val_loss: 0.6893 - val_accuracy: 0.8229\n",
      "Epoch 2833/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1072 - accuracy: 0.9621 - val_loss: 0.7082 - val_accuracy: 0.8196\n",
      "Epoch 2834/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1023 - accuracy: 0.9641 - val_loss: 0.6923 - val_accuracy: 0.8180\n",
      "Epoch 2835/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1042 - accuracy: 0.9634 - val_loss: 0.6893 - val_accuracy: 0.8201\n",
      "Epoch 2836/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0972 - accuracy: 0.9662 - val_loss: 0.7438 - val_accuracy: 0.8090\n",
      "Epoch 2837/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0959 - accuracy: 0.9663 - val_loss: 0.7302 - val_accuracy: 0.8137\n",
      "Epoch 2838/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0963 - accuracy: 0.9660 - val_loss: 0.6951 - val_accuracy: 0.8196\n",
      "Epoch 2839/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0975 - accuracy: 0.9661 - val_loss: 0.6955 - val_accuracy: 0.8202\n",
      "Epoch 2840/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0898 - accuracy: 0.9690 - val_loss: 0.7655 - val_accuracy: 0.8065\n",
      "Epoch 2841/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0983 - accuracy: 0.9655 - val_loss: 0.6878 - val_accuracy: 0.8204\n",
      "Epoch 2842/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0991 - accuracy: 0.9661 - val_loss: 0.6976 - val_accuracy: 0.8229\n",
      "Epoch 2843/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0951 - accuracy: 0.9668 - val_loss: 0.7369 - val_accuracy: 0.8134\n",
      "Epoch 2844/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0944 - accuracy: 0.9671 - val_loss: 0.7035 - val_accuracy: 0.8138\n",
      "Epoch 2845/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0923 - accuracy: 0.9673 - val_loss: 0.6979 - val_accuracy: 0.8207\n",
      "Epoch 2846/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0963 - accuracy: 0.9666 - val_loss: 0.6609 - val_accuracy: 0.8268\n",
      "Epoch 2847/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0948 - accuracy: 0.9663 - val_loss: 0.6793 - val_accuracy: 0.8191\n",
      "Epoch 2848/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0966 - accuracy: 0.9657 - val_loss: 0.7178 - val_accuracy: 0.8173\n",
      "Epoch 2849/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0985 - accuracy: 0.9652 - val_loss: 0.7507 - val_accuracy: 0.8115\n",
      "Epoch 2850/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1005 - accuracy: 0.9649 - val_loss: 0.7401 - val_accuracy: 0.8149\n",
      "Epoch 2851/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0955 - accuracy: 0.9662 - val_loss: 0.6567 - val_accuracy: 0.8242\n",
      "Epoch 2852/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0904 - accuracy: 0.9685 - val_loss: 0.7385 - val_accuracy: 0.8162\n",
      "Epoch 2853/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0963 - accuracy: 0.9662 - val_loss: 0.7398 - val_accuracy: 0.8116\n",
      "Epoch 2854/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0914 - accuracy: 0.9677 - val_loss: 0.6644 - val_accuracy: 0.8286\n",
      "Epoch 2855/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0938 - accuracy: 0.9669 - val_loss: 0.6728 - val_accuracy: 0.8241\n",
      "Epoch 2856/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0952 - accuracy: 0.9666 - val_loss: 0.6811 - val_accuracy: 0.8231\n",
      "Epoch 2857/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1045 - accuracy: 0.9646 - val_loss: 0.7793 - val_accuracy: 0.8062\n",
      "Epoch 2858/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0936 - accuracy: 0.9668 - val_loss: 0.7200 - val_accuracy: 0.8162\n",
      "Epoch 2859/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0920 - accuracy: 0.9675 - val_loss: 1.3120 - val_accuracy: 0.7875\n",
      "Epoch 2860/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1019 - accuracy: 0.9653 - val_loss: 0.7960 - val_accuracy: 0.8036\n",
      "Epoch 2861/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0907 - accuracy: 0.9684 - val_loss: 0.6824 - val_accuracy: 0.8214\n",
      "Epoch 2862/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0983 - accuracy: 0.9652 - val_loss: 0.7631 - val_accuracy: 0.8090\n",
      "Epoch 2863/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0963 - accuracy: 0.9657 - val_loss: 0.6811 - val_accuracy: 0.8247\n",
      "Epoch 2864/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0920 - accuracy: 0.9679 - val_loss: 0.6966 - val_accuracy: 0.8192\n",
      "Epoch 2865/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0953 - accuracy: 0.9660 - val_loss: 0.6657 - val_accuracy: 0.8265\n",
      "Epoch 2866/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0968 - accuracy: 0.9665 - val_loss: 0.6976 - val_accuracy: 0.8183\n",
      "Epoch 2867/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0977 - accuracy: 0.9663 - val_loss: 0.6950 - val_accuracy: 0.8176\n",
      "Epoch 2868/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0929 - accuracy: 0.9676 - val_loss: 0.6618 - val_accuracy: 0.8293\n",
      "Epoch 2869/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0954 - accuracy: 0.9668 - val_loss: 0.6950 - val_accuracy: 0.8258\n",
      "Epoch 2870/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0928 - accuracy: 0.9675 - val_loss: 0.6844 - val_accuracy: 0.8233\n",
      "Epoch 2871/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0905 - accuracy: 0.9687 - val_loss: 0.7253 - val_accuracy: 0.8178\n",
      "Epoch 2872/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0933 - accuracy: 0.9672 - val_loss: 0.7093 - val_accuracy: 0.8163\n",
      "Epoch 2873/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0932 - accuracy: 0.9671 - val_loss: 0.6789 - val_accuracy: 0.8242\n",
      "Epoch 2874/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1066 - accuracy: 0.9638 - val_loss: 0.7330 - val_accuracy: 0.8113\n",
      "Epoch 2875/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0955 - accuracy: 0.9667 - val_loss: 0.7264 - val_accuracy: 0.8173\n",
      "Epoch 2876/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0930 - accuracy: 0.9680 - val_loss: 0.6847 - val_accuracy: 0.8223\n",
      "Epoch 2877/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0927 - accuracy: 0.9679 - val_loss: 0.7465 - val_accuracy: 0.8137\n",
      "Epoch 2878/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0957 - accuracy: 0.9658 - val_loss: 0.7058 - val_accuracy: 0.8200\n",
      "Epoch 2879/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0910 - accuracy: 0.9677 - val_loss: 0.7220 - val_accuracy: 0.8188\n",
      "Epoch 2880/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0928 - accuracy: 0.9676 - val_loss: 0.8213 - val_accuracy: 0.8112\n",
      "Epoch 2881/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0924 - accuracy: 0.9687 - val_loss: 0.7412 - val_accuracy: 0.8141\n",
      "Epoch 2882/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0950 - accuracy: 0.9673 - val_loss: 0.7409 - val_accuracy: 0.8123\n",
      "Epoch 2883/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0910 - accuracy: 0.9681 - val_loss: 0.6847 - val_accuracy: 0.8230\n",
      "Epoch 2884/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0934 - accuracy: 0.9673 - val_loss: 0.6707 - val_accuracy: 0.8231\n",
      "Epoch 2885/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0927 - accuracy: 0.9680 - val_loss: 0.7114 - val_accuracy: 0.8210\n",
      "Epoch 2886/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0904 - accuracy: 0.9688 - val_loss: 0.7032 - val_accuracy: 0.8233\n",
      "Epoch 2887/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0989 - accuracy: 0.9661 - val_loss: 0.6899 - val_accuracy: 0.8225\n",
      "Epoch 2888/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0984 - accuracy: 0.9651 - val_loss: 0.7381 - val_accuracy: 0.8169\n",
      "Epoch 2889/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0946 - accuracy: 0.9664 - val_loss: 0.7464 - val_accuracy: 0.8134\n",
      "Epoch 2890/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0863 - accuracy: 0.9705 - val_loss: 0.6858 - val_accuracy: 0.8187\n",
      "Epoch 2891/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0924 - accuracy: 0.9680 - val_loss: 0.7058 - val_accuracy: 0.8192\n",
      "Epoch 2892/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0877 - accuracy: 0.9695 - val_loss: 0.6530 - val_accuracy: 0.8315\n",
      "Epoch 2893/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0995 - accuracy: 0.9651 - val_loss: 0.6704 - val_accuracy: 0.8256\n",
      "Epoch 2894/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.1014 - accuracy: 0.9649 - val_loss: 0.6636 - val_accuracy: 0.8253\n",
      "Epoch 2895/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0980 - accuracy: 0.9660 - val_loss: 0.6953 - val_accuracy: 0.8211\n",
      "Epoch 2896/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0927 - accuracy: 0.9681 - val_loss: 0.7447 - val_accuracy: 0.8087\n",
      "Epoch 2897/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0918 - accuracy: 0.9686 - val_loss: 0.7225 - val_accuracy: 0.8161\n",
      "Epoch 2898/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0910 - accuracy: 0.9682 - val_loss: 0.7052 - val_accuracy: 0.8201\n",
      "Epoch 2899/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0912 - accuracy: 0.9687 - val_loss: 0.8041 - val_accuracy: 0.8054\n",
      "Epoch 2900/8000\n",
      "1460/1463 [============================>.] - ETA: 0s - loss: 0.0964 - accuracy: 0.9658\n",
      "Epoch 2900: saving model to ./training_ckpt_20240109205949_v8_240109_d10000_n4096_b64_e8000_c100_Adamax\\cp-000002900.ckpt\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0964 - accuracy: 0.9658 - val_loss: 0.6635 - val_accuracy: 0.8277\n",
      "Epoch 2901/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0970 - accuracy: 0.9670 - val_loss: 0.6798 - val_accuracy: 0.8238\n",
      "Epoch 2902/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0923 - accuracy: 0.9677 - val_loss: 0.6821 - val_accuracy: 0.8211\n",
      "Epoch 2903/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0937 - accuracy: 0.9670 - val_loss: 0.6758 - val_accuracy: 0.8261\n",
      "Epoch 2904/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0915 - accuracy: 0.9677 - val_loss: 0.7615 - val_accuracy: 0.8163\n",
      "Epoch 2905/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0894 - accuracy: 0.9691 - val_loss: 0.7029 - val_accuracy: 0.8189\n",
      "Epoch 2906/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0950 - accuracy: 0.9670 - val_loss: 0.6940 - val_accuracy: 0.8212\n",
      "Epoch 2907/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0902 - accuracy: 0.9685 - val_loss: 0.7050 - val_accuracy: 0.8190\n",
      "Epoch 2908/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0938 - accuracy: 0.9671 - val_loss: 0.7272 - val_accuracy: 0.8169\n",
      "Epoch 2909/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0919 - accuracy: 0.9683 - val_loss: 0.6621 - val_accuracy: 0.8307\n",
      "Epoch 2910/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0933 - accuracy: 0.9678 - val_loss: 0.6893 - val_accuracy: 0.8212\n",
      "Epoch 2911/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0899 - accuracy: 0.9689 - val_loss: 0.7248 - val_accuracy: 0.8178\n",
      "Epoch 2912/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0899 - accuracy: 0.9686 - val_loss: 0.6769 - val_accuracy: 0.8235\n",
      "Epoch 2913/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0937 - accuracy: 0.9676 - val_loss: 0.6841 - val_accuracy: 0.8223\n",
      "Epoch 2914/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0924 - accuracy: 0.9679 - val_loss: 0.7198 - val_accuracy: 0.8218\n",
      "Epoch 2915/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0929 - accuracy: 0.9674 - val_loss: 0.7416 - val_accuracy: 0.8146\n",
      "Epoch 2916/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0943 - accuracy: 0.9671 - val_loss: 0.6774 - val_accuracy: 0.8213\n",
      "Epoch 2917/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0922 - accuracy: 0.9690 - val_loss: 0.7317 - val_accuracy: 0.8129\n",
      "Epoch 2918/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0950 - accuracy: 0.9671 - val_loss: 0.6710 - val_accuracy: 0.8258\n",
      "Epoch 2919/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0901 - accuracy: 0.9690 - val_loss: 0.6938 - val_accuracy: 0.8235\n",
      "Epoch 2920/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0969 - accuracy: 0.9658 - val_loss: 0.7169 - val_accuracy: 0.8190\n",
      "Epoch 2921/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0925 - accuracy: 0.9675 - val_loss: 0.7666 - val_accuracy: 0.8070\n",
      "Epoch 2922/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0956 - accuracy: 0.9673 - val_loss: 0.7032 - val_accuracy: 0.8213\n",
      "Epoch 2923/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0961 - accuracy: 0.9669 - val_loss: 0.7320 - val_accuracy: 0.8145\n",
      "Epoch 2924/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0925 - accuracy: 0.9680 - val_loss: 0.7043 - val_accuracy: 0.8221\n",
      "Epoch 2925/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0905 - accuracy: 0.9694 - val_loss: 0.7043 - val_accuracy: 0.8195\n",
      "Epoch 2926/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0962 - accuracy: 0.9669 - val_loss: 0.6881 - val_accuracy: 0.8238\n",
      "Epoch 2927/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0905 - accuracy: 0.9690 - val_loss: 0.7035 - val_accuracy: 0.8206\n",
      "Epoch 2928/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0881 - accuracy: 0.9688 - val_loss: 0.6598 - val_accuracy: 0.8305\n",
      "Epoch 2929/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0919 - accuracy: 0.9685 - val_loss: 0.7335 - val_accuracy: 0.8162\n",
      "Epoch 2930/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0942 - accuracy: 0.9674 - val_loss: 0.7628 - val_accuracy: 0.8140\n",
      "Epoch 2931/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0920 - accuracy: 0.9682 - val_loss: 0.6798 - val_accuracy: 0.8241\n",
      "Epoch 2932/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0914 - accuracy: 0.9677 - val_loss: 0.8228 - val_accuracy: 0.8075\n",
      "Epoch 2933/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0932 - accuracy: 0.9672 - val_loss: 0.7730 - val_accuracy: 0.8102\n",
      "Epoch 2934/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0936 - accuracy: 0.9676 - val_loss: 0.6776 - val_accuracy: 0.8261\n",
      "Epoch 2935/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0903 - accuracy: 0.9686 - val_loss: 0.6862 - val_accuracy: 0.8217\n",
      "Epoch 2936/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0933 - accuracy: 0.9669 - val_loss: 0.7411 - val_accuracy: 0.8156\n",
      "Epoch 2937/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0970 - accuracy: 0.9668 - val_loss: 0.7140 - val_accuracy: 0.8197\n",
      "Epoch 2938/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0965 - accuracy: 0.9667 - val_loss: 0.6808 - val_accuracy: 0.8263\n",
      "Epoch 2939/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0896 - accuracy: 0.9691 - val_loss: 0.6786 - val_accuracy: 0.8251\n",
      "Epoch 2940/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0866 - accuracy: 0.9702 - val_loss: 0.7253 - val_accuracy: 0.8173\n",
      "Epoch 2941/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0948 - accuracy: 0.9667 - val_loss: 0.7450 - val_accuracy: 0.8138\n",
      "Epoch 2942/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0938 - accuracy: 0.9675 - val_loss: 0.6799 - val_accuracy: 0.8227\n",
      "Epoch 2943/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0915 - accuracy: 0.9682 - val_loss: 0.6794 - val_accuracy: 0.8248\n",
      "Epoch 2944/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0914 - accuracy: 0.9681 - val_loss: 0.7343 - val_accuracy: 0.8177\n",
      "Epoch 2945/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0993 - accuracy: 0.9651 - val_loss: 0.7056 - val_accuracy: 0.8278\n",
      "Epoch 2946/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0904 - accuracy: 0.9685 - val_loss: 0.6691 - val_accuracy: 0.8277\n",
      "Epoch 2947/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0934 - accuracy: 0.9676 - val_loss: 0.6825 - val_accuracy: 0.8247\n",
      "Epoch 2948/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0914 - accuracy: 0.9680 - val_loss: 0.7061 - val_accuracy: 0.8219\n",
      "Epoch 2949/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0903 - accuracy: 0.9686 - val_loss: 0.6859 - val_accuracy: 0.8205\n",
      "Epoch 2950/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0905 - accuracy: 0.9683 - val_loss: 0.7555 - val_accuracy: 0.8097\n",
      "Epoch 2951/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0901 - accuracy: 0.9686 - val_loss: 0.7023 - val_accuracy: 0.8244\n",
      "Epoch 2952/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0903 - accuracy: 0.9688 - val_loss: 0.7007 - val_accuracy: 0.8230\n",
      "Epoch 2953/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0895 - accuracy: 0.9691 - val_loss: 0.6771 - val_accuracy: 0.8238\n",
      "Epoch 2954/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0876 - accuracy: 0.9696 - val_loss: 0.6725 - val_accuracy: 0.8244\n",
      "Epoch 2955/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.1095 - accuracy: 0.9627 - val_loss: 0.6882 - val_accuracy: 0.8244\n",
      "Epoch 2956/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0923 - accuracy: 0.9682 - val_loss: 0.6821 - val_accuracy: 0.8261\n",
      "Epoch 2957/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0966 - accuracy: 0.9672 - val_loss: 0.6937 - val_accuracy: 0.8179\n",
      "Epoch 2958/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0896 - accuracy: 0.9691 - val_loss: 0.7892 - val_accuracy: 0.8157\n",
      "Epoch 2959/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0936 - accuracy: 0.9675 - val_loss: 0.6998 - val_accuracy: 0.8163\n",
      "Epoch 2960/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0900 - accuracy: 0.9686 - val_loss: 0.7918 - val_accuracy: 0.8068\n",
      "Epoch 2961/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0870 - accuracy: 0.9699 - val_loss: 0.6684 - val_accuracy: 0.8252\n",
      "Epoch 2962/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0918 - accuracy: 0.9688 - val_loss: 0.6936 - val_accuracy: 0.8189\n",
      "Epoch 2963/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0868 - accuracy: 0.9701 - val_loss: 0.6833 - val_accuracy: 0.8262\n",
      "Epoch 2964/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0913 - accuracy: 0.9689 - val_loss: 0.6968 - val_accuracy: 0.8209\n",
      "Epoch 2965/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0935 - accuracy: 0.9676 - val_loss: 0.7216 - val_accuracy: 0.8179\n",
      "Epoch 2966/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0950 - accuracy: 0.9669 - val_loss: 0.7378 - val_accuracy: 0.8121\n",
      "Epoch 2967/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0919 - accuracy: 0.9678 - val_loss: 0.7031 - val_accuracy: 0.8164\n",
      "Epoch 2968/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0926 - accuracy: 0.9678 - val_loss: 0.7531 - val_accuracy: 0.8172\n",
      "Epoch 2969/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0906 - accuracy: 0.9677 - val_loss: 0.6748 - val_accuracy: 0.8281\n",
      "Epoch 2970/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0924 - accuracy: 0.9676 - val_loss: 0.6930 - val_accuracy: 0.8236\n",
      "Epoch 2971/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0925 - accuracy: 0.9677 - val_loss: 0.7223 - val_accuracy: 0.8207\n",
      "Epoch 2972/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0906 - accuracy: 0.9687 - val_loss: 0.6861 - val_accuracy: 0.8257\n",
      "Epoch 2973/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0982 - accuracy: 0.9650 - val_loss: 0.7353 - val_accuracy: 0.8176\n",
      "Epoch 2974/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0884 - accuracy: 0.9689 - val_loss: 0.6800 - val_accuracy: 0.8262\n",
      "Epoch 2975/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0890 - accuracy: 0.9690 - val_loss: 0.7435 - val_accuracy: 0.8108\n",
      "Epoch 2976/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0843 - accuracy: 0.9705 - val_loss: 0.6945 - val_accuracy: 0.8263\n",
      "Epoch 2977/8000\n",
      "1463/1463 [==============================] - 12s 9ms/step - loss: 0.0878 - accuracy: 0.9700 - val_loss: 0.6979 - val_accuracy: 0.8235\n",
      "Epoch 2978/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0934 - accuracy: 0.9671 - val_loss: 0.7519 - val_accuracy: 0.8154\n",
      "Epoch 2979/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0949 - accuracy: 0.9676 - val_loss: 0.6980 - val_accuracy: 0.8204\n",
      "Epoch 2980/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0909 - accuracy: 0.9686 - val_loss: 0.6736 - val_accuracy: 0.8306\n",
      "Epoch 2981/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0910 - accuracy: 0.9684 - val_loss: 0.7220 - val_accuracy: 0.8207\n",
      "Epoch 2982/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0944 - accuracy: 0.9676 - val_loss: 0.6491 - val_accuracy: 0.8318\n",
      "Epoch 2983/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0858 - accuracy: 0.9705 - val_loss: 0.7385 - val_accuracy: 0.8178\n",
      "Epoch 2984/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0888 - accuracy: 0.9693 - val_loss: 0.7087 - val_accuracy: 0.8247\n",
      "Epoch 2985/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0876 - accuracy: 0.9698 - val_loss: 0.6701 - val_accuracy: 0.8283\n",
      "Epoch 2986/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0997 - accuracy: 0.9663 - val_loss: 0.6951 - val_accuracy: 0.8213\n",
      "Epoch 2987/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0913 - accuracy: 0.9689 - val_loss: 0.6571 - val_accuracy: 0.8319\n",
      "Epoch 2988/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0894 - accuracy: 0.9691 - val_loss: 0.7533 - val_accuracy: 0.8088\n",
      "Epoch 2989/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0893 - accuracy: 0.9691 - val_loss: 0.7964 - val_accuracy: 0.8093\n",
      "Epoch 2990/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0920 - accuracy: 0.9681 - val_loss: 0.6845 - val_accuracy: 0.8286\n",
      "Epoch 2991/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0917 - accuracy: 0.9677 - val_loss: 0.7351 - val_accuracy: 0.8199\n",
      "Epoch 2992/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0855 - accuracy: 0.9707 - val_loss: 0.7244 - val_accuracy: 0.8181\n",
      "Epoch 2993/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0904 - accuracy: 0.9683 - val_loss: 0.6689 - val_accuracy: 0.8256\n",
      "Epoch 2994/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0973 - accuracy: 0.9663 - val_loss: 0.6945 - val_accuracy: 0.8265\n",
      "Epoch 2995/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0896 - accuracy: 0.9686 - val_loss: 0.7100 - val_accuracy: 0.8229\n",
      "Epoch 2996/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0915 - accuracy: 0.9679 - val_loss: 0.6580 - val_accuracy: 0.8312\n",
      "Epoch 2997/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0889 - accuracy: 0.9692 - val_loss: 0.6726 - val_accuracy: 0.8313\n",
      "Epoch 2998/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0870 - accuracy: 0.9697 - val_loss: 0.7222 - val_accuracy: 0.8193\n",
      "Epoch 2999/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0887 - accuracy: 0.9688 - val_loss: 0.7085 - val_accuracy: 0.8230\n",
      "Epoch 3000/8000\n",
      "1462/1463 [============================>.] - ETA: 0s - loss: 0.0893 - accuracy: 0.9690\n",
      "Epoch 3000: saving model to ./training_ckpt_20240109205949_v8_240109_d10000_n4096_b64_e8000_c100_Adamax\\cp-000003000.ckpt\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0894 - accuracy: 0.9690 - val_loss: 0.7235 - val_accuracy: 0.8202\n",
      "Epoch 3001/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0840 - accuracy: 0.9711 - val_loss: 0.7456 - val_accuracy: 0.8147\n",
      "Epoch 3002/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0911 - accuracy: 0.9688 - val_loss: 0.7102 - val_accuracy: 0.8207\n",
      "Epoch 3003/8000\n",
      "1463/1463 [==============================] - 10s 7ms/step - loss: 0.0908 - accuracy: 0.9687 - val_loss: 0.6989 - val_accuracy: 0.8212\n",
      "Epoch 3004/8000\n",
      "1463/1463 [==============================] - 9s 6ms/step - loss: 0.0968 - accuracy: 0.9665 - val_loss: 0.6673 - val_accuracy: 0.8259\n",
      "Epoch 3005/8000\n",
      "1463/1463 [==============================] - 9s 6ms/step - loss: 0.0877 - accuracy: 0.9695 - val_loss: 0.6895 - val_accuracy: 0.8255\n",
      "Epoch 3006/8000\n",
      "1463/1463 [==============================] - 9s 6ms/step - loss: 0.0899 - accuracy: 0.9694 - val_loss: 0.7392 - val_accuracy: 0.8180\n",
      "Epoch 3007/8000\n",
      "1463/1463 [==============================] - 9s 6ms/step - loss: 0.0902 - accuracy: 0.9685 - val_loss: 0.6924 - val_accuracy: 0.8233\n",
      "Epoch 3008/8000\n",
      "1463/1463 [==============================] - 9s 6ms/step - loss: 0.0895 - accuracy: 0.9689 - val_loss: 0.7335 - val_accuracy: 0.8174\n",
      "Epoch 3009/8000\n",
      "1463/1463 [==============================] - 9s 6ms/step - loss: 0.0905 - accuracy: 0.9682 - val_loss: 0.7669 - val_accuracy: 0.8125\n",
      "Epoch 3010/8000\n",
      "1463/1463 [==============================] - 9s 6ms/step - loss: 0.0918 - accuracy: 0.9681 - val_loss: 0.7153 - val_accuracy: 0.8186\n",
      "Epoch 3011/8000\n",
      "1463/1463 [==============================] - 9s 6ms/step - loss: 0.0944 - accuracy: 0.9670 - val_loss: 0.6894 - val_accuracy: 0.8264\n",
      "Epoch 3012/8000\n",
      "1463/1463 [==============================] - 9s 6ms/step - loss: 0.0867 - accuracy: 0.9700 - val_loss: 0.6725 - val_accuracy: 0.8292\n",
      "Epoch 3013/8000\n",
      "1463/1463 [==============================] - 9s 6ms/step - loss: 0.0912 - accuracy: 0.9685 - val_loss: 0.7049 - val_accuracy: 0.8231\n",
      "Epoch 3014/8000\n",
      "1463/1463 [==============================] - 9s 6ms/step - loss: 0.0925 - accuracy: 0.9680 - val_loss: 0.6669 - val_accuracy: 0.8300\n",
      "Epoch 3015/8000\n",
      "1463/1463 [==============================] - 9s 6ms/step - loss: 0.0943 - accuracy: 0.9675 - val_loss: 0.7797 - val_accuracy: 0.8102\n",
      "Epoch 3016/8000\n",
      "1463/1463 [==============================] - 9s 6ms/step - loss: 0.0879 - accuracy: 0.9689 - val_loss: 0.7626 - val_accuracy: 0.8118\n",
      "Epoch 3017/8000\n",
      "1463/1463 [==============================] - 9s 6ms/step - loss: 0.0914 - accuracy: 0.9685 - val_loss: 0.7024 - val_accuracy: 0.8200\n",
      "Epoch 3018/8000\n",
      "1463/1463 [==============================] - 9s 6ms/step - loss: 0.0913 - accuracy: 0.9676 - val_loss: 0.7156 - val_accuracy: 0.8181\n",
      "Epoch 3019/8000\n",
      "1463/1463 [==============================] - 10s 7ms/step - loss: 0.0886 - accuracy: 0.9693 - val_loss: 0.7147 - val_accuracy: 0.8223\n",
      "Epoch 3020/8000\n",
      "1463/1463 [==============================] - 10s 7ms/step - loss: 0.0887 - accuracy: 0.9694 - val_loss: 0.7228 - val_accuracy: 0.8170\n",
      "Epoch 3021/8000\n",
      "1463/1463 [==============================] - 9s 6ms/step - loss: 0.0888 - accuracy: 0.9693 - val_loss: 0.6686 - val_accuracy: 0.8272\n",
      "Epoch 3022/8000\n",
      "1463/1463 [==============================] - 9s 6ms/step - loss: 0.0902 - accuracy: 0.9690 - val_loss: 0.6852 - val_accuracy: 0.8256\n",
      "Epoch 3023/8000\n",
      "1463/1463 [==============================] - 10s 7ms/step - loss: 0.0948 - accuracy: 0.9674 - val_loss: 0.7106 - val_accuracy: 0.8193\n",
      "Epoch 3024/8000\n",
      "1463/1463 [==============================] - 10s 7ms/step - loss: 0.0878 - accuracy: 0.9692 - val_loss: 0.7947 - val_accuracy: 0.8106\n",
      "Epoch 3025/8000\n",
      "1463/1463 [==============================] - 10s 7ms/step - loss: 0.0911 - accuracy: 0.9681 - val_loss: 0.6689 - val_accuracy: 0.8271\n",
      "Epoch 3026/8000\n",
      "1463/1463 [==============================] - 10s 7ms/step - loss: 0.0881 - accuracy: 0.9697 - val_loss: 0.7233 - val_accuracy: 0.8215\n",
      "Epoch 3027/8000\n",
      "1463/1463 [==============================] - 10s 7ms/step - loss: 0.0947 - accuracy: 0.9671 - val_loss: 0.7040 - val_accuracy: 0.8207\n",
      "Epoch 3028/8000\n",
      "1463/1463 [==============================] - 10s 7ms/step - loss: 0.0919 - accuracy: 0.9679 - val_loss: 0.7696 - val_accuracy: 0.8093\n",
      "Epoch 3029/8000\n",
      "1463/1463 [==============================] - 10s 7ms/step - loss: 0.0928 - accuracy: 0.9675 - val_loss: 0.6875 - val_accuracy: 0.8238\n",
      "Epoch 3030/8000\n",
      "1463/1463 [==============================] - 10s 7ms/step - loss: 0.0914 - accuracy: 0.9684 - val_loss: 0.6674 - val_accuracy: 0.8277\n",
      "Epoch 3031/8000\n",
      "1463/1463 [==============================] - 10s 7ms/step - loss: 0.0866 - accuracy: 0.9694 - val_loss: 0.6699 - val_accuracy: 0.8310\n",
      "Epoch 3032/8000\n",
      "1463/1463 [==============================] - 10s 7ms/step - loss: 0.0900 - accuracy: 0.9690 - val_loss: 0.7154 - val_accuracy: 0.8206\n",
      "Epoch 3033/8000\n",
      "1463/1463 [==============================] - 10s 7ms/step - loss: 0.0854 - accuracy: 0.9706 - val_loss: 0.6718 - val_accuracy: 0.8288\n",
      "Epoch 3034/8000\n",
      "1463/1463 [==============================] - 10s 7ms/step - loss: 0.0889 - accuracy: 0.9689 - val_loss: 0.6610 - val_accuracy: 0.8313\n",
      "Epoch 3035/8000\n",
      "1463/1463 [==============================] - 10s 7ms/step - loss: 0.0890 - accuracy: 0.9686 - val_loss: 0.6951 - val_accuracy: 0.8243\n",
      "Epoch 3036/8000\n",
      "1463/1463 [==============================] - 10s 7ms/step - loss: 0.0921 - accuracy: 0.9685 - val_loss: 0.6687 - val_accuracy: 0.8280\n",
      "Epoch 3037/8000\n",
      "1463/1463 [==============================] - 10s 7ms/step - loss: 0.0874 - accuracy: 0.9698 - val_loss: 0.7155 - val_accuracy: 0.8210\n",
      "Epoch 3038/8000\n",
      "1463/1463 [==============================] - 10s 7ms/step - loss: 0.0902 - accuracy: 0.9690 - val_loss: 0.7200 - val_accuracy: 0.8207\n",
      "Epoch 3039/8000\n",
      "1463/1463 [==============================] - 10s 7ms/step - loss: 0.0921 - accuracy: 0.9679 - val_loss: 0.6974 - val_accuracy: 0.8234\n",
      "Epoch 3040/8000\n",
      "1463/1463 [==============================] - 10s 7ms/step - loss: 0.0874 - accuracy: 0.9700 - val_loss: 0.7829 - val_accuracy: 0.8122\n",
      "Epoch 3041/8000\n",
      "1463/1463 [==============================] - 10s 7ms/step - loss: 0.0864 - accuracy: 0.9696 - val_loss: 0.7429 - val_accuracy: 0.8190\n",
      "Epoch 3042/8000\n",
      "1463/1463 [==============================] - 10s 7ms/step - loss: 0.0874 - accuracy: 0.9702 - val_loss: 0.6846 - val_accuracy: 0.8264\n",
      "Epoch 3043/8000\n",
      "1463/1463 [==============================] - 10s 7ms/step - loss: 0.0893 - accuracy: 0.9688 - val_loss: 0.6657 - val_accuracy: 0.8293\n",
      "Epoch 3044/8000\n",
      "1463/1463 [==============================] - 10s 7ms/step - loss: 0.0873 - accuracy: 0.9688 - val_loss: 0.7099 - val_accuracy: 0.8218\n",
      "Epoch 3045/8000\n",
      "1463/1463 [==============================] - 10s 7ms/step - loss: 0.0928 - accuracy: 0.9679 - val_loss: 0.7207 - val_accuracy: 0.8174\n",
      "Epoch 3046/8000\n",
      "1463/1463 [==============================] - 10s 7ms/step - loss: 0.0880 - accuracy: 0.9698 - val_loss: 0.7325 - val_accuracy: 0.8172\n",
      "Epoch 3047/8000\n",
      "1463/1463 [==============================] - 10s 7ms/step - loss: 0.0863 - accuracy: 0.9699 - val_loss: 0.7270 - val_accuracy: 0.8171\n",
      "Epoch 3048/8000\n",
      "1463/1463 [==============================] - 10s 7ms/step - loss: 0.0898 - accuracy: 0.9697 - val_loss: 0.6715 - val_accuracy: 0.8313\n",
      "Epoch 3049/8000\n",
      "1463/1463 [==============================] - 10s 7ms/step - loss: 0.0931 - accuracy: 0.9675 - val_loss: 0.7186 - val_accuracy: 0.8213\n",
      "Epoch 3050/8000\n",
      "1463/1463 [==============================] - 10s 7ms/step - loss: 0.0863 - accuracy: 0.9699 - val_loss: 0.6739 - val_accuracy: 0.8275\n",
      "Epoch 3051/8000\n",
      "1463/1463 [==============================] - 11s 7ms/step - loss: 0.0865 - accuracy: 0.9705 - val_loss: 0.7006 - val_accuracy: 0.8238\n",
      "Epoch 3052/8000\n",
      "1463/1463 [==============================] - 10s 7ms/step - loss: 0.0910 - accuracy: 0.9676 - val_loss: 0.6980 - val_accuracy: 0.8232\n",
      "Epoch 3053/8000\n",
      "1463/1463 [==============================] - 10s 7ms/step - loss: 0.0860 - accuracy: 0.9712 - val_loss: 0.7166 - val_accuracy: 0.8169\n",
      "Epoch 3054/8000\n",
      "1463/1463 [==============================] - 11s 7ms/step - loss: 0.0938 - accuracy: 0.9676 - val_loss: 0.6682 - val_accuracy: 0.8316\n",
      "Epoch 3055/8000\n",
      "1463/1463 [==============================] - 10s 7ms/step - loss: 0.0880 - accuracy: 0.9693 - val_loss: 0.6957 - val_accuracy: 0.8205\n",
      "Epoch 3056/8000\n",
      "1463/1463 [==============================] - 10s 7ms/step - loss: 0.0901 - accuracy: 0.9692 - val_loss: 0.7017 - val_accuracy: 0.8240\n",
      "Epoch 3057/8000\n",
      "1463/1463 [==============================] - 11s 7ms/step - loss: 0.0955 - accuracy: 0.9678 - val_loss: 0.7614 - val_accuracy: 0.8090\n",
      "Epoch 3058/8000\n",
      "1463/1463 [==============================] - 11s 7ms/step - loss: 0.0849 - accuracy: 0.9708 - val_loss: 0.6805 - val_accuracy: 0.8272\n",
      "Epoch 3059/8000\n",
      "1463/1463 [==============================] - 11s 7ms/step - loss: 0.0923 - accuracy: 0.9690 - val_loss: 0.7869 - val_accuracy: 0.8093\n",
      "Epoch 3060/8000\n",
      "1463/1463 [==============================] - 11s 7ms/step - loss: 0.0846 - accuracy: 0.9705 - val_loss: 0.6624 - val_accuracy: 0.8313\n",
      "Epoch 3061/8000\n",
      "1463/1463 [==============================] - 11s 7ms/step - loss: 0.0886 - accuracy: 0.9689 - val_loss: 0.6756 - val_accuracy: 0.8290\n",
      "Epoch 3062/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0883 - accuracy: 0.9694 - val_loss: 0.7119 - val_accuracy: 0.8238\n",
      "Epoch 3063/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0898 - accuracy: 0.9694 - val_loss: 0.6767 - val_accuracy: 0.8313\n",
      "Epoch 3064/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0887 - accuracy: 0.9693 - val_loss: 0.7803 - val_accuracy: 0.8129\n",
      "Epoch 3065/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0856 - accuracy: 0.9709 - val_loss: 0.7080 - val_accuracy: 0.8240\n",
      "Epoch 3066/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0834 - accuracy: 0.9713 - val_loss: 0.6794 - val_accuracy: 0.8270\n",
      "Epoch 3067/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0869 - accuracy: 0.9702 - val_loss: 0.7207 - val_accuracy: 0.8197\n",
      "Epoch 3068/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0858 - accuracy: 0.9705 - val_loss: 0.7080 - val_accuracy: 0.8236\n",
      "Epoch 3069/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0929 - accuracy: 0.9676 - val_loss: 0.6618 - val_accuracy: 0.8280\n",
      "Epoch 3070/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0971 - accuracy: 0.9659 - val_loss: 0.6794 - val_accuracy: 0.8285\n",
      "Epoch 3071/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0884 - accuracy: 0.9696 - val_loss: 0.7594 - val_accuracy: 0.8119\n",
      "Epoch 3072/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0872 - accuracy: 0.9698 - val_loss: 0.7308 - val_accuracy: 0.8171\n",
      "Epoch 3073/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0874 - accuracy: 0.9695 - val_loss: 0.7468 - val_accuracy: 0.8149\n",
      "Epoch 3074/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0855 - accuracy: 0.9703 - val_loss: 0.7877 - val_accuracy: 0.8095\n",
      "Epoch 3075/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0909 - accuracy: 0.9680 - val_loss: 0.7125 - val_accuracy: 0.8197\n",
      "Epoch 3076/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0853 - accuracy: 0.9697 - val_loss: 0.6731 - val_accuracy: 0.8292\n",
      "Epoch 3077/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0887 - accuracy: 0.9697 - val_loss: 0.7299 - val_accuracy: 0.8178\n",
      "Epoch 3078/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0897 - accuracy: 0.9686 - val_loss: 0.7018 - val_accuracy: 0.8247\n",
      "Epoch 3079/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0869 - accuracy: 0.9706 - val_loss: 0.6920 - val_accuracy: 0.8240\n",
      "Epoch 3080/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0875 - accuracy: 0.9687 - val_loss: 0.7216 - val_accuracy: 0.8208\n",
      "Epoch 3081/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0874 - accuracy: 0.9696 - val_loss: 0.7214 - val_accuracy: 0.8252\n",
      "Epoch 3082/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0857 - accuracy: 0.9699 - val_loss: 0.7496 - val_accuracy: 0.8158\n",
      "Epoch 3083/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0868 - accuracy: 0.9700 - val_loss: 0.7426 - val_accuracy: 0.8163\n",
      "Epoch 3084/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0902 - accuracy: 0.9690 - val_loss: 0.7164 - val_accuracy: 0.8249\n",
      "Epoch 3085/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0925 - accuracy: 0.9690 - val_loss: 0.7769 - val_accuracy: 0.8121\n",
      "Epoch 3086/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0817 - accuracy: 0.9712 - val_loss: 0.7040 - val_accuracy: 0.8253\n",
      "Epoch 3087/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0906 - accuracy: 0.9685 - val_loss: 0.7682 - val_accuracy: 0.8162\n",
      "Epoch 3088/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0820 - accuracy: 0.9716 - val_loss: 0.7647 - val_accuracy: 0.8180\n",
      "Epoch 3089/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0884 - accuracy: 0.9698 - val_loss: 0.6709 - val_accuracy: 0.8292\n",
      "Epoch 3090/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0872 - accuracy: 0.9699 - val_loss: 0.7426 - val_accuracy: 0.8199\n",
      "Epoch 3091/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0889 - accuracy: 0.9692 - val_loss: 0.6617 - val_accuracy: 0.8296\n",
      "Epoch 3092/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0855 - accuracy: 0.9710 - val_loss: 0.6723 - val_accuracy: 0.8288\n",
      "Epoch 3093/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0873 - accuracy: 0.9694 - val_loss: 0.7270 - val_accuracy: 0.8209\n",
      "Epoch 3094/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0840 - accuracy: 0.9709 - val_loss: 0.7554 - val_accuracy: 0.8143\n",
      "Epoch 3095/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0919 - accuracy: 0.9681 - val_loss: 0.7069 - val_accuracy: 0.8249\n",
      "Epoch 3096/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0910 - accuracy: 0.9683 - val_loss: 0.6826 - val_accuracy: 0.8276\n",
      "Epoch 3097/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0872 - accuracy: 0.9701 - val_loss: 0.6893 - val_accuracy: 0.8260\n",
      "Epoch 3098/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0844 - accuracy: 0.9708 - val_loss: 0.7113 - val_accuracy: 0.8186\n",
      "Epoch 3099/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0885 - accuracy: 0.9701 - val_loss: 0.6761 - val_accuracy: 0.8285\n",
      "Epoch 3100/8000\n",
      "1463/1463 [==============================] - ETA: 0s - loss: 0.0821 - accuracy: 0.9713\n",
      "Epoch 3100: saving model to ./training_ckpt_20240109205949_v8_240109_d10000_n4096_b64_e8000_c100_Adamax\\cp-000003100.ckpt\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0821 - accuracy: 0.9713 - val_loss: 0.8223 - val_accuracy: 0.8155\n",
      "Epoch 3101/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0836 - accuracy: 0.9709 - val_loss: 0.6816 - val_accuracy: 0.8260\n",
      "Epoch 3102/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0910 - accuracy: 0.9691 - val_loss: 0.6903 - val_accuracy: 0.8260\n",
      "Epoch 3103/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0882 - accuracy: 0.9695 - val_loss: 0.6793 - val_accuracy: 0.8311\n",
      "Epoch 3104/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0846 - accuracy: 0.9707 - val_loss: 0.6892 - val_accuracy: 0.8251\n",
      "Epoch 3105/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0868 - accuracy: 0.9703 - val_loss: 0.7277 - val_accuracy: 0.8214\n",
      "Epoch 3106/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0868 - accuracy: 0.9697 - val_loss: 0.6658 - val_accuracy: 0.8305\n",
      "Epoch 3107/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0930 - accuracy: 0.9678 - val_loss: 0.6999 - val_accuracy: 0.8212\n",
      "Epoch 3108/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0857 - accuracy: 0.9705 - val_loss: 0.7047 - val_accuracy: 0.8258\n",
      "Epoch 3109/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0874 - accuracy: 0.9701 - val_loss: 0.6848 - val_accuracy: 0.8274\n",
      "Epoch 3110/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0861 - accuracy: 0.9700 - val_loss: 0.6709 - val_accuracy: 0.8275\n",
      "Epoch 3111/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0889 - accuracy: 0.9689 - val_loss: 0.6866 - val_accuracy: 0.8307\n",
      "Epoch 3112/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0870 - accuracy: 0.9696 - val_loss: 0.6696 - val_accuracy: 0.8294\n",
      "Epoch 3113/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0851 - accuracy: 0.9704 - val_loss: 0.6721 - val_accuracy: 0.8287\n",
      "Epoch 3114/8000\n",
      "1463/1463 [==============================] - 12s 9ms/step - loss: 0.0907 - accuracy: 0.9684 - val_loss: 0.6906 - val_accuracy: 0.8272\n",
      "Epoch 3115/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0834 - accuracy: 0.9709 - val_loss: 0.6991 - val_accuracy: 0.8252\n",
      "Epoch 3116/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0874 - accuracy: 0.9699 - val_loss: 0.7670 - val_accuracy: 0.8120\n",
      "Epoch 3117/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0892 - accuracy: 0.9696 - val_loss: 0.7022 - val_accuracy: 0.8236\n",
      "Epoch 3118/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0853 - accuracy: 0.9709 - val_loss: 0.6526 - val_accuracy: 0.8368\n",
      "Epoch 3119/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0843 - accuracy: 0.9708 - val_loss: 0.7498 - val_accuracy: 0.8114\n",
      "Epoch 3120/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0876 - accuracy: 0.9687 - val_loss: 0.6993 - val_accuracy: 0.8282\n",
      "Epoch 3121/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0824 - accuracy: 0.9719 - val_loss: 0.6984 - val_accuracy: 0.8267\n",
      "Epoch 3122/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0856 - accuracy: 0.9703 - val_loss: 0.6882 - val_accuracy: 0.8238\n",
      "Epoch 3123/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0843 - accuracy: 0.9706 - val_loss: 0.7898 - val_accuracy: 0.8096\n",
      "Epoch 3124/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0924 - accuracy: 0.9685 - val_loss: 0.6746 - val_accuracy: 0.8297\n",
      "Epoch 3125/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0880 - accuracy: 0.9689 - val_loss: 0.7435 - val_accuracy: 0.8168\n",
      "Epoch 3126/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0882 - accuracy: 0.9691 - val_loss: 0.6661 - val_accuracy: 0.8350\n",
      "Epoch 3127/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0845 - accuracy: 0.9706 - val_loss: 0.6866 - val_accuracy: 0.8241\n",
      "Epoch 3128/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0893 - accuracy: 0.9693 - val_loss: 0.6828 - val_accuracy: 0.8277\n",
      "Epoch 3129/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0818 - accuracy: 0.9719 - val_loss: 0.6967 - val_accuracy: 0.8259\n",
      "Epoch 3130/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0954 - accuracy: 0.9670 - val_loss: 0.6635 - val_accuracy: 0.8352\n",
      "Epoch 3131/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0846 - accuracy: 0.9709 - val_loss: 0.6797 - val_accuracy: 0.8279\n",
      "Epoch 3132/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0902 - accuracy: 0.9684 - val_loss: 0.7150 - val_accuracy: 0.8204\n",
      "Epoch 3133/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0901 - accuracy: 0.9695 - val_loss: 0.7285 - val_accuracy: 0.8172\n",
      "Epoch 3134/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0915 - accuracy: 0.9682 - val_loss: 0.6806 - val_accuracy: 0.8281\n",
      "Epoch 3135/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0902 - accuracy: 0.9689 - val_loss: 0.8098 - val_accuracy: 0.8135\n",
      "Epoch 3136/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0834 - accuracy: 0.9710 - val_loss: 0.7404 - val_accuracy: 0.8193\n",
      "Epoch 3137/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0882 - accuracy: 0.9697 - val_loss: 0.7943 - val_accuracy: 0.8096\n",
      "Epoch 3138/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0906 - accuracy: 0.9694 - val_loss: 0.7145 - val_accuracy: 0.8223\n",
      "Epoch 3139/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0828 - accuracy: 0.9710 - val_loss: 0.6656 - val_accuracy: 0.8322\n",
      "Epoch 3140/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0803 - accuracy: 0.9724 - val_loss: 0.7638 - val_accuracy: 0.8152\n",
      "Epoch 3141/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0886 - accuracy: 0.9693 - val_loss: 0.8223 - val_accuracy: 0.8071\n",
      "Epoch 3142/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0823 - accuracy: 0.9713 - val_loss: 0.7460 - val_accuracy: 0.8163\n",
      "Epoch 3143/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0887 - accuracy: 0.9696 - val_loss: 0.6995 - val_accuracy: 0.8287\n",
      "Epoch 3144/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0870 - accuracy: 0.9696 - val_loss: 0.7164 - val_accuracy: 0.8227\n",
      "Epoch 3145/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0869 - accuracy: 0.9700 - val_loss: 0.6781 - val_accuracy: 0.8310\n",
      "Epoch 3146/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0861 - accuracy: 0.9702 - val_loss: 0.7753 - val_accuracy: 0.8130\n",
      "Epoch 3147/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0851 - accuracy: 0.9706 - val_loss: 0.7219 - val_accuracy: 0.8213\n",
      "Epoch 3148/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0846 - accuracy: 0.9712 - val_loss: 0.7463 - val_accuracy: 0.8173\n",
      "Epoch 3149/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0844 - accuracy: 0.9709 - val_loss: 0.7075 - val_accuracy: 0.8235\n",
      "Epoch 3150/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0954 - accuracy: 0.9672 - val_loss: 0.6924 - val_accuracy: 0.8247\n",
      "Epoch 3151/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0882 - accuracy: 0.9694 - val_loss: 0.6488 - val_accuracy: 0.8347\n",
      "Epoch 3152/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0897 - accuracy: 0.9693 - val_loss: 0.7339 - val_accuracy: 0.8174\n",
      "Epoch 3153/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0812 - accuracy: 0.9722 - val_loss: 0.7296 - val_accuracy: 0.8210\n",
      "Epoch 3154/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0845 - accuracy: 0.9710 - val_loss: 0.6592 - val_accuracy: 0.8366\n",
      "Epoch 3155/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0900 - accuracy: 0.9688 - val_loss: 0.7613 - val_accuracy: 0.8189\n",
      "Epoch 3156/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0797 - accuracy: 0.9722 - val_loss: 0.7406 - val_accuracy: 0.8131\n",
      "Epoch 3157/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0910 - accuracy: 0.9685 - val_loss: 0.6999 - val_accuracy: 0.8253\n",
      "Epoch 3158/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0810 - accuracy: 0.9716 - val_loss: 0.7499 - val_accuracy: 0.8166\n",
      "Epoch 3159/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0883 - accuracy: 0.9692 - val_loss: 0.7199 - val_accuracy: 0.8221\n",
      "Epoch 3160/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0851 - accuracy: 0.9702 - val_loss: 0.7014 - val_accuracy: 0.8277\n",
      "Epoch 3161/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0796 - accuracy: 0.9720 - val_loss: 0.7060 - val_accuracy: 0.8284\n",
      "Epoch 3162/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0862 - accuracy: 0.9701 - val_loss: 0.7759 - val_accuracy: 0.8083\n",
      "Epoch 3163/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0843 - accuracy: 0.9710 - val_loss: 0.6962 - val_accuracy: 0.8259\n",
      "Epoch 3164/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0838 - accuracy: 0.9707 - val_loss: 0.7123 - val_accuracy: 0.8238\n",
      "Epoch 3165/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0896 - accuracy: 0.9686 - val_loss: 0.7062 - val_accuracy: 0.8217\n",
      "Epoch 3166/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0908 - accuracy: 0.9687 - val_loss: 0.7182 - val_accuracy: 0.8250\n",
      "Epoch 3167/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0862 - accuracy: 0.9695 - val_loss: 0.7238 - val_accuracy: 0.8219\n",
      "Epoch 3168/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0874 - accuracy: 0.9699 - val_loss: 0.7174 - val_accuracy: 0.8223\n",
      "Epoch 3169/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0892 - accuracy: 0.9692 - val_loss: 0.6889 - val_accuracy: 0.8314\n",
      "Epoch 3170/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0878 - accuracy: 0.9697 - val_loss: 0.6824 - val_accuracy: 0.8288\n",
      "Epoch 3171/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0892 - accuracy: 0.9691 - val_loss: 0.6968 - val_accuracy: 0.8254\n",
      "Epoch 3172/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0827 - accuracy: 0.9715 - val_loss: 0.6849 - val_accuracy: 0.8283\n",
      "Epoch 3173/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0849 - accuracy: 0.9705 - val_loss: 0.6584 - val_accuracy: 0.8385\n",
      "Epoch 3174/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0795 - accuracy: 0.9729 - val_loss: 0.7689 - val_accuracy: 0.8163\n",
      "Epoch 3175/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0815 - accuracy: 0.9719 - val_loss: 0.7269 - val_accuracy: 0.8250\n",
      "Epoch 3176/8000\n",
      "1463/1463 [==============================] - 12s 9ms/step - loss: 0.0907 - accuracy: 0.9693 - val_loss: 0.7210 - val_accuracy: 0.8261\n",
      "Epoch 3177/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0929 - accuracy: 0.9682 - val_loss: 0.7174 - val_accuracy: 0.8252\n",
      "Epoch 3178/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0931 - accuracy: 0.9678 - val_loss: 0.9260 - val_accuracy: 0.8077\n",
      "Epoch 3179/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0885 - accuracy: 0.9699 - val_loss: 0.6786 - val_accuracy: 0.8305\n",
      "Epoch 3180/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0890 - accuracy: 0.9691 - val_loss: 0.7050 - val_accuracy: 0.8282\n",
      "Epoch 3181/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0855 - accuracy: 0.9701 - val_loss: 0.7427 - val_accuracy: 0.8213\n",
      "Epoch 3182/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0816 - accuracy: 0.9716 - val_loss: 0.7152 - val_accuracy: 0.8174\n",
      "Epoch 3183/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0892 - accuracy: 0.9696 - val_loss: 0.7027 - val_accuracy: 0.8269\n",
      "Epoch 3184/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0829 - accuracy: 0.9714 - val_loss: 0.7033 - val_accuracy: 0.8262\n",
      "Epoch 3185/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0856 - accuracy: 0.9701 - val_loss: 0.7287 - val_accuracy: 0.8222\n",
      "Epoch 3186/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0853 - accuracy: 0.9702 - val_loss: 0.7026 - val_accuracy: 0.8238\n",
      "Epoch 3187/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0902 - accuracy: 0.9684 - val_loss: 0.7034 - val_accuracy: 0.8232\n",
      "Epoch 3188/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0810 - accuracy: 0.9719 - val_loss: 0.6616 - val_accuracy: 0.8322\n",
      "Epoch 3189/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0844 - accuracy: 0.9709 - val_loss: 0.7028 - val_accuracy: 0.8238\n",
      "Epoch 3190/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0859 - accuracy: 0.9706 - val_loss: 0.6895 - val_accuracy: 0.8245\n",
      "Epoch 3191/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0808 - accuracy: 0.9721 - val_loss: 0.6894 - val_accuracy: 0.8292\n",
      "Epoch 3192/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0812 - accuracy: 0.9722 - val_loss: 0.7502 - val_accuracy: 0.8208\n",
      "Epoch 3193/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0879 - accuracy: 0.9706 - val_loss: 0.7154 - val_accuracy: 0.8242\n",
      "Epoch 3194/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0842 - accuracy: 0.9709 - val_loss: 0.6695 - val_accuracy: 0.8309\n",
      "Epoch 3195/8000\n",
      "1463/1463 [==============================] - 12s 9ms/step - loss: 0.0848 - accuracy: 0.9701 - val_loss: 0.7065 - val_accuracy: 0.8263\n",
      "Epoch 3196/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0821 - accuracy: 0.9718 - val_loss: 0.8072 - val_accuracy: 0.8237\n",
      "Epoch 3197/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0859 - accuracy: 0.9708 - val_loss: 0.6594 - val_accuracy: 0.8336\n",
      "Epoch 3198/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0841 - accuracy: 0.9707 - val_loss: 0.6892 - val_accuracy: 0.8313\n",
      "Epoch 3199/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0830 - accuracy: 0.9715 - val_loss: 0.7024 - val_accuracy: 0.8291\n",
      "Epoch 3200/8000\n",
      "1463/1463 [==============================] - ETA: 0s - loss: 0.0851 - accuracy: 0.9705\n",
      "Epoch 3200: saving model to ./training_ckpt_20240109205949_v8_240109_d10000_n4096_b64_e8000_c100_Adamax\\cp-000003200.ckpt\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0851 - accuracy: 0.9705 - val_loss: 0.6851 - val_accuracy: 0.8289\n",
      "Epoch 3201/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0848 - accuracy: 0.9710 - val_loss: 0.7056 - val_accuracy: 0.8268\n",
      "Epoch 3202/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0837 - accuracy: 0.9712 - val_loss: 0.7041 - val_accuracy: 0.8254\n",
      "Epoch 3203/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0871 - accuracy: 0.9705 - val_loss: 0.6812 - val_accuracy: 0.8320\n",
      "Epoch 3204/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0901 - accuracy: 0.9694 - val_loss: 0.7485 - val_accuracy: 0.8174\n",
      "Epoch 3205/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0901 - accuracy: 0.9693 - val_loss: 0.6706 - val_accuracy: 0.8333\n",
      "Epoch 3206/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0856 - accuracy: 0.9705 - val_loss: 0.7407 - val_accuracy: 0.8186\n",
      "Epoch 3207/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0907 - accuracy: 0.9690 - val_loss: 0.7204 - val_accuracy: 0.8238\n",
      "Epoch 3208/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0869 - accuracy: 0.9702 - val_loss: 0.7149 - val_accuracy: 0.8216\n",
      "Epoch 3209/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0885 - accuracy: 0.9694 - val_loss: 0.7055 - val_accuracy: 0.8265\n",
      "Epoch 3210/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0891 - accuracy: 0.9699 - val_loss: 0.6803 - val_accuracy: 0.8319\n",
      "Epoch 3211/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0857 - accuracy: 0.9696 - val_loss: 0.6726 - val_accuracy: 0.8344\n",
      "Epoch 3212/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0863 - accuracy: 0.9700 - val_loss: 0.7026 - val_accuracy: 0.8233\n",
      "Epoch 3213/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0848 - accuracy: 0.9704 - val_loss: 0.7015 - val_accuracy: 0.8279\n",
      "Epoch 3214/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0915 - accuracy: 0.9694 - val_loss: 0.7029 - val_accuracy: 0.8268\n",
      "Epoch 3215/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0875 - accuracy: 0.9697 - val_loss: 0.6897 - val_accuracy: 0.8275\n",
      "Epoch 3216/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0841 - accuracy: 0.9711 - val_loss: 0.7284 - val_accuracy: 0.8236\n",
      "Epoch 3217/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0849 - accuracy: 0.9703 - val_loss: 0.7457 - val_accuracy: 0.8183\n",
      "Epoch 3218/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0855 - accuracy: 0.9702 - val_loss: 0.7181 - val_accuracy: 0.8252\n",
      "Epoch 3219/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0837 - accuracy: 0.9716 - val_loss: 0.6953 - val_accuracy: 0.8231\n",
      "Epoch 3220/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0876 - accuracy: 0.9695 - val_loss: 0.7612 - val_accuracy: 0.8163\n",
      "Epoch 3221/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0874 - accuracy: 0.9697 - val_loss: 0.6865 - val_accuracy: 0.8310\n",
      "Epoch 3222/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0815 - accuracy: 0.9718 - val_loss: 0.7376 - val_accuracy: 0.8199\n",
      "Epoch 3223/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0857 - accuracy: 0.9706 - val_loss: 0.7009 - val_accuracy: 0.8254\n",
      "Epoch 3224/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0818 - accuracy: 0.9715 - val_loss: 0.7120 - val_accuracy: 0.8207\n",
      "Epoch 3225/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0956 - accuracy: 0.9677 - val_loss: 0.7073 - val_accuracy: 0.8212\n",
      "Epoch 3226/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0814 - accuracy: 0.9726 - val_loss: 0.7315 - val_accuracy: 0.8210\n",
      "Epoch 3227/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0772 - accuracy: 0.9732 - val_loss: 0.7567 - val_accuracy: 0.8151\n",
      "Epoch 3228/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0835 - accuracy: 0.9713 - val_loss: 0.7365 - val_accuracy: 0.8165\n",
      "Epoch 3229/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0849 - accuracy: 0.9706 - val_loss: 0.7055 - val_accuracy: 0.8244\n",
      "Epoch 3230/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0838 - accuracy: 0.9706 - val_loss: 0.7322 - val_accuracy: 0.8170\n",
      "Epoch 3231/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0841 - accuracy: 0.9708 - val_loss: 0.6789 - val_accuracy: 0.8312\n",
      "Epoch 3232/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0818 - accuracy: 0.9716 - val_loss: 0.7433 - val_accuracy: 0.8186\n",
      "Epoch 3233/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0878 - accuracy: 0.9708 - val_loss: 0.7155 - val_accuracy: 0.8222\n",
      "Epoch 3234/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0911 - accuracy: 0.9689 - val_loss: 0.6913 - val_accuracy: 0.8254\n",
      "Epoch 3235/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0833 - accuracy: 0.9715 - val_loss: 0.7315 - val_accuracy: 0.8230\n",
      "Epoch 3236/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0835 - accuracy: 0.9713 - val_loss: 0.7716 - val_accuracy: 0.8147\n",
      "Epoch 3237/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0807 - accuracy: 0.9722 - val_loss: 0.8284 - val_accuracy: 0.8106\n",
      "Epoch 3238/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0930 - accuracy: 0.9684 - val_loss: 0.6857 - val_accuracy: 0.8321\n",
      "Epoch 3239/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0793 - accuracy: 0.9727 - val_loss: 0.7001 - val_accuracy: 0.8255\n",
      "Epoch 3240/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0829 - accuracy: 0.9712 - val_loss: 0.7113 - val_accuracy: 0.8225\n",
      "Epoch 3241/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0855 - accuracy: 0.9710 - val_loss: 0.7241 - val_accuracy: 0.8254\n",
      "Epoch 3242/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0813 - accuracy: 0.9723 - val_loss: 0.6838 - val_accuracy: 0.8291\n",
      "Epoch 3243/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0829 - accuracy: 0.9718 - val_loss: 0.7067 - val_accuracy: 0.8280\n",
      "Epoch 3244/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0876 - accuracy: 0.9704 - val_loss: 0.6657 - val_accuracy: 0.8347\n",
      "Epoch 3245/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0797 - accuracy: 0.9726 - val_loss: 0.7130 - val_accuracy: 0.8275\n",
      "Epoch 3246/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0822 - accuracy: 0.9724 - val_loss: 0.7132 - val_accuracy: 0.8221\n",
      "Epoch 3247/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0823 - accuracy: 0.9720 - val_loss: 0.6978 - val_accuracy: 0.8306\n",
      "Epoch 3248/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0837 - accuracy: 0.9717 - val_loss: 0.6955 - val_accuracy: 0.8299\n",
      "Epoch 3249/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0865 - accuracy: 0.9695 - val_loss: 0.6840 - val_accuracy: 0.8308\n",
      "Epoch 3250/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0875 - accuracy: 0.9705 - val_loss: 0.6901 - val_accuracy: 0.8282\n",
      "Epoch 3251/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0889 - accuracy: 0.9695 - val_loss: 0.6950 - val_accuracy: 0.8297\n",
      "Epoch 3252/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0894 - accuracy: 0.9692 - val_loss: 0.7001 - val_accuracy: 0.8293\n",
      "Epoch 3253/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0865 - accuracy: 0.9699 - val_loss: 0.7759 - val_accuracy: 0.8137\n",
      "Epoch 3254/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0825 - accuracy: 0.9715 - val_loss: 0.6641 - val_accuracy: 0.8322\n",
      "Epoch 3255/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0826 - accuracy: 0.9722 - val_loss: 0.6670 - val_accuracy: 0.8336\n",
      "Epoch 3256/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0831 - accuracy: 0.9714 - val_loss: 0.6837 - val_accuracy: 0.8306\n",
      "Epoch 3257/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0848 - accuracy: 0.9701 - val_loss: 0.6322 - val_accuracy: 0.8406\n",
      "Epoch 3258/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0828 - accuracy: 0.9716 - val_loss: 0.7649 - val_accuracy: 0.8175\n",
      "Epoch 3259/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0827 - accuracy: 0.9719 - val_loss: 0.6962 - val_accuracy: 0.8312\n",
      "Epoch 3260/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0828 - accuracy: 0.9714 - val_loss: 0.6848 - val_accuracy: 0.8287\n",
      "Epoch 3261/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0809 - accuracy: 0.9718 - val_loss: 0.6961 - val_accuracy: 0.8289\n",
      "Epoch 3262/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0852 - accuracy: 0.9714 - val_loss: 0.6728 - val_accuracy: 0.8303\n",
      "Epoch 3263/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0831 - accuracy: 0.9713 - val_loss: 0.7347 - val_accuracy: 0.8218\n",
      "Epoch 3264/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0811 - accuracy: 0.9721 - val_loss: 0.7067 - val_accuracy: 0.8245\n",
      "Epoch 3265/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0821 - accuracy: 0.9716 - val_loss: 0.6990 - val_accuracy: 0.8235\n",
      "Epoch 3266/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0809 - accuracy: 0.9720 - val_loss: 0.7160 - val_accuracy: 0.8243\n",
      "Epoch 3267/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0854 - accuracy: 0.9706 - val_loss: 0.7149 - val_accuracy: 0.8268\n",
      "Epoch 3268/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0829 - accuracy: 0.9711 - val_loss: 0.6898 - val_accuracy: 0.8288\n",
      "Epoch 3269/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0849 - accuracy: 0.9710 - val_loss: 0.6847 - val_accuracy: 0.8318\n",
      "Epoch 3270/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0829 - accuracy: 0.9712 - val_loss: 0.7049 - val_accuracy: 0.8288\n",
      "Epoch 3271/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0816 - accuracy: 0.9721 - val_loss: 0.6842 - val_accuracy: 0.8353\n",
      "Epoch 3272/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0880 - accuracy: 0.9693 - val_loss: 0.7381 - val_accuracy: 0.8182\n",
      "Epoch 3273/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0816 - accuracy: 0.9723 - val_loss: 0.6672 - val_accuracy: 0.8311\n",
      "Epoch 3274/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0841 - accuracy: 0.9700 - val_loss: 0.6573 - val_accuracy: 0.8356\n",
      "Epoch 3275/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0795 - accuracy: 0.9724 - val_loss: 0.7469 - val_accuracy: 0.8189\n",
      "Epoch 3276/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0879 - accuracy: 0.9700 - val_loss: 0.7139 - val_accuracy: 0.8258\n",
      "Epoch 3277/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0837 - accuracy: 0.9707 - val_loss: 0.7810 - val_accuracy: 0.8217\n",
      "Epoch 3278/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0834 - accuracy: 0.9713 - val_loss: 0.6935 - val_accuracy: 0.8296\n",
      "Epoch 3279/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0833 - accuracy: 0.9710 - val_loss: 0.6674 - val_accuracy: 0.8324\n",
      "Epoch 3280/8000\n",
      "1463/1463 [==============================] - 12s 9ms/step - loss: 0.0779 - accuracy: 0.9734 - val_loss: 0.6777 - val_accuracy: 0.8338\n",
      "Epoch 3281/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0805 - accuracy: 0.9722 - val_loss: 0.7079 - val_accuracy: 0.8272\n",
      "Epoch 3282/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0879 - accuracy: 0.9698 - val_loss: 0.6977 - val_accuracy: 0.8301\n",
      "Epoch 3283/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0834 - accuracy: 0.9705 - val_loss: 0.7719 - val_accuracy: 0.8113\n",
      "Epoch 3284/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0815 - accuracy: 0.9715 - val_loss: 0.7374 - val_accuracy: 0.8262\n",
      "Epoch 3285/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0848 - accuracy: 0.9714 - val_loss: 0.6985 - val_accuracy: 0.8290\n",
      "Epoch 3286/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0865 - accuracy: 0.9703 - val_loss: 0.6697 - val_accuracy: 0.8343\n",
      "Epoch 3287/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0883 - accuracy: 0.9699 - val_loss: 0.7590 - val_accuracy: 0.8135\n",
      "Epoch 3288/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0802 - accuracy: 0.9724 - val_loss: 0.7110 - val_accuracy: 0.8261\n",
      "Epoch 3289/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0823 - accuracy: 0.9720 - val_loss: 0.7562 - val_accuracy: 0.8161\n",
      "Epoch 3290/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0849 - accuracy: 0.9704 - val_loss: 0.7034 - val_accuracy: 0.8266\n",
      "Epoch 3291/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0808 - accuracy: 0.9720 - val_loss: 0.6612 - val_accuracy: 0.8373\n",
      "Epoch 3292/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0808 - accuracy: 0.9716 - val_loss: 0.7195 - val_accuracy: 0.8263\n",
      "Epoch 3293/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0864 - accuracy: 0.9709 - val_loss: 0.6903 - val_accuracy: 0.8289\n",
      "Epoch 3294/8000\n",
      "1463/1463 [==============================] - 11s 7ms/step - loss: 0.0820 - accuracy: 0.9718 - val_loss: 0.7718 - val_accuracy: 0.8131\n",
      "Epoch 3295/8000\n",
      "1463/1463 [==============================] - 9s 6ms/step - loss: 0.0852 - accuracy: 0.9702 - val_loss: 0.7111 - val_accuracy: 0.8263\n",
      "Epoch 3296/8000\n",
      "1463/1463 [==============================] - 9s 6ms/step - loss: 0.0772 - accuracy: 0.9733 - val_loss: 0.7465 - val_accuracy: 0.8210\n",
      "Epoch 3297/8000\n",
      "1463/1463 [==============================] - 9s 6ms/step - loss: 0.0837 - accuracy: 0.9712 - val_loss: 0.6796 - val_accuracy: 0.8323\n",
      "Epoch 3298/8000\n",
      "1463/1463 [==============================] - 9s 6ms/step - loss: 0.0809 - accuracy: 0.9724 - val_loss: 0.7670 - val_accuracy: 0.8145\n",
      "Epoch 3299/8000\n",
      "1463/1463 [==============================] - 9s 6ms/step - loss: 0.0920 - accuracy: 0.9691 - val_loss: 0.6948 - val_accuracy: 0.8313\n",
      "Epoch 3300/8000\n",
      "1463/1463 [==============================] - ETA: 0s - loss: 0.0826 - accuracy: 0.9719\n",
      "Epoch 3300: saving model to ./training_ckpt_20240109205949_v8_240109_d10000_n4096_b64_e8000_c100_Adamax\\cp-000003300.ckpt\n",
      "1463/1463 [==============================] - 9s 6ms/step - loss: 0.0826 - accuracy: 0.9719 - val_loss: 0.6955 - val_accuracy: 0.8318\n",
      "Epoch 3301/8000\n",
      "1463/1463 [==============================] - 9s 6ms/step - loss: 0.0890 - accuracy: 0.9698 - val_loss: 0.7478 - val_accuracy: 0.8237\n",
      "Epoch 3302/8000\n",
      "1463/1463 [==============================] - 9s 6ms/step - loss: 0.0741 - accuracy: 0.9745 - val_loss: 0.6817 - val_accuracy: 0.8293\n",
      "Epoch 3303/8000\n",
      "1463/1463 [==============================] - 9s 6ms/step - loss: 0.0851 - accuracy: 0.9711 - val_loss: 0.6779 - val_accuracy: 0.8322\n",
      "Epoch 3304/8000\n",
      "1463/1463 [==============================] - 9s 6ms/step - loss: 0.0804 - accuracy: 0.9729 - val_loss: 0.6869 - val_accuracy: 0.8301\n",
      "Epoch 3305/8000\n",
      "1463/1463 [==============================] - 9s 6ms/step - loss: 0.0871 - accuracy: 0.9696 - val_loss: 0.6563 - val_accuracy: 0.8361\n",
      "Epoch 3306/8000\n",
      "1463/1463 [==============================] - 9s 6ms/step - loss: 0.0837 - accuracy: 0.9711 - val_loss: 0.6911 - val_accuracy: 0.8290\n",
      "Epoch 3307/8000\n",
      "1463/1463 [==============================] - 9s 6ms/step - loss: 0.0791 - accuracy: 0.9726 - val_loss: 0.6729 - val_accuracy: 0.8367\n",
      "Epoch 3308/8000\n",
      "1463/1463 [==============================] - 9s 6ms/step - loss: 0.0822 - accuracy: 0.9723 - val_loss: 0.7783 - val_accuracy: 0.8212\n",
      "Epoch 3309/8000\n",
      "1463/1463 [==============================] - 9s 6ms/step - loss: 0.0823 - accuracy: 0.9723 - val_loss: 0.7603 - val_accuracy: 0.8196\n",
      "Epoch 3310/8000\n",
      "1463/1463 [==============================] - 10s 7ms/step - loss: 0.0816 - accuracy: 0.9712 - val_loss: 0.6623 - val_accuracy: 0.8367\n",
      "Epoch 3311/8000\n",
      "1463/1463 [==============================] - 9s 6ms/step - loss: 0.0855 - accuracy: 0.9718 - val_loss: 0.9413 - val_accuracy: 0.8152\n",
      "Epoch 3312/8000\n",
      "1463/1463 [==============================] - 10s 7ms/step - loss: 0.0760 - accuracy: 0.9744 - val_loss: 0.8090 - val_accuracy: 0.8107\n",
      "Epoch 3313/8000\n",
      "1463/1463 [==============================] - 10s 7ms/step - loss: 0.0870 - accuracy: 0.9709 - val_loss: 0.6623 - val_accuracy: 0.8363\n",
      "Epoch 3314/8000\n",
      "1463/1463 [==============================] - 10s 7ms/step - loss: 0.0839 - accuracy: 0.9714 - val_loss: 0.6867 - val_accuracy: 0.8312\n",
      "Epoch 3315/8000\n",
      "1463/1463 [==============================] - 10s 7ms/step - loss: 0.0814 - accuracy: 0.9716 - val_loss: 0.7279 - val_accuracy: 0.8237\n",
      "Epoch 3316/8000\n",
      "1463/1463 [==============================] - 10s 7ms/step - loss: 0.0781 - accuracy: 0.9736 - val_loss: 0.6900 - val_accuracy: 0.8302\n",
      "Epoch 3317/8000\n",
      "1463/1463 [==============================] - 10s 7ms/step - loss: 0.0815 - accuracy: 0.9722 - val_loss: 0.7210 - val_accuracy: 0.8235\n",
      "Epoch 3318/8000\n",
      "1463/1463 [==============================] - 10s 7ms/step - loss: 0.0769 - accuracy: 0.9729 - val_loss: 0.7381 - val_accuracy: 0.8191\n",
      "Epoch 3319/8000\n",
      "1463/1463 [==============================] - 10s 7ms/step - loss: 0.0819 - accuracy: 0.9719 - val_loss: 0.7038 - val_accuracy: 0.8281\n",
      "Epoch 3320/8000\n",
      "1463/1463 [==============================] - 10s 7ms/step - loss: 0.0837 - accuracy: 0.9707 - val_loss: 0.7152 - val_accuracy: 0.8282\n",
      "Epoch 3321/8000\n",
      "1463/1463 [==============================] - 10s 7ms/step - loss: 0.0770 - accuracy: 0.9736 - val_loss: 0.7028 - val_accuracy: 0.8299\n",
      "Epoch 3322/8000\n",
      "1463/1463 [==============================] - 10s 7ms/step - loss: 0.0804 - accuracy: 0.9719 - val_loss: 0.6863 - val_accuracy: 0.8299\n",
      "Epoch 3323/8000\n",
      "1463/1463 [==============================] - 10s 7ms/step - loss: 0.0885 - accuracy: 0.9701 - val_loss: 0.6985 - val_accuracy: 0.8259\n",
      "Epoch 3324/8000\n",
      "1463/1463 [==============================] - 10s 7ms/step - loss: 0.0807 - accuracy: 0.9728 - val_loss: 0.6869 - val_accuracy: 0.8310\n",
      "Epoch 3325/8000\n",
      "1463/1463 [==============================] - 10s 7ms/step - loss: 0.0869 - accuracy: 0.9703 - val_loss: 0.7107 - val_accuracy: 0.8233\n",
      "Epoch 3326/8000\n",
      "1463/1463 [==============================] - 10s 7ms/step - loss: 0.0764 - accuracy: 0.9740 - val_loss: 0.7260 - val_accuracy: 0.8229\n",
      "Epoch 3327/8000\n",
      "1463/1463 [==============================] - 10s 7ms/step - loss: 0.0824 - accuracy: 0.9710 - val_loss: 0.7008 - val_accuracy: 0.8276\n",
      "Epoch 3328/8000\n",
      "1463/1463 [==============================] - 10s 7ms/step - loss: 0.0824 - accuracy: 0.9718 - val_loss: 0.7028 - val_accuracy: 0.8278\n",
      "Epoch 3329/8000\n",
      "1463/1463 [==============================] - 10s 7ms/step - loss: 0.0831 - accuracy: 0.9715 - val_loss: 0.6974 - val_accuracy: 0.8306\n",
      "Epoch 3330/8000\n",
      "1463/1463 [==============================] - 10s 7ms/step - loss: 0.0855 - accuracy: 0.9698 - val_loss: 0.7552 - val_accuracy: 0.8190\n",
      "Epoch 3331/8000\n",
      "1463/1463 [==============================] - 10s 7ms/step - loss: 0.0802 - accuracy: 0.9718 - val_loss: 0.6675 - val_accuracy: 0.8330\n",
      "Epoch 3332/8000\n",
      "1463/1463 [==============================] - 10s 7ms/step - loss: 0.0804 - accuracy: 0.9724 - val_loss: 0.6868 - val_accuracy: 0.8327\n",
      "Epoch 3333/8000\n",
      "1463/1463 [==============================] - 10s 7ms/step - loss: 0.0812 - accuracy: 0.9719 - val_loss: 0.7074 - val_accuracy: 0.8257\n",
      "Epoch 3334/8000\n",
      "1463/1463 [==============================] - 10s 7ms/step - loss: 0.0821 - accuracy: 0.9718 - val_loss: 0.7685 - val_accuracy: 0.8138\n",
      "Epoch 3335/8000\n",
      "1463/1463 [==============================] - 10s 7ms/step - loss: 0.0818 - accuracy: 0.9713 - val_loss: 0.6951 - val_accuracy: 0.8267\n",
      "Epoch 3336/8000\n",
      "1463/1463 [==============================] - 10s 7ms/step - loss: 0.0832 - accuracy: 0.9719 - val_loss: 0.6698 - val_accuracy: 0.8311\n",
      "Epoch 3337/8000\n",
      "1463/1463 [==============================] - 10s 7ms/step - loss: 0.0811 - accuracy: 0.9719 - val_loss: 0.6990 - val_accuracy: 0.8316\n",
      "Epoch 3338/8000\n",
      "1463/1463 [==============================] - 10s 7ms/step - loss: 0.0831 - accuracy: 0.9710 - val_loss: 0.7623 - val_accuracy: 0.8242\n",
      "Epoch 3339/8000\n",
      "1463/1463 [==============================] - 10s 7ms/step - loss: 0.0838 - accuracy: 0.9711 - val_loss: 0.6562 - val_accuracy: 0.8371\n",
      "Epoch 3340/8000\n",
      "1463/1463 [==============================] - 10s 7ms/step - loss: 0.0819 - accuracy: 0.9725 - val_loss: 0.7650 - val_accuracy: 0.8154\n",
      "Epoch 3341/8000\n",
      "1463/1463 [==============================] - 10s 7ms/step - loss: 0.0839 - accuracy: 0.9714 - val_loss: 0.7191 - val_accuracy: 0.8271\n",
      "Epoch 3342/8000\n",
      "1463/1463 [==============================] - 10s 7ms/step - loss: 0.0790 - accuracy: 0.9727 - val_loss: 0.6425 - val_accuracy: 0.8410\n",
      "Epoch 3343/8000\n",
      "1463/1463 [==============================] - 10s 7ms/step - loss: 0.0793 - accuracy: 0.9729 - val_loss: 0.6818 - val_accuracy: 0.8296\n",
      "Epoch 3344/8000\n",
      "1463/1463 [==============================] - 10s 7ms/step - loss: 0.0831 - accuracy: 0.9716 - val_loss: 0.7615 - val_accuracy: 0.8204\n",
      "Epoch 3345/8000\n",
      "1463/1463 [==============================] - 11s 7ms/step - loss: 0.0799 - accuracy: 0.9732 - val_loss: 0.7175 - val_accuracy: 0.8296\n",
      "Epoch 3346/8000\n",
      "1463/1463 [==============================] - 11s 7ms/step - loss: 0.0753 - accuracy: 0.9748 - val_loss: 0.6669 - val_accuracy: 0.8370\n",
      "Epoch 3347/8000\n",
      "1463/1463 [==============================] - 11s 7ms/step - loss: 0.0830 - accuracy: 0.9717 - val_loss: 0.6778 - val_accuracy: 0.8334\n",
      "Epoch 3348/8000\n",
      "1463/1463 [==============================] - 11s 7ms/step - loss: 0.0808 - accuracy: 0.9727 - val_loss: 0.6634 - val_accuracy: 0.8376\n",
      "Epoch 3349/8000\n",
      "1463/1463 [==============================] - 11s 7ms/step - loss: 0.0775 - accuracy: 0.9737 - val_loss: 0.7091 - val_accuracy: 0.8299\n",
      "Epoch 3350/8000\n",
      "1463/1463 [==============================] - 11s 7ms/step - loss: 0.0802 - accuracy: 0.9719 - val_loss: 0.7273 - val_accuracy: 0.8204\n",
      "Epoch 3351/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0817 - accuracy: 0.9723 - val_loss: 0.6601 - val_accuracy: 0.8347\n",
      "Epoch 3352/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0799 - accuracy: 0.9733 - val_loss: 0.6936 - val_accuracy: 0.8329\n",
      "Epoch 3353/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0776 - accuracy: 0.9733 - val_loss: 0.7450 - val_accuracy: 0.8204\n",
      "Epoch 3354/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0801 - accuracy: 0.9723 - val_loss: 0.6541 - val_accuracy: 0.8375\n",
      "Epoch 3355/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0815 - accuracy: 0.9719 - val_loss: 0.6912 - val_accuracy: 0.8282\n",
      "Epoch 3356/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0788 - accuracy: 0.9725 - val_loss: 0.7196 - val_accuracy: 0.8242\n",
      "Epoch 3357/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0829 - accuracy: 0.9717 - val_loss: 0.7207 - val_accuracy: 0.8286\n",
      "Epoch 3358/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0763 - accuracy: 0.9740 - val_loss: 0.7207 - val_accuracy: 0.8319\n",
      "Epoch 3359/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0832 - accuracy: 0.9710 - val_loss: 0.6647 - val_accuracy: 0.8366\n",
      "Epoch 3360/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0758 - accuracy: 0.9738 - val_loss: 0.7540 - val_accuracy: 0.8183\n",
      "Epoch 3361/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0810 - accuracy: 0.9722 - val_loss: 0.6905 - val_accuracy: 0.8327\n",
      "Epoch 3362/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0809 - accuracy: 0.9721 - val_loss: 0.7127 - val_accuracy: 0.8265\n",
      "Epoch 3363/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0802 - accuracy: 0.9726 - val_loss: 0.7275 - val_accuracy: 0.8271\n",
      "Epoch 3364/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0819 - accuracy: 0.9717 - val_loss: 0.7436 - val_accuracy: 0.8273\n",
      "Epoch 3365/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0810 - accuracy: 0.9723 - val_loss: 0.6709 - val_accuracy: 0.8345\n",
      "Epoch 3366/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0748 - accuracy: 0.9748 - val_loss: 0.6786 - val_accuracy: 0.8370\n",
      "Epoch 3367/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0767 - accuracy: 0.9734 - val_loss: 0.7076 - val_accuracy: 0.8267\n",
      "Epoch 3368/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0784 - accuracy: 0.9742 - val_loss: 0.6713 - val_accuracy: 0.8351\n",
      "Epoch 3369/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0803 - accuracy: 0.9727 - val_loss: 0.6721 - val_accuracy: 0.8321\n",
      "Epoch 3370/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0795 - accuracy: 0.9720 - val_loss: 0.7040 - val_accuracy: 0.8265\n",
      "Epoch 3371/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0839 - accuracy: 0.9711 - val_loss: 0.6978 - val_accuracy: 0.8272\n",
      "Epoch 3372/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0775 - accuracy: 0.9735 - val_loss: 0.6928 - val_accuracy: 0.8280\n",
      "Epoch 3373/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0850 - accuracy: 0.9708 - val_loss: 0.7355 - val_accuracy: 0.8247\n",
      "Epoch 3374/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0826 - accuracy: 0.9714 - val_loss: 0.6652 - val_accuracy: 0.8356\n",
      "Epoch 3375/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0824 - accuracy: 0.9720 - val_loss: 0.6922 - val_accuracy: 0.8282\n",
      "Epoch 3376/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0792 - accuracy: 0.9728 - val_loss: 0.7014 - val_accuracy: 0.8320\n",
      "Epoch 3377/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0780 - accuracy: 0.9731 - val_loss: 0.7011 - val_accuracy: 0.8254\n",
      "Epoch 3378/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0808 - accuracy: 0.9713 - val_loss: 0.7125 - val_accuracy: 0.8254\n",
      "Epoch 3379/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0847 - accuracy: 0.9707 - val_loss: 0.6939 - val_accuracy: 0.8262\n",
      "Epoch 3380/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0789 - accuracy: 0.9727 - val_loss: 0.7172 - val_accuracy: 0.8260\n",
      "Epoch 3381/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0796 - accuracy: 0.9726 - val_loss: 0.6947 - val_accuracy: 0.8318\n",
      "Epoch 3382/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0884 - accuracy: 0.9701 - val_loss: 0.6680 - val_accuracy: 0.8353\n",
      "Epoch 3383/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0783 - accuracy: 0.9729 - val_loss: 0.7284 - val_accuracy: 0.8269\n",
      "Epoch 3384/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0778 - accuracy: 0.9729 - val_loss: 0.6949 - val_accuracy: 0.8306\n",
      "Epoch 3385/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0797 - accuracy: 0.9721 - val_loss: 0.7396 - val_accuracy: 0.8197\n",
      "Epoch 3386/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0807 - accuracy: 0.9725 - val_loss: 0.7972 - val_accuracy: 0.8168\n",
      "Epoch 3387/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0814 - accuracy: 0.9719 - val_loss: 0.7020 - val_accuracy: 0.8311\n",
      "Epoch 3388/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0816 - accuracy: 0.9718 - val_loss: 0.8288 - val_accuracy: 0.8177\n",
      "Epoch 3389/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0821 - accuracy: 0.9720 - val_loss: 0.7010 - val_accuracy: 0.8325\n",
      "Epoch 3390/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0821 - accuracy: 0.9725 - val_loss: 0.7043 - val_accuracy: 0.8263\n",
      "Epoch 3391/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0810 - accuracy: 0.9722 - val_loss: 0.6563 - val_accuracy: 0.8355\n",
      "Epoch 3392/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0804 - accuracy: 0.9720 - val_loss: 0.6632 - val_accuracy: 0.8348\n",
      "Epoch 3393/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0802 - accuracy: 0.9724 - val_loss: 0.7414 - val_accuracy: 0.8229\n",
      "Epoch 3394/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0777 - accuracy: 0.9735 - val_loss: 0.7084 - val_accuracy: 0.8304\n",
      "Epoch 3395/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0831 - accuracy: 0.9717 - val_loss: 0.7733 - val_accuracy: 0.8150\n",
      "Epoch 3396/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0807 - accuracy: 0.9721 - val_loss: 0.7303 - val_accuracy: 0.8231\n",
      "Epoch 3397/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0782 - accuracy: 0.9733 - val_loss: 0.7665 - val_accuracy: 0.8216\n",
      "Epoch 3398/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0841 - accuracy: 0.9713 - val_loss: 0.6773 - val_accuracy: 0.8326\n",
      "Epoch 3399/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0824 - accuracy: 0.9720 - val_loss: 0.7102 - val_accuracy: 0.8283\n",
      "Epoch 3400/8000\n",
      "1459/1463 [============================>.] - ETA: 0s - loss: 0.0839 - accuracy: 0.9710\n",
      "Epoch 3400: saving model to ./training_ckpt_20240109205949_v8_240109_d10000_n4096_b64_e8000_c100_Adamax\\cp-000003400.ckpt\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0840 - accuracy: 0.9710 - val_loss: 0.6699 - val_accuracy: 0.8371\n",
      "Epoch 3401/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0795 - accuracy: 0.9726 - val_loss: 0.8040 - val_accuracy: 0.8224\n",
      "Epoch 3402/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0850 - accuracy: 0.9706 - val_loss: 0.8332 - val_accuracy: 0.8122\n",
      "Epoch 3403/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0788 - accuracy: 0.9734 - val_loss: 0.7213 - val_accuracy: 0.8224\n",
      "Epoch 3404/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0794 - accuracy: 0.9717 - val_loss: 0.7994 - val_accuracy: 0.8140\n",
      "Epoch 3405/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0786 - accuracy: 0.9730 - val_loss: 0.6830 - val_accuracy: 0.8347\n",
      "Epoch 3406/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0796 - accuracy: 0.9723 - val_loss: 0.7014 - val_accuracy: 0.8325\n",
      "Epoch 3407/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0733 - accuracy: 0.9748 - val_loss: 0.6700 - val_accuracy: 0.8352\n",
      "Epoch 3408/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0762 - accuracy: 0.9739 - val_loss: 0.7162 - val_accuracy: 0.8261\n",
      "Epoch 3409/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0804 - accuracy: 0.9721 - val_loss: 0.7175 - val_accuracy: 0.8253\n",
      "Epoch 3410/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0837 - accuracy: 0.9717 - val_loss: 0.7740 - val_accuracy: 0.8148\n",
      "Epoch 3411/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0828 - accuracy: 0.9716 - val_loss: 0.7437 - val_accuracy: 0.8227\n",
      "Epoch 3412/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0787 - accuracy: 0.9734 - val_loss: 0.7198 - val_accuracy: 0.8252\n",
      "Epoch 3413/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0913 - accuracy: 0.9688 - val_loss: 0.6899 - val_accuracy: 0.8306\n",
      "Epoch 3414/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0787 - accuracy: 0.9731 - val_loss: 0.7648 - val_accuracy: 0.8224\n",
      "Epoch 3415/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0774 - accuracy: 0.9736 - val_loss: 0.7055 - val_accuracy: 0.8255\n",
      "Epoch 3416/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0805 - accuracy: 0.9725 - val_loss: 0.7146 - val_accuracy: 0.8267\n",
      "Epoch 3417/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0770 - accuracy: 0.9735 - val_loss: 0.6939 - val_accuracy: 0.8288\n",
      "Epoch 3418/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0803 - accuracy: 0.9719 - val_loss: 0.6853 - val_accuracy: 0.8323\n",
      "Epoch 3419/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0817 - accuracy: 0.9726 - val_loss: 0.6816 - val_accuracy: 0.8347\n",
      "Epoch 3420/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0807 - accuracy: 0.9724 - val_loss: 0.7354 - val_accuracy: 0.8298\n",
      "Epoch 3421/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0811 - accuracy: 0.9720 - val_loss: 0.6969 - val_accuracy: 0.8296\n",
      "Epoch 3422/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0766 - accuracy: 0.9736 - val_loss: 0.7144 - val_accuracy: 0.8301\n",
      "Epoch 3423/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0768 - accuracy: 0.9724 - val_loss: 0.6724 - val_accuracy: 0.8331\n",
      "Epoch 3424/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0820 - accuracy: 0.9723 - val_loss: 0.7099 - val_accuracy: 0.8273\n",
      "Epoch 3425/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0789 - accuracy: 0.9723 - val_loss: 0.7787 - val_accuracy: 0.8222\n",
      "Epoch 3426/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0780 - accuracy: 0.9737 - val_loss: 0.7052 - val_accuracy: 0.8316\n",
      "Epoch 3427/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0761 - accuracy: 0.9736 - val_loss: 0.7227 - val_accuracy: 0.8270\n",
      "Epoch 3428/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0833 - accuracy: 0.9713 - val_loss: 0.6992 - val_accuracy: 0.8317\n",
      "Epoch 3429/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0769 - accuracy: 0.9738 - val_loss: 0.7089 - val_accuracy: 0.8273\n",
      "Epoch 3430/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0815 - accuracy: 0.9724 - val_loss: 0.7019 - val_accuracy: 0.8305\n",
      "Epoch 3431/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0804 - accuracy: 0.9727 - val_loss: 0.6856 - val_accuracy: 0.8329\n",
      "Epoch 3432/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0819 - accuracy: 0.9726 - val_loss: 0.7062 - val_accuracy: 0.8297\n",
      "Epoch 3433/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0812 - accuracy: 0.9726 - val_loss: 0.6881 - val_accuracy: 0.8309\n",
      "Epoch 3434/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0792 - accuracy: 0.9732 - val_loss: 0.7025 - val_accuracy: 0.8309\n",
      "Epoch 3435/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0810 - accuracy: 0.9726 - val_loss: 0.6707 - val_accuracy: 0.8348\n",
      "Epoch 3436/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0757 - accuracy: 0.9737 - val_loss: 0.7520 - val_accuracy: 0.8210\n",
      "Epoch 3437/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0782 - accuracy: 0.9731 - val_loss: 0.6939 - val_accuracy: 0.8321\n",
      "Epoch 3438/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0785 - accuracy: 0.9729 - val_loss: 0.6981 - val_accuracy: 0.8285\n",
      "Epoch 3439/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0801 - accuracy: 0.9728 - val_loss: 0.6976 - val_accuracy: 0.8320\n",
      "Epoch 3440/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0814 - accuracy: 0.9721 - val_loss: 0.6785 - val_accuracy: 0.8337\n",
      "Epoch 3441/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0798 - accuracy: 0.9727 - val_loss: 0.7685 - val_accuracy: 0.8219\n",
      "Epoch 3442/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0819 - accuracy: 0.9721 - val_loss: 0.6730 - val_accuracy: 0.8333\n",
      "Epoch 3443/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0822 - accuracy: 0.9719 - val_loss: 0.7196 - val_accuracy: 0.8273\n",
      "Epoch 3444/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0759 - accuracy: 0.9735 - val_loss: 0.7101 - val_accuracy: 0.8299\n",
      "Epoch 3445/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0791 - accuracy: 0.9735 - val_loss: 0.7366 - val_accuracy: 0.8233\n",
      "Epoch 3446/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0847 - accuracy: 0.9718 - val_loss: 0.7209 - val_accuracy: 0.8278\n",
      "Epoch 3447/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0785 - accuracy: 0.9727 - val_loss: 0.7007 - val_accuracy: 0.8297\n",
      "Epoch 3448/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0791 - accuracy: 0.9731 - val_loss: 0.6806 - val_accuracy: 0.8324\n",
      "Epoch 3449/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0809 - accuracy: 0.9716 - val_loss: 0.6728 - val_accuracy: 0.8348\n",
      "Epoch 3450/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0800 - accuracy: 0.9724 - val_loss: 0.7284 - val_accuracy: 0.8235\n",
      "Epoch 3451/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0875 - accuracy: 0.9704 - val_loss: 0.6874 - val_accuracy: 0.8357\n",
      "Epoch 3452/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0774 - accuracy: 0.9737 - val_loss: 0.6988 - val_accuracy: 0.8311\n",
      "Epoch 3453/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0775 - accuracy: 0.9734 - val_loss: 0.7114 - val_accuracy: 0.8254\n",
      "Epoch 3454/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0820 - accuracy: 0.9720 - val_loss: 0.7758 - val_accuracy: 0.8176\n",
      "Epoch 3455/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0765 - accuracy: 0.9734 - val_loss: 0.6908 - val_accuracy: 0.8363\n",
      "Epoch 3456/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0807 - accuracy: 0.9726 - val_loss: 0.6926 - val_accuracy: 0.8338\n",
      "Epoch 3457/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0786 - accuracy: 0.9730 - val_loss: 0.7776 - val_accuracy: 0.8178\n",
      "Epoch 3458/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0789 - accuracy: 0.9734 - val_loss: 0.7029 - val_accuracy: 0.8295\n",
      "Epoch 3459/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0744 - accuracy: 0.9744 - val_loss: 0.7701 - val_accuracy: 0.8220\n",
      "Epoch 3460/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0779 - accuracy: 0.9734 - val_loss: 0.6690 - val_accuracy: 0.8377\n",
      "Epoch 3461/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0775 - accuracy: 0.9732 - val_loss: 0.6425 - val_accuracy: 0.8437\n",
      "Epoch 3462/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0806 - accuracy: 0.9720 - val_loss: 0.6840 - val_accuracy: 0.8346\n",
      "Epoch 3463/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0820 - accuracy: 0.9720 - val_loss: 0.7606 - val_accuracy: 0.8224\n",
      "Epoch 3464/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0836 - accuracy: 0.9714 - val_loss: 0.7267 - val_accuracy: 0.8227\n",
      "Epoch 3465/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0761 - accuracy: 0.9744 - val_loss: 0.7954 - val_accuracy: 0.8220\n",
      "Epoch 3466/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0748 - accuracy: 0.9741 - val_loss: 0.6957 - val_accuracy: 0.8290\n",
      "Epoch 3467/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0769 - accuracy: 0.9743 - val_loss: 0.8044 - val_accuracy: 0.8201\n",
      "Epoch 3468/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0802 - accuracy: 0.9721 - val_loss: 0.6779 - val_accuracy: 0.8333\n",
      "Epoch 3469/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0827 - accuracy: 0.9723 - val_loss: 0.7920 - val_accuracy: 0.8119\n",
      "Epoch 3470/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0729 - accuracy: 0.9747 - val_loss: 0.7172 - val_accuracy: 0.8328\n",
      "Epoch 3471/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0839 - accuracy: 0.9710 - val_loss: 0.6927 - val_accuracy: 0.8295\n",
      "Epoch 3472/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0759 - accuracy: 0.9738 - val_loss: 0.6848 - val_accuracy: 0.8340\n",
      "Epoch 3473/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0744 - accuracy: 0.9737 - val_loss: 0.7166 - val_accuracy: 0.8266\n",
      "Epoch 3474/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0785 - accuracy: 0.9730 - val_loss: 0.6821 - val_accuracy: 0.8387\n",
      "Epoch 3475/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0777 - accuracy: 0.9726 - val_loss: 0.6753 - val_accuracy: 0.8358\n",
      "Epoch 3476/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0709 - accuracy: 0.9754 - val_loss: 0.6685 - val_accuracy: 0.8367\n",
      "Epoch 3477/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0813 - accuracy: 0.9726 - val_loss: 0.7585 - val_accuracy: 0.8254\n",
      "Epoch 3478/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0831 - accuracy: 0.9717 - val_loss: 0.7207 - val_accuracy: 0.8277\n",
      "Epoch 3479/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0764 - accuracy: 0.9739 - val_loss: 0.7960 - val_accuracy: 0.8096\n",
      "Epoch 3480/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0832 - accuracy: 0.9713 - val_loss: 0.7226 - val_accuracy: 0.8266\n",
      "Epoch 3481/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0770 - accuracy: 0.9735 - val_loss: 0.6746 - val_accuracy: 0.8323\n",
      "Epoch 3482/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0806 - accuracy: 0.9729 - val_loss: 0.7530 - val_accuracy: 0.8213\n",
      "Epoch 3483/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0835 - accuracy: 0.9720 - val_loss: 0.7069 - val_accuracy: 0.8246\n",
      "Epoch 3484/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0799 - accuracy: 0.9728 - val_loss: 0.7043 - val_accuracy: 0.8288\n",
      "Epoch 3485/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0776 - accuracy: 0.9736 - val_loss: 0.6943 - val_accuracy: 0.8310\n",
      "Epoch 3486/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0798 - accuracy: 0.9726 - val_loss: 0.7285 - val_accuracy: 0.8221\n",
      "Epoch 3487/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0793 - accuracy: 0.9732 - val_loss: 0.7105 - val_accuracy: 0.8250\n",
      "Epoch 3488/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0792 - accuracy: 0.9727 - val_loss: 0.6717 - val_accuracy: 0.8389\n",
      "Epoch 3489/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0776 - accuracy: 0.9740 - val_loss: 0.6896 - val_accuracy: 0.8350\n",
      "Epoch 3490/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0767 - accuracy: 0.9735 - val_loss: 0.7143 - val_accuracy: 0.8261\n",
      "Epoch 3491/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0852 - accuracy: 0.9724 - val_loss: 0.7237 - val_accuracy: 0.8257\n",
      "Epoch 3492/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0769 - accuracy: 0.9737 - val_loss: 0.6885 - val_accuracy: 0.8348\n",
      "Epoch 3493/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0846 - accuracy: 0.9711 - val_loss: 0.7202 - val_accuracy: 0.8241\n",
      "Epoch 3494/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0762 - accuracy: 0.9737 - val_loss: 0.6957 - val_accuracy: 0.8309\n",
      "Epoch 3495/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0727 - accuracy: 0.9753 - val_loss: 0.6415 - val_accuracy: 0.8412\n",
      "Epoch 3496/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0815 - accuracy: 0.9720 - val_loss: 0.7091 - val_accuracy: 0.8319\n",
      "Epoch 3497/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0806 - accuracy: 0.9726 - val_loss: 0.7010 - val_accuracy: 0.8315\n",
      "Epoch 3498/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0802 - accuracy: 0.9724 - val_loss: 0.7094 - val_accuracy: 0.8284\n",
      "Epoch 3499/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0760 - accuracy: 0.9736 - val_loss: 0.6747 - val_accuracy: 0.8380\n",
      "Epoch 3500/8000\n",
      "1457/1463 [============================>.] - ETA: 0s - loss: 0.0811 - accuracy: 0.9714\n",
      "Epoch 3500: saving model to ./training_ckpt_20240109205949_v8_240109_d10000_n4096_b64_e8000_c100_Adamax\\cp-000003500.ckpt\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0812 - accuracy: 0.9714 - val_loss: 0.7075 - val_accuracy: 0.8304\n",
      "Epoch 3501/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0823 - accuracy: 0.9722 - val_loss: 0.7536 - val_accuracy: 0.8234\n",
      "Epoch 3502/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0759 - accuracy: 0.9738 - val_loss: 0.6853 - val_accuracy: 0.8316\n",
      "Epoch 3503/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0783 - accuracy: 0.9726 - val_loss: 0.7114 - val_accuracy: 0.8300\n",
      "Epoch 3504/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0785 - accuracy: 0.9732 - val_loss: 0.7532 - val_accuracy: 0.8195\n",
      "Epoch 3505/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0806 - accuracy: 0.9721 - val_loss: 0.7137 - val_accuracy: 0.8310\n",
      "Epoch 3506/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0784 - accuracy: 0.9730 - val_loss: 0.7170 - val_accuracy: 0.8240\n",
      "Epoch 3507/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0788 - accuracy: 0.9725 - val_loss: 0.6741 - val_accuracy: 0.8345\n",
      "Epoch 3508/8000\n",
      "1463/1463 [==============================] - 12s 9ms/step - loss: 0.0775 - accuracy: 0.9735 - val_loss: 0.7005 - val_accuracy: 0.8291\n",
      "Epoch 3509/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0806 - accuracy: 0.9717 - val_loss: 0.6650 - val_accuracy: 0.8366\n",
      "Epoch 3510/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0701 - accuracy: 0.9757 - val_loss: 0.7110 - val_accuracy: 0.8280\n",
      "Epoch 3511/8000\n",
      "1463/1463 [==============================] - 12s 9ms/step - loss: 0.0813 - accuracy: 0.9725 - val_loss: 0.7305 - val_accuracy: 0.8279\n",
      "Epoch 3512/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0763 - accuracy: 0.9733 - val_loss: 0.8197 - val_accuracy: 0.8198\n",
      "Epoch 3513/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0800 - accuracy: 0.9723 - val_loss: 0.7176 - val_accuracy: 0.8299\n",
      "Epoch 3514/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0763 - accuracy: 0.9743 - val_loss: 0.6585 - val_accuracy: 0.8398\n",
      "Epoch 3515/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0818 - accuracy: 0.9718 - val_loss: 0.6659 - val_accuracy: 0.8380\n",
      "Epoch 3516/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0779 - accuracy: 0.9738 - val_loss: 0.6964 - val_accuracy: 0.8314\n",
      "Epoch 3517/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0788 - accuracy: 0.9737 - val_loss: 0.7090 - val_accuracy: 0.8287\n",
      "Epoch 3518/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0772 - accuracy: 0.9730 - val_loss: 0.7800 - val_accuracy: 0.8254\n",
      "Epoch 3519/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0762 - accuracy: 0.9740 - val_loss: 0.7677 - val_accuracy: 0.8230\n",
      "Epoch 3520/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0819 - accuracy: 0.9728 - val_loss: 0.7443 - val_accuracy: 0.8235\n",
      "Epoch 3521/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0727 - accuracy: 0.9752 - val_loss: 0.7823 - val_accuracy: 0.8208\n",
      "Epoch 3522/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0817 - accuracy: 0.9722 - val_loss: 0.7304 - val_accuracy: 0.8239\n",
      "Epoch 3523/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0762 - accuracy: 0.9737 - val_loss: 0.6973 - val_accuracy: 0.8300\n",
      "Epoch 3524/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0786 - accuracy: 0.9728 - val_loss: 0.7119 - val_accuracy: 0.8288\n",
      "Epoch 3525/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0778 - accuracy: 0.9731 - val_loss: 0.7067 - val_accuracy: 0.8292\n",
      "Epoch 3526/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0798 - accuracy: 0.9723 - val_loss: 0.6884 - val_accuracy: 0.8355\n",
      "Epoch 3527/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0813 - accuracy: 0.9718 - val_loss: 0.6819 - val_accuracy: 0.8360\n",
      "Epoch 3528/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0715 - accuracy: 0.9759 - val_loss: 0.6896 - val_accuracy: 0.8328\n",
      "Epoch 3529/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0764 - accuracy: 0.9736 - val_loss: 0.6984 - val_accuracy: 0.8308\n",
      "Epoch 3530/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0775 - accuracy: 0.9740 - val_loss: 0.6887 - val_accuracy: 0.8313\n",
      "Epoch 3531/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0783 - accuracy: 0.9735 - val_loss: 0.7092 - val_accuracy: 0.8310\n",
      "Epoch 3532/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0790 - accuracy: 0.9726 - val_loss: 0.6821 - val_accuracy: 0.8366\n",
      "Epoch 3533/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0826 - accuracy: 0.9724 - val_loss: 0.6996 - val_accuracy: 0.8302\n",
      "Epoch 3534/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0768 - accuracy: 0.9736 - val_loss: 0.7277 - val_accuracy: 0.8279\n",
      "Epoch 3535/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0793 - accuracy: 0.9728 - val_loss: 0.6887 - val_accuracy: 0.8333\n",
      "Epoch 3536/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0815 - accuracy: 0.9726 - val_loss: 0.7513 - val_accuracy: 0.8263\n",
      "Epoch 3537/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0767 - accuracy: 0.9734 - val_loss: 0.7224 - val_accuracy: 0.8310\n",
      "Epoch 3538/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0815 - accuracy: 0.9716 - val_loss: 0.6998 - val_accuracy: 0.8339\n",
      "Epoch 3539/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0776 - accuracy: 0.9736 - val_loss: 0.6695 - val_accuracy: 0.8393\n",
      "Epoch 3540/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0728 - accuracy: 0.9756 - val_loss: 0.6736 - val_accuracy: 0.8363\n",
      "Epoch 3541/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0781 - accuracy: 0.9732 - val_loss: 0.6795 - val_accuracy: 0.8353\n",
      "Epoch 3542/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0760 - accuracy: 0.9739 - val_loss: 0.7103 - val_accuracy: 0.8290\n",
      "Epoch 3543/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0779 - accuracy: 0.9731 - val_loss: 0.7777 - val_accuracy: 0.8177\n",
      "Epoch 3544/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0756 - accuracy: 0.9751 - val_loss: 0.6743 - val_accuracy: 0.8396\n",
      "Epoch 3545/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0802 - accuracy: 0.9732 - val_loss: 0.7157 - val_accuracy: 0.8265\n",
      "Epoch 3546/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0777 - accuracy: 0.9736 - val_loss: 0.7095 - val_accuracy: 0.8310\n",
      "Epoch 3547/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0763 - accuracy: 0.9737 - val_loss: 0.6796 - val_accuracy: 0.8337\n",
      "Epoch 3548/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0801 - accuracy: 0.9736 - val_loss: 0.6884 - val_accuracy: 0.8341\n",
      "Epoch 3549/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0751 - accuracy: 0.9739 - val_loss: 0.6881 - val_accuracy: 0.8343\n",
      "Epoch 3550/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0783 - accuracy: 0.9733 - val_loss: 0.7398 - val_accuracy: 0.8273\n",
      "Epoch 3551/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0836 - accuracy: 0.9709 - val_loss: 0.7408 - val_accuracy: 0.8248\n",
      "Epoch 3552/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0778 - accuracy: 0.9738 - val_loss: 0.7445 - val_accuracy: 0.8245\n",
      "Epoch 3553/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0786 - accuracy: 0.9724 - val_loss: 0.6851 - val_accuracy: 0.8338\n",
      "Epoch 3554/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0796 - accuracy: 0.9730 - val_loss: 0.6751 - val_accuracy: 0.8334\n",
      "Epoch 3555/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0750 - accuracy: 0.9741 - val_loss: 0.7660 - val_accuracy: 0.8177\n",
      "Epoch 3556/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0740 - accuracy: 0.9754 - val_loss: 0.7974 - val_accuracy: 0.8241\n",
      "Epoch 3557/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0724 - accuracy: 0.9749 - val_loss: 0.7386 - val_accuracy: 0.8284\n",
      "Epoch 3558/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0704 - accuracy: 0.9762 - val_loss: 0.6974 - val_accuracy: 0.8315\n",
      "Epoch 3559/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0766 - accuracy: 0.9738 - val_loss: 0.7380 - val_accuracy: 0.8235\n",
      "Epoch 3560/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0757 - accuracy: 0.9737 - val_loss: 0.7599 - val_accuracy: 0.8243\n",
      "Epoch 3561/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0800 - accuracy: 0.9732 - val_loss: 0.7020 - val_accuracy: 0.8326\n",
      "Epoch 3562/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0811 - accuracy: 0.9730 - val_loss: 0.7694 - val_accuracy: 0.8238\n",
      "Epoch 3563/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0853 - accuracy: 0.9723 - val_loss: 0.6589 - val_accuracy: 0.8363\n",
      "Epoch 3564/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0714 - accuracy: 0.9756 - val_loss: 0.6669 - val_accuracy: 0.8376\n",
      "Epoch 3565/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0778 - accuracy: 0.9738 - val_loss: 0.7576 - val_accuracy: 0.8237\n",
      "Epoch 3566/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0763 - accuracy: 0.9741 - val_loss: 0.7142 - val_accuracy: 0.8297\n",
      "Epoch 3567/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0809 - accuracy: 0.9729 - val_loss: 0.6980 - val_accuracy: 0.8340\n",
      "Epoch 3568/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0753 - accuracy: 0.9739 - val_loss: 0.6713 - val_accuracy: 0.8390\n",
      "Epoch 3569/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0845 - accuracy: 0.9716 - val_loss: 0.6999 - val_accuracy: 0.8309\n",
      "Epoch 3570/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0736 - accuracy: 0.9752 - val_loss: 0.6975 - val_accuracy: 0.8301\n",
      "Epoch 3571/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0699 - accuracy: 0.9759 - val_loss: 0.6938 - val_accuracy: 0.8309\n",
      "Epoch 3572/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0786 - accuracy: 0.9730 - val_loss: 0.7016 - val_accuracy: 0.8307\n",
      "Epoch 3573/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0797 - accuracy: 0.9734 - val_loss: 0.6975 - val_accuracy: 0.8371\n",
      "Epoch 3574/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0741 - accuracy: 0.9746 - val_loss: 0.8027 - val_accuracy: 0.8232\n",
      "Epoch 3575/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0790 - accuracy: 0.9733 - val_loss: 0.7319 - val_accuracy: 0.8296\n",
      "Epoch 3576/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0759 - accuracy: 0.9740 - val_loss: 0.6945 - val_accuracy: 0.8329\n",
      "Epoch 3577/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0772 - accuracy: 0.9731 - val_loss: 0.6677 - val_accuracy: 0.8378\n",
      "Epoch 3578/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0739 - accuracy: 0.9746 - val_loss: 0.6711 - val_accuracy: 0.8387\n",
      "Epoch 3579/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0761 - accuracy: 0.9745 - val_loss: 0.7468 - val_accuracy: 0.8239\n",
      "Epoch 3580/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0813 - accuracy: 0.9725 - val_loss: 0.7662 - val_accuracy: 0.8223\n",
      "Epoch 3581/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0812 - accuracy: 0.9719 - val_loss: 0.7519 - val_accuracy: 0.8264\n",
      "Epoch 3582/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0814 - accuracy: 0.9728 - val_loss: 0.6491 - val_accuracy: 0.8403\n",
      "Epoch 3583/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0758 - accuracy: 0.9738 - val_loss: 0.6875 - val_accuracy: 0.8317\n",
      "Epoch 3584/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0769 - accuracy: 0.9738 - val_loss: 0.6791 - val_accuracy: 0.8338\n",
      "Epoch 3585/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0768 - accuracy: 0.9741 - val_loss: 0.7164 - val_accuracy: 0.8314\n",
      "Epoch 3586/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0839 - accuracy: 0.9718 - val_loss: 0.7271 - val_accuracy: 0.8269\n",
      "Epoch 3587/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0726 - accuracy: 0.9749 - val_loss: 0.7309 - val_accuracy: 0.8273\n",
      "Epoch 3588/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0782 - accuracy: 0.9740 - val_loss: 0.6851 - val_accuracy: 0.8329\n",
      "Epoch 3589/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0764 - accuracy: 0.9736 - val_loss: 0.6952 - val_accuracy: 0.8342\n",
      "Epoch 3590/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0771 - accuracy: 0.9739 - val_loss: 0.7636 - val_accuracy: 0.8239\n",
      "Epoch 3591/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0745 - accuracy: 0.9749 - val_loss: 0.6471 - val_accuracy: 0.8421\n",
      "Epoch 3592/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0802 - accuracy: 0.9727 - val_loss: 0.7537 - val_accuracy: 0.8255\n",
      "Epoch 3593/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0782 - accuracy: 0.9729 - val_loss: 0.7188 - val_accuracy: 0.8265\n",
      "Epoch 3594/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0766 - accuracy: 0.9738 - val_loss: 0.6575 - val_accuracy: 0.8405\n",
      "Epoch 3595/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0807 - accuracy: 0.9728 - val_loss: 0.7238 - val_accuracy: 0.8270\n",
      "Epoch 3596/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0709 - accuracy: 0.9754 - val_loss: 0.7408 - val_accuracy: 0.8271\n",
      "Epoch 3597/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0798 - accuracy: 0.9733 - val_loss: 0.6938 - val_accuracy: 0.8320\n",
      "Epoch 3598/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0754 - accuracy: 0.9744 - val_loss: 0.6815 - val_accuracy: 0.8372\n",
      "Epoch 3599/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0793 - accuracy: 0.9731 - val_loss: 0.6897 - val_accuracy: 0.8339\n",
      "Epoch 3600/8000\n",
      "1461/1463 [============================>.] - ETA: 0s - loss: 0.0759 - accuracy: 0.9741\n",
      "Epoch 3600: saving model to ./training_ckpt_20240109205949_v8_240109_d10000_n4096_b64_e8000_c100_Adamax\\cp-000003600.ckpt\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0759 - accuracy: 0.9741 - val_loss: 0.6843 - val_accuracy: 0.8385\n",
      "Epoch 3601/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0746 - accuracy: 0.9747 - val_loss: 0.6631 - val_accuracy: 0.8405\n",
      "Epoch 3602/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0742 - accuracy: 0.9745 - val_loss: 0.6747 - val_accuracy: 0.8371\n",
      "Epoch 3603/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0778 - accuracy: 0.9740 - val_loss: 0.7271 - val_accuracy: 0.8275\n",
      "Epoch 3604/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0749 - accuracy: 0.9738 - val_loss: 0.7252 - val_accuracy: 0.8266\n",
      "Epoch 3605/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0749 - accuracy: 0.9742 - val_loss: 0.6932 - val_accuracy: 0.8314\n",
      "Epoch 3606/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0786 - accuracy: 0.9733 - val_loss: 0.7094 - val_accuracy: 0.8275\n",
      "Epoch 3607/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0756 - accuracy: 0.9742 - val_loss: 0.7155 - val_accuracy: 0.8263\n",
      "Epoch 3608/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0783 - accuracy: 0.9737 - val_loss: 0.7128 - val_accuracy: 0.8335\n",
      "Epoch 3609/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0754 - accuracy: 0.9742 - val_loss: 0.6719 - val_accuracy: 0.8384\n",
      "Epoch 3610/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0777 - accuracy: 0.9742 - val_loss: 0.6826 - val_accuracy: 0.8384\n",
      "Epoch 3611/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0774 - accuracy: 0.9740 - val_loss: 0.8299 - val_accuracy: 0.8182\n",
      "Epoch 3612/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0774 - accuracy: 0.9740 - val_loss: 0.7084 - val_accuracy: 0.8307\n",
      "Epoch 3613/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0760 - accuracy: 0.9734 - val_loss: 0.7228 - val_accuracy: 0.8313\n",
      "Epoch 3614/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0757 - accuracy: 0.9742 - val_loss: 0.7891 - val_accuracy: 0.8232\n",
      "Epoch 3615/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0781 - accuracy: 0.9732 - val_loss: 0.6704 - val_accuracy: 0.8363\n",
      "Epoch 3616/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0763 - accuracy: 0.9745 - val_loss: 0.7646 - val_accuracy: 0.8190\n",
      "Epoch 3617/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0761 - accuracy: 0.9745 - val_loss: 0.7116 - val_accuracy: 0.8297\n",
      "Epoch 3618/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0750 - accuracy: 0.9744 - val_loss: 0.7313 - val_accuracy: 0.8275\n",
      "Epoch 3619/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0790 - accuracy: 0.9734 - val_loss: 0.6863 - val_accuracy: 0.8364\n",
      "Epoch 3620/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0739 - accuracy: 0.9749 - val_loss: 0.6617 - val_accuracy: 0.8411\n",
      "Epoch 3621/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0748 - accuracy: 0.9743 - val_loss: 0.7111 - val_accuracy: 0.8352\n",
      "Epoch 3622/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0793 - accuracy: 0.9731 - val_loss: 0.6959 - val_accuracy: 0.8326\n",
      "Epoch 3623/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0700 - accuracy: 0.9765 - val_loss: 0.6985 - val_accuracy: 0.8298\n",
      "Epoch 3624/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0799 - accuracy: 0.9730 - val_loss: 0.7101 - val_accuracy: 0.8283\n",
      "Epoch 3625/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0750 - accuracy: 0.9738 - val_loss: 0.7742 - val_accuracy: 0.8238\n",
      "Epoch 3626/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0793 - accuracy: 0.9727 - val_loss: 0.8260 - val_accuracy: 0.8189\n",
      "Epoch 3627/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0761 - accuracy: 0.9748 - val_loss: 0.7203 - val_accuracy: 0.8307\n",
      "Epoch 3628/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0797 - accuracy: 0.9736 - val_loss: 0.7261 - val_accuracy: 0.8288\n",
      "Epoch 3629/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0721 - accuracy: 0.9756 - val_loss: 0.7054 - val_accuracy: 0.8328\n",
      "Epoch 3630/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0807 - accuracy: 0.9724 - val_loss: 0.6958 - val_accuracy: 0.8305\n",
      "Epoch 3631/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0745 - accuracy: 0.9747 - val_loss: 0.7382 - val_accuracy: 0.8263\n",
      "Epoch 3632/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0766 - accuracy: 0.9737 - val_loss: 0.6915 - val_accuracy: 0.8340\n",
      "Epoch 3633/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0726 - accuracy: 0.9753 - val_loss: 0.6687 - val_accuracy: 0.8395\n",
      "Epoch 3634/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0742 - accuracy: 0.9748 - val_loss: 0.7243 - val_accuracy: 0.8265\n",
      "Epoch 3635/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0734 - accuracy: 0.9751 - val_loss: 0.7076 - val_accuracy: 0.8331\n",
      "Epoch 3636/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0778 - accuracy: 0.9739 - val_loss: 0.7676 - val_accuracy: 0.8288\n",
      "Epoch 3637/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0792 - accuracy: 0.9741 - val_loss: 0.7555 - val_accuracy: 0.8235\n",
      "Epoch 3638/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0775 - accuracy: 0.9730 - val_loss: 0.7582 - val_accuracy: 0.8199\n",
      "Epoch 3639/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0705 - accuracy: 0.9764 - val_loss: 0.6892 - val_accuracy: 0.8343\n",
      "Epoch 3640/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0771 - accuracy: 0.9733 - val_loss: 0.6984 - val_accuracy: 0.8376\n",
      "Epoch 3641/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0734 - accuracy: 0.9745 - val_loss: 0.6812 - val_accuracy: 0.8349\n",
      "Epoch 3642/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0793 - accuracy: 0.9728 - val_loss: 0.6577 - val_accuracy: 0.8439\n",
      "Epoch 3643/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0735 - accuracy: 0.9744 - val_loss: 0.7077 - val_accuracy: 0.8293\n",
      "Epoch 3644/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0810 - accuracy: 0.9728 - val_loss: 0.6866 - val_accuracy: 0.8353\n",
      "Epoch 3645/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0736 - accuracy: 0.9748 - val_loss: 0.7137 - val_accuracy: 0.8288\n",
      "Epoch 3646/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0697 - accuracy: 0.9760 - val_loss: 0.6917 - val_accuracy: 0.8343\n",
      "Epoch 3647/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0772 - accuracy: 0.9737 - val_loss: 0.6921 - val_accuracy: 0.8358\n",
      "Epoch 3648/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0724 - accuracy: 0.9750 - val_loss: 0.6803 - val_accuracy: 0.8374\n",
      "Epoch 3649/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0758 - accuracy: 0.9740 - val_loss: 0.6910 - val_accuracy: 0.8346\n",
      "Epoch 3650/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0773 - accuracy: 0.9737 - val_loss: 0.6746 - val_accuracy: 0.8359\n",
      "Epoch 3651/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0738 - accuracy: 0.9746 - val_loss: 0.6896 - val_accuracy: 0.8330\n",
      "Epoch 3652/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0753 - accuracy: 0.9739 - val_loss: 0.6592 - val_accuracy: 0.8423\n",
      "Epoch 3653/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0767 - accuracy: 0.9739 - val_loss: 0.6668 - val_accuracy: 0.8412\n",
      "Epoch 3654/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0744 - accuracy: 0.9743 - val_loss: 0.6846 - val_accuracy: 0.8379\n",
      "Epoch 3655/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0794 - accuracy: 0.9731 - val_loss: 0.7562 - val_accuracy: 0.8251\n",
      "Epoch 3656/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0745 - accuracy: 0.9749 - val_loss: 0.7658 - val_accuracy: 0.8243\n",
      "Epoch 3657/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0777 - accuracy: 0.9738 - val_loss: 0.6982 - val_accuracy: 0.8322\n",
      "Epoch 3658/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0815 - accuracy: 0.9724 - val_loss: 0.6977 - val_accuracy: 0.8339\n",
      "Epoch 3659/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0794 - accuracy: 0.9737 - val_loss: 0.6544 - val_accuracy: 0.8438\n",
      "Epoch 3660/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0772 - accuracy: 0.9734 - val_loss: 0.7284 - val_accuracy: 0.8277\n",
      "Epoch 3661/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0737 - accuracy: 0.9746 - val_loss: 0.7482 - val_accuracy: 0.8252\n",
      "Epoch 3662/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0726 - accuracy: 0.9750 - val_loss: 0.6790 - val_accuracy: 0.8367\n",
      "Epoch 3663/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0730 - accuracy: 0.9752 - val_loss: 0.6962 - val_accuracy: 0.8351\n",
      "Epoch 3664/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0763 - accuracy: 0.9739 - val_loss: 0.7284 - val_accuracy: 0.8246\n",
      "Epoch 3665/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0738 - accuracy: 0.9745 - val_loss: 0.7312 - val_accuracy: 0.8317\n",
      "Epoch 3666/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0743 - accuracy: 0.9745 - val_loss: 0.6768 - val_accuracy: 0.8383\n",
      "Epoch 3667/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0796 - accuracy: 0.9726 - val_loss: 0.7864 - val_accuracy: 0.8144\n",
      "Epoch 3668/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0741 - accuracy: 0.9749 - val_loss: 0.6537 - val_accuracy: 0.8405\n",
      "Epoch 3669/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0776 - accuracy: 0.9730 - val_loss: 0.7080 - val_accuracy: 0.8306\n",
      "Epoch 3670/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0802 - accuracy: 0.9726 - val_loss: 0.7334 - val_accuracy: 0.8273\n",
      "Epoch 3671/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0729 - accuracy: 0.9755 - val_loss: 0.7282 - val_accuracy: 0.8278\n",
      "Epoch 3672/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0807 - accuracy: 0.9731 - val_loss: 0.7078 - val_accuracy: 0.8340\n",
      "Epoch 3673/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0730 - accuracy: 0.9750 - val_loss: 0.6994 - val_accuracy: 0.8336\n",
      "Epoch 3674/8000\n",
      "1463/1463 [==============================] - 18s 12ms/step - loss: 0.0727 - accuracy: 0.9750 - val_loss: 0.6893 - val_accuracy: 0.8335\n",
      "Epoch 3675/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0767 - accuracy: 0.9736 - val_loss: 0.7879 - val_accuracy: 0.8229\n",
      "Epoch 3676/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0766 - accuracy: 0.9739 - val_loss: 0.6823 - val_accuracy: 0.8368\n",
      "Epoch 3677/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0708 - accuracy: 0.9761 - val_loss: 0.7226 - val_accuracy: 0.8282\n",
      "Epoch 3678/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0745 - accuracy: 0.9751 - val_loss: 0.8755 - val_accuracy: 0.8207\n",
      "Epoch 3679/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0743 - accuracy: 0.9748 - val_loss: 0.7719 - val_accuracy: 0.8191\n",
      "Epoch 3680/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0759 - accuracy: 0.9745 - val_loss: 0.7440 - val_accuracy: 0.8286\n",
      "Epoch 3681/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0702 - accuracy: 0.9761 - val_loss: 0.7067 - val_accuracy: 0.8311\n",
      "Epoch 3682/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0758 - accuracy: 0.9742 - val_loss: 0.7138 - val_accuracy: 0.8356\n",
      "Epoch 3683/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0813 - accuracy: 0.9743 - val_loss: 0.7175 - val_accuracy: 0.8293\n",
      "Epoch 3684/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0753 - accuracy: 0.9749 - val_loss: 0.6772 - val_accuracy: 0.8372\n",
      "Epoch 3685/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0745 - accuracy: 0.9746 - val_loss: 0.7054 - val_accuracy: 0.8308\n",
      "Epoch 3686/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0751 - accuracy: 0.9751 - val_loss: 0.7877 - val_accuracy: 0.8269\n",
      "Epoch 3687/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0840 - accuracy: 0.9733 - val_loss: 0.6915 - val_accuracy: 0.8357\n",
      "Epoch 3688/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0755 - accuracy: 0.9743 - val_loss: 0.6858 - val_accuracy: 0.8380\n",
      "Epoch 3689/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0735 - accuracy: 0.9753 - val_loss: 0.6657 - val_accuracy: 0.8400\n",
      "Epoch 3690/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0778 - accuracy: 0.9738 - val_loss: 0.8716 - val_accuracy: 0.8037\n",
      "Epoch 3691/8000\n",
      "1463/1463 [==============================] - 18s 12ms/step - loss: 0.0743 - accuracy: 0.9749 - val_loss: 0.7862 - val_accuracy: 0.8279\n",
      "Epoch 3692/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0749 - accuracy: 0.9751 - val_loss: 0.7027 - val_accuracy: 0.8349\n",
      "Epoch 3693/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0772 - accuracy: 0.9737 - val_loss: 0.7059 - val_accuracy: 0.8331\n",
      "Epoch 3694/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0746 - accuracy: 0.9746 - val_loss: 0.7584 - val_accuracy: 0.8204\n",
      "Epoch 3695/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0724 - accuracy: 0.9757 - val_loss: 0.6803 - val_accuracy: 0.8372\n",
      "Epoch 3696/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0710 - accuracy: 0.9760 - val_loss: 0.7229 - val_accuracy: 0.8285\n",
      "Epoch 3697/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0720 - accuracy: 0.9754 - val_loss: 0.6992 - val_accuracy: 0.8343\n",
      "Epoch 3698/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0769 - accuracy: 0.9737 - val_loss: 0.6687 - val_accuracy: 0.8386\n",
      "Epoch 3699/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0775 - accuracy: 0.9741 - val_loss: 0.6872 - val_accuracy: 0.8353\n",
      "Epoch 3700/8000\n",
      "1460/1463 [============================>.] - ETA: 0s - loss: 0.0739 - accuracy: 0.9744\n",
      "Epoch 3700: saving model to ./training_ckpt_20240109205949_v8_240109_d10000_n4096_b64_e8000_c100_Adamax\\cp-000003700.ckpt\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0739 - accuracy: 0.9745 - val_loss: 0.6964 - val_accuracy: 0.8333\n",
      "Epoch 3701/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0774 - accuracy: 0.9743 - val_loss: 0.8295 - val_accuracy: 0.8153\n",
      "Epoch 3702/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0737 - accuracy: 0.9750 - val_loss: 0.8284 - val_accuracy: 0.8129\n",
      "Epoch 3703/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0729 - accuracy: 0.9744 - val_loss: 0.6599 - val_accuracy: 0.8418\n",
      "Epoch 3704/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0714 - accuracy: 0.9753 - val_loss: 0.7067 - val_accuracy: 0.8328\n",
      "Epoch 3705/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0724 - accuracy: 0.9752 - val_loss: 0.6798 - val_accuracy: 0.8394\n",
      "Epoch 3706/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0735 - accuracy: 0.9753 - val_loss: 0.6848 - val_accuracy: 0.8360\n",
      "Epoch 3707/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0758 - accuracy: 0.9745 - val_loss: 0.7353 - val_accuracy: 0.8313\n",
      "Epoch 3708/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0750 - accuracy: 0.9744 - val_loss: 0.7180 - val_accuracy: 0.8333\n",
      "Epoch 3709/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0767 - accuracy: 0.9743 - val_loss: 0.7081 - val_accuracy: 0.8349\n",
      "Epoch 3710/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0759 - accuracy: 0.9740 - val_loss: 0.7670 - val_accuracy: 0.8239\n",
      "Epoch 3711/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0752 - accuracy: 0.9753 - val_loss: 0.7079 - val_accuracy: 0.8323\n",
      "Epoch 3712/8000\n",
      "1463/1463 [==============================] - 12s 9ms/step - loss: 0.0722 - accuracy: 0.9754 - val_loss: 0.7202 - val_accuracy: 0.8353\n",
      "Epoch 3713/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0776 - accuracy: 0.9740 - val_loss: 0.7246 - val_accuracy: 0.8292\n",
      "Epoch 3714/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0742 - accuracy: 0.9746 - val_loss: 0.6721 - val_accuracy: 0.8413\n",
      "Epoch 3715/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0691 - accuracy: 0.9759 - val_loss: 0.6984 - val_accuracy: 0.8331\n",
      "Epoch 3716/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0726 - accuracy: 0.9753 - val_loss: 0.7342 - val_accuracy: 0.8327\n",
      "Epoch 3717/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0795 - accuracy: 0.9730 - val_loss: 0.7105 - val_accuracy: 0.8331\n",
      "Epoch 3718/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0771 - accuracy: 0.9738 - val_loss: 0.6454 - val_accuracy: 0.8444\n",
      "Epoch 3719/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0721 - accuracy: 0.9757 - val_loss: 0.7180 - val_accuracy: 0.8318\n",
      "Epoch 3720/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0732 - accuracy: 0.9751 - val_loss: 0.7040 - val_accuracy: 0.8295\n",
      "Epoch 3721/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0755 - accuracy: 0.9741 - val_loss: 0.6819 - val_accuracy: 0.8404\n",
      "Epoch 3722/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0763 - accuracy: 0.9743 - val_loss: 0.7283 - val_accuracy: 0.8276\n",
      "Epoch 3723/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0732 - accuracy: 0.9756 - val_loss: 0.7049 - val_accuracy: 0.8341\n",
      "Epoch 3724/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0720 - accuracy: 0.9749 - val_loss: 0.7910 - val_accuracy: 0.8176\n",
      "Epoch 3725/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0782 - accuracy: 0.9727 - val_loss: 0.6901 - val_accuracy: 0.8393\n",
      "Epoch 3726/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0736 - accuracy: 0.9744 - val_loss: 0.6781 - val_accuracy: 0.8380\n",
      "Epoch 3727/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0723 - accuracy: 0.9749 - val_loss: 0.6857 - val_accuracy: 0.8359\n",
      "Epoch 3728/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0741 - accuracy: 0.9747 - val_loss: 0.7151 - val_accuracy: 0.8342\n",
      "Epoch 3729/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0737 - accuracy: 0.9749 - val_loss: 0.7126 - val_accuracy: 0.8340\n",
      "Epoch 3730/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0732 - accuracy: 0.9759 - val_loss: 0.7723 - val_accuracy: 0.8202\n",
      "Epoch 3731/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0705 - accuracy: 0.9761 - val_loss: 0.7247 - val_accuracy: 0.8302\n",
      "Epoch 3732/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0751 - accuracy: 0.9742 - val_loss: 0.7206 - val_accuracy: 0.8302\n",
      "Epoch 3733/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0776 - accuracy: 0.9735 - val_loss: 0.7534 - val_accuracy: 0.8258\n",
      "Epoch 3734/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0755 - accuracy: 0.9746 - val_loss: 0.7221 - val_accuracy: 0.8349\n",
      "Epoch 3735/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0754 - accuracy: 0.9747 - val_loss: 0.7613 - val_accuracy: 0.8216\n",
      "Epoch 3736/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0758 - accuracy: 0.9742 - val_loss: 0.6489 - val_accuracy: 0.8418\n",
      "Epoch 3737/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0763 - accuracy: 0.9742 - val_loss: 0.6854 - val_accuracy: 0.8387\n",
      "Epoch 3738/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0786 - accuracy: 0.9734 - val_loss: 0.7546 - val_accuracy: 0.8273\n",
      "Epoch 3739/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0713 - accuracy: 0.9756 - val_loss: 0.7311 - val_accuracy: 0.8263\n",
      "Epoch 3740/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0720 - accuracy: 0.9752 - val_loss: 0.6802 - val_accuracy: 0.8377\n",
      "Epoch 3741/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0759 - accuracy: 0.9745 - val_loss: 0.6925 - val_accuracy: 0.8365\n",
      "Epoch 3742/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0753 - accuracy: 0.9735 - val_loss: 0.7487 - val_accuracy: 0.8255\n",
      "Epoch 3743/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0709 - accuracy: 0.9759 - val_loss: 0.6793 - val_accuracy: 0.8376\n",
      "Epoch 3744/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0819 - accuracy: 0.9726 - val_loss: 0.7233 - val_accuracy: 0.8329\n",
      "Epoch 3745/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0739 - accuracy: 0.9750 - val_loss: 0.7635 - val_accuracy: 0.8233\n",
      "Epoch 3746/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0678 - accuracy: 0.9768 - val_loss: 0.7415 - val_accuracy: 0.8329\n",
      "Epoch 3747/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0764 - accuracy: 0.9742 - val_loss: 0.7255 - val_accuracy: 0.8289\n",
      "Epoch 3748/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0740 - accuracy: 0.9755 - val_loss: 0.7163 - val_accuracy: 0.8325\n",
      "Epoch 3749/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0749 - accuracy: 0.9742 - val_loss: 0.7517 - val_accuracy: 0.8298\n",
      "Epoch 3750/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0725 - accuracy: 0.9756 - val_loss: 0.6646 - val_accuracy: 0.8415\n",
      "Epoch 3751/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0695 - accuracy: 0.9760 - val_loss: 0.6949 - val_accuracy: 0.8369\n",
      "Epoch 3752/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0762 - accuracy: 0.9734 - val_loss: 0.7176 - val_accuracy: 0.8318\n",
      "Epoch 3753/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0724 - accuracy: 0.9755 - val_loss: 0.6777 - val_accuracy: 0.8358\n",
      "Epoch 3754/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0678 - accuracy: 0.9773 - val_loss: 0.6450 - val_accuracy: 0.8421\n",
      "Epoch 3755/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0746 - accuracy: 0.9747 - val_loss: 0.7082 - val_accuracy: 0.8345\n",
      "Epoch 3756/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0695 - accuracy: 0.9761 - val_loss: 0.6690 - val_accuracy: 0.8405\n",
      "Epoch 3757/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0760 - accuracy: 0.9743 - val_loss: 0.6562 - val_accuracy: 0.8391\n",
      "Epoch 3758/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0753 - accuracy: 0.9744 - val_loss: 0.7559 - val_accuracy: 0.8301\n",
      "Epoch 3759/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0768 - accuracy: 0.9743 - val_loss: 0.6830 - val_accuracy: 0.8385\n",
      "Epoch 3760/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0697 - accuracy: 0.9765 - val_loss: 0.7344 - val_accuracy: 0.8273\n",
      "Epoch 3761/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0769 - accuracy: 0.9742 - val_loss: 0.7622 - val_accuracy: 0.8207\n",
      "Epoch 3762/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0719 - accuracy: 0.9753 - val_loss: 0.6406 - val_accuracy: 0.8462\n",
      "Epoch 3763/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0703 - accuracy: 0.9761 - val_loss: 0.6787 - val_accuracy: 0.8389\n",
      "Epoch 3764/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0681 - accuracy: 0.9765 - val_loss: 0.6916 - val_accuracy: 0.8368\n",
      "Epoch 3765/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0699 - accuracy: 0.9765 - val_loss: 0.7755 - val_accuracy: 0.8190\n",
      "Epoch 3766/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0688 - accuracy: 0.9770 - val_loss: 0.7208 - val_accuracy: 0.8330\n",
      "Epoch 3767/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0742 - accuracy: 0.9752 - val_loss: 0.6684 - val_accuracy: 0.8433\n",
      "Epoch 3768/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0749 - accuracy: 0.9744 - val_loss: 0.7000 - val_accuracy: 0.8364\n",
      "Epoch 3769/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0753 - accuracy: 0.9741 - val_loss: 0.7796 - val_accuracy: 0.8200\n",
      "Epoch 3770/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0723 - accuracy: 0.9755 - val_loss: 0.8428 - val_accuracy: 0.8197\n",
      "Epoch 3771/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0755 - accuracy: 0.9744 - val_loss: 0.6819 - val_accuracy: 0.8377\n",
      "Epoch 3772/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0763 - accuracy: 0.9741 - val_loss: 0.7530 - val_accuracy: 0.8218\n",
      "Epoch 3773/8000\n",
      "1463/1463 [==============================] - 12s 9ms/step - loss: 0.0720 - accuracy: 0.9761 - val_loss: 0.7362 - val_accuracy: 0.8314\n",
      "Epoch 3774/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0777 - accuracy: 0.9739 - val_loss: 0.6948 - val_accuracy: 0.8336\n",
      "Epoch 3775/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0704 - accuracy: 0.9763 - val_loss: 0.7160 - val_accuracy: 0.8326\n",
      "Epoch 3776/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0722 - accuracy: 0.9754 - val_loss: 0.6567 - val_accuracy: 0.8432\n",
      "Epoch 3777/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0732 - accuracy: 0.9749 - val_loss: 0.7099 - val_accuracy: 0.8313\n",
      "Epoch 3778/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0742 - accuracy: 0.9751 - val_loss: 0.6602 - val_accuracy: 0.8426\n",
      "Epoch 3779/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0739 - accuracy: 0.9747 - val_loss: 0.7002 - val_accuracy: 0.8353\n",
      "Epoch 3780/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0735 - accuracy: 0.9750 - val_loss: 0.6568 - val_accuracy: 0.8416\n",
      "Epoch 3781/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0777 - accuracy: 0.9743 - val_loss: 0.7575 - val_accuracy: 0.8203\n",
      "Epoch 3782/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0791 - accuracy: 0.9738 - val_loss: 0.7197 - val_accuracy: 0.8330\n",
      "Epoch 3783/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0709 - accuracy: 0.9757 - val_loss: 0.6707 - val_accuracy: 0.8413\n",
      "Epoch 3784/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0719 - accuracy: 0.9752 - val_loss: 0.7051 - val_accuracy: 0.8326\n",
      "Epoch 3785/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0743 - accuracy: 0.9750 - val_loss: 0.7617 - val_accuracy: 0.8240\n",
      "Epoch 3786/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0685 - accuracy: 0.9772 - val_loss: 0.7217 - val_accuracy: 0.8329\n",
      "Epoch 3787/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0762 - accuracy: 0.9731 - val_loss: 0.7375 - val_accuracy: 0.8245\n",
      "Epoch 3788/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0752 - accuracy: 0.9746 - val_loss: 0.7212 - val_accuracy: 0.8287\n",
      "Epoch 3789/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0727 - accuracy: 0.9746 - val_loss: 0.7353 - val_accuracy: 0.8302\n",
      "Epoch 3790/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0788 - accuracy: 0.9727 - val_loss: 0.7749 - val_accuracy: 0.8229\n",
      "Epoch 3791/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0702 - accuracy: 0.9762 - val_loss: 0.6445 - val_accuracy: 0.8463\n",
      "Epoch 3792/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0685 - accuracy: 0.9772 - val_loss: 0.6940 - val_accuracy: 0.8390\n",
      "Epoch 3793/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0753 - accuracy: 0.9756 - val_loss: 0.7467 - val_accuracy: 0.8304\n",
      "Epoch 3794/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0702 - accuracy: 0.9768 - val_loss: 0.7492 - val_accuracy: 0.8281\n",
      "Epoch 3795/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0696 - accuracy: 0.9761 - val_loss: 0.7126 - val_accuracy: 0.8307\n",
      "Epoch 3796/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0767 - accuracy: 0.9740 - val_loss: 0.7025 - val_accuracy: 0.8338\n",
      "Epoch 3797/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0784 - accuracy: 0.9741 - val_loss: 0.6704 - val_accuracy: 0.8398\n",
      "Epoch 3798/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0728 - accuracy: 0.9749 - val_loss: 0.7382 - val_accuracy: 0.8359\n",
      "Epoch 3799/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0678 - accuracy: 0.9768 - val_loss: 0.6974 - val_accuracy: 0.8370\n",
      "Epoch 3800/8000\n",
      "1460/1463 [============================>.] - ETA: 0s - loss: 0.0707 - accuracy: 0.9763\n",
      "Epoch 3800: saving model to ./training_ckpt_20240109205949_v8_240109_d10000_n4096_b64_e8000_c100_Adamax\\cp-000003800.ckpt\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0706 - accuracy: 0.9763 - val_loss: 0.7203 - val_accuracy: 0.8315\n",
      "Epoch 3801/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0720 - accuracy: 0.9753 - val_loss: 0.6881 - val_accuracy: 0.8362\n",
      "Epoch 3802/8000\n",
      "1463/1463 [==============================] - 12s 9ms/step - loss: 0.0786 - accuracy: 0.9736 - val_loss: 0.7237 - val_accuracy: 0.8292\n",
      "Epoch 3803/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0758 - accuracy: 0.9742 - val_loss: 0.6790 - val_accuracy: 0.8377\n",
      "Epoch 3804/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0730 - accuracy: 0.9751 - val_loss: 0.7192 - val_accuracy: 0.8313\n",
      "Epoch 3805/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0748 - accuracy: 0.9742 - val_loss: 0.7151 - val_accuracy: 0.8373\n",
      "Epoch 3806/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0702 - accuracy: 0.9763 - val_loss: 0.6742 - val_accuracy: 0.8425\n",
      "Epoch 3807/8000\n",
      "1463/1463 [==============================] - 12s 9ms/step - loss: 0.0733 - accuracy: 0.9753 - val_loss: 0.7592 - val_accuracy: 0.8243\n",
      "Epoch 3808/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0699 - accuracy: 0.9760 - val_loss: 0.6866 - val_accuracy: 0.8376\n",
      "Epoch 3809/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0744 - accuracy: 0.9746 - val_loss: 0.6730 - val_accuracy: 0.8385\n",
      "Epoch 3810/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0785 - accuracy: 0.9728 - val_loss: 0.7433 - val_accuracy: 0.8291\n",
      "Epoch 3811/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0741 - accuracy: 0.9744 - val_loss: 0.7178 - val_accuracy: 0.8354\n",
      "Epoch 3812/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0712 - accuracy: 0.9750 - val_loss: 0.6772 - val_accuracy: 0.8390\n",
      "Epoch 3813/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0739 - accuracy: 0.9740 - val_loss: 0.7323 - val_accuracy: 0.8312\n",
      "Epoch 3814/8000\n",
      "1463/1463 [==============================] - 20s 14ms/step - loss: 0.0833 - accuracy: 0.9725 - val_loss: 0.6866 - val_accuracy: 0.8357\n",
      "Epoch 3815/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0724 - accuracy: 0.9755 - val_loss: 0.7142 - val_accuracy: 0.8316\n",
      "Epoch 3816/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0790 - accuracy: 0.9731 - val_loss: 0.6612 - val_accuracy: 0.8458\n",
      "Epoch 3817/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0768 - accuracy: 0.9738 - val_loss: 0.7289 - val_accuracy: 0.8315\n",
      "Epoch 3818/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0780 - accuracy: 0.9738 - val_loss: 0.6922 - val_accuracy: 0.8372\n",
      "Epoch 3819/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0727 - accuracy: 0.9753 - val_loss: 0.6915 - val_accuracy: 0.8327\n",
      "Epoch 3820/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0663 - accuracy: 0.9776 - val_loss: 0.7032 - val_accuracy: 0.8380\n",
      "Epoch 3821/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0754 - accuracy: 0.9741 - val_loss: 0.6597 - val_accuracy: 0.8416\n",
      "Epoch 3822/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0774 - accuracy: 0.9738 - val_loss: 0.6721 - val_accuracy: 0.8372\n",
      "Epoch 3823/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0739 - accuracy: 0.9745 - val_loss: 0.7123 - val_accuracy: 0.8338\n",
      "Epoch 3824/8000\n",
      "1463/1463 [==============================] - 15s 11ms/step - loss: 0.0749 - accuracy: 0.9742 - val_loss: 0.7430 - val_accuracy: 0.8258\n",
      "Epoch 3825/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0724 - accuracy: 0.9757 - val_loss: 0.6727 - val_accuracy: 0.8394\n",
      "Epoch 3826/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0701 - accuracy: 0.9757 - val_loss: 0.6555 - val_accuracy: 0.8421\n",
      "Epoch 3827/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0761 - accuracy: 0.9743 - val_loss: 0.7452 - val_accuracy: 0.8307\n",
      "Epoch 3828/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0765 - accuracy: 0.9747 - val_loss: 0.7450 - val_accuracy: 0.8316\n",
      "Epoch 3829/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0718 - accuracy: 0.9758 - val_loss: 0.6965 - val_accuracy: 0.8377\n",
      "Epoch 3830/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0789 - accuracy: 0.9733 - val_loss: 0.6817 - val_accuracy: 0.8385\n",
      "Epoch 3831/8000\n",
      "1463/1463 [==============================] - 15s 11ms/step - loss: 0.0750 - accuracy: 0.9753 - val_loss: 0.6834 - val_accuracy: 0.8376\n",
      "Epoch 3832/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0788 - accuracy: 0.9734 - val_loss: 0.6824 - val_accuracy: 0.8382\n",
      "Epoch 3833/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0756 - accuracy: 0.9745 - val_loss: 0.7072 - val_accuracy: 0.8360\n",
      "Epoch 3834/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0827 - accuracy: 0.9723 - val_loss: 0.7099 - val_accuracy: 0.8356\n",
      "Epoch 3835/8000\n",
      "1463/1463 [==============================] - 15s 11ms/step - loss: 0.0724 - accuracy: 0.9759 - val_loss: 0.7202 - val_accuracy: 0.8312\n",
      "Epoch 3836/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0771 - accuracy: 0.9736 - val_loss: 0.7893 - val_accuracy: 0.8244\n",
      "Epoch 3837/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0908 - accuracy: 0.9719 - val_loss: 0.6558 - val_accuracy: 0.8445\n",
      "Epoch 3838/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0706 - accuracy: 0.9755 - val_loss: 0.6933 - val_accuracy: 0.8387\n",
      "Epoch 3839/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0719 - accuracy: 0.9752 - val_loss: 0.7084 - val_accuracy: 0.8314\n",
      "Epoch 3840/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0684 - accuracy: 0.9769 - val_loss: 0.6986 - val_accuracy: 0.8389\n",
      "Epoch 3841/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0766 - accuracy: 0.9741 - val_loss: 0.6950 - val_accuracy: 0.8361\n",
      "Epoch 3842/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0770 - accuracy: 0.9746 - val_loss: 0.7387 - val_accuracy: 0.8268\n",
      "Epoch 3843/8000\n",
      "1463/1463 [==============================] - 12s 9ms/step - loss: 0.0707 - accuracy: 0.9760 - val_loss: 0.8384 - val_accuracy: 0.8184\n",
      "Epoch 3844/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0729 - accuracy: 0.9754 - val_loss: 0.7561 - val_accuracy: 0.8300\n",
      "Epoch 3845/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0736 - accuracy: 0.9749 - val_loss: 0.6921 - val_accuracy: 0.8363\n",
      "Epoch 3846/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0668 - accuracy: 0.9770 - val_loss: 0.6905 - val_accuracy: 0.8374\n",
      "Epoch 3847/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0745 - accuracy: 0.9750 - val_loss: 0.7345 - val_accuracy: 0.8298\n",
      "Epoch 3848/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0728 - accuracy: 0.9757 - val_loss: 0.8017 - val_accuracy: 0.8132\n",
      "Epoch 3849/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0751 - accuracy: 0.9745 - val_loss: 0.6991 - val_accuracy: 0.8374\n",
      "Epoch 3850/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0734 - accuracy: 0.9753 - val_loss: 0.7833 - val_accuracy: 0.8211\n",
      "Epoch 3851/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0711 - accuracy: 0.9755 - val_loss: 0.7230 - val_accuracy: 0.8295\n",
      "Epoch 3852/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0706 - accuracy: 0.9762 - val_loss: 0.6830 - val_accuracy: 0.8349\n",
      "Epoch 3853/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0717 - accuracy: 0.9756 - val_loss: 0.7724 - val_accuracy: 0.8250\n",
      "Epoch 3854/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0719 - accuracy: 0.9760 - val_loss: 0.6922 - val_accuracy: 0.8379\n",
      "Epoch 3855/8000\n",
      "1463/1463 [==============================] - 12s 9ms/step - loss: 0.0739 - accuracy: 0.9754 - val_loss: 0.6643 - val_accuracy: 0.8443\n",
      "Epoch 3856/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0804 - accuracy: 0.9731 - val_loss: 0.7422 - val_accuracy: 0.8322\n",
      "Epoch 3857/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0705 - accuracy: 0.9757 - val_loss: 0.7076 - val_accuracy: 0.8396\n",
      "Epoch 3858/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0719 - accuracy: 0.9762 - val_loss: 0.6912 - val_accuracy: 0.8369\n",
      "Epoch 3859/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0682 - accuracy: 0.9774 - val_loss: 0.7090 - val_accuracy: 0.8334\n",
      "Epoch 3860/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0738 - accuracy: 0.9744 - val_loss: 0.7502 - val_accuracy: 0.8288\n",
      "Epoch 3861/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0742 - accuracy: 0.9749 - val_loss: 0.6984 - val_accuracy: 0.8382\n",
      "Epoch 3862/8000\n",
      "1463/1463 [==============================] - 18s 12ms/step - loss: 0.0725 - accuracy: 0.9757 - val_loss: 0.6633 - val_accuracy: 0.8406\n",
      "Epoch 3863/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0720 - accuracy: 0.9761 - val_loss: 0.6892 - val_accuracy: 0.8354\n",
      "Epoch 3864/8000\n",
      "1463/1463 [==============================] - 19s 13ms/step - loss: 0.0751 - accuracy: 0.9749 - val_loss: 0.7136 - val_accuracy: 0.8316\n",
      "Epoch 3865/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0735 - accuracy: 0.9758 - val_loss: 0.6966 - val_accuracy: 0.8342\n",
      "Epoch 3866/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0697 - accuracy: 0.9764 - val_loss: 0.7640 - val_accuracy: 0.8260\n",
      "Epoch 3867/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0712 - accuracy: 0.9764 - val_loss: 0.7664 - val_accuracy: 0.8223\n",
      "Epoch 3868/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0717 - accuracy: 0.9754 - val_loss: 0.7237 - val_accuracy: 0.8330\n",
      "Epoch 3869/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0733 - accuracy: 0.9752 - val_loss: 0.6397 - val_accuracy: 0.8479\n",
      "Epoch 3870/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0701 - accuracy: 0.9762 - val_loss: 0.7427 - val_accuracy: 0.8300\n",
      "Epoch 3871/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0732 - accuracy: 0.9754 - val_loss: 0.8006 - val_accuracy: 0.8172\n",
      "Epoch 3872/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0723 - accuracy: 0.9755 - val_loss: 0.6605 - val_accuracy: 0.8434\n",
      "Epoch 3873/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0673 - accuracy: 0.9772 - val_loss: 0.6736 - val_accuracy: 0.8400\n",
      "Epoch 3874/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0753 - accuracy: 0.9744 - val_loss: 0.8003 - val_accuracy: 0.8221\n",
      "Epoch 3875/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0703 - accuracy: 0.9758 - val_loss: 0.7503 - val_accuracy: 0.8252\n",
      "Epoch 3876/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0752 - accuracy: 0.9742 - val_loss: 0.6720 - val_accuracy: 0.8402\n",
      "Epoch 3877/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0712 - accuracy: 0.9762 - val_loss: 0.6544 - val_accuracy: 0.8438\n",
      "Epoch 3878/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0709 - accuracy: 0.9766 - val_loss: 0.7375 - val_accuracy: 0.8287\n",
      "Epoch 3879/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0758 - accuracy: 0.9751 - val_loss: 0.7624 - val_accuracy: 0.8262\n",
      "Epoch 3880/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0706 - accuracy: 0.9761 - val_loss: 0.6609 - val_accuracy: 0.8438\n",
      "Epoch 3881/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0762 - accuracy: 0.9742 - val_loss: 0.7245 - val_accuracy: 0.8325\n",
      "Epoch 3882/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0753 - accuracy: 0.9745 - val_loss: 0.6829 - val_accuracy: 0.8387\n",
      "Epoch 3883/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0738 - accuracy: 0.9755 - val_loss: 0.7422 - val_accuracy: 0.8309\n",
      "Epoch 3884/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0736 - accuracy: 0.9758 - val_loss: 0.7178 - val_accuracy: 0.8339\n",
      "Epoch 3885/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0735 - accuracy: 0.9756 - val_loss: 0.7372 - val_accuracy: 0.8263\n",
      "Epoch 3886/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0674 - accuracy: 0.9771 - val_loss: 0.7046 - val_accuracy: 0.8360\n",
      "Epoch 3887/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0711 - accuracy: 0.9759 - val_loss: 0.7097 - val_accuracy: 0.8319\n",
      "Epoch 3888/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0736 - accuracy: 0.9748 - val_loss: 0.7787 - val_accuracy: 0.8248\n",
      "Epoch 3889/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0707 - accuracy: 0.9758 - val_loss: 0.7240 - val_accuracy: 0.8373\n",
      "Epoch 3890/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0644 - accuracy: 0.9779 - val_loss: 0.7125 - val_accuracy: 0.8342\n",
      "Epoch 3891/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0743 - accuracy: 0.9751 - val_loss: 0.6994 - val_accuracy: 0.8344\n",
      "Epoch 3892/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0711 - accuracy: 0.9758 - val_loss: 0.7157 - val_accuracy: 0.8325\n",
      "Epoch 3893/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0771 - accuracy: 0.9746 - val_loss: 0.7181 - val_accuracy: 0.8325\n",
      "Epoch 3894/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0701 - accuracy: 0.9770 - val_loss: 0.7425 - val_accuracy: 0.8293\n",
      "Epoch 3895/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0726 - accuracy: 0.9750 - val_loss: 0.7549 - val_accuracy: 0.8239\n",
      "Epoch 3896/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0757 - accuracy: 0.9749 - val_loss: 0.6545 - val_accuracy: 0.8444\n",
      "Epoch 3897/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0658 - accuracy: 0.9774 - val_loss: 0.7124 - val_accuracy: 0.8288\n",
      "Epoch 3898/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0764 - accuracy: 0.9744 - val_loss: 0.6667 - val_accuracy: 0.8409\n",
      "Epoch 3899/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0706 - accuracy: 0.9758 - val_loss: 0.7215 - val_accuracy: 0.8311\n",
      "Epoch 3900/8000\n",
      "1461/1463 [============================>.] - ETA: 0s - loss: 0.0694 - accuracy: 0.9767\n",
      "Epoch 3900: saving model to ./training_ckpt_20240109205949_v8_240109_d10000_n4096_b64_e8000_c100_Adamax\\cp-000003900.ckpt\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0694 - accuracy: 0.9767 - val_loss: 0.6785 - val_accuracy: 0.8347\n",
      "Epoch 3901/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0740 - accuracy: 0.9754 - val_loss: 0.6755 - val_accuracy: 0.8396\n",
      "Epoch 3902/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0724 - accuracy: 0.9754 - val_loss: 0.6728 - val_accuracy: 0.8397\n",
      "Epoch 3903/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0717 - accuracy: 0.9759 - val_loss: 0.7471 - val_accuracy: 0.8292\n",
      "Epoch 3904/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0725 - accuracy: 0.9753 - val_loss: 0.7672 - val_accuracy: 0.8273\n",
      "Epoch 3905/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0726 - accuracy: 0.9753 - val_loss: 0.6761 - val_accuracy: 0.8413\n",
      "Epoch 3906/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0650 - accuracy: 0.9775 - val_loss: 0.6828 - val_accuracy: 0.8392\n",
      "Epoch 3907/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0772 - accuracy: 0.9739 - val_loss: 0.6929 - val_accuracy: 0.8370\n",
      "Epoch 3908/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0739 - accuracy: 0.9753 - val_loss: 0.6607 - val_accuracy: 0.8421\n",
      "Epoch 3909/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0739 - accuracy: 0.9746 - val_loss: 0.7055 - val_accuracy: 0.8338\n",
      "Epoch 3910/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0693 - accuracy: 0.9763 - val_loss: 0.6570 - val_accuracy: 0.8413\n",
      "Epoch 3911/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0720 - accuracy: 0.9753 - val_loss: 0.6973 - val_accuracy: 0.8339\n",
      "Epoch 3912/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0719 - accuracy: 0.9761 - val_loss: 0.6814 - val_accuracy: 0.8389\n",
      "Epoch 3913/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0740 - accuracy: 0.9759 - val_loss: 0.6862 - val_accuracy: 0.8384\n",
      "Epoch 3914/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0723 - accuracy: 0.9759 - val_loss: 0.6710 - val_accuracy: 0.8418\n",
      "Epoch 3915/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0733 - accuracy: 0.9752 - val_loss: 0.7775 - val_accuracy: 0.8269\n",
      "Epoch 3916/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0753 - accuracy: 0.9744 - val_loss: 0.7222 - val_accuracy: 0.8322\n",
      "Epoch 3917/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0711 - accuracy: 0.9756 - val_loss: 0.6780 - val_accuracy: 0.8400\n",
      "Epoch 3918/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0664 - accuracy: 0.9778 - val_loss: 0.7052 - val_accuracy: 0.8374\n",
      "Epoch 3919/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0702 - accuracy: 0.9765 - val_loss: 0.6879 - val_accuracy: 0.8410\n",
      "Epoch 3920/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0661 - accuracy: 0.9772 - val_loss: 0.6732 - val_accuracy: 0.8410\n",
      "Epoch 3921/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0713 - accuracy: 0.9759 - val_loss: 0.6856 - val_accuracy: 0.8416\n",
      "Epoch 3922/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0723 - accuracy: 0.9757 - val_loss: 0.6635 - val_accuracy: 0.8415\n",
      "Epoch 3923/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0683 - accuracy: 0.9768 - val_loss: 0.7722 - val_accuracy: 0.8262\n",
      "Epoch 3924/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0712 - accuracy: 0.9761 - val_loss: 0.6469 - val_accuracy: 0.8454\n",
      "Epoch 3925/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0674 - accuracy: 0.9769 - val_loss: 0.6879 - val_accuracy: 0.8374\n",
      "Epoch 3926/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0668 - accuracy: 0.9770 - val_loss: 0.6524 - val_accuracy: 0.8441\n",
      "Epoch 3927/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0685 - accuracy: 0.9770 - val_loss: 0.6601 - val_accuracy: 0.8420\n",
      "Epoch 3928/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0763 - accuracy: 0.9745 - val_loss: 0.7296 - val_accuracy: 0.8297\n",
      "Epoch 3929/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0659 - accuracy: 0.9773 - val_loss: 0.7041 - val_accuracy: 0.8349\n",
      "Epoch 3930/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0775 - accuracy: 0.9737 - val_loss: 0.6783 - val_accuracy: 0.8413\n",
      "Epoch 3931/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0731 - accuracy: 0.9751 - val_loss: 0.7164 - val_accuracy: 0.8350\n",
      "Epoch 3932/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0771 - accuracy: 0.9740 - val_loss: 0.7486 - val_accuracy: 0.8290\n",
      "Epoch 3933/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0707 - accuracy: 0.9771 - val_loss: 0.7336 - val_accuracy: 0.8328\n",
      "Epoch 3934/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0728 - accuracy: 0.9756 - val_loss: 0.7146 - val_accuracy: 0.8338\n",
      "Epoch 3935/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0724 - accuracy: 0.9754 - val_loss: 0.6606 - val_accuracy: 0.8435\n",
      "Epoch 3936/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0702 - accuracy: 0.9763 - val_loss: 0.6537 - val_accuracy: 0.8449\n",
      "Epoch 3937/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0723 - accuracy: 0.9755 - val_loss: 0.6886 - val_accuracy: 0.8391\n",
      "Epoch 3938/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0737 - accuracy: 0.9754 - val_loss: 0.6691 - val_accuracy: 0.8427\n",
      "Epoch 3939/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0720 - accuracy: 0.9759 - val_loss: 0.7128 - val_accuracy: 0.8325\n",
      "Epoch 3940/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0725 - accuracy: 0.9745 - val_loss: 0.7245 - val_accuracy: 0.8336\n",
      "Epoch 3941/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0717 - accuracy: 0.9762 - val_loss: 0.6904 - val_accuracy: 0.8379\n",
      "Epoch 3942/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0712 - accuracy: 0.9765 - val_loss: 0.7635 - val_accuracy: 0.8246\n",
      "Epoch 3943/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0737 - accuracy: 0.9751 - val_loss: 0.6906 - val_accuracy: 0.8374\n",
      "Epoch 3944/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0721 - accuracy: 0.9764 - val_loss: 0.7371 - val_accuracy: 0.8322\n",
      "Epoch 3945/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0705 - accuracy: 0.9765 - val_loss: 0.7217 - val_accuracy: 0.8329\n",
      "Epoch 3946/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0739 - accuracy: 0.9748 - val_loss: 0.7024 - val_accuracy: 0.8343\n",
      "Epoch 3947/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0773 - accuracy: 0.9737 - val_loss: 0.6873 - val_accuracy: 0.8380\n",
      "Epoch 3948/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0682 - accuracy: 0.9773 - val_loss: 0.6759 - val_accuracy: 0.8395\n",
      "Epoch 3949/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0736 - accuracy: 0.9758 - val_loss: 0.6984 - val_accuracy: 0.8344\n",
      "Epoch 3950/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0670 - accuracy: 0.9771 - val_loss: 0.7170 - val_accuracy: 0.8352\n",
      "Epoch 3951/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0736 - accuracy: 0.9748 - val_loss: 0.7038 - val_accuracy: 0.8400\n",
      "Epoch 3952/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0694 - accuracy: 0.9761 - val_loss: 0.6717 - val_accuracy: 0.8409\n",
      "Epoch 3953/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0703 - accuracy: 0.9758 - val_loss: 0.7608 - val_accuracy: 0.8275\n",
      "Epoch 3954/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0674 - accuracy: 0.9766 - val_loss: 0.7106 - val_accuracy: 0.8376\n",
      "Epoch 3955/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0820 - accuracy: 0.9724 - val_loss: 0.7014 - val_accuracy: 0.8321\n",
      "Epoch 3956/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0748 - accuracy: 0.9745 - val_loss: 0.7275 - val_accuracy: 0.8329\n",
      "Epoch 3957/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0729 - accuracy: 0.9757 - val_loss: 0.6672 - val_accuracy: 0.8419\n",
      "Epoch 3958/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0738 - accuracy: 0.9751 - val_loss: 0.6987 - val_accuracy: 0.8363\n",
      "Epoch 3959/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0704 - accuracy: 0.9763 - val_loss: 0.6928 - val_accuracy: 0.8372\n",
      "Epoch 3960/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0743 - accuracy: 0.9751 - val_loss: 0.7067 - val_accuracy: 0.8377\n",
      "Epoch 3961/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0706 - accuracy: 0.9761 - val_loss: 0.7296 - val_accuracy: 0.8331\n",
      "Epoch 3962/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0750 - accuracy: 0.9747 - val_loss: 0.7473 - val_accuracy: 0.8293\n",
      "Epoch 3963/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0633 - accuracy: 0.9790 - val_loss: 0.7260 - val_accuracy: 0.8300\n",
      "Epoch 3964/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0708 - accuracy: 0.9761 - val_loss: 0.6835 - val_accuracy: 0.8452\n",
      "Epoch 3965/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0644 - accuracy: 0.9780 - val_loss: 0.6932 - val_accuracy: 0.8395\n",
      "Epoch 3966/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0764 - accuracy: 0.9741 - val_loss: 0.7765 - val_accuracy: 0.8238\n",
      "Epoch 3967/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0713 - accuracy: 0.9763 - val_loss: 0.7726 - val_accuracy: 0.8274\n",
      "Epoch 3968/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0668 - accuracy: 0.9775 - val_loss: 0.7026 - val_accuracy: 0.8352\n",
      "Epoch 3969/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0791 - accuracy: 0.9732 - val_loss: 0.6680 - val_accuracy: 0.8446\n",
      "Epoch 3970/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0742 - accuracy: 0.9752 - val_loss: 0.7816 - val_accuracy: 0.8211\n",
      "Epoch 3971/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0769 - accuracy: 0.9740 - val_loss: 0.6686 - val_accuracy: 0.8400\n",
      "Epoch 3972/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0688 - accuracy: 0.9765 - val_loss: 0.7175 - val_accuracy: 0.8329\n",
      "Epoch 3973/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0715 - accuracy: 0.9755 - val_loss: 0.6909 - val_accuracy: 0.8388\n",
      "Epoch 3974/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0729 - accuracy: 0.9754 - val_loss: 0.7138 - val_accuracy: 0.8359\n",
      "Epoch 3975/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0689 - accuracy: 0.9762 - val_loss: 0.7484 - val_accuracy: 0.8298\n",
      "Epoch 3976/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0683 - accuracy: 0.9768 - val_loss: 0.7059 - val_accuracy: 0.8370\n",
      "Epoch 3977/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0725 - accuracy: 0.9759 - val_loss: 0.7081 - val_accuracy: 0.8334\n",
      "Epoch 3978/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0670 - accuracy: 0.9767 - val_loss: 0.6364 - val_accuracy: 0.8487\n",
      "Epoch 3979/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0754 - accuracy: 0.9743 - val_loss: 0.7862 - val_accuracy: 0.8257\n",
      "Epoch 3980/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0757 - accuracy: 0.9752 - val_loss: 0.6991 - val_accuracy: 0.8368\n",
      "Epoch 3981/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0723 - accuracy: 0.9759 - val_loss: 0.6821 - val_accuracy: 0.8406\n",
      "Epoch 3982/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0692 - accuracy: 0.9764 - val_loss: 0.6754 - val_accuracy: 0.8408\n",
      "Epoch 3983/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0678 - accuracy: 0.9771 - val_loss: 0.6666 - val_accuracy: 0.8429\n",
      "Epoch 3984/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0734 - accuracy: 0.9757 - val_loss: 0.7059 - val_accuracy: 0.8365\n",
      "Epoch 3985/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0689 - accuracy: 0.9769 - val_loss: 0.6811 - val_accuracy: 0.8388\n",
      "Epoch 3986/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0758 - accuracy: 0.9745 - val_loss: 0.7354 - val_accuracy: 0.8276\n",
      "Epoch 3987/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0707 - accuracy: 0.9767 - val_loss: 0.6987 - val_accuracy: 0.8376\n",
      "Epoch 3988/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0675 - accuracy: 0.9772 - val_loss: 0.6516 - val_accuracy: 0.8432\n",
      "Epoch 3989/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0695 - accuracy: 0.9768 - val_loss: 0.6945 - val_accuracy: 0.8406\n",
      "Epoch 3990/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0704 - accuracy: 0.9764 - val_loss: 0.6655 - val_accuracy: 0.8422\n",
      "Epoch 3991/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0710 - accuracy: 0.9762 - val_loss: 0.6729 - val_accuracy: 0.8408\n",
      "Epoch 3992/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0689 - accuracy: 0.9765 - val_loss: 0.7172 - val_accuracy: 0.8340\n",
      "Epoch 3993/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0718 - accuracy: 0.9759 - val_loss: 0.6917 - val_accuracy: 0.8368\n",
      "Epoch 3994/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0688 - accuracy: 0.9766 - val_loss: 0.6509 - val_accuracy: 0.8469\n",
      "Epoch 3995/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0703 - accuracy: 0.9761 - val_loss: 0.7067 - val_accuracy: 0.8391\n",
      "Epoch 3996/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0660 - accuracy: 0.9773 - val_loss: 0.6747 - val_accuracy: 0.8424\n",
      "Epoch 3997/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0697 - accuracy: 0.9760 - val_loss: 0.6886 - val_accuracy: 0.8398\n",
      "Epoch 3998/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0701 - accuracy: 0.9768 - val_loss: 0.9243 - val_accuracy: 0.8127\n",
      "Epoch 3999/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0667 - accuracy: 0.9776 - val_loss: 0.7761 - val_accuracy: 0.8229\n",
      "Epoch 4000/8000\n",
      "1457/1463 [============================>.] - ETA: 0s - loss: 0.0685 - accuracy: 0.9776\n",
      "Epoch 4000: saving model to ./training_ckpt_20240109205949_v8_240109_d10000_n4096_b64_e8000_c100_Adamax\\cp-000004000.ckpt\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0685 - accuracy: 0.9775 - val_loss: 0.6882 - val_accuracy: 0.8391\n",
      "Epoch 4001/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0724 - accuracy: 0.9762 - val_loss: 0.6986 - val_accuracy: 0.8371\n",
      "Epoch 4002/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0717 - accuracy: 0.9755 - val_loss: 0.6741 - val_accuracy: 0.8399\n",
      "Epoch 4003/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0705 - accuracy: 0.9762 - val_loss: 0.7044 - val_accuracy: 0.8379\n",
      "Epoch 4004/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0667 - accuracy: 0.9778 - val_loss: 0.7813 - val_accuracy: 0.8256\n",
      "Epoch 4005/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0746 - accuracy: 0.9755 - val_loss: 0.6725 - val_accuracy: 0.8422\n",
      "Epoch 4006/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0754 - accuracy: 0.9743 - val_loss: 0.7791 - val_accuracy: 0.8283\n",
      "Epoch 4007/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0773 - accuracy: 0.9750 - val_loss: 0.6701 - val_accuracy: 0.8409\n",
      "Epoch 4008/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0662 - accuracy: 0.9778 - val_loss: 0.6889 - val_accuracy: 0.8377\n",
      "Epoch 4009/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0765 - accuracy: 0.9745 - val_loss: 0.6748 - val_accuracy: 0.8393\n",
      "Epoch 4010/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0705 - accuracy: 0.9764 - val_loss: 0.7537 - val_accuracy: 0.8250\n",
      "Epoch 4011/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0720 - accuracy: 0.9762 - val_loss: 0.7457 - val_accuracy: 0.8290\n",
      "Epoch 4012/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0701 - accuracy: 0.9768 - val_loss: 0.6793 - val_accuracy: 0.8423\n",
      "Epoch 4013/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0689 - accuracy: 0.9759 - val_loss: 0.6711 - val_accuracy: 0.8404\n",
      "Epoch 4014/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0708 - accuracy: 0.9758 - val_loss: 0.7209 - val_accuracy: 0.8332\n",
      "Epoch 4015/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0727 - accuracy: 0.9754 - val_loss: 0.6747 - val_accuracy: 0.8394\n",
      "Epoch 4016/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0708 - accuracy: 0.9757 - val_loss: 0.7049 - val_accuracy: 0.8376\n",
      "Epoch 4017/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0718 - accuracy: 0.9757 - val_loss: 0.6735 - val_accuracy: 0.8423\n",
      "Epoch 4018/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0763 - accuracy: 0.9745 - val_loss: 0.7379 - val_accuracy: 0.8304\n",
      "Epoch 4019/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0730 - accuracy: 0.9758 - val_loss: 0.7189 - val_accuracy: 0.8322\n",
      "Epoch 4020/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0674 - accuracy: 0.9771 - val_loss: 0.6436 - val_accuracy: 0.8480\n",
      "Epoch 4021/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0722 - accuracy: 0.9753 - val_loss: 0.7555 - val_accuracy: 0.8262\n",
      "Epoch 4022/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0647 - accuracy: 0.9781 - val_loss: 0.6639 - val_accuracy: 0.8401\n",
      "Epoch 4023/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0703 - accuracy: 0.9762 - val_loss: 0.7491 - val_accuracy: 0.8297\n",
      "Epoch 4024/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0730 - accuracy: 0.9757 - val_loss: 0.7211 - val_accuracy: 0.8343\n",
      "Epoch 4025/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0705 - accuracy: 0.9762 - val_loss: 0.7155 - val_accuracy: 0.8367\n",
      "Epoch 4026/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0660 - accuracy: 0.9777 - val_loss: 0.6913 - val_accuracy: 0.8381\n",
      "Epoch 4027/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0698 - accuracy: 0.9765 - val_loss: 0.6576 - val_accuracy: 0.8460\n",
      "Epoch 4028/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0668 - accuracy: 0.9773 - val_loss: 0.7022 - val_accuracy: 0.8363\n",
      "Epoch 4029/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0702 - accuracy: 0.9765 - val_loss: 0.6700 - val_accuracy: 0.8448\n",
      "Epoch 4030/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0640 - accuracy: 0.9782 - val_loss: 0.7102 - val_accuracy: 0.8368\n",
      "Epoch 4031/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0695 - accuracy: 0.9763 - val_loss: 0.7529 - val_accuracy: 0.8313\n",
      "Epoch 4032/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0666 - accuracy: 0.9781 - val_loss: 0.6970 - val_accuracy: 0.8410\n",
      "Epoch 4033/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0721 - accuracy: 0.9756 - val_loss: 0.7513 - val_accuracy: 0.8316\n",
      "Epoch 4034/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0695 - accuracy: 0.9764 - val_loss: 0.6862 - val_accuracy: 0.8397\n",
      "Epoch 4035/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0692 - accuracy: 0.9767 - val_loss: 0.6822 - val_accuracy: 0.8420\n",
      "Epoch 4036/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0703 - accuracy: 0.9760 - val_loss: 0.6843 - val_accuracy: 0.8415\n",
      "Epoch 4037/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0678 - accuracy: 0.9772 - val_loss: 0.6692 - val_accuracy: 0.8415\n",
      "Epoch 4038/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0744 - accuracy: 0.9749 - val_loss: 0.6707 - val_accuracy: 0.8415\n",
      "Epoch 4039/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0678 - accuracy: 0.9766 - val_loss: 0.6675 - val_accuracy: 0.8430\n",
      "Epoch 4040/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0631 - accuracy: 0.9789 - val_loss: 0.7930 - val_accuracy: 0.8315\n",
      "Epoch 4041/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0689 - accuracy: 0.9769 - val_loss: 0.6772 - val_accuracy: 0.8421\n",
      "Epoch 4042/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0704 - accuracy: 0.9763 - val_loss: 0.7139 - val_accuracy: 0.8335\n",
      "Epoch 4043/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0706 - accuracy: 0.9761 - val_loss: 0.6643 - val_accuracy: 0.8430\n",
      "Epoch 4044/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0715 - accuracy: 0.9759 - val_loss: 0.6721 - val_accuracy: 0.8392\n",
      "Epoch 4045/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0634 - accuracy: 0.9784 - val_loss: 0.7332 - val_accuracy: 0.8310\n",
      "Epoch 4046/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0657 - accuracy: 0.9779 - val_loss: 0.7475 - val_accuracy: 0.8285\n",
      "Epoch 4047/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0646 - accuracy: 0.9788 - val_loss: 0.7322 - val_accuracy: 0.8335\n",
      "Epoch 4048/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0687 - accuracy: 0.9766 - val_loss: 0.7532 - val_accuracy: 0.8276\n",
      "Epoch 4049/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0705 - accuracy: 0.9760 - val_loss: 0.7186 - val_accuracy: 0.8316\n",
      "Epoch 4050/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0752 - accuracy: 0.9743 - val_loss: 0.6990 - val_accuracy: 0.8414\n",
      "Epoch 4051/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0721 - accuracy: 0.9760 - val_loss: 0.7028 - val_accuracy: 0.8365\n",
      "Epoch 4052/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0716 - accuracy: 0.9768 - val_loss: 0.6765 - val_accuracy: 0.8401\n",
      "Epoch 4053/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0708 - accuracy: 0.9759 - val_loss: 0.7295 - val_accuracy: 0.8307\n",
      "Epoch 4054/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0682 - accuracy: 0.9765 - val_loss: 0.6814 - val_accuracy: 0.8399\n",
      "Epoch 4055/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0666 - accuracy: 0.9775 - val_loss: 0.7094 - val_accuracy: 0.8343\n",
      "Epoch 4056/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0736 - accuracy: 0.9764 - val_loss: 0.6778 - val_accuracy: 0.8428\n",
      "Epoch 4057/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0653 - accuracy: 0.9776 - val_loss: 0.7002 - val_accuracy: 0.8367\n",
      "Epoch 4058/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0712 - accuracy: 0.9769 - val_loss: 0.7145 - val_accuracy: 0.8341\n",
      "Epoch 4059/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0683 - accuracy: 0.9768 - val_loss: 0.8172 - val_accuracy: 0.8188\n",
      "Epoch 4060/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0693 - accuracy: 0.9764 - val_loss: 0.7550 - val_accuracy: 0.8295\n",
      "Epoch 4061/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0700 - accuracy: 0.9768 - val_loss: 0.6845 - val_accuracy: 0.8415\n",
      "Epoch 4062/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0613 - accuracy: 0.9794 - val_loss: 0.6733 - val_accuracy: 0.8398\n",
      "Epoch 4063/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0658 - accuracy: 0.9781 - val_loss: 0.8430 - val_accuracy: 0.8143\n",
      "Epoch 4064/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0663 - accuracy: 0.9778 - val_loss: 0.6635 - val_accuracy: 0.8475\n",
      "Epoch 4065/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0674 - accuracy: 0.9770 - val_loss: 0.6637 - val_accuracy: 0.8460\n",
      "Epoch 4066/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0702 - accuracy: 0.9761 - val_loss: 0.6968 - val_accuracy: 0.8388\n",
      "Epoch 4067/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0756 - accuracy: 0.9748 - val_loss: 0.7727 - val_accuracy: 0.8198\n",
      "Epoch 4068/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0694 - accuracy: 0.9766 - val_loss: 0.7325 - val_accuracy: 0.8326\n",
      "Epoch 4069/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0731 - accuracy: 0.9752 - val_loss: 0.7174 - val_accuracy: 0.8318\n",
      "Epoch 4070/8000\n",
      "1463/1463 [==============================] - 17s 11ms/step - loss: 0.0734 - accuracy: 0.9758 - val_loss: 0.7139 - val_accuracy: 0.8352\n",
      "Epoch 4071/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0700 - accuracy: 0.9771 - val_loss: 0.7036 - val_accuracy: 0.8370\n",
      "Epoch 4072/8000\n",
      "1463/1463 [==============================] - 17s 11ms/step - loss: 0.0731 - accuracy: 0.9757 - val_loss: 0.7398 - val_accuracy: 0.8333\n",
      "Epoch 4073/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0737 - accuracy: 0.9751 - val_loss: 0.6883 - val_accuracy: 0.8375\n",
      "Epoch 4074/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0680 - accuracy: 0.9773 - val_loss: 0.7097 - val_accuracy: 0.8363\n",
      "Epoch 4075/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0747 - accuracy: 0.9753 - val_loss: 0.6632 - val_accuracy: 0.8435\n",
      "Epoch 4076/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0666 - accuracy: 0.9775 - val_loss: 0.7838 - val_accuracy: 0.8236\n",
      "Epoch 4077/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0715 - accuracy: 0.9758 - val_loss: 0.7220 - val_accuracy: 0.8312\n",
      "Epoch 4078/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0666 - accuracy: 0.9782 - val_loss: 0.7128 - val_accuracy: 0.8339\n",
      "Epoch 4079/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0721 - accuracy: 0.9764 - val_loss: 0.7661 - val_accuracy: 0.8235\n",
      "Epoch 4080/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0703 - accuracy: 0.9768 - val_loss: 0.6659 - val_accuracy: 0.8420\n",
      "Epoch 4081/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0665 - accuracy: 0.9770 - val_loss: 0.7928 - val_accuracy: 0.8227\n",
      "Epoch 4082/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0671 - accuracy: 0.9782 - val_loss: 0.6607 - val_accuracy: 0.8406\n",
      "Epoch 4083/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0683 - accuracy: 0.9773 - val_loss: 0.7882 - val_accuracy: 0.8232\n",
      "Epoch 4084/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0725 - accuracy: 0.9759 - val_loss: 0.7360 - val_accuracy: 0.8303\n",
      "Epoch 4085/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0678 - accuracy: 0.9771 - val_loss: 0.6786 - val_accuracy: 0.8396\n",
      "Epoch 4086/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0732 - accuracy: 0.9753 - val_loss: 0.7391 - val_accuracy: 0.8268\n",
      "Epoch 4087/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0744 - accuracy: 0.9748 - val_loss: 0.7076 - val_accuracy: 0.8377\n",
      "Epoch 4088/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0708 - accuracy: 0.9760 - val_loss: 0.6920 - val_accuracy: 0.8405\n",
      "Epoch 4089/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0714 - accuracy: 0.9757 - val_loss: 0.6987 - val_accuracy: 0.8373\n",
      "Epoch 4090/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0675 - accuracy: 0.9772 - val_loss: 0.6764 - val_accuracy: 0.8446\n",
      "Epoch 4091/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0683 - accuracy: 0.9772 - val_loss: 0.7159 - val_accuracy: 0.8353\n",
      "Epoch 4092/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0676 - accuracy: 0.9777 - val_loss: 0.7070 - val_accuracy: 0.8369\n",
      "Epoch 4093/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0678 - accuracy: 0.9772 - val_loss: 0.6567 - val_accuracy: 0.8437\n",
      "Epoch 4094/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0679 - accuracy: 0.9773 - val_loss: 0.6913 - val_accuracy: 0.8343\n",
      "Epoch 4095/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0660 - accuracy: 0.9775 - val_loss: 0.6663 - val_accuracy: 0.8423\n",
      "Epoch 4096/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0739 - accuracy: 0.9759 - val_loss: 0.7129 - val_accuracy: 0.8373\n",
      "Epoch 4097/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0693 - accuracy: 0.9772 - val_loss: 0.6793 - val_accuracy: 0.8430\n",
      "Epoch 4098/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0668 - accuracy: 0.9780 - val_loss: 0.6726 - val_accuracy: 0.8429\n",
      "Epoch 4099/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0704 - accuracy: 0.9770 - val_loss: 0.7050 - val_accuracy: 0.8398\n",
      "Epoch 4100/8000\n",
      "1461/1463 [============================>.] - ETA: 0s - loss: 0.0652 - accuracy: 0.9783\n",
      "Epoch 4100: saving model to ./training_ckpt_20240109205949_v8_240109_d10000_n4096_b64_e8000_c100_Adamax\\cp-000004100.ckpt\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0652 - accuracy: 0.9783 - val_loss: 0.6674 - val_accuracy: 0.8415\n",
      "Epoch 4101/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0685 - accuracy: 0.9775 - val_loss: 0.6915 - val_accuracy: 0.8443\n",
      "Epoch 4102/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0672 - accuracy: 0.9773 - val_loss: 0.7386 - val_accuracy: 0.8359\n",
      "Epoch 4103/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0652 - accuracy: 0.9784 - val_loss: 0.6422 - val_accuracy: 0.8464\n",
      "Epoch 4104/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0721 - accuracy: 0.9759 - val_loss: 0.7927 - val_accuracy: 0.8240\n",
      "Epoch 4105/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0736 - accuracy: 0.9760 - val_loss: 0.6965 - val_accuracy: 0.8397\n",
      "Epoch 4106/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0659 - accuracy: 0.9781 - val_loss: 0.6958 - val_accuracy: 0.8366\n",
      "Epoch 4107/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0695 - accuracy: 0.9766 - val_loss: 0.7627 - val_accuracy: 0.8270\n",
      "Epoch 4108/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0691 - accuracy: 0.9770 - val_loss: 0.7110 - val_accuracy: 0.8339\n",
      "Epoch 4109/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0671 - accuracy: 0.9767 - val_loss: 0.6560 - val_accuracy: 0.8453\n",
      "Epoch 4110/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0679 - accuracy: 0.9769 - val_loss: 0.6839 - val_accuracy: 0.8389\n",
      "Epoch 4111/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0693 - accuracy: 0.9762 - val_loss: 0.6885 - val_accuracy: 0.8405\n",
      "Epoch 4112/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0629 - accuracy: 0.9792 - val_loss: 0.6686 - val_accuracy: 0.8426\n",
      "Epoch 4113/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0710 - accuracy: 0.9761 - val_loss: 0.8090 - val_accuracy: 0.8239\n",
      "Epoch 4114/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0680 - accuracy: 0.9770 - val_loss: 0.6724 - val_accuracy: 0.8447\n",
      "Epoch 4115/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0673 - accuracy: 0.9779 - val_loss: 0.6556 - val_accuracy: 0.8438\n",
      "Epoch 4116/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0665 - accuracy: 0.9784 - val_loss: 0.6998 - val_accuracy: 0.8363\n",
      "Epoch 4117/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0653 - accuracy: 0.9780 - val_loss: 0.6908 - val_accuracy: 0.8386\n",
      "Epoch 4118/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0785 - accuracy: 0.9753 - val_loss: 0.6847 - val_accuracy: 0.8402\n",
      "Epoch 4119/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0664 - accuracy: 0.9778 - val_loss: 0.7805 - val_accuracy: 0.8278\n",
      "Epoch 4120/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0672 - accuracy: 0.9778 - val_loss: 0.6960 - val_accuracy: 0.8417\n",
      "Epoch 4121/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0720 - accuracy: 0.9760 - val_loss: 0.6988 - val_accuracy: 0.8405\n",
      "Epoch 4122/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0661 - accuracy: 0.9778 - val_loss: 0.6447 - val_accuracy: 0.8465\n",
      "Epoch 4123/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0731 - accuracy: 0.9753 - val_loss: 0.6541 - val_accuracy: 0.8467\n",
      "Epoch 4124/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0682 - accuracy: 0.9773 - val_loss: 0.6859 - val_accuracy: 0.8406\n",
      "Epoch 4125/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0707 - accuracy: 0.9764 - val_loss: 0.7080 - val_accuracy: 0.8396\n",
      "Epoch 4126/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0729 - accuracy: 0.9757 - val_loss: 0.7084 - val_accuracy: 0.8387\n",
      "Epoch 4127/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0696 - accuracy: 0.9767 - val_loss: 0.6827 - val_accuracy: 0.8408\n",
      "Epoch 4128/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0727 - accuracy: 0.9758 - val_loss: 0.7794 - val_accuracy: 0.8252\n",
      "Epoch 4129/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0703 - accuracy: 0.9767 - val_loss: 0.7118 - val_accuracy: 0.8361\n",
      "Epoch 4130/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0627 - accuracy: 0.9789 - val_loss: 0.6823 - val_accuracy: 0.8398\n",
      "Epoch 4131/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0725 - accuracy: 0.9763 - val_loss: 0.7178 - val_accuracy: 0.8319\n",
      "Epoch 4132/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0729 - accuracy: 0.9751 - val_loss: 0.6878 - val_accuracy: 0.8407\n",
      "Epoch 4133/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0686 - accuracy: 0.9771 - val_loss: 0.6377 - val_accuracy: 0.8472\n",
      "Epoch 4134/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0621 - accuracy: 0.9793 - val_loss: 0.6827 - val_accuracy: 0.8432\n",
      "Epoch 4135/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0666 - accuracy: 0.9774 - val_loss: 0.7060 - val_accuracy: 0.8413\n",
      "Epoch 4136/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0698 - accuracy: 0.9773 - val_loss: 0.6972 - val_accuracy: 0.8362\n",
      "Epoch 4137/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0692 - accuracy: 0.9768 - val_loss: 0.6615 - val_accuracy: 0.8466\n",
      "Epoch 4138/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0632 - accuracy: 0.9790 - val_loss: 0.7004 - val_accuracy: 0.8366\n",
      "Epoch 4139/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0690 - accuracy: 0.9762 - val_loss: 0.6800 - val_accuracy: 0.8431\n",
      "Epoch 4140/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0713 - accuracy: 0.9761 - val_loss: 0.6836 - val_accuracy: 0.8396\n",
      "Epoch 4141/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0695 - accuracy: 0.9768 - val_loss: 0.7335 - val_accuracy: 0.8344\n",
      "Epoch 4142/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0633 - accuracy: 0.9785 - val_loss: 0.7102 - val_accuracy: 0.8346\n",
      "Epoch 4143/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0648 - accuracy: 0.9788 - val_loss: 0.6873 - val_accuracy: 0.8388\n",
      "Epoch 4144/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0669 - accuracy: 0.9773 - val_loss: 0.6774 - val_accuracy: 0.8436\n",
      "Epoch 4145/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0726 - accuracy: 0.9754 - val_loss: 0.7055 - val_accuracy: 0.8353\n",
      "Epoch 4146/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0642 - accuracy: 0.9782 - val_loss: 0.7105 - val_accuracy: 0.8336\n",
      "Epoch 4147/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0679 - accuracy: 0.9770 - val_loss: 0.8115 - val_accuracy: 0.8223\n",
      "Epoch 4148/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0705 - accuracy: 0.9770 - val_loss: 0.6742 - val_accuracy: 0.8422\n",
      "Epoch 4149/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0709 - accuracy: 0.9772 - val_loss: 0.7480 - val_accuracy: 0.8288\n",
      "Epoch 4150/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0680 - accuracy: 0.9773 - val_loss: 0.6432 - val_accuracy: 0.8497\n",
      "Epoch 4151/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0636 - accuracy: 0.9789 - val_loss: 0.6808 - val_accuracy: 0.8414\n",
      "Epoch 4152/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0725 - accuracy: 0.9756 - val_loss: 0.6630 - val_accuracy: 0.8476\n",
      "Epoch 4153/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0653 - accuracy: 0.9787 - val_loss: 0.6973 - val_accuracy: 0.8381\n",
      "Epoch 4154/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0657 - accuracy: 0.9778 - val_loss: 0.7387 - val_accuracy: 0.8317\n",
      "Epoch 4155/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0679 - accuracy: 0.9776 - val_loss: 0.6699 - val_accuracy: 0.8419\n",
      "Epoch 4156/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0644 - accuracy: 0.9787 - val_loss: 0.6663 - val_accuracy: 0.8428\n",
      "Epoch 4157/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0651 - accuracy: 0.9783 - val_loss: 0.6514 - val_accuracy: 0.8493\n",
      "Epoch 4158/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0707 - accuracy: 0.9768 - val_loss: 0.6891 - val_accuracy: 0.8364\n",
      "Epoch 4159/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0651 - accuracy: 0.9779 - val_loss: 0.6614 - val_accuracy: 0.8472\n",
      "Epoch 4160/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0684 - accuracy: 0.9774 - val_loss: 0.6622 - val_accuracy: 0.8456\n",
      "Epoch 4161/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0665 - accuracy: 0.9780 - val_loss: 0.7087 - val_accuracy: 0.8380\n",
      "Epoch 4162/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0665 - accuracy: 0.9776 - val_loss: 0.6997 - val_accuracy: 0.8418\n",
      "Epoch 4163/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0680 - accuracy: 0.9777 - val_loss: 0.6490 - val_accuracy: 0.8490\n",
      "Epoch 4164/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0630 - accuracy: 0.9790 - val_loss: 0.6761 - val_accuracy: 0.8413\n",
      "Epoch 4165/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0654 - accuracy: 0.9781 - val_loss: 0.6618 - val_accuracy: 0.8466\n",
      "Epoch 4166/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0639 - accuracy: 0.9787 - val_loss: 0.7638 - val_accuracy: 0.8331\n",
      "Epoch 4167/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0699 - accuracy: 0.9763 - val_loss: 0.6842 - val_accuracy: 0.8395\n",
      "Epoch 4168/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0619 - accuracy: 0.9791 - val_loss: 0.7202 - val_accuracy: 0.8395\n",
      "Epoch 4169/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0695 - accuracy: 0.9772 - val_loss: 0.6757 - val_accuracy: 0.8406\n",
      "Epoch 4170/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0627 - accuracy: 0.9786 - val_loss: 0.6421 - val_accuracy: 0.8481\n",
      "Epoch 4171/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0653 - accuracy: 0.9772 - val_loss: 0.6698 - val_accuracy: 0.8404\n",
      "Epoch 4172/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0714 - accuracy: 0.9764 - val_loss: 0.6830 - val_accuracy: 0.8424\n",
      "Epoch 4173/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0658 - accuracy: 0.9783 - val_loss: 0.7249 - val_accuracy: 0.8329\n",
      "Epoch 4174/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0716 - accuracy: 0.9762 - val_loss: 0.7362 - val_accuracy: 0.8339\n",
      "Epoch 4175/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0720 - accuracy: 0.9757 - val_loss: 0.7519 - val_accuracy: 0.8319\n",
      "Epoch 4176/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0701 - accuracy: 0.9767 - val_loss: 0.7067 - val_accuracy: 0.8398\n",
      "Epoch 4177/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0657 - accuracy: 0.9783 - val_loss: 0.7404 - val_accuracy: 0.8325\n",
      "Epoch 4178/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0678 - accuracy: 0.9771 - val_loss: 0.6391 - val_accuracy: 0.8494\n",
      "Epoch 4179/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0668 - accuracy: 0.9781 - val_loss: 0.6868 - val_accuracy: 0.8453\n",
      "Epoch 4180/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0661 - accuracy: 0.9779 - val_loss: 0.6709 - val_accuracy: 0.8436\n",
      "Epoch 4181/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0661 - accuracy: 0.9777 - val_loss: 0.6817 - val_accuracy: 0.8470\n",
      "Epoch 4182/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0695 - accuracy: 0.9774 - val_loss: 0.6424 - val_accuracy: 0.8460\n",
      "Epoch 4183/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0680 - accuracy: 0.9773 - val_loss: 0.7544 - val_accuracy: 0.8348\n",
      "Epoch 4184/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0695 - accuracy: 0.9768 - val_loss: 0.6914 - val_accuracy: 0.8373\n",
      "Epoch 4185/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0626 - accuracy: 0.9793 - val_loss: 0.6367 - val_accuracy: 0.8506\n",
      "Epoch 4186/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0640 - accuracy: 0.9792 - val_loss: 0.6677 - val_accuracy: 0.8438\n",
      "Epoch 4187/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0657 - accuracy: 0.9783 - val_loss: 0.6971 - val_accuracy: 0.8399\n",
      "Epoch 4188/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0682 - accuracy: 0.9772 - val_loss: 0.7323 - val_accuracy: 0.8334\n",
      "Epoch 4189/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0653 - accuracy: 0.9781 - val_loss: 0.7029 - val_accuracy: 0.8364\n",
      "Epoch 4190/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0626 - accuracy: 0.9794 - val_loss: 0.6946 - val_accuracy: 0.8413\n",
      "Epoch 4191/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0652 - accuracy: 0.9782 - val_loss: 0.7021 - val_accuracy: 0.8371\n",
      "Epoch 4192/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0690 - accuracy: 0.9768 - val_loss: 0.7133 - val_accuracy: 0.8390\n",
      "Epoch 4193/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0705 - accuracy: 0.9767 - val_loss: 0.6702 - val_accuracy: 0.8468\n",
      "Epoch 4194/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0648 - accuracy: 0.9785 - val_loss: 0.7281 - val_accuracy: 0.8272\n",
      "Epoch 4195/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0639 - accuracy: 0.9785 - val_loss: 0.6771 - val_accuracy: 0.8422\n",
      "Epoch 4196/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0702 - accuracy: 0.9767 - val_loss: 0.6888 - val_accuracy: 0.8426\n",
      "Epoch 4197/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0650 - accuracy: 0.9780 - val_loss: 0.6607 - val_accuracy: 0.8452\n",
      "Epoch 4198/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0746 - accuracy: 0.9756 - val_loss: 0.7035 - val_accuracy: 0.8402\n",
      "Epoch 4199/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0678 - accuracy: 0.9770 - val_loss: 0.7629 - val_accuracy: 0.8298\n",
      "Epoch 4200/8000\n",
      "1462/1463 [============================>.] - ETA: 0s - loss: 0.0645 - accuracy: 0.9787\n",
      "Epoch 4200: saving model to ./training_ckpt_20240109205949_v8_240109_d10000_n4096_b64_e8000_c100_Adamax\\cp-000004200.ckpt\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0645 - accuracy: 0.9787 - val_loss: 0.6942 - val_accuracy: 0.8386\n",
      "Epoch 4201/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0726 - accuracy: 0.9761 - val_loss: 0.7248 - val_accuracy: 0.8338\n",
      "Epoch 4202/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0689 - accuracy: 0.9770 - val_loss: 0.7484 - val_accuracy: 0.8324\n",
      "Epoch 4203/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0652 - accuracy: 0.9778 - val_loss: 0.7091 - val_accuracy: 0.8373\n",
      "Epoch 4204/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0720 - accuracy: 0.9758 - val_loss: 0.6980 - val_accuracy: 0.8390\n",
      "Epoch 4205/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0713 - accuracy: 0.9761 - val_loss: 0.7292 - val_accuracy: 0.8346\n",
      "Epoch 4206/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0672 - accuracy: 0.9776 - val_loss: 0.7049 - val_accuracy: 0.8383\n",
      "Epoch 4207/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0671 - accuracy: 0.9785 - val_loss: 0.6832 - val_accuracy: 0.8399\n",
      "Epoch 4208/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0696 - accuracy: 0.9772 - val_loss: 0.6821 - val_accuracy: 0.8374\n",
      "Epoch 4209/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0767 - accuracy: 0.9756 - val_loss: 0.7085 - val_accuracy: 0.8381\n",
      "Epoch 4210/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0654 - accuracy: 0.9777 - val_loss: 0.6980 - val_accuracy: 0.8394\n",
      "Epoch 4211/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0668 - accuracy: 0.9781 - val_loss: 0.6588 - val_accuracy: 0.8466\n",
      "Epoch 4212/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0695 - accuracy: 0.9769 - val_loss: 0.6802 - val_accuracy: 0.8393\n",
      "Epoch 4213/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0677 - accuracy: 0.9772 - val_loss: 0.6938 - val_accuracy: 0.8393\n",
      "Epoch 4214/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0650 - accuracy: 0.9790 - val_loss: 0.8225 - val_accuracy: 0.8201\n",
      "Epoch 4215/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0648 - accuracy: 0.9786 - val_loss: 0.6802 - val_accuracy: 0.8431\n",
      "Epoch 4216/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0688 - accuracy: 0.9772 - val_loss: 0.6502 - val_accuracy: 0.8467\n",
      "Epoch 4217/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0661 - accuracy: 0.9785 - val_loss: 0.6947 - val_accuracy: 0.8383\n",
      "Epoch 4218/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0663 - accuracy: 0.9776 - val_loss: 0.7000 - val_accuracy: 0.8413\n",
      "Epoch 4219/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0633 - accuracy: 0.9790 - val_loss: 0.7845 - val_accuracy: 0.8238\n",
      "Epoch 4220/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0654 - accuracy: 0.9780 - val_loss: 0.6832 - val_accuracy: 0.8423\n",
      "Epoch 4221/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0681 - accuracy: 0.9776 - val_loss: 0.6797 - val_accuracy: 0.8438\n",
      "Epoch 4222/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0649 - accuracy: 0.9788 - val_loss: 0.7223 - val_accuracy: 0.8386\n",
      "Epoch 4223/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0616 - accuracy: 0.9799 - val_loss: 0.6872 - val_accuracy: 0.8394\n",
      "Epoch 4224/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0683 - accuracy: 0.9772 - val_loss: 0.7113 - val_accuracy: 0.8415\n",
      "Epoch 4225/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0611 - accuracy: 0.9796 - val_loss: 0.6353 - val_accuracy: 0.8490\n",
      "Epoch 4226/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0652 - accuracy: 0.9782 - val_loss: 0.6957 - val_accuracy: 0.8404\n",
      "Epoch 4227/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0671 - accuracy: 0.9781 - val_loss: 0.7230 - val_accuracy: 0.8377\n",
      "Epoch 4228/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0660 - accuracy: 0.9782 - val_loss: 0.7622 - val_accuracy: 0.8238\n",
      "Epoch 4229/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0731 - accuracy: 0.9757 - val_loss: 0.7553 - val_accuracy: 0.8280\n",
      "Epoch 4230/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0692 - accuracy: 0.9774 - val_loss: 0.7811 - val_accuracy: 0.8293\n",
      "Epoch 4231/8000\n",
      "1463/1463 [==============================] - 12s 9ms/step - loss: 0.0690 - accuracy: 0.9774 - val_loss: 0.6585 - val_accuracy: 0.8469\n",
      "Epoch 4232/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0601 - accuracy: 0.9798 - val_loss: 0.7099 - val_accuracy: 0.8380\n",
      "Epoch 4233/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0675 - accuracy: 0.9774 - val_loss: 0.7438 - val_accuracy: 0.8310\n",
      "Epoch 4234/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0658 - accuracy: 0.9794 - val_loss: 0.6533 - val_accuracy: 0.8479\n",
      "Epoch 4235/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0607 - accuracy: 0.9794 - val_loss: 0.6766 - val_accuracy: 0.8443\n",
      "Epoch 4236/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0665 - accuracy: 0.9773 - val_loss: 0.6754 - val_accuracy: 0.8438\n",
      "Epoch 4237/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0694 - accuracy: 0.9771 - val_loss: 0.7974 - val_accuracy: 0.8249\n",
      "Epoch 4238/8000\n",
      "1463/1463 [==============================] - 11s 8ms/step - loss: 0.0646 - accuracy: 0.9782 - val_loss: 0.7069 - val_accuracy: 0.8389\n",
      "Epoch 4239/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0655 - accuracy: 0.9781 - val_loss: 0.6811 - val_accuracy: 0.8436\n",
      "Epoch 4240/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0679 - accuracy: 0.9770 - val_loss: 0.6890 - val_accuracy: 0.8422\n",
      "Epoch 4241/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0640 - accuracy: 0.9786 - val_loss: 0.6786 - val_accuracy: 0.8462\n",
      "Epoch 4242/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0624 - accuracy: 0.9795 - val_loss: 0.6961 - val_accuracy: 0.8410\n",
      "Epoch 4243/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0683 - accuracy: 0.9772 - val_loss: 0.7251 - val_accuracy: 0.8353\n",
      "Epoch 4244/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0651 - accuracy: 0.9784 - val_loss: 0.7009 - val_accuracy: 0.8406\n",
      "Epoch 4245/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0642 - accuracy: 0.9793 - val_loss: 0.6862 - val_accuracy: 0.8417\n",
      "Epoch 4246/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0623 - accuracy: 0.9793 - val_loss: 0.6539 - val_accuracy: 0.8472\n",
      "Epoch 4247/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0648 - accuracy: 0.9789 - val_loss: 0.6508 - val_accuracy: 0.8485\n",
      "Epoch 4248/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0658 - accuracy: 0.9789 - val_loss: 0.6639 - val_accuracy: 0.8439\n",
      "Epoch 4249/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0668 - accuracy: 0.9780 - val_loss: 0.6890 - val_accuracy: 0.8428\n",
      "Epoch 4250/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0621 - accuracy: 0.9797 - val_loss: 0.6896 - val_accuracy: 0.8418\n",
      "Epoch 4251/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0722 - accuracy: 0.9761 - val_loss: 0.6716 - val_accuracy: 0.8446\n",
      "Epoch 4252/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0639 - accuracy: 0.9793 - val_loss: 0.7444 - val_accuracy: 0.8365\n",
      "Epoch 4253/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0668 - accuracy: 0.9777 - val_loss: 0.7002 - val_accuracy: 0.8401\n",
      "Epoch 4254/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0648 - accuracy: 0.9781 - val_loss: 0.7372 - val_accuracy: 0.8358\n",
      "Epoch 4255/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0676 - accuracy: 0.9780 - val_loss: 0.6972 - val_accuracy: 0.8380\n",
      "Epoch 4256/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0630 - accuracy: 0.9790 - val_loss: 0.7007 - val_accuracy: 0.8403\n",
      "Epoch 4257/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0685 - accuracy: 0.9772 - val_loss: 0.7019 - val_accuracy: 0.8388\n",
      "Epoch 4258/8000\n",
      "1463/1463 [==============================] - 12s 9ms/step - loss: 0.0677 - accuracy: 0.9776 - val_loss: 0.6649 - val_accuracy: 0.8432\n",
      "Epoch 4259/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0704 - accuracy: 0.9770 - val_loss: 0.7086 - val_accuracy: 0.8364\n",
      "Epoch 4260/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0610 - accuracy: 0.9796 - val_loss: 0.6816 - val_accuracy: 0.8410\n",
      "Epoch 4261/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0669 - accuracy: 0.9780 - val_loss: 0.8304 - val_accuracy: 0.8251\n",
      "Epoch 4262/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0643 - accuracy: 0.9783 - val_loss: 0.7489 - val_accuracy: 0.8292\n",
      "Epoch 4263/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0713 - accuracy: 0.9770 - val_loss: 0.6867 - val_accuracy: 0.8436\n",
      "Epoch 4264/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0691 - accuracy: 0.9772 - val_loss: 0.6643 - val_accuracy: 0.8449\n",
      "Epoch 4265/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0665 - accuracy: 0.9783 - val_loss: 0.7030 - val_accuracy: 0.8402\n",
      "Epoch 4266/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0653 - accuracy: 0.9788 - val_loss: 0.8213 - val_accuracy: 0.8188\n",
      "Epoch 4267/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0654 - accuracy: 0.9787 - val_loss: 0.6496 - val_accuracy: 0.8485\n",
      "Epoch 4268/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0683 - accuracy: 0.9782 - val_loss: 0.7100 - val_accuracy: 0.8402\n",
      "Epoch 4269/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0665 - accuracy: 0.9783 - val_loss: 0.6980 - val_accuracy: 0.8392\n",
      "Epoch 4270/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0658 - accuracy: 0.9787 - val_loss: 0.6587 - val_accuracy: 0.8470\n",
      "Epoch 4271/8000\n",
      "1463/1463 [==============================] - 12s 9ms/step - loss: 0.0653 - accuracy: 0.9785 - val_loss: 0.7575 - val_accuracy: 0.8285\n",
      "Epoch 4272/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0645 - accuracy: 0.9785 - val_loss: 0.7544 - val_accuracy: 0.8330\n",
      "Epoch 4273/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0696 - accuracy: 0.9773 - val_loss: 0.7798 - val_accuracy: 0.8293\n",
      "Epoch 4274/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0673 - accuracy: 0.9779 - val_loss: 0.7389 - val_accuracy: 0.8391\n",
      "Epoch 4275/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0657 - accuracy: 0.9782 - val_loss: 0.7219 - val_accuracy: 0.8387\n",
      "Epoch 4276/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0665 - accuracy: 0.9779 - val_loss: 0.6671 - val_accuracy: 0.8441\n",
      "Epoch 4277/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0607 - accuracy: 0.9797 - val_loss: 0.7151 - val_accuracy: 0.8366\n",
      "Epoch 4278/8000\n",
      "1463/1463 [==============================] - 17s 11ms/step - loss: 0.0614 - accuracy: 0.9799 - val_loss: 0.6821 - val_accuracy: 0.8431\n",
      "Epoch 4279/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0668 - accuracy: 0.9783 - val_loss: 0.7509 - val_accuracy: 0.8305\n",
      "Epoch 4280/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0646 - accuracy: 0.9789 - val_loss: 0.7430 - val_accuracy: 0.8302\n",
      "Epoch 4281/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0590 - accuracy: 0.9805 - val_loss: 0.6833 - val_accuracy: 0.8413\n",
      "Epoch 4282/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0650 - accuracy: 0.9783 - val_loss: 0.6623 - val_accuracy: 0.8444\n",
      "Epoch 4283/8000\n",
      "1463/1463 [==============================] - 12s 9ms/step - loss: 0.0674 - accuracy: 0.9775 - val_loss: 0.6775 - val_accuracy: 0.8452\n",
      "Epoch 4284/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0655 - accuracy: 0.9782 - val_loss: 0.6566 - val_accuracy: 0.8466\n",
      "Epoch 4285/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0637 - accuracy: 0.9787 - val_loss: 0.6880 - val_accuracy: 0.8409\n",
      "Epoch 4286/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0615 - accuracy: 0.9793 - val_loss: 0.6728 - val_accuracy: 0.8437\n",
      "Epoch 4287/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0639 - accuracy: 0.9791 - val_loss: 0.7499 - val_accuracy: 0.8282\n",
      "Epoch 4288/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0686 - accuracy: 0.9771 - val_loss: 0.6821 - val_accuracy: 0.8458\n",
      "Epoch 4289/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0678 - accuracy: 0.9774 - val_loss: 0.6601 - val_accuracy: 0.8469\n",
      "Epoch 4290/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0657 - accuracy: 0.9782 - val_loss: 0.6686 - val_accuracy: 0.8462\n",
      "Epoch 4291/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0622 - accuracy: 0.9795 - val_loss: 0.6303 - val_accuracy: 0.8517\n",
      "Epoch 4292/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0684 - accuracy: 0.9771 - val_loss: 0.6805 - val_accuracy: 0.8422\n",
      "Epoch 4293/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0674 - accuracy: 0.9779 - val_loss: 0.8446 - val_accuracy: 0.8221\n",
      "Epoch 4294/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0635 - accuracy: 0.9793 - val_loss: 0.6906 - val_accuracy: 0.8405\n",
      "Epoch 4295/8000\n",
      "1463/1463 [==============================] - 15s 11ms/step - loss: 0.0669 - accuracy: 0.9784 - val_loss: 0.7171 - val_accuracy: 0.8359\n",
      "Epoch 4296/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0614 - accuracy: 0.9798 - val_loss: 0.7066 - val_accuracy: 0.8390\n",
      "Epoch 4297/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0651 - accuracy: 0.9785 - val_loss: 0.7144 - val_accuracy: 0.8383\n",
      "Epoch 4298/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0705 - accuracy: 0.9773 - val_loss: 0.8226 - val_accuracy: 0.8190\n",
      "Epoch 4299/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0657 - accuracy: 0.9781 - val_loss: 0.6397 - val_accuracy: 0.8493\n",
      "Epoch 4300/8000\n",
      "1459/1463 [============================>.] - ETA: 0s - loss: 0.0701 - accuracy: 0.9767\n",
      "Epoch 4300: saving model to ./training_ckpt_20240109205949_v8_240109_d10000_n4096_b64_e8000_c100_Adamax\\cp-000004300.ckpt\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0701 - accuracy: 0.9767 - val_loss: 0.6733 - val_accuracy: 0.8443\n",
      "Epoch 4301/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0718 - accuracy: 0.9763 - val_loss: 0.6716 - val_accuracy: 0.8472\n",
      "Epoch 4302/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0634 - accuracy: 0.9796 - val_loss: 0.6507 - val_accuracy: 0.8473\n",
      "Epoch 4303/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0617 - accuracy: 0.9792 - val_loss: 0.6836 - val_accuracy: 0.8452\n",
      "Epoch 4304/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0669 - accuracy: 0.9781 - val_loss: 0.6350 - val_accuracy: 0.8528\n",
      "Epoch 4305/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0646 - accuracy: 0.9795 - val_loss: 0.6478 - val_accuracy: 0.8474\n",
      "Epoch 4306/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0623 - accuracy: 0.9792 - val_loss: 0.6594 - val_accuracy: 0.8478\n",
      "Epoch 4307/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0625 - accuracy: 0.9788 - val_loss: 0.6525 - val_accuracy: 0.8504\n",
      "Epoch 4308/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0591 - accuracy: 0.9803 - val_loss: 0.6978 - val_accuracy: 0.8445\n",
      "Epoch 4309/8000\n",
      "1463/1463 [==============================] - 12s 9ms/step - loss: 0.0668 - accuracy: 0.9784 - val_loss: 0.6726 - val_accuracy: 0.8449\n",
      "Epoch 4310/8000\n",
      "1463/1463 [==============================] - 12s 9ms/step - loss: 0.0667 - accuracy: 0.9779 - val_loss: 0.6711 - val_accuracy: 0.8459\n",
      "Epoch 4311/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0631 - accuracy: 0.9791 - val_loss: 0.6802 - val_accuracy: 0.8422\n",
      "Epoch 4312/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0622 - accuracy: 0.9798 - val_loss: 0.6823 - val_accuracy: 0.8396\n",
      "Epoch 4313/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0734 - accuracy: 0.9760 - val_loss: 0.7590 - val_accuracy: 0.8263\n",
      "Epoch 4314/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0636 - accuracy: 0.9787 - val_loss: 0.6401 - val_accuracy: 0.8483\n",
      "Epoch 4315/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0657 - accuracy: 0.9788 - val_loss: 0.6495 - val_accuracy: 0.8504\n",
      "Epoch 4316/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0691 - accuracy: 0.9770 - val_loss: 0.6777 - val_accuracy: 0.8455\n",
      "Epoch 4317/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0609 - accuracy: 0.9803 - val_loss: 0.6844 - val_accuracy: 0.8394\n",
      "Epoch 4318/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0616 - accuracy: 0.9796 - val_loss: 0.7049 - val_accuracy: 0.8401\n",
      "Epoch 4319/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0640 - accuracy: 0.9791 - val_loss: 0.7293 - val_accuracy: 0.8339\n",
      "Epoch 4320/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0665 - accuracy: 0.9782 - val_loss: 0.6721 - val_accuracy: 0.8467\n",
      "Epoch 4321/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0646 - accuracy: 0.9790 - val_loss: 0.7087 - val_accuracy: 0.8370\n",
      "Epoch 4322/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0732 - accuracy: 0.9758 - val_loss: 0.6705 - val_accuracy: 0.8445\n",
      "Epoch 4323/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0605 - accuracy: 0.9801 - val_loss: 0.7146 - val_accuracy: 0.8411\n",
      "Epoch 4324/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0648 - accuracy: 0.9786 - val_loss: 0.7035 - val_accuracy: 0.8408\n",
      "Epoch 4325/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0662 - accuracy: 0.9782 - val_loss: 0.7199 - val_accuracy: 0.8388\n",
      "Epoch 4326/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0707 - accuracy: 0.9769 - val_loss: 0.7648 - val_accuracy: 0.8263\n",
      "Epoch 4327/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0688 - accuracy: 0.9781 - val_loss: 0.6213 - val_accuracy: 0.8546\n",
      "Epoch 4328/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0683 - accuracy: 0.9779 - val_loss: 0.7433 - val_accuracy: 0.8334\n",
      "Epoch 4329/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0665 - accuracy: 0.9782 - val_loss: 0.6844 - val_accuracy: 0.8430\n",
      "Epoch 4330/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0633 - accuracy: 0.9789 - val_loss: 0.6547 - val_accuracy: 0.8457\n",
      "Epoch 4331/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0631 - accuracy: 0.9794 - val_loss: 0.7406 - val_accuracy: 0.8349\n",
      "Epoch 4332/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0648 - accuracy: 0.9788 - val_loss: 0.6788 - val_accuracy: 0.8439\n",
      "Epoch 4333/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0592 - accuracy: 0.9806 - val_loss: 0.6739 - val_accuracy: 0.8436\n",
      "Epoch 4334/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0755 - accuracy: 0.9765 - val_loss: 0.7805 - val_accuracy: 0.8238\n",
      "Epoch 4335/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0671 - accuracy: 0.9778 - val_loss: 0.8497 - val_accuracy: 0.8194\n",
      "Epoch 4336/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0618 - accuracy: 0.9798 - val_loss: 0.6603 - val_accuracy: 0.8498\n",
      "Epoch 4337/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0679 - accuracy: 0.9774 - val_loss: 0.6741 - val_accuracy: 0.8462\n",
      "Epoch 4338/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0696 - accuracy: 0.9767 - val_loss: 0.6558 - val_accuracy: 0.8454\n",
      "Epoch 4339/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0680 - accuracy: 0.9774 - val_loss: 0.6492 - val_accuracy: 0.8476\n",
      "Epoch 4340/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0632 - accuracy: 0.9790 - val_loss: 0.7097 - val_accuracy: 0.8370\n",
      "Epoch 4341/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0827 - accuracy: 0.9749 - val_loss: 0.7197 - val_accuracy: 0.8371\n",
      "Epoch 4342/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0706 - accuracy: 0.9768 - val_loss: 0.7508 - val_accuracy: 0.8302\n",
      "Epoch 4343/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0641 - accuracy: 0.9790 - val_loss: 0.6724 - val_accuracy: 0.8421\n",
      "Epoch 4344/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0656 - accuracy: 0.9783 - val_loss: 0.6728 - val_accuracy: 0.8445\n",
      "Epoch 4345/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0696 - accuracy: 0.9772 - val_loss: 0.7657 - val_accuracy: 0.8255\n",
      "Epoch 4346/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0674 - accuracy: 0.9774 - val_loss: 0.8037 - val_accuracy: 0.8230\n",
      "Epoch 4347/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0710 - accuracy: 0.9764 - val_loss: 0.7075 - val_accuracy: 0.8321\n",
      "Epoch 4348/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0671 - accuracy: 0.9776 - val_loss: 0.7014 - val_accuracy: 0.8379\n",
      "Epoch 4349/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0698 - accuracy: 0.9770 - val_loss: 0.6597 - val_accuracy: 0.8428\n",
      "Epoch 4350/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0642 - accuracy: 0.9791 - val_loss: 0.6958 - val_accuracy: 0.8420\n",
      "Epoch 4351/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0704 - accuracy: 0.9768 - val_loss: 0.7078 - val_accuracy: 0.8364\n",
      "Epoch 4352/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0715 - accuracy: 0.9762 - val_loss: 0.7118 - val_accuracy: 0.8390\n",
      "Epoch 4353/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0654 - accuracy: 0.9778 - val_loss: 0.6840 - val_accuracy: 0.8398\n",
      "Epoch 4354/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0739 - accuracy: 0.9757 - val_loss: 0.6362 - val_accuracy: 0.8487\n",
      "Epoch 4355/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0671 - accuracy: 0.9774 - val_loss: 0.6549 - val_accuracy: 0.8451\n",
      "Epoch 4356/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0645 - accuracy: 0.9786 - val_loss: 0.6878 - val_accuracy: 0.8405\n",
      "Epoch 4357/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0680 - accuracy: 0.9776 - val_loss: 0.6884 - val_accuracy: 0.8429\n",
      "Epoch 4358/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0639 - accuracy: 0.9787 - val_loss: 0.6581 - val_accuracy: 0.8471\n",
      "Epoch 4359/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0695 - accuracy: 0.9771 - val_loss: 0.7420 - val_accuracy: 0.8311\n",
      "Epoch 4360/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0634 - accuracy: 0.9789 - val_loss: 0.6586 - val_accuracy: 0.8503\n",
      "Epoch 4361/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0675 - accuracy: 0.9784 - val_loss: 0.6924 - val_accuracy: 0.8378\n",
      "Epoch 4362/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0671 - accuracy: 0.9780 - val_loss: 0.7116 - val_accuracy: 0.8436\n",
      "Epoch 4363/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0687 - accuracy: 0.9767 - val_loss: 0.6703 - val_accuracy: 0.8422\n",
      "Epoch 4364/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0668 - accuracy: 0.9778 - val_loss: 0.6411 - val_accuracy: 0.8498\n",
      "Epoch 4365/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0691 - accuracy: 0.9772 - val_loss: 0.6837 - val_accuracy: 0.8387\n",
      "Epoch 4366/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0709 - accuracy: 0.9769 - val_loss: 0.7308 - val_accuracy: 0.8379\n",
      "Epoch 4367/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0679 - accuracy: 0.9775 - val_loss: 0.6910 - val_accuracy: 0.8432\n",
      "Epoch 4368/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0649 - accuracy: 0.9782 - val_loss: 0.6843 - val_accuracy: 0.8399\n",
      "Epoch 4369/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0712 - accuracy: 0.9774 - val_loss: 0.7251 - val_accuracy: 0.8369\n",
      "Epoch 4370/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0650 - accuracy: 0.9785 - val_loss: 0.7518 - val_accuracy: 0.8377\n",
      "Epoch 4371/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0713 - accuracy: 0.9758 - val_loss: 0.6744 - val_accuracy: 0.8408\n",
      "Epoch 4372/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0638 - accuracy: 0.9790 - val_loss: 0.6889 - val_accuracy: 0.8406\n",
      "Epoch 4373/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0669 - accuracy: 0.9786 - val_loss: 0.7028 - val_accuracy: 0.8378\n",
      "Epoch 4374/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0677 - accuracy: 0.9777 - val_loss: 0.7276 - val_accuracy: 0.8343\n",
      "Epoch 4375/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0672 - accuracy: 0.9774 - val_loss: 0.7072 - val_accuracy: 0.8378\n",
      "Epoch 4376/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0663 - accuracy: 0.9780 - val_loss: 0.6986 - val_accuracy: 0.8393\n",
      "Epoch 4377/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0708 - accuracy: 0.9768 - val_loss: 0.6907 - val_accuracy: 0.8400\n",
      "Epoch 4378/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0620 - accuracy: 0.9799 - val_loss: 0.7127 - val_accuracy: 0.8419\n",
      "Epoch 4379/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0666 - accuracy: 0.9778 - val_loss: 0.6560 - val_accuracy: 0.8470\n",
      "Epoch 4380/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0657 - accuracy: 0.9790 - val_loss: 0.7211 - val_accuracy: 0.8367\n",
      "Epoch 4381/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0702 - accuracy: 0.9766 - val_loss: 0.6716 - val_accuracy: 0.8448\n",
      "Epoch 4382/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0671 - accuracy: 0.9791 - val_loss: 0.7215 - val_accuracy: 0.8376\n",
      "Epoch 4383/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0607 - accuracy: 0.9796 - val_loss: 0.6985 - val_accuracy: 0.8399\n",
      "Epoch 4384/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0635 - accuracy: 0.9789 - val_loss: 0.6895 - val_accuracy: 0.8421\n",
      "Epoch 4385/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0716 - accuracy: 0.9762 - val_loss: 0.7224 - val_accuracy: 0.8351\n",
      "Epoch 4386/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0672 - accuracy: 0.9782 - val_loss: 0.7510 - val_accuracy: 0.8312\n",
      "Epoch 4387/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0644 - accuracy: 0.9784 - val_loss: 0.6644 - val_accuracy: 0.8461\n",
      "Epoch 4388/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0678 - accuracy: 0.9776 - val_loss: 0.7013 - val_accuracy: 0.8388\n",
      "Epoch 4389/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0640 - accuracy: 0.9787 - val_loss: 0.7066 - val_accuracy: 0.8394\n",
      "Epoch 4390/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0655 - accuracy: 0.9782 - val_loss: 0.6818 - val_accuracy: 0.8403\n",
      "Epoch 4391/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0688 - accuracy: 0.9775 - val_loss: 0.6683 - val_accuracy: 0.8436\n",
      "Epoch 4392/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0676 - accuracy: 0.9777 - val_loss: 0.6761 - val_accuracy: 0.8442\n",
      "Epoch 4393/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0624 - accuracy: 0.9796 - val_loss: 0.6517 - val_accuracy: 0.8455\n",
      "Epoch 4394/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0610 - accuracy: 0.9801 - val_loss: 0.6374 - val_accuracy: 0.8507\n",
      "Epoch 4395/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0712 - accuracy: 0.9760 - val_loss: 0.6630 - val_accuracy: 0.8473\n",
      "Epoch 4396/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0632 - accuracy: 0.9793 - val_loss: 0.8106 - val_accuracy: 0.8232\n",
      "Epoch 4397/8000\n",
      "1463/1463 [==============================] - 15s 11ms/step - loss: 0.0714 - accuracy: 0.9768 - val_loss: 0.6244 - val_accuracy: 0.8514\n",
      "Epoch 4398/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0641 - accuracy: 0.9792 - val_loss: 0.7026 - val_accuracy: 0.8372\n",
      "Epoch 4399/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0693 - accuracy: 0.9778 - val_loss: 0.7153 - val_accuracy: 0.8356\n",
      "Epoch 4400/8000\n",
      "1462/1463 [============================>.] - ETA: 0s - loss: 0.0653 - accuracy: 0.9785\n",
      "Epoch 4400: saving model to ./training_ckpt_20240109205949_v8_240109_d10000_n4096_b64_e8000_c100_Adamax\\cp-000004400.ckpt\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0653 - accuracy: 0.9785 - val_loss: 0.8065 - val_accuracy: 0.8210\n",
      "Epoch 4401/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0676 - accuracy: 0.9774 - val_loss: 0.7088 - val_accuracy: 0.8401\n",
      "Epoch 4402/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0692 - accuracy: 0.9775 - val_loss: 0.7289 - val_accuracy: 0.8336\n",
      "Epoch 4403/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0663 - accuracy: 0.9784 - val_loss: 0.7079 - val_accuracy: 0.8380\n",
      "Epoch 4404/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0649 - accuracy: 0.9793 - val_loss: 0.6610 - val_accuracy: 0.8412\n",
      "Epoch 4405/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0614 - accuracy: 0.9796 - val_loss: 0.7481 - val_accuracy: 0.8300\n",
      "Epoch 4406/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0655 - accuracy: 0.9785 - val_loss: 0.7092 - val_accuracy: 0.8400\n",
      "Epoch 4407/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0683 - accuracy: 0.9777 - val_loss: 0.7379 - val_accuracy: 0.8338\n",
      "Epoch 4408/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0612 - accuracy: 0.9798 - val_loss: 0.6848 - val_accuracy: 0.8407\n",
      "Epoch 4409/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0680 - accuracy: 0.9780 - val_loss: 0.7926 - val_accuracy: 0.8252\n",
      "Epoch 4410/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0750 - accuracy: 0.9752 - val_loss: 0.6845 - val_accuracy: 0.8422\n",
      "Epoch 4411/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0662 - accuracy: 0.9785 - val_loss: 0.7418 - val_accuracy: 0.8370\n",
      "Epoch 4412/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0668 - accuracy: 0.9780 - val_loss: 0.7056 - val_accuracy: 0.8355\n",
      "Epoch 4413/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0692 - accuracy: 0.9774 - val_loss: 0.7020 - val_accuracy: 0.8371\n",
      "Epoch 4414/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0647 - accuracy: 0.9784 - val_loss: 0.6817 - val_accuracy: 0.8423\n",
      "Epoch 4415/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0710 - accuracy: 0.9761 - val_loss: 0.7529 - val_accuracy: 0.8300\n",
      "Epoch 4416/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0707 - accuracy: 0.9770 - val_loss: 0.6861 - val_accuracy: 0.8400\n",
      "Epoch 4417/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0720 - accuracy: 0.9762 - val_loss: 0.6714 - val_accuracy: 0.8420\n",
      "Epoch 4418/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0656 - accuracy: 0.9781 - val_loss: 0.6667 - val_accuracy: 0.8465\n",
      "Epoch 4419/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0662 - accuracy: 0.9779 - val_loss: 0.7715 - val_accuracy: 0.8258\n",
      "Epoch 4420/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0644 - accuracy: 0.9788 - val_loss: 0.7260 - val_accuracy: 0.8350\n",
      "Epoch 4421/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0663 - accuracy: 0.9782 - val_loss: 0.6448 - val_accuracy: 0.8499\n",
      "Epoch 4422/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0622 - accuracy: 0.9790 - val_loss: 0.7371 - val_accuracy: 0.8375\n",
      "Epoch 4423/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0624 - accuracy: 0.9783 - val_loss: 0.6729 - val_accuracy: 0.8439\n",
      "Epoch 4424/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0666 - accuracy: 0.9786 - val_loss: 0.6914 - val_accuracy: 0.8428\n",
      "Epoch 4425/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0596 - accuracy: 0.9810 - val_loss: 0.6747 - val_accuracy: 0.8435\n",
      "Epoch 4426/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0692 - accuracy: 0.9769 - val_loss: 0.7456 - val_accuracy: 0.8302\n",
      "Epoch 4427/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0604 - accuracy: 0.9799 - val_loss: 0.7162 - val_accuracy: 0.8402\n",
      "Epoch 4428/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0656 - accuracy: 0.9782 - val_loss: 0.6759 - val_accuracy: 0.8411\n",
      "Epoch 4429/8000\n",
      "1463/1463 [==============================] - 15s 11ms/step - loss: 0.0645 - accuracy: 0.9783 - val_loss: 0.6842 - val_accuracy: 0.8429\n",
      "Epoch 4430/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0654 - accuracy: 0.9784 - val_loss: 0.7519 - val_accuracy: 0.8330\n",
      "Epoch 4431/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0679 - accuracy: 0.9776 - val_loss: 0.6515 - val_accuracy: 0.8474\n",
      "Epoch 4432/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0656 - accuracy: 0.9784 - val_loss: 0.6478 - val_accuracy: 0.8500\n",
      "Epoch 4433/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0699 - accuracy: 0.9776 - val_loss: 0.7009 - val_accuracy: 0.8357\n",
      "Epoch 4434/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0697 - accuracy: 0.9776 - val_loss: 0.7164 - val_accuracy: 0.8338\n",
      "Epoch 4435/8000\n",
      "1463/1463 [==============================] - 22s 15ms/step - loss: 0.0642 - accuracy: 0.9785 - val_loss: 0.6796 - val_accuracy: 0.8448\n",
      "Epoch 4436/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0646 - accuracy: 0.9789 - val_loss: 0.6734 - val_accuracy: 0.8413\n",
      "Epoch 4437/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0701 - accuracy: 0.9774 - val_loss: 0.6831 - val_accuracy: 0.8441\n",
      "Epoch 4438/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0616 - accuracy: 0.9797 - val_loss: 0.7389 - val_accuracy: 0.8377\n",
      "Epoch 4439/8000\n",
      "1463/1463 [==============================] - 18s 12ms/step - loss: 0.0723 - accuracy: 0.9771 - val_loss: 0.7174 - val_accuracy: 0.8370\n",
      "Epoch 4440/8000\n",
      "1463/1463 [==============================] - 19s 13ms/step - loss: 0.0635 - accuracy: 0.9787 - val_loss: 0.7042 - val_accuracy: 0.8396\n",
      "Epoch 4441/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0646 - accuracy: 0.9784 - val_loss: 0.6886 - val_accuracy: 0.8445\n",
      "Epoch 4442/8000\n",
      "1463/1463 [==============================] - 18s 12ms/step - loss: 0.0694 - accuracy: 0.9781 - val_loss: 0.7125 - val_accuracy: 0.8379\n",
      "Epoch 4443/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0689 - accuracy: 0.9777 - val_loss: 0.7726 - val_accuracy: 0.8286\n",
      "Epoch 4444/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0690 - accuracy: 0.9780 - val_loss: 0.7190 - val_accuracy: 0.8371\n",
      "Epoch 4445/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0601 - accuracy: 0.9809 - val_loss: 0.6948 - val_accuracy: 0.8427\n",
      "Epoch 4446/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0639 - accuracy: 0.9791 - val_loss: 0.6610 - val_accuracy: 0.8483\n",
      "Epoch 4447/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0666 - accuracy: 0.9783 - val_loss: 0.7300 - val_accuracy: 0.8360\n",
      "Epoch 4448/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0633 - accuracy: 0.9791 - val_loss: 0.6991 - val_accuracy: 0.8393\n",
      "Epoch 4449/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0628 - accuracy: 0.9789 - val_loss: 0.6910 - val_accuracy: 0.8421\n",
      "Epoch 4450/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0639 - accuracy: 0.9789 - val_loss: 0.6926 - val_accuracy: 0.8395\n",
      "Epoch 4451/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0743 - accuracy: 0.9764 - val_loss: 0.6595 - val_accuracy: 0.8478\n",
      "Epoch 4452/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0685 - accuracy: 0.9777 - val_loss: 0.6395 - val_accuracy: 0.8515\n",
      "Epoch 4453/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0599 - accuracy: 0.9801 - val_loss: 0.6797 - val_accuracy: 0.8454\n",
      "Epoch 4454/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0632 - accuracy: 0.9794 - val_loss: 0.6817 - val_accuracy: 0.8417\n",
      "Epoch 4455/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0647 - accuracy: 0.9792 - val_loss: 0.7052 - val_accuracy: 0.8413\n",
      "Epoch 4456/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0668 - accuracy: 0.9776 - val_loss: 0.6520 - val_accuracy: 0.8445\n",
      "Epoch 4457/8000\n",
      "1463/1463 [==============================] - 19s 13ms/step - loss: 0.0644 - accuracy: 0.9787 - val_loss: 0.6620 - val_accuracy: 0.8470\n",
      "Epoch 4458/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0688 - accuracy: 0.9770 - val_loss: 0.6876 - val_accuracy: 0.8428\n",
      "Epoch 4459/8000\n",
      "1463/1463 [==============================] - 22s 15ms/step - loss: 0.0636 - accuracy: 0.9785 - val_loss: 0.6474 - val_accuracy: 0.8480\n",
      "Epoch 4460/8000\n",
      "1463/1463 [==============================] - 22s 15ms/step - loss: 0.0687 - accuracy: 0.9776 - val_loss: 0.6842 - val_accuracy: 0.8442\n",
      "Epoch 4461/8000\n",
      "1463/1463 [==============================] - 19s 13ms/step - loss: 0.0659 - accuracy: 0.9795 - val_loss: 0.7098 - val_accuracy: 0.8392\n",
      "Epoch 4462/8000\n",
      "1463/1463 [==============================] - 20s 13ms/step - loss: 0.0683 - accuracy: 0.9780 - val_loss: 0.6756 - val_accuracy: 0.8458\n",
      "Epoch 4463/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0701 - accuracy: 0.9773 - val_loss: 0.6651 - val_accuracy: 0.8473\n",
      "Epoch 4464/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0638 - accuracy: 0.9789 - val_loss: 0.6643 - val_accuracy: 0.8495\n",
      "Epoch 4465/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0610 - accuracy: 0.9800 - val_loss: 0.7238 - val_accuracy: 0.8369\n",
      "Epoch 4466/8000\n",
      "1463/1463 [==============================] - 17s 11ms/step - loss: 0.0668 - accuracy: 0.9777 - val_loss: 0.6685 - val_accuracy: 0.8443\n",
      "Epoch 4467/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0635 - accuracy: 0.9792 - val_loss: 0.7728 - val_accuracy: 0.8308\n",
      "Epoch 4468/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0644 - accuracy: 0.9787 - val_loss: 0.6551 - val_accuracy: 0.8457\n",
      "Epoch 4469/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0628 - accuracy: 0.9797 - val_loss: 0.6596 - val_accuracy: 0.8449\n",
      "Epoch 4470/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0666 - accuracy: 0.9789 - val_loss: 0.7716 - val_accuracy: 0.8305\n",
      "Epoch 4471/8000\n",
      "1463/1463 [==============================] - 22s 15ms/step - loss: 0.0659 - accuracy: 0.9781 - val_loss: 0.6586 - val_accuracy: 0.8473\n",
      "Epoch 4472/8000\n",
      "1463/1463 [==============================] - 26s 18ms/step - loss: 0.0627 - accuracy: 0.9796 - val_loss: 0.6498 - val_accuracy: 0.8489\n",
      "Epoch 4473/8000\n",
      "1463/1463 [==============================] - 20s 14ms/step - loss: 0.0656 - accuracy: 0.9790 - val_loss: 0.7259 - val_accuracy: 0.8383\n",
      "Epoch 4474/8000\n",
      "1463/1463 [==============================] - 24s 16ms/step - loss: 0.0671 - accuracy: 0.9781 - val_loss: 0.7042 - val_accuracy: 0.8366\n",
      "Epoch 4475/8000\n",
      "1463/1463 [==============================] - 21s 15ms/step - loss: 0.0655 - accuracy: 0.9792 - val_loss: 0.6798 - val_accuracy: 0.8397\n",
      "Epoch 4476/8000\n",
      "1463/1463 [==============================] - 18s 12ms/step - loss: 0.0658 - accuracy: 0.9790 - val_loss: 0.6695 - val_accuracy: 0.8452\n",
      "Epoch 4477/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0642 - accuracy: 0.9789 - val_loss: 0.6664 - val_accuracy: 0.8470\n",
      "Epoch 4478/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0650 - accuracy: 0.9788 - val_loss: 0.6868 - val_accuracy: 0.8415\n",
      "Epoch 4479/8000\n",
      "1463/1463 [==============================] - 17s 11ms/step - loss: 0.0677 - accuracy: 0.9776 - val_loss: 0.7116 - val_accuracy: 0.8365\n",
      "Epoch 4480/8000\n",
      "1463/1463 [==============================] - 18s 12ms/step - loss: 0.0642 - accuracy: 0.9789 - val_loss: 0.7740 - val_accuracy: 0.8270\n",
      "Epoch 4481/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0662 - accuracy: 0.9786 - val_loss: 0.7091 - val_accuracy: 0.8371\n",
      "Epoch 4482/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0685 - accuracy: 0.9772 - val_loss: 0.6584 - val_accuracy: 0.8474\n",
      "Epoch 4483/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0696 - accuracy: 0.9772 - val_loss: 0.7419 - val_accuracy: 0.8351\n",
      "Epoch 4484/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0638 - accuracy: 0.9792 - val_loss: 0.6988 - val_accuracy: 0.8400\n",
      "Epoch 4485/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0624 - accuracy: 0.9796 - val_loss: 0.6871 - val_accuracy: 0.8460\n",
      "Epoch 4486/8000\n",
      "1463/1463 [==============================] - 17s 11ms/step - loss: 0.0628 - accuracy: 0.9797 - val_loss: 0.7114 - val_accuracy: 0.8362\n",
      "Epoch 4487/8000\n",
      "1463/1463 [==============================] - 15s 11ms/step - loss: 0.0638 - accuracy: 0.9787 - val_loss: 0.6962 - val_accuracy: 0.8403\n",
      "Epoch 4488/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0632 - accuracy: 0.9791 - val_loss: 0.7205 - val_accuracy: 0.8368\n",
      "Epoch 4489/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0650 - accuracy: 0.9789 - val_loss: 0.7293 - val_accuracy: 0.8384\n",
      "Epoch 4490/8000\n",
      "1463/1463 [==============================] - 15s 11ms/step - loss: 0.0644 - accuracy: 0.9794 - val_loss: 0.6699 - val_accuracy: 0.8417\n",
      "Epoch 4491/8000\n",
      "1463/1463 [==============================] - 15s 11ms/step - loss: 0.0647 - accuracy: 0.9785 - val_loss: 0.6977 - val_accuracy: 0.8401\n",
      "Epoch 4492/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0676 - accuracy: 0.9776 - val_loss: 0.6774 - val_accuracy: 0.8404\n",
      "Epoch 4493/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0642 - accuracy: 0.9788 - val_loss: 0.6652 - val_accuracy: 0.8450\n",
      "Epoch 4494/8000\n",
      "1463/1463 [==============================] - 15s 11ms/step - loss: 0.0648 - accuracy: 0.9782 - val_loss: 0.7798 - val_accuracy: 0.8268\n",
      "Epoch 4495/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0657 - accuracy: 0.9779 - val_loss: 0.7138 - val_accuracy: 0.8404\n",
      "Epoch 4496/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0606 - accuracy: 0.9805 - val_loss: 0.6470 - val_accuracy: 0.8490\n",
      "Epoch 4497/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0627 - accuracy: 0.9793 - val_loss: 0.6614 - val_accuracy: 0.8472\n",
      "Epoch 4498/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0626 - accuracy: 0.9796 - val_loss: 0.6561 - val_accuracy: 0.8497\n",
      "Epoch 4499/8000\n",
      "1463/1463 [==============================] - 15s 11ms/step - loss: 0.0618 - accuracy: 0.9796 - val_loss: 0.6903 - val_accuracy: 0.8395\n",
      "Epoch 4500/8000\n",
      "1460/1463 [============================>.] - ETA: 0s - loss: 0.0642 - accuracy: 0.9792\n",
      "Epoch 4500: saving model to ./training_ckpt_20240109205949_v8_240109_d10000_n4096_b64_e8000_c100_Adamax\\cp-000004500.ckpt\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0643 - accuracy: 0.9792 - val_loss: 0.6713 - val_accuracy: 0.8445\n",
      "Epoch 4501/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0617 - accuracy: 0.9796 - val_loss: 0.6522 - val_accuracy: 0.8491\n",
      "Epoch 4502/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0616 - accuracy: 0.9792 - val_loss: 0.6732 - val_accuracy: 0.8448\n",
      "Epoch 4503/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0626 - accuracy: 0.9789 - val_loss: 0.7044 - val_accuracy: 0.8435\n",
      "Epoch 4504/8000\n",
      "1463/1463 [==============================] - 15s 11ms/step - loss: 0.0667 - accuracy: 0.9782 - val_loss: 0.6618 - val_accuracy: 0.8439\n",
      "Epoch 4505/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0660 - accuracy: 0.9786 - val_loss: 0.6633 - val_accuracy: 0.8462\n",
      "Epoch 4506/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0732 - accuracy: 0.9783 - val_loss: 0.7107 - val_accuracy: 0.8359\n",
      "Epoch 4507/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0619 - accuracy: 0.9797 - val_loss: 0.7025 - val_accuracy: 0.8400\n",
      "Epoch 4508/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0649 - accuracy: 0.9792 - val_loss: 0.6504 - val_accuracy: 0.8471\n",
      "Epoch 4509/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0638 - accuracy: 0.9790 - val_loss: 0.7564 - val_accuracy: 0.8339\n",
      "Epoch 4510/8000\n",
      "1463/1463 [==============================] - 18s 12ms/step - loss: 0.0668 - accuracy: 0.9780 - val_loss: 0.6885 - val_accuracy: 0.8408\n",
      "Epoch 4511/8000\n",
      "1463/1463 [==============================] - 17s 11ms/step - loss: 0.0673 - accuracy: 0.9779 - val_loss: 0.7476 - val_accuracy: 0.8323\n",
      "Epoch 4512/8000\n",
      "1463/1463 [==============================] - 17s 11ms/step - loss: 0.0599 - accuracy: 0.9803 - val_loss: 0.6661 - val_accuracy: 0.8461\n",
      "Epoch 4513/8000\n",
      "1463/1463 [==============================] - 17s 11ms/step - loss: 0.0649 - accuracy: 0.9792 - val_loss: 0.6408 - val_accuracy: 0.8498\n",
      "Epoch 4514/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0591 - accuracy: 0.9806 - val_loss: 0.6832 - val_accuracy: 0.8429\n",
      "Epoch 4515/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0647 - accuracy: 0.9787 - val_loss: 0.6653 - val_accuracy: 0.8439\n",
      "Epoch 4516/8000\n",
      "1463/1463 [==============================] - 17s 11ms/step - loss: 0.0634 - accuracy: 0.9790 - val_loss: 0.7211 - val_accuracy: 0.8342\n",
      "Epoch 4517/8000\n",
      "1463/1463 [==============================] - 17s 11ms/step - loss: 0.0664 - accuracy: 0.9783 - val_loss: 0.7024 - val_accuracy: 0.8396\n",
      "Epoch 4518/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0661 - accuracy: 0.9786 - val_loss: 0.7220 - val_accuracy: 0.8378\n",
      "Epoch 4519/8000\n",
      "1463/1463 [==============================] - 18s 12ms/step - loss: 0.0628 - accuracy: 0.9793 - val_loss: 0.6858 - val_accuracy: 0.8419\n",
      "Epoch 4520/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0610 - accuracy: 0.9806 - val_loss: 0.6587 - val_accuracy: 0.8485\n",
      "Epoch 4521/8000\n",
      "1463/1463 [==============================] - 18s 12ms/step - loss: 0.0604 - accuracy: 0.9801 - val_loss: 0.6386 - val_accuracy: 0.8506\n",
      "Epoch 4522/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0621 - accuracy: 0.9796 - val_loss: 0.7295 - val_accuracy: 0.8356\n",
      "Epoch 4523/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0653 - accuracy: 0.9783 - val_loss: 0.7110 - val_accuracy: 0.8397\n",
      "Epoch 4524/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0638 - accuracy: 0.9791 - val_loss: 0.6672 - val_accuracy: 0.8429\n",
      "Epoch 4525/8000\n",
      "1463/1463 [==============================] - 18s 12ms/step - loss: 0.0605 - accuracy: 0.9803 - val_loss: 0.6960 - val_accuracy: 0.8440\n",
      "Epoch 4526/8000\n",
      "1463/1463 [==============================] - 18s 12ms/step - loss: 0.0644 - accuracy: 0.9787 - val_loss: 0.7456 - val_accuracy: 0.8323\n",
      "Epoch 4527/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0644 - accuracy: 0.9787 - val_loss: 0.6569 - val_accuracy: 0.8478\n",
      "Epoch 4528/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0618 - accuracy: 0.9798 - val_loss: 0.6682 - val_accuracy: 0.8469\n",
      "Epoch 4529/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0607 - accuracy: 0.9800 - val_loss: 0.6608 - val_accuracy: 0.8495\n",
      "Epoch 4530/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0637 - accuracy: 0.9793 - val_loss: 0.6903 - val_accuracy: 0.8458\n",
      "Epoch 4531/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0670 - accuracy: 0.9784 - val_loss: 0.6982 - val_accuracy: 0.8443\n",
      "Epoch 4532/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0691 - accuracy: 0.9777 - val_loss: 0.7231 - val_accuracy: 0.8371\n",
      "Epoch 4533/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0625 - accuracy: 0.9789 - val_loss: 0.6718 - val_accuracy: 0.8482\n",
      "Epoch 4534/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0679 - accuracy: 0.9778 - val_loss: 0.7325 - val_accuracy: 0.8352\n",
      "Epoch 4535/8000\n",
      "1463/1463 [==============================] - 15s 11ms/step - loss: 0.0675 - accuracy: 0.9779 - val_loss: 0.6763 - val_accuracy: 0.8459\n",
      "Epoch 4536/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0605 - accuracy: 0.9802 - val_loss: 0.6870 - val_accuracy: 0.8432\n",
      "Epoch 4537/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0589 - accuracy: 0.9804 - val_loss: 0.6619 - val_accuracy: 0.8467\n",
      "Epoch 4538/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0614 - accuracy: 0.9804 - val_loss: 0.6480 - val_accuracy: 0.8477\n",
      "Epoch 4539/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0653 - accuracy: 0.9792 - val_loss: 0.7029 - val_accuracy: 0.8438\n",
      "Epoch 4540/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0629 - accuracy: 0.9789 - val_loss: 0.6768 - val_accuracy: 0.8437\n",
      "Epoch 4541/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0607 - accuracy: 0.9800 - val_loss: 0.7208 - val_accuracy: 0.8365\n",
      "Epoch 4542/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0626 - accuracy: 0.9796 - val_loss: 0.7467 - val_accuracy: 0.8349\n",
      "Epoch 4543/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0665 - accuracy: 0.9785 - val_loss: 0.6959 - val_accuracy: 0.8399\n",
      "Epoch 4544/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0645 - accuracy: 0.9789 - val_loss: 0.7456 - val_accuracy: 0.8313\n",
      "Epoch 4545/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0670 - accuracy: 0.9779 - val_loss: 0.7167 - val_accuracy: 0.8363\n",
      "Epoch 4546/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0650 - accuracy: 0.9787 - val_loss: 0.8296 - val_accuracy: 0.8211\n",
      "Epoch 4547/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0683 - accuracy: 0.9776 - val_loss: 0.6473 - val_accuracy: 0.8488\n",
      "Epoch 4548/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0598 - accuracy: 0.9810 - val_loss: 0.7230 - val_accuracy: 0.8381\n",
      "Epoch 4549/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0652 - accuracy: 0.9788 - val_loss: 0.6820 - val_accuracy: 0.8457\n",
      "Epoch 4550/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0644 - accuracy: 0.9793 - val_loss: 0.7094 - val_accuracy: 0.8360\n",
      "Epoch 4551/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0617 - accuracy: 0.9801 - val_loss: 0.6945 - val_accuracy: 0.8409\n",
      "Epoch 4552/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0616 - accuracy: 0.9797 - val_loss: 0.7165 - val_accuracy: 0.8379\n",
      "Epoch 4553/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0606 - accuracy: 0.9798 - val_loss: 0.6825 - val_accuracy: 0.8448\n",
      "Epoch 4554/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0685 - accuracy: 0.9778 - val_loss: 0.6789 - val_accuracy: 0.8451\n",
      "Epoch 4555/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0606 - accuracy: 0.9803 - val_loss: 0.7492 - val_accuracy: 0.8327\n",
      "Epoch 4556/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0626 - accuracy: 0.9797 - val_loss: 0.6592 - val_accuracy: 0.8484\n",
      "Epoch 4557/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0651 - accuracy: 0.9787 - val_loss: 0.7225 - val_accuracy: 0.8383\n",
      "Epoch 4558/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0640 - accuracy: 0.9790 - val_loss: 0.7334 - val_accuracy: 0.8380\n",
      "Epoch 4559/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0618 - accuracy: 0.9795 - val_loss: 0.6582 - val_accuracy: 0.8457\n",
      "Epoch 4560/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0579 - accuracy: 0.9810 - val_loss: 0.6661 - val_accuracy: 0.8437\n",
      "Epoch 4561/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0674 - accuracy: 0.9779 - val_loss: 0.6768 - val_accuracy: 0.8447\n",
      "Epoch 4562/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0629 - accuracy: 0.9791 - val_loss: 0.6735 - val_accuracy: 0.8456\n",
      "Epoch 4563/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0661 - accuracy: 0.9789 - val_loss: 0.6662 - val_accuracy: 0.8477\n",
      "Epoch 4564/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0598 - accuracy: 0.9802 - val_loss: 0.6274 - val_accuracy: 0.8541\n",
      "Epoch 4565/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0663 - accuracy: 0.9781 - val_loss: 0.6900 - val_accuracy: 0.8413\n",
      "Epoch 4566/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0633 - accuracy: 0.9793 - val_loss: 0.7698 - val_accuracy: 0.8281\n",
      "Epoch 4567/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0624 - accuracy: 0.9793 - val_loss: 0.7866 - val_accuracy: 0.8226\n",
      "Epoch 4568/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0657 - accuracy: 0.9779 - val_loss: 0.6613 - val_accuracy: 0.8478\n",
      "Epoch 4569/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0614 - accuracy: 0.9799 - val_loss: 0.6594 - val_accuracy: 0.8469\n",
      "Epoch 4570/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0624 - accuracy: 0.9793 - val_loss: 0.7060 - val_accuracy: 0.8421\n",
      "Epoch 4571/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0647 - accuracy: 0.9786 - val_loss: 0.7212 - val_accuracy: 0.8341\n",
      "Epoch 4572/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0643 - accuracy: 0.9791 - val_loss: 0.6523 - val_accuracy: 0.8486\n",
      "Epoch 4573/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0652 - accuracy: 0.9794 - val_loss: 0.7301 - val_accuracy: 0.8374\n",
      "Epoch 4574/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0613 - accuracy: 0.9803 - val_loss: 0.6505 - val_accuracy: 0.8465\n",
      "Epoch 4575/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0643 - accuracy: 0.9791 - val_loss: 0.6956 - val_accuracy: 0.8413\n",
      "Epoch 4576/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0668 - accuracy: 0.9779 - val_loss: 0.7236 - val_accuracy: 0.8363\n",
      "Epoch 4577/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0599 - accuracy: 0.9805 - val_loss: 0.6542 - val_accuracy: 0.8474\n",
      "Epoch 4578/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0609 - accuracy: 0.9796 - val_loss: 0.7164 - val_accuracy: 0.8393\n",
      "Epoch 4579/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0640 - accuracy: 0.9793 - val_loss: 0.6676 - val_accuracy: 0.8445\n",
      "Epoch 4580/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0724 - accuracy: 0.9774 - val_loss: 0.6776 - val_accuracy: 0.8441\n",
      "Epoch 4581/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0591 - accuracy: 0.9799 - val_loss: 0.7172 - val_accuracy: 0.8357\n",
      "Epoch 4582/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0610 - accuracy: 0.9799 - val_loss: 0.6851 - val_accuracy: 0.8410\n",
      "Epoch 4583/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0660 - accuracy: 0.9783 - val_loss: 0.7003 - val_accuracy: 0.8399\n",
      "Epoch 4584/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0632 - accuracy: 0.9791 - val_loss: 0.6619 - val_accuracy: 0.8476\n",
      "Epoch 4585/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0627 - accuracy: 0.9795 - val_loss: 0.7692 - val_accuracy: 0.8278\n",
      "Epoch 4586/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0621 - accuracy: 0.9795 - val_loss: 0.7155 - val_accuracy: 0.8392\n",
      "Epoch 4587/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0619 - accuracy: 0.9799 - val_loss: 0.6923 - val_accuracy: 0.8408\n",
      "Epoch 4588/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0649 - accuracy: 0.9793 - val_loss: 0.6748 - val_accuracy: 0.8469\n",
      "Epoch 4589/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0631 - accuracy: 0.9791 - val_loss: 0.6863 - val_accuracy: 0.8446\n",
      "Epoch 4590/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0623 - accuracy: 0.9790 - val_loss: 0.6810 - val_accuracy: 0.8417\n",
      "Epoch 4591/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0597 - accuracy: 0.9807 - val_loss: 0.7392 - val_accuracy: 0.8321\n",
      "Epoch 4592/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0639 - accuracy: 0.9797 - val_loss: 0.7225 - val_accuracy: 0.8341\n",
      "Epoch 4593/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0667 - accuracy: 0.9787 - val_loss: 0.7007 - val_accuracy: 0.8446\n",
      "Epoch 4594/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0634 - accuracy: 0.9789 - val_loss: 0.6494 - val_accuracy: 0.8482\n",
      "Epoch 4595/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0577 - accuracy: 0.9818 - val_loss: 0.7108 - val_accuracy: 0.8376\n",
      "Epoch 4596/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0656 - accuracy: 0.9786 - val_loss: 0.6857 - val_accuracy: 0.8434\n",
      "Epoch 4597/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0624 - accuracy: 0.9794 - val_loss: 0.6847 - val_accuracy: 0.8421\n",
      "Epoch 4598/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0636 - accuracy: 0.9793 - val_loss: 0.7010 - val_accuracy: 0.8390\n",
      "Epoch 4599/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0642 - accuracy: 0.9787 - val_loss: 0.6298 - val_accuracy: 0.8512\n",
      "Epoch 4600/8000\n",
      "1462/1463 [============================>.] - ETA: 0s - loss: 0.0644 - accuracy: 0.9795\n",
      "Epoch 4600: saving model to ./training_ckpt_20240109205949_v8_240109_d10000_n4096_b64_e8000_c100_Adamax\\cp-000004600.ckpt\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0644 - accuracy: 0.9795 - val_loss: 0.6767 - val_accuracy: 0.8447\n",
      "Epoch 4601/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0633 - accuracy: 0.9790 - val_loss: 0.6725 - val_accuracy: 0.8510\n",
      "Epoch 4602/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0614 - accuracy: 0.9800 - val_loss: 0.6873 - val_accuracy: 0.8438\n",
      "Epoch 4603/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0590 - accuracy: 0.9807 - val_loss: 0.7128 - val_accuracy: 0.8364\n",
      "Epoch 4604/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0676 - accuracy: 0.9785 - val_loss: 0.6763 - val_accuracy: 0.8438\n",
      "Epoch 4605/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0637 - accuracy: 0.9793 - val_loss: 0.7523 - val_accuracy: 0.8306\n",
      "Epoch 4606/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0631 - accuracy: 0.9790 - val_loss: 0.6773 - val_accuracy: 0.8449\n",
      "Epoch 4607/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0623 - accuracy: 0.9798 - val_loss: 0.6830 - val_accuracy: 0.8463\n",
      "Epoch 4608/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0642 - accuracy: 0.9791 - val_loss: 0.6274 - val_accuracy: 0.8542\n",
      "Epoch 4609/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0601 - accuracy: 0.9810 - val_loss: 0.7341 - val_accuracy: 0.8369\n",
      "Epoch 4610/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0623 - accuracy: 0.9795 - val_loss: 0.6902 - val_accuracy: 0.8421\n",
      "Epoch 4611/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0665 - accuracy: 0.9789 - val_loss: 0.6971 - val_accuracy: 0.8393\n",
      "Epoch 4612/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0652 - accuracy: 0.9788 - val_loss: 0.7310 - val_accuracy: 0.8357\n",
      "Epoch 4613/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0672 - accuracy: 0.9787 - val_loss: 0.6808 - val_accuracy: 0.8451\n",
      "Epoch 4614/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0607 - accuracy: 0.9799 - val_loss: 0.6791 - val_accuracy: 0.8428\n",
      "Epoch 4615/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0603 - accuracy: 0.9810 - val_loss: 0.7396 - val_accuracy: 0.8364\n",
      "Epoch 4616/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0669 - accuracy: 0.9790 - val_loss: 0.7358 - val_accuracy: 0.8375\n",
      "Epoch 4617/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0610 - accuracy: 0.9800 - val_loss: 0.6942 - val_accuracy: 0.8447\n",
      "Epoch 4618/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0620 - accuracy: 0.9795 - val_loss: 0.6754 - val_accuracy: 0.8506\n",
      "Epoch 4619/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0601 - accuracy: 0.9804 - val_loss: 0.6526 - val_accuracy: 0.8470\n",
      "Epoch 4620/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0599 - accuracy: 0.9804 - val_loss: 0.6930 - val_accuracy: 0.8420\n",
      "Epoch 4621/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0681 - accuracy: 0.9778 - val_loss: 0.6460 - val_accuracy: 0.8487\n",
      "Epoch 4622/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0684 - accuracy: 0.9784 - val_loss: 0.8220 - val_accuracy: 0.8241\n",
      "Epoch 4623/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0607 - accuracy: 0.9802 - val_loss: 0.7062 - val_accuracy: 0.8399\n",
      "Epoch 4624/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0611 - accuracy: 0.9797 - val_loss: 0.6652 - val_accuracy: 0.8435\n",
      "Epoch 4625/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0590 - accuracy: 0.9813 - val_loss: 0.6803 - val_accuracy: 0.8445\n",
      "Epoch 4626/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0664 - accuracy: 0.9784 - val_loss: 0.6712 - val_accuracy: 0.8478\n",
      "Epoch 4627/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0616 - accuracy: 0.9802 - val_loss: 0.7017 - val_accuracy: 0.8426\n",
      "Epoch 4628/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0582 - accuracy: 0.9810 - val_loss: 0.6782 - val_accuracy: 0.8428\n",
      "Epoch 4629/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0630 - accuracy: 0.9794 - val_loss: 0.6775 - val_accuracy: 0.8477\n",
      "Epoch 4630/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0605 - accuracy: 0.9799 - val_loss: 0.6681 - val_accuracy: 0.8437\n",
      "Epoch 4631/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0660 - accuracy: 0.9792 - val_loss: 0.6880 - val_accuracy: 0.8409\n",
      "Epoch 4632/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0610 - accuracy: 0.9806 - val_loss: 0.6988 - val_accuracy: 0.8429\n",
      "Epoch 4633/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0657 - accuracy: 0.9785 - val_loss: 0.6680 - val_accuracy: 0.8485\n",
      "Epoch 4634/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0660 - accuracy: 0.9780 - val_loss: 0.6975 - val_accuracy: 0.8385\n",
      "Epoch 4635/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0704 - accuracy: 0.9784 - val_loss: 0.7140 - val_accuracy: 0.8362\n",
      "Epoch 4636/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0604 - accuracy: 0.9802 - val_loss: 0.6793 - val_accuracy: 0.8439\n",
      "Epoch 4637/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0591 - accuracy: 0.9807 - val_loss: 0.6940 - val_accuracy: 0.8411\n",
      "Epoch 4638/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0649 - accuracy: 0.9786 - val_loss: 0.6880 - val_accuracy: 0.8428\n",
      "Epoch 4639/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0640 - accuracy: 0.9795 - val_loss: 0.6642 - val_accuracy: 0.8486\n",
      "Epoch 4640/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0610 - accuracy: 0.9801 - val_loss: 0.7327 - val_accuracy: 0.8371\n",
      "Epoch 4641/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0638 - accuracy: 0.9789 - val_loss: 0.6798 - val_accuracy: 0.8461\n",
      "Epoch 4642/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0624 - accuracy: 0.9798 - val_loss: 0.6394 - val_accuracy: 0.8525\n",
      "Epoch 4643/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0648 - accuracy: 0.9788 - val_loss: 0.6841 - val_accuracy: 0.8435\n",
      "Epoch 4644/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0641 - accuracy: 0.9789 - val_loss: 0.6894 - val_accuracy: 0.8452\n",
      "Epoch 4645/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0653 - accuracy: 0.9789 - val_loss: 0.6936 - val_accuracy: 0.8399\n",
      "Epoch 4646/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0638 - accuracy: 0.9792 - val_loss: 0.6846 - val_accuracy: 0.8455\n",
      "Epoch 4647/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0592 - accuracy: 0.9803 - val_loss: 0.6948 - val_accuracy: 0.8408\n",
      "Epoch 4648/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0625 - accuracy: 0.9799 - val_loss: 0.6922 - val_accuracy: 0.8389\n",
      "Epoch 4649/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0586 - accuracy: 0.9813 - val_loss: 0.6993 - val_accuracy: 0.8380\n",
      "Epoch 4650/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0637 - accuracy: 0.9791 - val_loss: 0.6960 - val_accuracy: 0.8406\n",
      "Epoch 4651/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0702 - accuracy: 0.9773 - val_loss: 0.6441 - val_accuracy: 0.8508\n",
      "Epoch 4652/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0570 - accuracy: 0.9816 - val_loss: 0.7480 - val_accuracy: 0.8355\n",
      "Epoch 4653/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0575 - accuracy: 0.9813 - val_loss: 0.6815 - val_accuracy: 0.8431\n",
      "Epoch 4654/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0623 - accuracy: 0.9795 - val_loss: 0.7421 - val_accuracy: 0.8332\n",
      "Epoch 4655/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0697 - accuracy: 0.9783 - val_loss: 0.6948 - val_accuracy: 0.8434\n",
      "Epoch 4656/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0601 - accuracy: 0.9806 - val_loss: 0.6503 - val_accuracy: 0.8483\n",
      "Epoch 4657/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0613 - accuracy: 0.9797 - val_loss: 0.6745 - val_accuracy: 0.8458\n",
      "Epoch 4658/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0593 - accuracy: 0.9810 - val_loss: 0.7357 - val_accuracy: 0.8379\n",
      "Epoch 4659/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0673 - accuracy: 0.9783 - val_loss: 0.6816 - val_accuracy: 0.8422\n",
      "Epoch 4660/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0618 - accuracy: 0.9794 - val_loss: 0.7125 - val_accuracy: 0.8407\n",
      "Epoch 4661/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0709 - accuracy: 0.9775 - val_loss: 0.7095 - val_accuracy: 0.8363\n",
      "Epoch 4662/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0603 - accuracy: 0.9800 - val_loss: 0.6556 - val_accuracy: 0.8526\n",
      "Epoch 4663/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0618 - accuracy: 0.9796 - val_loss: 0.7233 - val_accuracy: 0.8394\n",
      "Epoch 4664/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0610 - accuracy: 0.9799 - val_loss: 0.6896 - val_accuracy: 0.8432\n",
      "Epoch 4665/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0639 - accuracy: 0.9791 - val_loss: 0.7488 - val_accuracy: 0.8358\n",
      "Epoch 4666/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0640 - accuracy: 0.9794 - val_loss: 0.7117 - val_accuracy: 0.8384\n",
      "Epoch 4667/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0620 - accuracy: 0.9798 - val_loss: 0.6916 - val_accuracy: 0.8441\n",
      "Epoch 4668/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0622 - accuracy: 0.9792 - val_loss: 0.6704 - val_accuracy: 0.8468\n",
      "Epoch 4669/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0587 - accuracy: 0.9809 - val_loss: 0.7990 - val_accuracy: 0.8257\n",
      "Epoch 4670/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0583 - accuracy: 0.9813 - val_loss: 0.7751 - val_accuracy: 0.8297\n",
      "Epoch 4671/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0654 - accuracy: 0.9798 - val_loss: 0.7285 - val_accuracy: 0.8344\n",
      "Epoch 4672/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0632 - accuracy: 0.9793 - val_loss: 0.6702 - val_accuracy: 0.8469\n",
      "Epoch 4673/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0658 - accuracy: 0.9787 - val_loss: 0.7019 - val_accuracy: 0.8402\n",
      "Epoch 4674/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0621 - accuracy: 0.9798 - val_loss: 0.6792 - val_accuracy: 0.8441\n",
      "Epoch 4675/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0609 - accuracy: 0.9801 - val_loss: 0.7438 - val_accuracy: 0.8309\n",
      "Epoch 4676/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0591 - accuracy: 0.9806 - val_loss: 0.6908 - val_accuracy: 0.8397\n",
      "Epoch 4677/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0630 - accuracy: 0.9791 - val_loss: 0.7374 - val_accuracy: 0.8334\n",
      "Epoch 4678/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0654 - accuracy: 0.9785 - val_loss: 0.6726 - val_accuracy: 0.8465\n",
      "Epoch 4679/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0622 - accuracy: 0.9799 - val_loss: 0.7083 - val_accuracy: 0.8384\n",
      "Epoch 4680/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0654 - accuracy: 0.9785 - val_loss: 0.6727 - val_accuracy: 0.8422\n",
      "Epoch 4681/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0640 - accuracy: 0.9790 - val_loss: 0.6958 - val_accuracy: 0.8452\n",
      "Epoch 4682/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0578 - accuracy: 0.9808 - val_loss: 0.6792 - val_accuracy: 0.8450\n",
      "Epoch 4683/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0668 - accuracy: 0.9790 - val_loss: 0.7281 - val_accuracy: 0.8338\n",
      "Epoch 4684/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0589 - accuracy: 0.9808 - val_loss: 0.6828 - val_accuracy: 0.8460\n",
      "Epoch 4685/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0567 - accuracy: 0.9818 - val_loss: 0.7003 - val_accuracy: 0.8406\n",
      "Epoch 4686/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0653 - accuracy: 0.9786 - val_loss: 0.6611 - val_accuracy: 0.8522\n",
      "Epoch 4687/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0580 - accuracy: 0.9812 - val_loss: 0.6995 - val_accuracy: 0.8393\n",
      "Epoch 4688/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0615 - accuracy: 0.9802 - val_loss: 0.6995 - val_accuracy: 0.8388\n",
      "Epoch 4689/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0647 - accuracy: 0.9788 - val_loss: 0.7163 - val_accuracy: 0.8364\n",
      "Epoch 4690/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0612 - accuracy: 0.9803 - val_loss: 0.7285 - val_accuracy: 0.8360\n",
      "Epoch 4691/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0639 - accuracy: 0.9800 - val_loss: 0.6802 - val_accuracy: 0.8443\n",
      "Epoch 4692/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0667 - accuracy: 0.9788 - val_loss: 0.6482 - val_accuracy: 0.8497\n",
      "Epoch 4693/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0621 - accuracy: 0.9793 - val_loss: 0.6640 - val_accuracy: 0.8497\n",
      "Epoch 4694/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0574 - accuracy: 0.9810 - val_loss: 0.6874 - val_accuracy: 0.8425\n",
      "Epoch 4695/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0601 - accuracy: 0.9806 - val_loss: 0.6592 - val_accuracy: 0.8487\n",
      "Epoch 4696/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0692 - accuracy: 0.9779 - val_loss: 0.8370 - val_accuracy: 0.8222\n",
      "Epoch 4697/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0629 - accuracy: 0.9797 - val_loss: 0.7416 - val_accuracy: 0.8333\n",
      "Epoch 4698/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0649 - accuracy: 0.9795 - val_loss: 0.6910 - val_accuracy: 0.8437\n",
      "Epoch 4699/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0612 - accuracy: 0.9797 - val_loss: 0.7072 - val_accuracy: 0.8395\n",
      "Epoch 4700/8000\n",
      "1461/1463 [============================>.] - ETA: 0s - loss: 0.0602 - accuracy: 0.9800\n",
      "Epoch 4700: saving model to ./training_ckpt_20240109205949_v8_240109_d10000_n4096_b64_e8000_c100_Adamax\\cp-000004700.ckpt\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0602 - accuracy: 0.9800 - val_loss: 0.7050 - val_accuracy: 0.8371\n",
      "Epoch 4701/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0619 - accuracy: 0.9795 - val_loss: 0.7094 - val_accuracy: 0.8434\n",
      "Epoch 4702/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0680 - accuracy: 0.9780 - val_loss: 0.6689 - val_accuracy: 0.8470\n",
      "Epoch 4703/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0666 - accuracy: 0.9794 - val_loss: 0.6556 - val_accuracy: 0.8514\n",
      "Epoch 4704/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0577 - accuracy: 0.9809 - val_loss: 0.7724 - val_accuracy: 0.8316\n",
      "Epoch 4705/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0604 - accuracy: 0.9804 - val_loss: 0.6632 - val_accuracy: 0.8476\n",
      "Epoch 4706/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0636 - accuracy: 0.9795 - val_loss: 0.6738 - val_accuracy: 0.8480\n",
      "Epoch 4707/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0638 - accuracy: 0.9789 - val_loss: 0.6817 - val_accuracy: 0.8457\n",
      "Epoch 4708/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0634 - accuracy: 0.9803 - val_loss: 0.7189 - val_accuracy: 0.8391\n",
      "Epoch 4709/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0689 - accuracy: 0.9773 - val_loss: 0.7332 - val_accuracy: 0.8336\n",
      "Epoch 4710/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0627 - accuracy: 0.9802 - val_loss: 0.6604 - val_accuracy: 0.8495\n",
      "Epoch 4711/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0612 - accuracy: 0.9797 - val_loss: 0.7069 - val_accuracy: 0.8386\n",
      "Epoch 4712/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0642 - accuracy: 0.9798 - val_loss: 0.6910 - val_accuracy: 0.8457\n",
      "Epoch 4713/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0621 - accuracy: 0.9803 - val_loss: 0.7723 - val_accuracy: 0.8338\n",
      "Epoch 4714/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0607 - accuracy: 0.9803 - val_loss: 0.6731 - val_accuracy: 0.8456\n",
      "Epoch 4715/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0609 - accuracy: 0.9804 - val_loss: 0.6643 - val_accuracy: 0.8459\n",
      "Epoch 4716/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0641 - accuracy: 0.9793 - val_loss: 0.6972 - val_accuracy: 0.8446\n",
      "Epoch 4717/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0615 - accuracy: 0.9794 - val_loss: 0.6624 - val_accuracy: 0.8426\n",
      "Epoch 4718/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0601 - accuracy: 0.9806 - val_loss: 0.6864 - val_accuracy: 0.8451\n",
      "Epoch 4719/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0624 - accuracy: 0.9797 - val_loss: 0.6718 - val_accuracy: 0.8454\n",
      "Epoch 4720/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0684 - accuracy: 0.9781 - val_loss: 0.7114 - val_accuracy: 0.8404\n",
      "Epoch 4721/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0635 - accuracy: 0.9795 - val_loss: 0.6954 - val_accuracy: 0.8448\n",
      "Epoch 4722/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0611 - accuracy: 0.9806 - val_loss: 0.6866 - val_accuracy: 0.8458\n",
      "Epoch 4723/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0574 - accuracy: 0.9807 - val_loss: 0.7515 - val_accuracy: 0.8306\n",
      "Epoch 4724/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0636 - accuracy: 0.9798 - val_loss: 0.6672 - val_accuracy: 0.8488\n",
      "Epoch 4725/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0614 - accuracy: 0.9800 - val_loss: 0.7073 - val_accuracy: 0.8409\n",
      "Epoch 4726/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0603 - accuracy: 0.9810 - val_loss: 0.7071 - val_accuracy: 0.8400\n",
      "Epoch 4727/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0605 - accuracy: 0.9802 - val_loss: 0.6574 - val_accuracy: 0.8496\n",
      "Epoch 4728/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0638 - accuracy: 0.9786 - val_loss: 0.6544 - val_accuracy: 0.8481\n",
      "Epoch 4729/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0663 - accuracy: 0.9785 - val_loss: 0.6730 - val_accuracy: 0.8475\n",
      "Epoch 4730/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0647 - accuracy: 0.9793 - val_loss: 0.7352 - val_accuracy: 0.8338\n",
      "Epoch 4731/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0652 - accuracy: 0.9789 - val_loss: 0.7583 - val_accuracy: 0.8340\n",
      "Epoch 4732/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0605 - accuracy: 0.9799 - val_loss: 0.6919 - val_accuracy: 0.8443\n",
      "Epoch 4733/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0635 - accuracy: 0.9793 - val_loss: 0.6615 - val_accuracy: 0.8474\n",
      "Epoch 4734/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0626 - accuracy: 0.9791 - val_loss: 0.6826 - val_accuracy: 0.8445\n",
      "Epoch 4735/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0614 - accuracy: 0.9795 - val_loss: 0.6870 - val_accuracy: 0.8447\n",
      "Epoch 4736/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0626 - accuracy: 0.9799 - val_loss: 0.7287 - val_accuracy: 0.8401\n",
      "Epoch 4737/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0678 - accuracy: 0.9794 - val_loss: 0.6464 - val_accuracy: 0.8510\n",
      "Epoch 4738/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0619 - accuracy: 0.9803 - val_loss: 0.7108 - val_accuracy: 0.8420\n",
      "Epoch 4739/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0603 - accuracy: 0.9806 - val_loss: 0.7215 - val_accuracy: 0.8402\n",
      "Epoch 4740/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0642 - accuracy: 0.9793 - val_loss: 0.6965 - val_accuracy: 0.8437\n",
      "Epoch 4741/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0578 - accuracy: 0.9811 - val_loss: 0.7097 - val_accuracy: 0.8411\n",
      "Epoch 4742/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0640 - accuracy: 0.9791 - val_loss: 0.7347 - val_accuracy: 0.8389\n",
      "Epoch 4743/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0581 - accuracy: 0.9812 - val_loss: 0.6668 - val_accuracy: 0.8457\n",
      "Epoch 4744/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0622 - accuracy: 0.9797 - val_loss: 0.6804 - val_accuracy: 0.8477\n",
      "Epoch 4745/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0577 - accuracy: 0.9812 - val_loss: 0.6269 - val_accuracy: 0.8542\n",
      "Epoch 4746/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0602 - accuracy: 0.9804 - val_loss: 0.6690 - val_accuracy: 0.8471\n",
      "Epoch 4747/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0623 - accuracy: 0.9800 - val_loss: 0.6878 - val_accuracy: 0.8447\n",
      "Epoch 4748/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0572 - accuracy: 0.9810 - val_loss: 0.7557 - val_accuracy: 0.8323\n",
      "Epoch 4749/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0648 - accuracy: 0.9792 - val_loss: 0.6491 - val_accuracy: 0.8538\n",
      "Epoch 4750/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0583 - accuracy: 0.9809 - val_loss: 0.6944 - val_accuracy: 0.8443\n",
      "Epoch 4751/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0645 - accuracy: 0.9793 - val_loss: 0.6789 - val_accuracy: 0.8482\n",
      "Epoch 4752/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0617 - accuracy: 0.9796 - val_loss: 0.6684 - val_accuracy: 0.8486\n",
      "Epoch 4753/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0591 - accuracy: 0.9812 - val_loss: 0.6269 - val_accuracy: 0.8516\n",
      "Epoch 4754/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0628 - accuracy: 0.9796 - val_loss: 0.7359 - val_accuracy: 0.8374\n",
      "Epoch 4755/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0616 - accuracy: 0.9803 - val_loss: 0.7056 - val_accuracy: 0.8438\n",
      "Epoch 4756/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0694 - accuracy: 0.9785 - val_loss: 0.6702 - val_accuracy: 0.8488\n",
      "Epoch 4757/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0578 - accuracy: 0.9815 - val_loss: 0.6925 - val_accuracy: 0.8427\n",
      "Epoch 4758/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0645 - accuracy: 0.9793 - val_loss: 0.6664 - val_accuracy: 0.8498\n",
      "Epoch 4759/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0671 - accuracy: 0.9783 - val_loss: 0.7067 - val_accuracy: 0.8430\n",
      "Epoch 4760/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0565 - accuracy: 0.9815 - val_loss: 0.7517 - val_accuracy: 0.8296\n",
      "Epoch 4761/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0673 - accuracy: 0.9784 - val_loss: 0.6984 - val_accuracy: 0.8401\n",
      "Epoch 4762/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0594 - accuracy: 0.9807 - val_loss: 0.7079 - val_accuracy: 0.8426\n",
      "Epoch 4763/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0559 - accuracy: 0.9811 - val_loss: 0.6762 - val_accuracy: 0.8467\n",
      "Epoch 4764/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0636 - accuracy: 0.9794 - val_loss: 0.6752 - val_accuracy: 0.8479\n",
      "Epoch 4765/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0608 - accuracy: 0.9804 - val_loss: 0.6995 - val_accuracy: 0.8420\n",
      "Epoch 4766/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0654 - accuracy: 0.9792 - val_loss: 0.6862 - val_accuracy: 0.8461\n",
      "Epoch 4767/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0665 - accuracy: 0.9792 - val_loss: 0.6882 - val_accuracy: 0.8475\n",
      "Epoch 4768/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0606 - accuracy: 0.9805 - val_loss: 0.7353 - val_accuracy: 0.8387\n",
      "Epoch 4769/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0661 - accuracy: 0.9786 - val_loss: 0.7417 - val_accuracy: 0.8392\n",
      "Epoch 4770/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0592 - accuracy: 0.9807 - val_loss: 0.7039 - val_accuracy: 0.8438\n",
      "Epoch 4771/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0600 - accuracy: 0.9807 - val_loss: 0.7444 - val_accuracy: 0.8335\n",
      "Epoch 4772/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0565 - accuracy: 0.9813 - val_loss: 0.6888 - val_accuracy: 0.8405\n",
      "Epoch 4773/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0564 - accuracy: 0.9812 - val_loss: 0.6834 - val_accuracy: 0.8437\n",
      "Epoch 4774/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0633 - accuracy: 0.9794 - val_loss: 0.6830 - val_accuracy: 0.8442\n",
      "Epoch 4775/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0633 - accuracy: 0.9796 - val_loss: 0.6956 - val_accuracy: 0.8465\n",
      "Epoch 4776/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0683 - accuracy: 0.9783 - val_loss: 0.6437 - val_accuracy: 0.8512\n",
      "Epoch 4777/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0568 - accuracy: 0.9816 - val_loss: 0.7087 - val_accuracy: 0.8371\n",
      "Epoch 4778/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0681 - accuracy: 0.9780 - val_loss: 0.6737 - val_accuracy: 0.8408\n",
      "Epoch 4779/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0604 - accuracy: 0.9803 - val_loss: 0.6692 - val_accuracy: 0.8466\n",
      "Epoch 4780/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0614 - accuracy: 0.9804 - val_loss: 0.6950 - val_accuracy: 0.8389\n",
      "Epoch 4781/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0593 - accuracy: 0.9808 - val_loss: 0.7539 - val_accuracy: 0.8349\n",
      "Epoch 4782/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0631 - accuracy: 0.9799 - val_loss: 0.7244 - val_accuracy: 0.8374\n",
      "Epoch 4783/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0631 - accuracy: 0.9797 - val_loss: 0.6916 - val_accuracy: 0.8456\n",
      "Epoch 4784/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0634 - accuracy: 0.9792 - val_loss: 0.7055 - val_accuracy: 0.8393\n",
      "Epoch 4785/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0610 - accuracy: 0.9805 - val_loss: 0.7443 - val_accuracy: 0.8310\n",
      "Epoch 4786/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0587 - accuracy: 0.9810 - val_loss: 0.6917 - val_accuracy: 0.8482\n",
      "Epoch 4787/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0603 - accuracy: 0.9807 - val_loss: 0.6748 - val_accuracy: 0.8490\n",
      "Epoch 4788/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0616 - accuracy: 0.9795 - val_loss: 0.6992 - val_accuracy: 0.8413\n",
      "Epoch 4789/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0574 - accuracy: 0.9812 - val_loss: 0.7112 - val_accuracy: 0.8376\n",
      "Epoch 4790/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0622 - accuracy: 0.9794 - val_loss: 0.7117 - val_accuracy: 0.8388\n",
      "Epoch 4791/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0600 - accuracy: 0.9812 - val_loss: 0.6442 - val_accuracy: 0.8504\n",
      "Epoch 4792/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0586 - accuracy: 0.9808 - val_loss: 0.8084 - val_accuracy: 0.8204\n",
      "Epoch 4793/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0596 - accuracy: 0.9808 - val_loss: 0.6482 - val_accuracy: 0.8505\n",
      "Epoch 4794/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0606 - accuracy: 0.9798 - val_loss: 0.7047 - val_accuracy: 0.8411\n",
      "Epoch 4795/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0618 - accuracy: 0.9799 - val_loss: 0.6865 - val_accuracy: 0.8449\n",
      "Epoch 4796/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0623 - accuracy: 0.9799 - val_loss: 0.6870 - val_accuracy: 0.8452\n",
      "Epoch 4797/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0578 - accuracy: 0.9812 - val_loss: 0.6877 - val_accuracy: 0.8458\n",
      "Epoch 4798/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0580 - accuracy: 0.9816 - val_loss: 0.7741 - val_accuracy: 0.8288\n",
      "Epoch 4799/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0630 - accuracy: 0.9794 - val_loss: 0.6701 - val_accuracy: 0.8434\n",
      "Epoch 4800/8000\n",
      "1463/1463 [==============================] - ETA: 0s - loss: 0.0578 - accuracy: 0.9815\n",
      "Epoch 4800: saving model to ./training_ckpt_20240109205949_v8_240109_d10000_n4096_b64_e8000_c100_Adamax\\cp-000004800.ckpt\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0578 - accuracy: 0.9815 - val_loss: 0.6782 - val_accuracy: 0.8493\n",
      "Epoch 4801/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0604 - accuracy: 0.9803 - val_loss: 0.6627 - val_accuracy: 0.8490\n",
      "Epoch 4802/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0563 - accuracy: 0.9816 - val_loss: 0.7052 - val_accuracy: 0.8414\n",
      "Epoch 4803/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0631 - accuracy: 0.9799 - val_loss: 0.6940 - val_accuracy: 0.8468\n",
      "Epoch 4804/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0583 - accuracy: 0.9812 - val_loss: 0.6772 - val_accuracy: 0.8452\n",
      "Epoch 4805/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0570 - accuracy: 0.9813 - val_loss: 0.7256 - val_accuracy: 0.8395\n",
      "Epoch 4806/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0602 - accuracy: 0.9805 - val_loss: 0.6763 - val_accuracy: 0.8455\n",
      "Epoch 4807/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0633 - accuracy: 0.9793 - val_loss: 0.6475 - val_accuracy: 0.8507\n",
      "Epoch 4808/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0653 - accuracy: 0.9789 - val_loss: 0.6599 - val_accuracy: 0.8484\n",
      "Epoch 4809/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0659 - accuracy: 0.9787 - val_loss: 0.6759 - val_accuracy: 0.8483\n",
      "Epoch 4810/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0555 - accuracy: 0.9821 - val_loss: 0.6752 - val_accuracy: 0.8480\n",
      "Epoch 4811/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0550 - accuracy: 0.9819 - val_loss: 0.6628 - val_accuracy: 0.8499\n",
      "Epoch 4812/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0640 - accuracy: 0.9793 - val_loss: 0.6601 - val_accuracy: 0.8526\n",
      "Epoch 4813/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0565 - accuracy: 0.9810 - val_loss: 0.6940 - val_accuracy: 0.8412\n",
      "Epoch 4814/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0555 - accuracy: 0.9819 - val_loss: 0.6838 - val_accuracy: 0.8454\n",
      "Epoch 4815/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0595 - accuracy: 0.9807 - val_loss: 0.6637 - val_accuracy: 0.8468\n",
      "Epoch 4816/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0598 - accuracy: 0.9812 - val_loss: 0.7174 - val_accuracy: 0.8379\n",
      "Epoch 4817/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0601 - accuracy: 0.9804 - val_loss: 0.7262 - val_accuracy: 0.8369\n",
      "Epoch 4818/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0576 - accuracy: 0.9814 - val_loss: 0.6759 - val_accuracy: 0.8465\n",
      "Epoch 4819/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0642 - accuracy: 0.9792 - val_loss: 0.7417 - val_accuracy: 0.8377\n",
      "Epoch 4820/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0556 - accuracy: 0.9820 - val_loss: 0.6759 - val_accuracy: 0.8471\n",
      "Epoch 4821/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0629 - accuracy: 0.9798 - val_loss: 0.7420 - val_accuracy: 0.8366\n",
      "Epoch 4822/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0619 - accuracy: 0.9794 - val_loss: 0.6766 - val_accuracy: 0.8464\n",
      "Epoch 4823/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0549 - accuracy: 0.9829 - val_loss: 0.7322 - val_accuracy: 0.8418\n",
      "Epoch 4824/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0688 - accuracy: 0.9781 - val_loss: 0.7152 - val_accuracy: 0.8388\n",
      "Epoch 4825/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0553 - accuracy: 0.9830 - val_loss: 0.9587 - val_accuracy: 0.8176\n",
      "Epoch 4826/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0666 - accuracy: 0.9790 - val_loss: 0.6894 - val_accuracy: 0.8426\n",
      "Epoch 4827/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0591 - accuracy: 0.9809 - val_loss: 0.6699 - val_accuracy: 0.8479\n",
      "Epoch 4828/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0636 - accuracy: 0.9800 - val_loss: 0.6940 - val_accuracy: 0.8452\n",
      "Epoch 4829/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0606 - accuracy: 0.9802 - val_loss: 0.7761 - val_accuracy: 0.8326\n",
      "Epoch 4830/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0633 - accuracy: 0.9798 - val_loss: 0.6808 - val_accuracy: 0.8465\n",
      "Epoch 4831/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0672 - accuracy: 0.9784 - val_loss: 0.6709 - val_accuracy: 0.8421\n",
      "Epoch 4832/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0582 - accuracy: 0.9809 - val_loss: 0.6647 - val_accuracy: 0.8476\n",
      "Epoch 4833/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0604 - accuracy: 0.9807 - val_loss: 0.6573 - val_accuracy: 0.8497\n",
      "Epoch 4834/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0600 - accuracy: 0.9810 - val_loss: 0.7102 - val_accuracy: 0.8417\n",
      "Epoch 4835/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0602 - accuracy: 0.9804 - val_loss: 0.7186 - val_accuracy: 0.8437\n",
      "Epoch 4836/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0697 - accuracy: 0.9781 - val_loss: 0.6937 - val_accuracy: 0.8448\n",
      "Epoch 4837/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0594 - accuracy: 0.9806 - val_loss: 0.7472 - val_accuracy: 0.8335\n",
      "Epoch 4838/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0612 - accuracy: 0.9812 - val_loss: 0.6883 - val_accuracy: 0.8438\n",
      "Epoch 4839/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0646 - accuracy: 0.9787 - val_loss: 0.6741 - val_accuracy: 0.8467\n",
      "Epoch 4840/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0650 - accuracy: 0.9786 - val_loss: 0.7186 - val_accuracy: 0.8406\n",
      "Epoch 4841/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0564 - accuracy: 0.9816 - val_loss: 0.6870 - val_accuracy: 0.8418\n",
      "Epoch 4842/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0566 - accuracy: 0.9810 - val_loss: 0.6799 - val_accuracy: 0.8452\n",
      "Epoch 4843/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0647 - accuracy: 0.9792 - val_loss: 0.6545 - val_accuracy: 0.8499\n",
      "Epoch 4844/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0575 - accuracy: 0.9814 - val_loss: 0.7505 - val_accuracy: 0.8351\n",
      "Epoch 4845/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0628 - accuracy: 0.9799 - val_loss: 0.6780 - val_accuracy: 0.8479\n",
      "Epoch 4846/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0552 - accuracy: 0.9824 - val_loss: 0.6574 - val_accuracy: 0.8482\n",
      "Epoch 4847/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0654 - accuracy: 0.9795 - val_loss: 0.6497 - val_accuracy: 0.8506\n",
      "Epoch 4848/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0580 - accuracy: 0.9819 - val_loss: 0.7065 - val_accuracy: 0.8459\n",
      "Epoch 4849/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0614 - accuracy: 0.9799 - val_loss: 0.7467 - val_accuracy: 0.8381\n",
      "Epoch 4850/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0604 - accuracy: 0.9811 - val_loss: 0.6716 - val_accuracy: 0.8477\n",
      "Epoch 4851/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0559 - accuracy: 0.9827 - val_loss: 0.7189 - val_accuracy: 0.8410\n",
      "Epoch 4852/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0593 - accuracy: 0.9815 - val_loss: 0.7615 - val_accuracy: 0.8346\n",
      "Epoch 4853/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0572 - accuracy: 0.9816 - val_loss: 0.7393 - val_accuracy: 0.8343\n",
      "Epoch 4854/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0616 - accuracy: 0.9805 - val_loss: 0.6655 - val_accuracy: 0.8471\n",
      "Epoch 4855/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0574 - accuracy: 0.9814 - val_loss: 0.7106 - val_accuracy: 0.8444\n",
      "Epoch 4856/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0607 - accuracy: 0.9804 - val_loss: 0.6680 - val_accuracy: 0.8478\n",
      "Epoch 4857/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0626 - accuracy: 0.9795 - val_loss: 0.6617 - val_accuracy: 0.8487\n",
      "Epoch 4858/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0596 - accuracy: 0.9812 - val_loss: 0.7211 - val_accuracy: 0.8404\n",
      "Epoch 4859/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0596 - accuracy: 0.9805 - val_loss: 0.7131 - val_accuracy: 0.8417\n",
      "Epoch 4860/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0628 - accuracy: 0.9798 - val_loss: 0.6992 - val_accuracy: 0.8413\n",
      "Epoch 4861/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0603 - accuracy: 0.9805 - val_loss: 0.6596 - val_accuracy: 0.8494\n",
      "Epoch 4862/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0572 - accuracy: 0.9816 - val_loss: 0.7215 - val_accuracy: 0.8399\n",
      "Epoch 4863/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0600 - accuracy: 0.9805 - val_loss: 0.6915 - val_accuracy: 0.8451\n",
      "Epoch 4864/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0632 - accuracy: 0.9794 - val_loss: 0.6473 - val_accuracy: 0.8515\n",
      "Epoch 4865/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0598 - accuracy: 0.9809 - val_loss: 0.6320 - val_accuracy: 0.8511\n",
      "Epoch 4866/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0591 - accuracy: 0.9812 - val_loss: 0.6764 - val_accuracy: 0.8451\n",
      "Epoch 4867/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0571 - accuracy: 0.9813 - val_loss: 0.6726 - val_accuracy: 0.8461\n",
      "Epoch 4868/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0572 - accuracy: 0.9812 - val_loss: 0.6542 - val_accuracy: 0.8515\n",
      "Epoch 4869/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0552 - accuracy: 0.9820 - val_loss: 0.6655 - val_accuracy: 0.8475\n",
      "Epoch 4870/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0619 - accuracy: 0.9803 - val_loss: 0.6790 - val_accuracy: 0.8455\n",
      "Epoch 4871/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0636 - accuracy: 0.9796 - val_loss: 0.6569 - val_accuracy: 0.8511\n",
      "Epoch 4872/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0635 - accuracy: 0.9797 - val_loss: 0.7128 - val_accuracy: 0.8390\n",
      "Epoch 4873/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0610 - accuracy: 0.9807 - val_loss: 0.6971 - val_accuracy: 0.8432\n",
      "Epoch 4874/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0605 - accuracy: 0.9808 - val_loss: 0.7685 - val_accuracy: 0.8332\n",
      "Epoch 4875/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0561 - accuracy: 0.9819 - val_loss: 0.6999 - val_accuracy: 0.8425\n",
      "Epoch 4876/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0613 - accuracy: 0.9804 - val_loss: 0.6995 - val_accuracy: 0.8430\n",
      "Epoch 4877/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0664 - accuracy: 0.9785 - val_loss: 0.6711 - val_accuracy: 0.8444\n",
      "Epoch 4878/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0609 - accuracy: 0.9802 - val_loss: 0.7201 - val_accuracy: 0.8387\n",
      "Epoch 4879/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0638 - accuracy: 0.9796 - val_loss: 0.6684 - val_accuracy: 0.8493\n",
      "Epoch 4880/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0603 - accuracy: 0.9806 - val_loss: 0.6964 - val_accuracy: 0.8410\n",
      "Epoch 4881/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0569 - accuracy: 0.9813 - val_loss: 0.7752 - val_accuracy: 0.8336\n",
      "Epoch 4882/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0620 - accuracy: 0.9801 - val_loss: 0.6731 - val_accuracy: 0.8467\n",
      "Epoch 4883/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0569 - accuracy: 0.9817 - val_loss: 0.6880 - val_accuracy: 0.8414\n",
      "Epoch 4884/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0602 - accuracy: 0.9804 - val_loss: 0.6852 - val_accuracy: 0.8437\n",
      "Epoch 4885/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0561 - accuracy: 0.9824 - val_loss: 0.6808 - val_accuracy: 0.8481\n",
      "Epoch 4886/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0668 - accuracy: 0.9779 - val_loss: 0.6791 - val_accuracy: 0.8462\n",
      "Epoch 4887/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0595 - accuracy: 0.9808 - val_loss: 0.6638 - val_accuracy: 0.8488\n",
      "Epoch 4888/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0603 - accuracy: 0.9809 - val_loss: 0.7707 - val_accuracy: 0.8285\n",
      "Epoch 4889/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0577 - accuracy: 0.9814 - val_loss: 0.7067 - val_accuracy: 0.8404\n",
      "Epoch 4890/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0664 - accuracy: 0.9782 - val_loss: 0.7955 - val_accuracy: 0.8289\n",
      "Epoch 4891/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0604 - accuracy: 0.9808 - val_loss: 0.7139 - val_accuracy: 0.8406\n",
      "Epoch 4892/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0611 - accuracy: 0.9799 - val_loss: 0.7056 - val_accuracy: 0.8419\n",
      "Epoch 4893/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0656 - accuracy: 0.9792 - val_loss: 0.6536 - val_accuracy: 0.8543\n",
      "Epoch 4894/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0597 - accuracy: 0.9808 - val_loss: 0.7313 - val_accuracy: 0.8370\n",
      "Epoch 4895/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0542 - accuracy: 0.9825 - val_loss: 0.6843 - val_accuracy: 0.8469\n",
      "Epoch 4896/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0563 - accuracy: 0.9818 - val_loss: 0.6511 - val_accuracy: 0.8528\n",
      "Epoch 4897/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0640 - accuracy: 0.9795 - val_loss: 0.7558 - val_accuracy: 0.8356\n",
      "Epoch 4898/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0552 - accuracy: 0.9820 - val_loss: 0.6796 - val_accuracy: 0.8480\n",
      "Epoch 4899/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0624 - accuracy: 0.9796 - val_loss: 0.7300 - val_accuracy: 0.8378\n",
      "Epoch 4900/8000\n",
      "1460/1463 [============================>.] - ETA: 0s - loss: 0.0596 - accuracy: 0.9807\n",
      "Epoch 4900: saving model to ./training_ckpt_20240109205949_v8_240109_d10000_n4096_b64_e8000_c100_Adamax\\cp-000004900.ckpt\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0597 - accuracy: 0.9807 - val_loss: 0.7625 - val_accuracy: 0.8322\n",
      "Epoch 4901/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0628 - accuracy: 0.9806 - val_loss: 0.6805 - val_accuracy: 0.8476\n",
      "Epoch 4902/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0632 - accuracy: 0.9798 - val_loss: 0.6959 - val_accuracy: 0.8410\n",
      "Epoch 4903/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0535 - accuracy: 0.9826 - val_loss: 0.6607 - val_accuracy: 0.8479\n",
      "Epoch 4904/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0609 - accuracy: 0.9805 - val_loss: 0.6827 - val_accuracy: 0.8433\n",
      "Epoch 4905/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0531 - accuracy: 0.9831 - val_loss: 0.7315 - val_accuracy: 0.8375\n",
      "Epoch 4906/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0609 - accuracy: 0.9808 - val_loss: 0.6764 - val_accuracy: 0.8459\n",
      "Epoch 4907/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0543 - accuracy: 0.9826 - val_loss: 0.6488 - val_accuracy: 0.8507\n",
      "Epoch 4908/8000\n",
      "1463/1463 [==============================] - 15s 11ms/step - loss: 0.0645 - accuracy: 0.9795 - val_loss: 0.7683 - val_accuracy: 0.8368\n",
      "Epoch 4909/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0632 - accuracy: 0.9788 - val_loss: 0.6719 - val_accuracy: 0.8487\n",
      "Epoch 4910/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0743 - accuracy: 0.9772 - val_loss: 0.6966 - val_accuracy: 0.8430\n",
      "Epoch 4911/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0687 - accuracy: 0.9786 - val_loss: 0.7498 - val_accuracy: 0.8345\n",
      "Epoch 4912/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0572 - accuracy: 0.9819 - val_loss: 0.7179 - val_accuracy: 0.8410\n",
      "Epoch 4913/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0617 - accuracy: 0.9803 - val_loss: 0.6779 - val_accuracy: 0.8467\n",
      "Epoch 4914/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0571 - accuracy: 0.9819 - val_loss: 0.6547 - val_accuracy: 0.8530\n",
      "Epoch 4915/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0582 - accuracy: 0.9815 - val_loss: 0.6981 - val_accuracy: 0.8419\n",
      "Epoch 4916/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0609 - accuracy: 0.9801 - val_loss: 0.7098 - val_accuracy: 0.8400\n",
      "Epoch 4917/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0540 - accuracy: 0.9822 - val_loss: 0.6753 - val_accuracy: 0.8487\n",
      "Epoch 4918/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0602 - accuracy: 0.9804 - val_loss: 0.7771 - val_accuracy: 0.8370\n",
      "Epoch 4919/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0623 - accuracy: 0.9800 - val_loss: 0.6564 - val_accuracy: 0.8520\n",
      "Epoch 4920/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0598 - accuracy: 0.9809 - val_loss: 0.6999 - val_accuracy: 0.8407\n",
      "Epoch 4921/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0634 - accuracy: 0.9798 - val_loss: 0.6920 - val_accuracy: 0.8468\n",
      "Epoch 4922/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0581 - accuracy: 0.9810 - val_loss: 0.7214 - val_accuracy: 0.8409\n",
      "Epoch 4923/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0609 - accuracy: 0.9805 - val_loss: 0.7055 - val_accuracy: 0.8416\n",
      "Epoch 4924/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0606 - accuracy: 0.9807 - val_loss: 0.6868 - val_accuracy: 0.8467\n",
      "Epoch 4925/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0612 - accuracy: 0.9800 - val_loss: 0.6682 - val_accuracy: 0.8475\n",
      "Epoch 4926/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0566 - accuracy: 0.9820 - val_loss: 0.7740 - val_accuracy: 0.8277\n",
      "Epoch 4927/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0584 - accuracy: 0.9817 - val_loss: 0.6278 - val_accuracy: 0.8514\n",
      "Epoch 4928/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0645 - accuracy: 0.9795 - val_loss: 0.6887 - val_accuracy: 0.8450\n",
      "Epoch 4929/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0628 - accuracy: 0.9800 - val_loss: 0.7642 - val_accuracy: 0.8328\n",
      "Epoch 4930/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0574 - accuracy: 0.9817 - val_loss: 0.6659 - val_accuracy: 0.8467\n",
      "Epoch 4931/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0582 - accuracy: 0.9813 - val_loss: 0.7402 - val_accuracy: 0.8336\n",
      "Epoch 4932/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0663 - accuracy: 0.9794 - val_loss: 0.6721 - val_accuracy: 0.8467\n",
      "Epoch 4933/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0610 - accuracy: 0.9809 - val_loss: 0.6791 - val_accuracy: 0.8503\n",
      "Epoch 4934/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0593 - accuracy: 0.9804 - val_loss: 0.6914 - val_accuracy: 0.8445\n",
      "Epoch 4935/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0604 - accuracy: 0.9799 - val_loss: 0.7086 - val_accuracy: 0.8426\n",
      "Epoch 4936/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0575 - accuracy: 0.9820 - val_loss: 0.6434 - val_accuracy: 0.8523\n",
      "Epoch 4937/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0637 - accuracy: 0.9792 - val_loss: 0.6725 - val_accuracy: 0.8481\n",
      "Epoch 4938/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0572 - accuracy: 0.9822 - val_loss: 0.7062 - val_accuracy: 0.8462\n",
      "Epoch 4939/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0616 - accuracy: 0.9802 - val_loss: 0.7100 - val_accuracy: 0.8385\n",
      "Epoch 4940/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0543 - accuracy: 0.9827 - val_loss: 0.7115 - val_accuracy: 0.8367\n",
      "Epoch 4941/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0593 - accuracy: 0.9806 - val_loss: 0.6480 - val_accuracy: 0.8518\n",
      "Epoch 4942/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0562 - accuracy: 0.9814 - val_loss: 0.7255 - val_accuracy: 0.8383\n",
      "Epoch 4943/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0605 - accuracy: 0.9806 - val_loss: 0.6543 - val_accuracy: 0.8519\n",
      "Epoch 4944/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0597 - accuracy: 0.9804 - val_loss: 0.6683 - val_accuracy: 0.8492\n",
      "Epoch 4945/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0558 - accuracy: 0.9816 - val_loss: 0.6204 - val_accuracy: 0.8574\n",
      "Epoch 4946/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0559 - accuracy: 0.9820 - val_loss: 0.6535 - val_accuracy: 0.8517\n",
      "Epoch 4947/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0589 - accuracy: 0.9808 - val_loss: 0.7083 - val_accuracy: 0.8421\n",
      "Epoch 4948/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0614 - accuracy: 0.9802 - val_loss: 0.6426 - val_accuracy: 0.8510\n",
      "Epoch 4949/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0623 - accuracy: 0.9798 - val_loss: 0.7210 - val_accuracy: 0.8352\n",
      "Epoch 4950/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0560 - accuracy: 0.9816 - val_loss: 0.6382 - val_accuracy: 0.8524\n",
      "Epoch 4951/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0659 - accuracy: 0.9790 - val_loss: 0.7023 - val_accuracy: 0.8442\n",
      "Epoch 4952/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0592 - accuracy: 0.9812 - val_loss: 0.6959 - val_accuracy: 0.8462\n",
      "Epoch 4953/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0559 - accuracy: 0.9819 - val_loss: 0.6685 - val_accuracy: 0.8499\n",
      "Epoch 4954/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0538 - accuracy: 0.9828 - val_loss: 0.7479 - val_accuracy: 0.8336\n",
      "Epoch 4955/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0621 - accuracy: 0.9798 - val_loss: 0.6832 - val_accuracy: 0.8459\n",
      "Epoch 4956/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0567 - accuracy: 0.9818 - val_loss: 0.6983 - val_accuracy: 0.8413\n",
      "Epoch 4957/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0591 - accuracy: 0.9817 - val_loss: 0.6979 - val_accuracy: 0.8445\n",
      "Epoch 4958/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0542 - accuracy: 0.9824 - val_loss: 0.7240 - val_accuracy: 0.8458\n",
      "Epoch 4959/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0589 - accuracy: 0.9816 - val_loss: 0.7006 - val_accuracy: 0.8452\n",
      "Epoch 4960/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0597 - accuracy: 0.9803 - val_loss: 0.6810 - val_accuracy: 0.8467\n",
      "Epoch 4961/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0568 - accuracy: 0.9814 - val_loss: 0.6811 - val_accuracy: 0.8491\n",
      "Epoch 4962/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0530 - accuracy: 0.9827 - val_loss: 0.7350 - val_accuracy: 0.8327\n",
      "Epoch 4963/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0538 - accuracy: 0.9827 - val_loss: 0.6929 - val_accuracy: 0.8459\n",
      "Epoch 4964/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0631 - accuracy: 0.9799 - val_loss: 0.6919 - val_accuracy: 0.8469\n",
      "Epoch 4965/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0581 - accuracy: 0.9810 - val_loss: 0.6679 - val_accuracy: 0.8457\n",
      "Epoch 4966/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0591 - accuracy: 0.9811 - val_loss: 0.7102 - val_accuracy: 0.8379\n",
      "Epoch 4967/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0585 - accuracy: 0.9818 - val_loss: 0.7203 - val_accuracy: 0.8436\n",
      "Epoch 4968/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0605 - accuracy: 0.9804 - val_loss: 0.7089 - val_accuracy: 0.8388\n",
      "Epoch 4969/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0587 - accuracy: 0.9811 - val_loss: 0.8722 - val_accuracy: 0.8221\n",
      "Epoch 4970/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0549 - accuracy: 0.9822 - val_loss: 0.6914 - val_accuracy: 0.8490\n",
      "Epoch 4971/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0589 - accuracy: 0.9806 - val_loss: 0.6631 - val_accuracy: 0.8507\n",
      "Epoch 4972/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0550 - accuracy: 0.9818 - val_loss: 0.6736 - val_accuracy: 0.8489\n",
      "Epoch 4973/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0590 - accuracy: 0.9810 - val_loss: 0.8228 - val_accuracy: 0.8244\n",
      "Epoch 4974/8000\n",
      "1463/1463 [==============================] - 15s 11ms/step - loss: 0.0561 - accuracy: 0.9821 - val_loss: 0.6899 - val_accuracy: 0.8451\n",
      "Epoch 4975/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0591 - accuracy: 0.9811 - val_loss: 0.7413 - val_accuracy: 0.8404\n",
      "Epoch 4976/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0588 - accuracy: 0.9811 - val_loss: 0.6779 - val_accuracy: 0.8481\n",
      "Epoch 4977/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0576 - accuracy: 0.9811 - val_loss: 0.6730 - val_accuracy: 0.8461\n",
      "Epoch 4978/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0560 - accuracy: 0.9819 - val_loss: 0.7275 - val_accuracy: 0.8422\n",
      "Epoch 4979/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0605 - accuracy: 0.9806 - val_loss: 0.6867 - val_accuracy: 0.8422\n",
      "Epoch 4980/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0568 - accuracy: 0.9816 - val_loss: 0.6435 - val_accuracy: 0.8524\n",
      "Epoch 4981/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0570 - accuracy: 0.9819 - val_loss: 0.6835 - val_accuracy: 0.8460\n",
      "Epoch 4982/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0585 - accuracy: 0.9808 - val_loss: 0.6626 - val_accuracy: 0.8513\n",
      "Epoch 4983/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0561 - accuracy: 0.9815 - val_loss: 0.7070 - val_accuracy: 0.8434\n",
      "Epoch 4984/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0595 - accuracy: 0.9811 - val_loss: 0.7078 - val_accuracy: 0.8391\n",
      "Epoch 4985/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0560 - accuracy: 0.9819 - val_loss: 0.7112 - val_accuracy: 0.8432\n",
      "Epoch 4986/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0557 - accuracy: 0.9819 - val_loss: 0.6816 - val_accuracy: 0.8499\n",
      "Epoch 4987/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0566 - accuracy: 0.9817 - val_loss: 0.6771 - val_accuracy: 0.8470\n",
      "Epoch 4988/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0608 - accuracy: 0.9807 - val_loss: 0.6872 - val_accuracy: 0.8454\n",
      "Epoch 4989/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0524 - accuracy: 0.9833 - val_loss: 0.7797 - val_accuracy: 0.8316\n",
      "Epoch 4990/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0598 - accuracy: 0.9808 - val_loss: 0.7249 - val_accuracy: 0.8422\n",
      "Epoch 4991/8000\n",
      "1463/1463 [==============================] - 15s 11ms/step - loss: 0.0689 - accuracy: 0.9785 - val_loss: 0.7184 - val_accuracy: 0.8421\n",
      "Epoch 4992/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0609 - accuracy: 0.9801 - val_loss: 0.6747 - val_accuracy: 0.8479\n",
      "Epoch 4993/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0580 - accuracy: 0.9809 - val_loss: 0.6936 - val_accuracy: 0.8428\n",
      "Epoch 4994/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0557 - accuracy: 0.9822 - val_loss: 0.7202 - val_accuracy: 0.8388\n",
      "Epoch 4995/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0548 - accuracy: 0.9822 - val_loss: 0.6649 - val_accuracy: 0.8515\n",
      "Epoch 4996/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0590 - accuracy: 0.9812 - val_loss: 0.6746 - val_accuracy: 0.8482\n",
      "Epoch 4997/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0617 - accuracy: 0.9808 - val_loss: 0.6794 - val_accuracy: 0.8480\n",
      "Epoch 4998/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0598 - accuracy: 0.9802 - val_loss: 0.6827 - val_accuracy: 0.8487\n",
      "Epoch 4999/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0574 - accuracy: 0.9819 - val_loss: 0.8776 - val_accuracy: 0.8280\n",
      "Epoch 5000/8000\n",
      "1463/1463 [==============================] - ETA: 0s - loss: 0.0549 - accuracy: 0.9824\n",
      "Epoch 5000: saving model to ./training_ckpt_20240109205949_v8_240109_d10000_n4096_b64_e8000_c100_Adamax\\cp-000005000.ckpt\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0549 - accuracy: 0.9824 - val_loss: 0.7508 - val_accuracy: 0.8379\n",
      "Epoch 5001/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0551 - accuracy: 0.9826 - val_loss: 0.6606 - val_accuracy: 0.8537\n",
      "Epoch 5002/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0611 - accuracy: 0.9808 - val_loss: 0.6674 - val_accuracy: 0.8489\n",
      "Epoch 5003/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0518 - accuracy: 0.9834 - val_loss: 0.7601 - val_accuracy: 0.8359\n",
      "Epoch 5004/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0568 - accuracy: 0.9823 - val_loss: 0.6621 - val_accuracy: 0.8502\n",
      "Epoch 5005/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0515 - accuracy: 0.9835 - val_loss: 0.7801 - val_accuracy: 0.8303\n",
      "Epoch 5006/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0587 - accuracy: 0.9809 - val_loss: 0.6739 - val_accuracy: 0.8491\n",
      "Epoch 5007/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0572 - accuracy: 0.9815 - val_loss: 0.6793 - val_accuracy: 0.8495\n",
      "Epoch 5008/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0525 - accuracy: 0.9831 - val_loss: 0.6419 - val_accuracy: 0.8562\n",
      "Epoch 5009/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0553 - accuracy: 0.9823 - val_loss: 0.7513 - val_accuracy: 0.8367\n",
      "Epoch 5010/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0638 - accuracy: 0.9793 - val_loss: 0.7658 - val_accuracy: 0.8363\n",
      "Epoch 5011/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0643 - accuracy: 0.9798 - val_loss: 0.6875 - val_accuracy: 0.8496\n",
      "Epoch 5012/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0530 - accuracy: 0.9826 - val_loss: 0.6757 - val_accuracy: 0.8506\n",
      "Epoch 5013/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0602 - accuracy: 0.9803 - val_loss: 0.7003 - val_accuracy: 0.8456\n",
      "Epoch 5014/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0596 - accuracy: 0.9806 - val_loss: 0.7730 - val_accuracy: 0.8345\n",
      "Epoch 5015/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0591 - accuracy: 0.9807 - val_loss: 0.6488 - val_accuracy: 0.8536\n",
      "Epoch 5016/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0557 - accuracy: 0.9823 - val_loss: 0.6474 - val_accuracy: 0.8503\n",
      "Epoch 5017/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0617 - accuracy: 0.9803 - val_loss: 0.6696 - val_accuracy: 0.8465\n",
      "Epoch 5018/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0519 - accuracy: 0.9832 - val_loss: 0.6634 - val_accuracy: 0.8501\n",
      "Epoch 5019/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0600 - accuracy: 0.9811 - val_loss: 0.7138 - val_accuracy: 0.8377\n",
      "Epoch 5020/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0538 - accuracy: 0.9830 - val_loss: 0.6917 - val_accuracy: 0.8429\n",
      "Epoch 5021/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0594 - accuracy: 0.9808 - val_loss: 0.6590 - val_accuracy: 0.8505\n",
      "Epoch 5022/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0572 - accuracy: 0.9809 - val_loss: 0.7921 - val_accuracy: 0.8317\n",
      "Epoch 5023/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0580 - accuracy: 0.9812 - val_loss: 0.7040 - val_accuracy: 0.8462\n",
      "Epoch 5024/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0554 - accuracy: 0.9817 - val_loss: 0.6919 - val_accuracy: 0.8464\n",
      "Epoch 5025/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0563 - accuracy: 0.9816 - val_loss: 0.7174 - val_accuracy: 0.8411\n",
      "Epoch 5026/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0639 - accuracy: 0.9794 - val_loss: 0.7211 - val_accuracy: 0.8422\n",
      "Epoch 5027/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0545 - accuracy: 0.9827 - val_loss: 0.6851 - val_accuracy: 0.8497\n",
      "Epoch 5028/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0558 - accuracy: 0.9822 - val_loss: 0.6773 - val_accuracy: 0.8502\n",
      "Epoch 5029/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0615 - accuracy: 0.9802 - val_loss: 0.7214 - val_accuracy: 0.8449\n",
      "Epoch 5030/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0613 - accuracy: 0.9801 - val_loss: 0.8302 - val_accuracy: 0.8252\n",
      "Epoch 5031/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0563 - accuracy: 0.9819 - val_loss: 0.6968 - val_accuracy: 0.8487\n",
      "Epoch 5032/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0539 - accuracy: 0.9826 - val_loss: 0.6893 - val_accuracy: 0.8406\n",
      "Epoch 5033/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0677 - accuracy: 0.9784 - val_loss: 0.7031 - val_accuracy: 0.8425\n",
      "Epoch 5034/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0568 - accuracy: 0.9821 - val_loss: 0.6594 - val_accuracy: 0.8535\n",
      "Epoch 5035/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0558 - accuracy: 0.9822 - val_loss: 0.6733 - val_accuracy: 0.8494\n",
      "Epoch 5036/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0577 - accuracy: 0.9816 - val_loss: 0.7429 - val_accuracy: 0.8377\n",
      "Epoch 5037/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0575 - accuracy: 0.9812 - val_loss: 0.6819 - val_accuracy: 0.8450\n",
      "Epoch 5038/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0581 - accuracy: 0.9809 - val_loss: 0.7191 - val_accuracy: 0.8439\n",
      "Epoch 5039/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0631 - accuracy: 0.9799 - val_loss: 0.6554 - val_accuracy: 0.8519\n",
      "Epoch 5040/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0593 - accuracy: 0.9812 - val_loss: 0.7206 - val_accuracy: 0.8391\n",
      "Epoch 5041/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0585 - accuracy: 0.9815 - val_loss: 0.6852 - val_accuracy: 0.8476\n",
      "Epoch 5042/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0574 - accuracy: 0.9818 - val_loss: 0.8865 - val_accuracy: 0.8218\n",
      "Epoch 5043/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0577 - accuracy: 0.9818 - val_loss: 0.6686 - val_accuracy: 0.8516\n",
      "Epoch 5044/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0531 - accuracy: 0.9832 - val_loss: 0.6965 - val_accuracy: 0.8473\n",
      "Epoch 5045/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0618 - accuracy: 0.9801 - val_loss: 0.6818 - val_accuracy: 0.8474\n",
      "Epoch 5046/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0560 - accuracy: 0.9816 - val_loss: 0.6868 - val_accuracy: 0.8476\n",
      "Epoch 5047/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0601 - accuracy: 0.9807 - val_loss: 0.7585 - val_accuracy: 0.8374\n",
      "Epoch 5048/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0581 - accuracy: 0.9816 - val_loss: 0.7299 - val_accuracy: 0.8413\n",
      "Epoch 5049/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0544 - accuracy: 0.9835 - val_loss: 0.8103 - val_accuracy: 0.8259\n",
      "Epoch 5050/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0601 - accuracy: 0.9812 - val_loss: 0.6530 - val_accuracy: 0.8505\n",
      "Epoch 5051/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0532 - accuracy: 0.9833 - val_loss: 0.6911 - val_accuracy: 0.8471\n",
      "Epoch 5052/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0655 - accuracy: 0.9800 - val_loss: 0.7164 - val_accuracy: 0.8387\n",
      "Epoch 5053/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0572 - accuracy: 0.9814 - val_loss: 0.7221 - val_accuracy: 0.8385\n",
      "Epoch 5054/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0543 - accuracy: 0.9825 - val_loss: 0.7041 - val_accuracy: 0.8467\n",
      "Epoch 5055/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0563 - accuracy: 0.9821 - val_loss: 0.6566 - val_accuracy: 0.8548\n",
      "Epoch 5056/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0532 - accuracy: 0.9832 - val_loss: 0.6820 - val_accuracy: 0.8478\n",
      "Epoch 5057/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0623 - accuracy: 0.9797 - val_loss: 0.6635 - val_accuracy: 0.8491\n",
      "Epoch 5058/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0570 - accuracy: 0.9815 - val_loss: 0.7165 - val_accuracy: 0.8401\n",
      "Epoch 5059/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0580 - accuracy: 0.9817 - val_loss: 0.6545 - val_accuracy: 0.8511\n",
      "Epoch 5060/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0576 - accuracy: 0.9815 - val_loss: 0.7768 - val_accuracy: 0.8381\n",
      "Epoch 5061/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0582 - accuracy: 0.9808 - val_loss: 0.7626 - val_accuracy: 0.8346\n",
      "Epoch 5062/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0551 - accuracy: 0.9826 - val_loss: 0.6967 - val_accuracy: 0.8457\n",
      "Epoch 5063/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0586 - accuracy: 0.9815 - val_loss: 0.7226 - val_accuracy: 0.8437\n",
      "Epoch 5064/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0622 - accuracy: 0.9798 - val_loss: 0.6546 - val_accuracy: 0.8522\n",
      "Epoch 5065/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0575 - accuracy: 0.9814 - val_loss: 0.7237 - val_accuracy: 0.8449\n",
      "Epoch 5066/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0589 - accuracy: 0.9806 - val_loss: 0.6825 - val_accuracy: 0.8461\n",
      "Epoch 5067/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0614 - accuracy: 0.9803 - val_loss: 0.7417 - val_accuracy: 0.8385\n",
      "Epoch 5068/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0563 - accuracy: 0.9819 - val_loss: 0.6656 - val_accuracy: 0.8495\n",
      "Epoch 5069/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0600 - accuracy: 0.9810 - val_loss: 0.7171 - val_accuracy: 0.8409\n",
      "Epoch 5070/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0541 - accuracy: 0.9827 - val_loss: 0.6529 - val_accuracy: 0.8512\n",
      "Epoch 5071/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0561 - accuracy: 0.9820 - val_loss: 0.6484 - val_accuracy: 0.8525\n",
      "Epoch 5072/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0548 - accuracy: 0.9828 - val_loss: 0.6670 - val_accuracy: 0.8517\n",
      "Epoch 5073/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0539 - accuracy: 0.9828 - val_loss: 0.6955 - val_accuracy: 0.8440\n",
      "Epoch 5074/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0601 - accuracy: 0.9806 - val_loss: 0.6375 - val_accuracy: 0.8511\n",
      "Epoch 5075/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0623 - accuracy: 0.9801 - val_loss: 0.6842 - val_accuracy: 0.8477\n",
      "Epoch 5076/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0570 - accuracy: 0.9825 - val_loss: 0.6863 - val_accuracy: 0.8489\n",
      "Epoch 5077/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0533 - accuracy: 0.9832 - val_loss: 0.6972 - val_accuracy: 0.8437\n",
      "Epoch 5078/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0563 - accuracy: 0.9819 - val_loss: 0.6630 - val_accuracy: 0.8494\n",
      "Epoch 5079/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0572 - accuracy: 0.9822 - val_loss: 0.6408 - val_accuracy: 0.8565\n",
      "Epoch 5080/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0516 - accuracy: 0.9830 - val_loss: 0.6962 - val_accuracy: 0.8478\n",
      "Epoch 5081/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0593 - accuracy: 0.9809 - val_loss: 0.7368 - val_accuracy: 0.8349\n",
      "Epoch 5082/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0583 - accuracy: 0.9813 - val_loss: 0.6478 - val_accuracy: 0.8527\n",
      "Epoch 5083/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0592 - accuracy: 0.9814 - val_loss: 0.6997 - val_accuracy: 0.8391\n",
      "Epoch 5084/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0558 - accuracy: 0.9823 - val_loss: 0.6484 - val_accuracy: 0.8542\n",
      "Epoch 5085/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0628 - accuracy: 0.9800 - val_loss: 0.6975 - val_accuracy: 0.8442\n",
      "Epoch 5086/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0545 - accuracy: 0.9825 - val_loss: 0.6403 - val_accuracy: 0.8547\n",
      "Epoch 5087/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0604 - accuracy: 0.9805 - val_loss: 0.7855 - val_accuracy: 0.8304\n",
      "Epoch 5088/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0590 - accuracy: 0.9815 - val_loss: 0.6887 - val_accuracy: 0.8449\n",
      "Epoch 5089/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0538 - accuracy: 0.9826 - val_loss: 0.7188 - val_accuracy: 0.8374\n",
      "Epoch 5090/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0621 - accuracy: 0.9805 - val_loss: 0.6924 - val_accuracy: 0.8466\n",
      "Epoch 5091/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0548 - accuracy: 0.9821 - val_loss: 0.6770 - val_accuracy: 0.8448\n",
      "Epoch 5092/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0618 - accuracy: 0.9808 - val_loss: 0.7259 - val_accuracy: 0.8384\n",
      "Epoch 5093/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0544 - accuracy: 0.9826 - val_loss: 0.6904 - val_accuracy: 0.8434\n",
      "Epoch 5094/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0573 - accuracy: 0.9812 - val_loss: 0.7798 - val_accuracy: 0.8319\n",
      "Epoch 5095/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0557 - accuracy: 0.9822 - val_loss: 0.7008 - val_accuracy: 0.8430\n",
      "Epoch 5096/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0565 - accuracy: 0.9815 - val_loss: 0.6682 - val_accuracy: 0.8478\n",
      "Epoch 5097/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0550 - accuracy: 0.9824 - val_loss: 0.6634 - val_accuracy: 0.8509\n",
      "Epoch 5098/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0571 - accuracy: 0.9815 - val_loss: 0.6550 - val_accuracy: 0.8495\n",
      "Epoch 5099/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0612 - accuracy: 0.9809 - val_loss: 0.6621 - val_accuracy: 0.8509\n",
      "Epoch 5100/8000\n",
      "1461/1463 [============================>.] - ETA: 0s - loss: 0.0547 - accuracy: 0.9826\n",
      "Epoch 5100: saving model to ./training_ckpt_20240109205949_v8_240109_d10000_n4096_b64_e8000_c100_Adamax\\cp-000005100.ckpt\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0547 - accuracy: 0.9826 - val_loss: 0.6885 - val_accuracy: 0.8473\n",
      "Epoch 5101/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0574 - accuracy: 0.9821 - val_loss: 0.7057 - val_accuracy: 0.8449\n",
      "Epoch 5102/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0591 - accuracy: 0.9812 - val_loss: 0.6812 - val_accuracy: 0.8449\n",
      "Epoch 5103/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0586 - accuracy: 0.9813 - val_loss: 0.6581 - val_accuracy: 0.8534\n",
      "Epoch 5104/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0547 - accuracy: 0.9831 - val_loss: 0.6622 - val_accuracy: 0.8512\n",
      "Epoch 5105/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0606 - accuracy: 0.9807 - val_loss: 0.7757 - val_accuracy: 0.8418\n",
      "Epoch 5106/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0595 - accuracy: 0.9814 - val_loss: 0.7004 - val_accuracy: 0.8454\n",
      "Epoch 5107/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0643 - accuracy: 0.9796 - val_loss: 0.6990 - val_accuracy: 0.8435\n",
      "Epoch 5108/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0549 - accuracy: 0.9826 - val_loss: 0.6816 - val_accuracy: 0.8473\n",
      "Epoch 5109/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0572 - accuracy: 0.9816 - val_loss: 0.7196 - val_accuracy: 0.8447\n",
      "Epoch 5110/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0560 - accuracy: 0.9820 - val_loss: 0.7291 - val_accuracy: 0.8386\n",
      "Epoch 5111/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0546 - accuracy: 0.9821 - val_loss: 0.6738 - val_accuracy: 0.8521\n",
      "Epoch 5112/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0562 - accuracy: 0.9821 - val_loss: 0.7434 - val_accuracy: 0.8363\n",
      "Epoch 5113/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0580 - accuracy: 0.9814 - val_loss: 0.7041 - val_accuracy: 0.8438\n",
      "Epoch 5114/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0541 - accuracy: 0.9822 - val_loss: 0.6872 - val_accuracy: 0.8481\n",
      "Epoch 5115/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0577 - accuracy: 0.9812 - val_loss: 0.6345 - val_accuracy: 0.8569\n",
      "Epoch 5116/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0565 - accuracy: 0.9815 - val_loss: 0.6925 - val_accuracy: 0.8481\n",
      "Epoch 5117/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0567 - accuracy: 0.9811 - val_loss: 0.6702 - val_accuracy: 0.8499\n",
      "Epoch 5118/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0559 - accuracy: 0.9824 - val_loss: 0.7593 - val_accuracy: 0.8380\n",
      "Epoch 5119/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0575 - accuracy: 0.9812 - val_loss: 0.7154 - val_accuracy: 0.8441\n",
      "Epoch 5120/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0552 - accuracy: 0.9824 - val_loss: 0.7029 - val_accuracy: 0.8475\n",
      "Epoch 5121/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0569 - accuracy: 0.9822 - val_loss: 0.6495 - val_accuracy: 0.8517\n",
      "Epoch 5122/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0533 - accuracy: 0.9830 - val_loss: 0.6538 - val_accuracy: 0.8532\n",
      "Epoch 5123/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0609 - accuracy: 0.9808 - val_loss: 0.7820 - val_accuracy: 0.8348\n",
      "Epoch 5124/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0594 - accuracy: 0.9808 - val_loss: 0.6904 - val_accuracy: 0.8459\n",
      "Epoch 5125/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0581 - accuracy: 0.9812 - val_loss: 0.6540 - val_accuracy: 0.8539\n",
      "Epoch 5126/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0502 - accuracy: 0.9838 - val_loss: 0.7488 - val_accuracy: 0.8371\n",
      "Epoch 5127/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0569 - accuracy: 0.9824 - val_loss: 0.6657 - val_accuracy: 0.8507\n",
      "Epoch 5128/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0573 - accuracy: 0.9821 - val_loss: 0.6678 - val_accuracy: 0.8505\n",
      "Epoch 5129/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0565 - accuracy: 0.9815 - val_loss: 0.6776 - val_accuracy: 0.8471\n",
      "Epoch 5130/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0562 - accuracy: 0.9819 - val_loss: 0.7396 - val_accuracy: 0.8398\n",
      "Epoch 5131/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0557 - accuracy: 0.9819 - val_loss: 0.7222 - val_accuracy: 0.8393\n",
      "Epoch 5132/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0542 - accuracy: 0.9819 - val_loss: 0.6857 - val_accuracy: 0.8469\n",
      "Epoch 5133/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0566 - accuracy: 0.9823 - val_loss: 0.6621 - val_accuracy: 0.8519\n",
      "Epoch 5134/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0574 - accuracy: 0.9823 - val_loss: 0.7025 - val_accuracy: 0.8458\n",
      "Epoch 5135/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0571 - accuracy: 0.9824 - val_loss: 0.7197 - val_accuracy: 0.8425\n",
      "Epoch 5136/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0571 - accuracy: 0.9817 - val_loss: 0.6506 - val_accuracy: 0.8537\n",
      "Epoch 5137/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0561 - accuracy: 0.9817 - val_loss: 0.6374 - val_accuracy: 0.8579\n",
      "Epoch 5138/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0570 - accuracy: 0.9826 - val_loss: 0.7060 - val_accuracy: 0.8432\n",
      "Epoch 5139/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0565 - accuracy: 0.9815 - val_loss: 0.6717 - val_accuracy: 0.8491\n",
      "Epoch 5140/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0586 - accuracy: 0.9808 - val_loss: 0.6895 - val_accuracy: 0.8469\n",
      "Epoch 5141/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0534 - accuracy: 0.9830 - val_loss: 0.8329 - val_accuracy: 0.8211\n",
      "Epoch 5142/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0615 - accuracy: 0.9803 - val_loss: 0.6537 - val_accuracy: 0.8516\n",
      "Epoch 5143/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0546 - accuracy: 0.9831 - val_loss: 0.6847 - val_accuracy: 0.8493\n",
      "Epoch 5144/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0593 - accuracy: 0.9813 - val_loss: 0.6976 - val_accuracy: 0.8426\n",
      "Epoch 5145/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0538 - accuracy: 0.9829 - val_loss: 0.7115 - val_accuracy: 0.8454\n",
      "Epoch 5146/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0596 - accuracy: 0.9803 - val_loss: 0.6908 - val_accuracy: 0.8486\n",
      "Epoch 5147/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0538 - accuracy: 0.9829 - val_loss: 0.6857 - val_accuracy: 0.8474\n",
      "Epoch 5148/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0656 - accuracy: 0.9804 - val_loss: 0.6472 - val_accuracy: 0.8546\n",
      "Epoch 5149/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0622 - accuracy: 0.9801 - val_loss: 0.8232 - val_accuracy: 0.8257\n",
      "Epoch 5150/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0534 - accuracy: 0.9829 - val_loss: 0.6614 - val_accuracy: 0.8535\n",
      "Epoch 5151/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0563 - accuracy: 0.9818 - val_loss: 0.6631 - val_accuracy: 0.8511\n",
      "Epoch 5152/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0544 - accuracy: 0.9824 - val_loss: 0.7068 - val_accuracy: 0.8422\n",
      "Epoch 5153/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0511 - accuracy: 0.9838 - val_loss: 0.7036 - val_accuracy: 0.8454\n",
      "Epoch 5154/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0563 - accuracy: 0.9815 - val_loss: 0.7078 - val_accuracy: 0.8431\n",
      "Epoch 5155/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0576 - accuracy: 0.9818 - val_loss: 0.6834 - val_accuracy: 0.8462\n",
      "Epoch 5156/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0569 - accuracy: 0.9822 - val_loss: 0.6777 - val_accuracy: 0.8474\n",
      "Epoch 5157/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0519 - accuracy: 0.9835 - val_loss: 0.6560 - val_accuracy: 0.8539\n",
      "Epoch 5158/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0600 - accuracy: 0.9803 - val_loss: 0.6541 - val_accuracy: 0.8496\n",
      "Epoch 5159/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0541 - accuracy: 0.9830 - val_loss: 0.7148 - val_accuracy: 0.8428\n",
      "Epoch 5160/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0558 - accuracy: 0.9819 - val_loss: 0.6865 - val_accuracy: 0.8475\n",
      "Epoch 5161/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0562 - accuracy: 0.9816 - val_loss: 0.6593 - val_accuracy: 0.8530\n",
      "Epoch 5162/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0606 - accuracy: 0.9807 - val_loss: 0.6850 - val_accuracy: 0.8472\n",
      "Epoch 5163/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0550 - accuracy: 0.9819 - val_loss: 0.6880 - val_accuracy: 0.8477\n",
      "Epoch 5164/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0594 - accuracy: 0.9806 - val_loss: 0.6620 - val_accuracy: 0.8539\n",
      "Epoch 5165/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0619 - accuracy: 0.9799 - val_loss: 0.7761 - val_accuracy: 0.8343\n",
      "Epoch 5166/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0563 - accuracy: 0.9819 - val_loss: 0.6510 - val_accuracy: 0.8540\n",
      "Epoch 5167/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0568 - accuracy: 0.9817 - val_loss: 0.6939 - val_accuracy: 0.8477\n",
      "Epoch 5168/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0541 - accuracy: 0.9828 - val_loss: 0.7034 - val_accuracy: 0.8482\n",
      "Epoch 5169/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0576 - accuracy: 0.9813 - val_loss: 0.6622 - val_accuracy: 0.8475\n",
      "Epoch 5170/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0559 - accuracy: 0.9821 - val_loss: 0.7075 - val_accuracy: 0.8470\n",
      "Epoch 5171/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0596 - accuracy: 0.9819 - val_loss: 0.6665 - val_accuracy: 0.8489\n",
      "Epoch 5172/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0639 - accuracy: 0.9805 - val_loss: 0.6739 - val_accuracy: 0.8496\n",
      "Epoch 5173/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0587 - accuracy: 0.9824 - val_loss: 0.7063 - val_accuracy: 0.8451\n",
      "Epoch 5174/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0553 - accuracy: 0.9821 - val_loss: 0.7273 - val_accuracy: 0.8433\n",
      "Epoch 5175/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0578 - accuracy: 0.9819 - val_loss: 0.6939 - val_accuracy: 0.8463\n",
      "Epoch 5176/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0529 - accuracy: 0.9829 - val_loss: 0.7313 - val_accuracy: 0.8438\n",
      "Epoch 5177/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0528 - accuracy: 0.9832 - val_loss: 0.7063 - val_accuracy: 0.8400\n",
      "Epoch 5178/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0534 - accuracy: 0.9828 - val_loss: 0.6887 - val_accuracy: 0.8489\n",
      "Epoch 5179/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0563 - accuracy: 0.9819 - val_loss: 0.6991 - val_accuracy: 0.8476\n",
      "Epoch 5180/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0601 - accuracy: 0.9813 - val_loss: 0.7095 - val_accuracy: 0.8463\n",
      "Epoch 5181/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0568 - accuracy: 0.9817 - val_loss: 0.7038 - val_accuracy: 0.8422\n",
      "Epoch 5182/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0563 - accuracy: 0.9824 - val_loss: 0.6823 - val_accuracy: 0.8465\n",
      "Epoch 5183/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0510 - accuracy: 0.9834 - val_loss: 0.6642 - val_accuracy: 0.8496\n",
      "Epoch 5184/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0504 - accuracy: 0.9839 - val_loss: 0.7254 - val_accuracy: 0.8378\n",
      "Epoch 5185/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0584 - accuracy: 0.9817 - val_loss: 0.7845 - val_accuracy: 0.8353\n",
      "Epoch 5186/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0586 - accuracy: 0.9808 - val_loss: 0.7440 - val_accuracy: 0.8397\n",
      "Epoch 5187/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0533 - accuracy: 0.9828 - val_loss: 0.6633 - val_accuracy: 0.8498\n",
      "Epoch 5188/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0581 - accuracy: 0.9816 - val_loss: 0.6473 - val_accuracy: 0.8536\n",
      "Epoch 5189/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0584 - accuracy: 0.9816 - val_loss: 0.7422 - val_accuracy: 0.8366\n",
      "Epoch 5190/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0596 - accuracy: 0.9812 - val_loss: 0.6974 - val_accuracy: 0.8417\n",
      "Epoch 5191/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0540 - accuracy: 0.9823 - val_loss: 0.6565 - val_accuracy: 0.8522\n",
      "Epoch 5192/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0517 - accuracy: 0.9839 - val_loss: 0.6506 - val_accuracy: 0.8524\n",
      "Epoch 5193/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0594 - accuracy: 0.9817 - val_loss: 0.6711 - val_accuracy: 0.8504\n",
      "Epoch 5194/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0559 - accuracy: 0.9817 - val_loss: 0.7426 - val_accuracy: 0.8388\n",
      "Epoch 5195/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0569 - accuracy: 0.9816 - val_loss: 0.7229 - val_accuracy: 0.8441\n",
      "Epoch 5196/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0553 - accuracy: 0.9822 - val_loss: 0.7272 - val_accuracy: 0.8395\n",
      "Epoch 5197/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0534 - accuracy: 0.9831 - val_loss: 0.7080 - val_accuracy: 0.8446\n",
      "Epoch 5198/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0524 - accuracy: 0.9833 - val_loss: 0.6970 - val_accuracy: 0.8462\n",
      "Epoch 5199/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0510 - accuracy: 0.9839 - val_loss: 0.7005 - val_accuracy: 0.8428\n",
      "Epoch 5200/8000\n",
      "1458/1463 [============================>.] - ETA: 0s - loss: 0.0480 - accuracy: 0.9850\n",
      "Epoch 5200: saving model to ./training_ckpt_20240109205949_v8_240109_d10000_n4096_b64_e8000_c100_Adamax\\cp-000005200.ckpt\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0480 - accuracy: 0.9850 - val_loss: 0.7197 - val_accuracy: 0.8431\n",
      "Epoch 5201/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0565 - accuracy: 0.9819 - val_loss: 0.6780 - val_accuracy: 0.8477\n",
      "Epoch 5202/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0541 - accuracy: 0.9824 - val_loss: 0.7357 - val_accuracy: 0.8417\n",
      "Epoch 5203/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0578 - accuracy: 0.9823 - val_loss: 0.7120 - val_accuracy: 0.8444\n",
      "Epoch 5204/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0549 - accuracy: 0.9822 - val_loss: 0.6989 - val_accuracy: 0.8475\n",
      "Epoch 5205/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0554 - accuracy: 0.9824 - val_loss: 0.6629 - val_accuracy: 0.8537\n",
      "Epoch 5206/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0569 - accuracy: 0.9823 - val_loss: 0.7903 - val_accuracy: 0.8299\n",
      "Epoch 5207/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0537 - accuracy: 0.9830 - val_loss: 0.6688 - val_accuracy: 0.8504\n",
      "Epoch 5208/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0540 - accuracy: 0.9831 - val_loss: 0.6981 - val_accuracy: 0.8462\n",
      "Epoch 5209/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0584 - accuracy: 0.9812 - val_loss: 0.6665 - val_accuracy: 0.8524\n",
      "Epoch 5210/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0571 - accuracy: 0.9825 - val_loss: 0.7556 - val_accuracy: 0.8346\n",
      "Epoch 5211/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0566 - accuracy: 0.9814 - val_loss: 0.6631 - val_accuracy: 0.8490\n",
      "Epoch 5212/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0564 - accuracy: 0.9813 - val_loss: 0.6298 - val_accuracy: 0.8587\n",
      "Epoch 5213/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0531 - accuracy: 0.9832 - val_loss: 0.7226 - val_accuracy: 0.8398\n",
      "Epoch 5214/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0523 - accuracy: 0.9835 - val_loss: 0.6676 - val_accuracy: 0.8487\n",
      "Epoch 5215/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0588 - accuracy: 0.9810 - val_loss: 0.6701 - val_accuracy: 0.8510\n",
      "Epoch 5216/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0579 - accuracy: 0.9824 - val_loss: 0.7042 - val_accuracy: 0.8462\n",
      "Epoch 5217/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0536 - accuracy: 0.9830 - val_loss: 0.6930 - val_accuracy: 0.8475\n",
      "Epoch 5218/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0622 - accuracy: 0.9802 - val_loss: 0.6858 - val_accuracy: 0.8447\n",
      "Epoch 5219/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0573 - accuracy: 0.9814 - val_loss: 0.6257 - val_accuracy: 0.8569\n",
      "Epoch 5220/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0593 - accuracy: 0.9807 - val_loss: 0.6398 - val_accuracy: 0.8565\n",
      "Epoch 5221/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0503 - accuracy: 0.9835 - val_loss: 0.7050 - val_accuracy: 0.8449\n",
      "Epoch 5222/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0590 - accuracy: 0.9810 - val_loss: 0.6710 - val_accuracy: 0.8504\n",
      "Epoch 5223/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0548 - accuracy: 0.9818 - val_loss: 0.6943 - val_accuracy: 0.8437\n",
      "Epoch 5224/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0550 - accuracy: 0.9825 - val_loss: 0.6919 - val_accuracy: 0.8468\n",
      "Epoch 5225/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0618 - accuracy: 0.9804 - val_loss: 0.6361 - val_accuracy: 0.8549\n",
      "Epoch 5226/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0540 - accuracy: 0.9829 - val_loss: 0.6561 - val_accuracy: 0.8531\n",
      "Epoch 5227/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0496 - accuracy: 0.9839 - val_loss: 0.6590 - val_accuracy: 0.8541\n",
      "Epoch 5228/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0585 - accuracy: 0.9815 - val_loss: 0.7249 - val_accuracy: 0.8439\n",
      "Epoch 5229/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0513 - accuracy: 0.9838 - val_loss: 0.7541 - val_accuracy: 0.8342\n",
      "Epoch 5230/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0563 - accuracy: 0.9822 - val_loss: 0.6886 - val_accuracy: 0.8480\n",
      "Epoch 5231/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0567 - accuracy: 0.9819 - val_loss: 0.6968 - val_accuracy: 0.8450\n",
      "Epoch 5232/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0605 - accuracy: 0.9810 - val_loss: 0.7271 - val_accuracy: 0.8404\n",
      "Epoch 5233/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0562 - accuracy: 0.9818 - val_loss: 0.7082 - val_accuracy: 0.8422\n",
      "Epoch 5234/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0592 - accuracy: 0.9814 - val_loss: 0.7141 - val_accuracy: 0.8392\n",
      "Epoch 5235/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0563 - accuracy: 0.9820 - val_loss: 0.6973 - val_accuracy: 0.8433\n",
      "Epoch 5236/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0640 - accuracy: 0.9799 - val_loss: 0.7195 - val_accuracy: 0.8433\n",
      "Epoch 5237/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0549 - accuracy: 0.9826 - val_loss: 0.6677 - val_accuracy: 0.8512\n",
      "Epoch 5238/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0562 - accuracy: 0.9828 - val_loss: 0.7317 - val_accuracy: 0.8440\n",
      "Epoch 5239/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0560 - accuracy: 0.9822 - val_loss: 0.7562 - val_accuracy: 0.8368\n",
      "Epoch 5240/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0532 - accuracy: 0.9830 - val_loss: 0.6642 - val_accuracy: 0.8535\n",
      "Epoch 5241/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0543 - accuracy: 0.9828 - val_loss: 0.6630 - val_accuracy: 0.8511\n",
      "Epoch 5242/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0556 - accuracy: 0.9827 - val_loss: 0.6763 - val_accuracy: 0.8497\n",
      "Epoch 5243/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0496 - accuracy: 0.9846 - val_loss: 0.7541 - val_accuracy: 0.8368\n",
      "Epoch 5244/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0502 - accuracy: 0.9842 - val_loss: 0.7457 - val_accuracy: 0.8361\n",
      "Epoch 5245/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0651 - accuracy: 0.9790 - val_loss: 0.6808 - val_accuracy: 0.8486\n",
      "Epoch 5246/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0547 - accuracy: 0.9823 - val_loss: 0.7410 - val_accuracy: 0.8377\n",
      "Epoch 5247/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0537 - accuracy: 0.9832 - val_loss: 0.6763 - val_accuracy: 0.8464\n",
      "Epoch 5248/8000\n",
      "1463/1463 [==============================] - 19s 13ms/step - loss: 0.0581 - accuracy: 0.9814 - val_loss: 0.6817 - val_accuracy: 0.8483\n",
      "Epoch 5249/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0571 - accuracy: 0.9819 - val_loss: 0.6707 - val_accuracy: 0.8487\n",
      "Epoch 5250/8000\n",
      "1463/1463 [==============================] - 20s 14ms/step - loss: 0.0594 - accuracy: 0.9814 - val_loss: 0.6994 - val_accuracy: 0.8437\n",
      "Epoch 5251/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0565 - accuracy: 0.9819 - val_loss: 0.6824 - val_accuracy: 0.8455\n",
      "Epoch 5252/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0529 - accuracy: 0.9837 - val_loss: 0.6485 - val_accuracy: 0.8546\n",
      "Epoch 5253/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0638 - accuracy: 0.9804 - val_loss: 0.6581 - val_accuracy: 0.8506\n",
      "Epoch 5254/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0585 - accuracy: 0.9815 - val_loss: 0.7022 - val_accuracy: 0.8468\n",
      "Epoch 5255/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0585 - accuracy: 0.9815 - val_loss: 0.6689 - val_accuracy: 0.8467\n",
      "Epoch 5256/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0537 - accuracy: 0.9824 - val_loss: 0.6754 - val_accuracy: 0.8501\n",
      "Epoch 5257/8000\n",
      "1463/1463 [==============================] - 20s 14ms/step - loss: 0.0560 - accuracy: 0.9822 - val_loss: 0.6758 - val_accuracy: 0.8523\n",
      "Epoch 5258/8000\n",
      "1463/1463 [==============================] - 18s 12ms/step - loss: 0.0625 - accuracy: 0.9805 - val_loss: 0.7644 - val_accuracy: 0.8363\n",
      "Epoch 5259/8000\n",
      "1463/1463 [==============================] - 18s 12ms/step - loss: 0.0553 - accuracy: 0.9828 - val_loss: 0.7756 - val_accuracy: 0.8368\n",
      "Epoch 5260/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0539 - accuracy: 0.9831 - val_loss: 0.6813 - val_accuracy: 0.8506\n",
      "Epoch 5261/8000\n",
      "1463/1463 [==============================] - 17s 11ms/step - loss: 0.0556 - accuracy: 0.9828 - val_loss: 0.6884 - val_accuracy: 0.8449\n",
      "Epoch 5262/8000\n",
      "1463/1463 [==============================] - 17s 11ms/step - loss: 0.0582 - accuracy: 0.9812 - val_loss: 0.6863 - val_accuracy: 0.8510\n",
      "Epoch 5263/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0558 - accuracy: 0.9823 - val_loss: 0.7013 - val_accuracy: 0.8441\n",
      "Epoch 5264/8000\n",
      "1463/1463 [==============================] - 19s 13ms/step - loss: 0.0573 - accuracy: 0.9814 - val_loss: 0.6887 - val_accuracy: 0.8493\n",
      "Epoch 5265/8000\n",
      "1463/1463 [==============================] - 18s 12ms/step - loss: 0.0559 - accuracy: 0.9821 - val_loss: 0.7433 - val_accuracy: 0.8385\n",
      "Epoch 5266/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0574 - accuracy: 0.9818 - val_loss: 0.6802 - val_accuracy: 0.8487\n",
      "Epoch 5267/8000\n",
      "1463/1463 [==============================] - 17s 11ms/step - loss: 0.0573 - accuracy: 0.9820 - val_loss: 0.7021 - val_accuracy: 0.8445\n",
      "Epoch 5268/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0535 - accuracy: 0.9826 - val_loss: 0.6481 - val_accuracy: 0.8530\n",
      "Epoch 5269/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0538 - accuracy: 0.9828 - val_loss: 0.7397 - val_accuracy: 0.8427\n",
      "Epoch 5270/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0548 - accuracy: 0.9827 - val_loss: 0.7211 - val_accuracy: 0.8436\n",
      "Epoch 5271/8000\n",
      "1463/1463 [==============================] - 18s 12ms/step - loss: 0.0543 - accuracy: 0.9822 - val_loss: 0.6767 - val_accuracy: 0.8511\n",
      "Epoch 5272/8000\n",
      "1463/1463 [==============================] - 18s 12ms/step - loss: 0.0542 - accuracy: 0.9822 - val_loss: 0.7315 - val_accuracy: 0.8394\n",
      "Epoch 5273/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0555 - accuracy: 0.9824 - val_loss: 0.6814 - val_accuracy: 0.8487\n",
      "Epoch 5274/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0556 - accuracy: 0.9817 - val_loss: 0.6892 - val_accuracy: 0.8488\n",
      "Epoch 5275/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0573 - accuracy: 0.9819 - val_loss: 0.6740 - val_accuracy: 0.8503\n",
      "Epoch 5276/8000\n",
      "1463/1463 [==============================] - 18s 12ms/step - loss: 0.0536 - accuracy: 0.9828 - val_loss: 0.6750 - val_accuracy: 0.8469\n",
      "Epoch 5277/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0515 - accuracy: 0.9837 - val_loss: 0.6727 - val_accuracy: 0.8485\n",
      "Epoch 5278/8000\n",
      "1463/1463 [==============================] - 17s 11ms/step - loss: 0.0567 - accuracy: 0.9824 - val_loss: 0.6740 - val_accuracy: 0.8521\n",
      "Epoch 5279/8000\n",
      "1463/1463 [==============================] - 17s 11ms/step - loss: 0.0490 - accuracy: 0.9844 - val_loss: 0.6836 - val_accuracy: 0.8486\n",
      "Epoch 5280/8000\n",
      "1463/1463 [==============================] - 17s 11ms/step - loss: 0.0583 - accuracy: 0.9813 - val_loss: 0.7110 - val_accuracy: 0.8427\n",
      "Epoch 5281/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0526 - accuracy: 0.9826 - val_loss: 0.7157 - val_accuracy: 0.8428\n",
      "Epoch 5282/8000\n",
      "1463/1463 [==============================] - 17s 11ms/step - loss: 0.0492 - accuracy: 0.9842 - val_loss: 0.6662 - val_accuracy: 0.8505\n",
      "Epoch 5283/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0523 - accuracy: 0.9836 - val_loss: 0.6816 - val_accuracy: 0.8506\n",
      "Epoch 5284/8000\n",
      "1463/1463 [==============================] - 17s 11ms/step - loss: 0.0615 - accuracy: 0.9808 - val_loss: 0.6456 - val_accuracy: 0.8550\n",
      "Epoch 5285/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0505 - accuracy: 0.9838 - val_loss: 0.6665 - val_accuracy: 0.8545\n",
      "Epoch 5286/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0572 - accuracy: 0.9814 - val_loss: 0.6727 - val_accuracy: 0.8532\n",
      "Epoch 5287/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0528 - accuracy: 0.9834 - val_loss: 0.6685 - val_accuracy: 0.8524\n",
      "Epoch 5288/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0566 - accuracy: 0.9824 - val_loss: 0.7353 - val_accuracy: 0.8379\n",
      "Epoch 5289/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0571 - accuracy: 0.9819 - val_loss: 0.7367 - val_accuracy: 0.8405\n",
      "Epoch 5290/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0468 - accuracy: 0.9848 - val_loss: 0.6857 - val_accuracy: 0.8464\n",
      "Epoch 5291/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0545 - accuracy: 0.9830 - val_loss: 0.6539 - val_accuracy: 0.8538\n",
      "Epoch 5292/8000\n",
      "1463/1463 [==============================] - 17s 11ms/step - loss: 0.0539 - accuracy: 0.9830 - val_loss: 0.6830 - val_accuracy: 0.8507\n",
      "Epoch 5293/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0594 - accuracy: 0.9809 - val_loss: 0.6788 - val_accuracy: 0.8506\n",
      "Epoch 5294/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0542 - accuracy: 0.9832 - val_loss: 0.6768 - val_accuracy: 0.8523\n",
      "Epoch 5295/8000\n",
      "1463/1463 [==============================] - 17s 11ms/step - loss: 0.0556 - accuracy: 0.9829 - val_loss: 0.6726 - val_accuracy: 0.8490\n",
      "Epoch 5296/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0555 - accuracy: 0.9822 - val_loss: 0.7009 - val_accuracy: 0.8454\n",
      "Epoch 5297/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0567 - accuracy: 0.9820 - val_loss: 0.7156 - val_accuracy: 0.8435\n",
      "Epoch 5298/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0541 - accuracy: 0.9825 - val_loss: 0.6569 - val_accuracy: 0.8555\n",
      "Epoch 5299/8000\n",
      "1463/1463 [==============================] - 17s 11ms/step - loss: 0.0517 - accuracy: 0.9840 - val_loss: 0.6906 - val_accuracy: 0.8508\n",
      "Epoch 5300/8000\n",
      "1459/1463 [============================>.] - ETA: 0s - loss: 0.0498 - accuracy: 0.9837\n",
      "Epoch 5300: saving model to ./training_ckpt_20240109205949_v8_240109_d10000_n4096_b64_e8000_c100_Adamax\\cp-000005300.ckpt\n",
      "1463/1463 [==============================] - 17s 11ms/step - loss: 0.0498 - accuracy: 0.9837 - val_loss: 0.6565 - val_accuracy: 0.8531\n",
      "Epoch 5301/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0521 - accuracy: 0.9835 - val_loss: 0.6716 - val_accuracy: 0.8546\n",
      "Epoch 5302/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0529 - accuracy: 0.9831 - val_loss: 0.7019 - val_accuracy: 0.8451\n",
      "Epoch 5303/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0535 - accuracy: 0.9830 - val_loss: 0.6855 - val_accuracy: 0.8490\n",
      "Epoch 5304/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0643 - accuracy: 0.9788 - val_loss: 0.6894 - val_accuracy: 0.8486\n",
      "Epoch 5305/8000\n",
      "1463/1463 [==============================] - 18s 12ms/step - loss: 0.0534 - accuracy: 0.9827 - val_loss: 0.7339 - val_accuracy: 0.8394\n",
      "Epoch 5306/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0540 - accuracy: 0.9834 - val_loss: 0.6730 - val_accuracy: 0.8526\n",
      "Epoch 5307/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0559 - accuracy: 0.9821 - val_loss: 0.6700 - val_accuracy: 0.8460\n",
      "Epoch 5308/8000\n",
      "1463/1463 [==============================] - 17s 11ms/step - loss: 0.0579 - accuracy: 0.9815 - val_loss: 0.6873 - val_accuracy: 0.8475\n",
      "Epoch 5309/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0560 - accuracy: 0.9817 - val_loss: 0.7096 - val_accuracy: 0.8417\n",
      "Epoch 5310/8000\n",
      "1463/1463 [==============================] - 17s 11ms/step - loss: 0.0551 - accuracy: 0.9825 - val_loss: 0.6911 - val_accuracy: 0.8513\n",
      "Epoch 5311/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0572 - accuracy: 0.9825 - val_loss: 0.6912 - val_accuracy: 0.8488\n",
      "Epoch 5312/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0547 - accuracy: 0.9823 - val_loss: 0.6877 - val_accuracy: 0.8525\n",
      "Epoch 5313/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0509 - accuracy: 0.9837 - val_loss: 0.6439 - val_accuracy: 0.8578\n",
      "Epoch 5314/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0546 - accuracy: 0.9822 - val_loss: 0.6812 - val_accuracy: 0.8480\n",
      "Epoch 5315/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0577 - accuracy: 0.9810 - val_loss: 0.7402 - val_accuracy: 0.8404\n",
      "Epoch 5316/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0600 - accuracy: 0.9806 - val_loss: 0.6941 - val_accuracy: 0.8491\n",
      "Epoch 5317/8000\n",
      "1463/1463 [==============================] - 17s 11ms/step - loss: 0.0545 - accuracy: 0.9825 - val_loss: 0.7720 - val_accuracy: 0.8417\n",
      "Epoch 5318/8000\n",
      "1463/1463 [==============================] - 17s 11ms/step - loss: 0.0544 - accuracy: 0.9819 - val_loss: 0.6734 - val_accuracy: 0.8499\n",
      "Epoch 5319/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0553 - accuracy: 0.9822 - val_loss: 0.7381 - val_accuracy: 0.8363\n",
      "Epoch 5320/8000\n",
      "1463/1463 [==============================] - 17s 11ms/step - loss: 0.0566 - accuracy: 0.9819 - val_loss: 0.7135 - val_accuracy: 0.8440\n",
      "Epoch 5321/8000\n",
      "1463/1463 [==============================] - 17s 11ms/step - loss: 0.0556 - accuracy: 0.9826 - val_loss: 0.7143 - val_accuracy: 0.8458\n",
      "Epoch 5322/8000\n",
      "1463/1463 [==============================] - 17s 11ms/step - loss: 0.0584 - accuracy: 0.9813 - val_loss: 0.6711 - val_accuracy: 0.8488\n",
      "Epoch 5323/8000\n",
      "1463/1463 [==============================] - 17s 11ms/step - loss: 0.0569 - accuracy: 0.9818 - val_loss: 0.7052 - val_accuracy: 0.8461\n",
      "Epoch 5324/8000\n",
      "1463/1463 [==============================] - 17s 11ms/step - loss: 0.0541 - accuracy: 0.9825 - val_loss: 0.7622 - val_accuracy: 0.8404\n",
      "Epoch 5325/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0509 - accuracy: 0.9834 - val_loss: 0.6728 - val_accuracy: 0.8507\n",
      "Epoch 5326/8000\n",
      "1463/1463 [==============================] - 17s 11ms/step - loss: 0.0597 - accuracy: 0.9819 - val_loss: 0.7542 - val_accuracy: 0.8403\n",
      "Epoch 5327/8000\n",
      "1463/1463 [==============================] - 17s 11ms/step - loss: 0.0545 - accuracy: 0.9823 - val_loss: 0.6865 - val_accuracy: 0.8489\n",
      "Epoch 5328/8000\n",
      "1463/1463 [==============================] - 17s 11ms/step - loss: 0.0537 - accuracy: 0.9830 - val_loss: 0.7050 - val_accuracy: 0.8450\n",
      "Epoch 5329/8000\n",
      "1463/1463 [==============================] - 17s 11ms/step - loss: 0.0545 - accuracy: 0.9826 - val_loss: 0.7414 - val_accuracy: 0.8385\n",
      "Epoch 5330/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0514 - accuracy: 0.9839 - val_loss: 0.7157 - val_accuracy: 0.8431\n",
      "Epoch 5331/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0547 - accuracy: 0.9828 - val_loss: 0.6274 - val_accuracy: 0.8573\n",
      "Epoch 5332/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0517 - accuracy: 0.9831 - val_loss: 0.7316 - val_accuracy: 0.8416\n",
      "Epoch 5333/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0550 - accuracy: 0.9827 - val_loss: 0.7604 - val_accuracy: 0.8399\n",
      "Epoch 5334/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0488 - accuracy: 0.9844 - val_loss: 0.7007 - val_accuracy: 0.8448\n",
      "Epoch 5335/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0558 - accuracy: 0.9827 - val_loss: 0.6629 - val_accuracy: 0.8502\n",
      "Epoch 5336/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0526 - accuracy: 0.9833 - val_loss: 0.6928 - val_accuracy: 0.8461\n",
      "Epoch 5337/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0575 - accuracy: 0.9815 - val_loss: 0.6830 - val_accuracy: 0.8524\n",
      "Epoch 5338/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0555 - accuracy: 0.9831 - val_loss: 0.6628 - val_accuracy: 0.8535\n",
      "Epoch 5339/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0572 - accuracy: 0.9816 - val_loss: 0.6754 - val_accuracy: 0.8517\n",
      "Epoch 5340/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0575 - accuracy: 0.9817 - val_loss: 0.6726 - val_accuracy: 0.8499\n",
      "Epoch 5341/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0584 - accuracy: 0.9814 - val_loss: 0.7208 - val_accuracy: 0.8398\n",
      "Epoch 5342/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0511 - accuracy: 0.9836 - val_loss: 0.6961 - val_accuracy: 0.8462\n",
      "Epoch 5343/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0566 - accuracy: 0.9816 - val_loss: 0.6843 - val_accuracy: 0.8499\n",
      "Epoch 5344/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0489 - accuracy: 0.9843 - val_loss: 0.7210 - val_accuracy: 0.8443\n",
      "Epoch 5345/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0562 - accuracy: 0.9814 - val_loss: 0.6470 - val_accuracy: 0.8558\n",
      "Epoch 5346/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0497 - accuracy: 0.9844 - val_loss: 0.6416 - val_accuracy: 0.8556\n",
      "Epoch 5347/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0557 - accuracy: 0.9823 - val_loss: 0.7040 - val_accuracy: 0.8453\n",
      "Epoch 5348/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0511 - accuracy: 0.9832 - val_loss: 0.6417 - val_accuracy: 0.8556\n",
      "Epoch 5349/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0529 - accuracy: 0.9834 - val_loss: 0.6824 - val_accuracy: 0.8497\n",
      "Epoch 5350/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0606 - accuracy: 0.9816 - val_loss: 0.7351 - val_accuracy: 0.8391\n",
      "Epoch 5351/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0576 - accuracy: 0.9814 - val_loss: 0.6676 - val_accuracy: 0.8509\n",
      "Epoch 5352/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0592 - accuracy: 0.9821 - val_loss: 0.7176 - val_accuracy: 0.8484\n",
      "Epoch 5353/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0471 - accuracy: 0.9851 - val_loss: 0.6484 - val_accuracy: 0.8558\n",
      "Epoch 5354/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0545 - accuracy: 0.9827 - val_loss: 0.6694 - val_accuracy: 0.8539\n",
      "Epoch 5355/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0518 - accuracy: 0.9837 - val_loss: 0.7492 - val_accuracy: 0.8391\n",
      "Epoch 5356/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0563 - accuracy: 0.9824 - val_loss: 0.6713 - val_accuracy: 0.8478\n",
      "Epoch 5357/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0514 - accuracy: 0.9835 - val_loss: 0.7535 - val_accuracy: 0.8373\n",
      "Epoch 5358/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0572 - accuracy: 0.9815 - val_loss: 0.6680 - val_accuracy: 0.8523\n",
      "Epoch 5359/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0575 - accuracy: 0.9815 - val_loss: 0.6677 - val_accuracy: 0.8529\n",
      "Epoch 5360/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0529 - accuracy: 0.9824 - val_loss: 0.6628 - val_accuracy: 0.8536\n",
      "Epoch 5361/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0527 - accuracy: 0.9830 - val_loss: 0.7056 - val_accuracy: 0.8457\n",
      "Epoch 5362/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0583 - accuracy: 0.9818 - val_loss: 0.7400 - val_accuracy: 0.8384\n",
      "Epoch 5363/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0590 - accuracy: 0.9810 - val_loss: 0.7230 - val_accuracy: 0.8420\n",
      "Epoch 5364/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0536 - accuracy: 0.9828 - val_loss: 0.6960 - val_accuracy: 0.8481\n",
      "Epoch 5365/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0529 - accuracy: 0.9828 - val_loss: 0.6621 - val_accuracy: 0.8522\n",
      "Epoch 5366/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0573 - accuracy: 0.9819 - val_loss: 0.7068 - val_accuracy: 0.8438\n",
      "Epoch 5367/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0494 - accuracy: 0.9846 - val_loss: 0.6691 - val_accuracy: 0.8526\n",
      "Epoch 5368/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0531 - accuracy: 0.9830 - val_loss: 0.7837 - val_accuracy: 0.8405\n",
      "Epoch 5369/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0525 - accuracy: 0.9835 - val_loss: 0.6806 - val_accuracy: 0.8484\n",
      "Epoch 5370/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0539 - accuracy: 0.9821 - val_loss: 0.6819 - val_accuracy: 0.8512\n",
      "Epoch 5371/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0517 - accuracy: 0.9837 - val_loss: 0.7008 - val_accuracy: 0.8454\n",
      "Epoch 5372/8000\n",
      "1463/1463 [==============================] - 18s 12ms/step - loss: 0.0536 - accuracy: 0.9824 - val_loss: 0.7382 - val_accuracy: 0.8393\n",
      "Epoch 5373/8000\n",
      "1463/1463 [==============================] - 18s 12ms/step - loss: 0.0543 - accuracy: 0.9827 - val_loss: 0.7126 - val_accuracy: 0.8515\n",
      "Epoch 5374/8000\n",
      "1463/1463 [==============================] - 18s 12ms/step - loss: 0.0538 - accuracy: 0.9824 - val_loss: 0.7219 - val_accuracy: 0.8455\n",
      "Epoch 5375/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0551 - accuracy: 0.9827 - val_loss: 0.6937 - val_accuracy: 0.8527\n",
      "Epoch 5376/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0535 - accuracy: 0.9828 - val_loss: 0.6988 - val_accuracy: 0.8481\n",
      "Epoch 5377/8000\n",
      "1463/1463 [==============================] - 18s 12ms/step - loss: 0.0572 - accuracy: 0.9820 - val_loss: 0.7070 - val_accuracy: 0.8474\n",
      "Epoch 5378/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0565 - accuracy: 0.9822 - val_loss: 0.7363 - val_accuracy: 0.8447\n",
      "Epoch 5379/8000\n",
      "1463/1463 [==============================] - 17s 11ms/step - loss: 0.0533 - accuracy: 0.9834 - val_loss: 0.6632 - val_accuracy: 0.8538\n",
      "Epoch 5380/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0545 - accuracy: 0.9828 - val_loss: 0.7361 - val_accuracy: 0.8412\n",
      "Epoch 5381/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0550 - accuracy: 0.9826 - val_loss: 0.7121 - val_accuracy: 0.8460\n",
      "Epoch 5382/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0588 - accuracy: 0.9811 - val_loss: 0.7156 - val_accuracy: 0.8444\n",
      "Epoch 5383/8000\n",
      "1463/1463 [==============================] - 19s 13ms/step - loss: 0.0611 - accuracy: 0.9812 - val_loss: 0.6964 - val_accuracy: 0.8456\n",
      "Epoch 5384/8000\n",
      "1463/1463 [==============================] - 17s 11ms/step - loss: 0.0543 - accuracy: 0.9828 - val_loss: 0.6614 - val_accuracy: 0.8548\n",
      "Epoch 5385/8000\n",
      "1463/1463 [==============================] - 18s 12ms/step - loss: 0.0573 - accuracy: 0.9820 - val_loss: 0.7246 - val_accuracy: 0.8477\n",
      "Epoch 5386/8000\n",
      "1463/1463 [==============================] - 17s 11ms/step - loss: 0.0518 - accuracy: 0.9830 - val_loss: 0.6959 - val_accuracy: 0.8485\n",
      "Epoch 5387/8000\n",
      "1463/1463 [==============================] - 17s 11ms/step - loss: 0.0523 - accuracy: 0.9831 - val_loss: 0.6739 - val_accuracy: 0.8501\n",
      "Epoch 5388/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0507 - accuracy: 0.9843 - val_loss: 0.6895 - val_accuracy: 0.8537\n",
      "Epoch 5389/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0568 - accuracy: 0.9811 - val_loss: 0.7559 - val_accuracy: 0.8387\n",
      "Epoch 5390/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0524 - accuracy: 0.9831 - val_loss: 0.6594 - val_accuracy: 0.8524\n",
      "Epoch 5391/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0478 - accuracy: 0.9845 - val_loss: 0.6756 - val_accuracy: 0.8481\n",
      "Epoch 5392/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0570 - accuracy: 0.9826 - val_loss: 0.6610 - val_accuracy: 0.8530\n",
      "Epoch 5393/8000\n",
      "1463/1463 [==============================] - 17s 11ms/step - loss: 0.0563 - accuracy: 0.9824 - val_loss: 0.6985 - val_accuracy: 0.8467\n",
      "Epoch 5394/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0520 - accuracy: 0.9834 - val_loss: 0.6792 - val_accuracy: 0.8515\n",
      "Epoch 5395/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0526 - accuracy: 0.9833 - val_loss: 0.6570 - val_accuracy: 0.8536\n",
      "Epoch 5396/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0484 - accuracy: 0.9843 - val_loss: 0.7605 - val_accuracy: 0.8383\n",
      "Epoch 5397/8000\n",
      "1463/1463 [==============================] - 17s 11ms/step - loss: 0.0569 - accuracy: 0.9815 - val_loss: 0.6793 - val_accuracy: 0.8496\n",
      "Epoch 5398/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0571 - accuracy: 0.9821 - val_loss: 0.7216 - val_accuracy: 0.8480\n",
      "Epoch 5399/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0537 - accuracy: 0.9831 - val_loss: 0.7422 - val_accuracy: 0.8399\n",
      "Epoch 5400/8000\n",
      "1461/1463 [============================>.] - ETA: 0s - loss: 0.0512 - accuracy: 0.9837\n",
      "Epoch 5400: saving model to ./training_ckpt_20240109205949_v8_240109_d10000_n4096_b64_e8000_c100_Adamax\\cp-000005400.ckpt\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0512 - accuracy: 0.9837 - val_loss: 0.7099 - val_accuracy: 0.8439\n",
      "Epoch 5401/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0574 - accuracy: 0.9819 - val_loss: 0.6614 - val_accuracy: 0.8547\n",
      "Epoch 5402/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0499 - accuracy: 0.9835 - val_loss: 0.6520 - val_accuracy: 0.8529\n",
      "Epoch 5403/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0584 - accuracy: 0.9814 - val_loss: 0.6637 - val_accuracy: 0.8510\n",
      "Epoch 5404/8000\n",
      "1463/1463 [==============================] - 17s 11ms/step - loss: 0.0571 - accuracy: 0.9815 - val_loss: 0.7094 - val_accuracy: 0.8461\n",
      "Epoch 5405/8000\n",
      "1463/1463 [==============================] - 17s 11ms/step - loss: 0.0524 - accuracy: 0.9825 - val_loss: 0.6973 - val_accuracy: 0.8462\n",
      "Epoch 5406/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0499 - accuracy: 0.9836 - val_loss: 0.7252 - val_accuracy: 0.8452\n",
      "Epoch 5407/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0571 - accuracy: 0.9823 - val_loss: 0.7556 - val_accuracy: 0.8464\n",
      "Epoch 5408/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0530 - accuracy: 0.9832 - val_loss: 0.6958 - val_accuracy: 0.8503\n",
      "Epoch 5409/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0510 - accuracy: 0.9842 - val_loss: 0.6851 - val_accuracy: 0.8503\n",
      "Epoch 5410/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0540 - accuracy: 0.9829 - val_loss: 0.6884 - val_accuracy: 0.8499\n",
      "Epoch 5411/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0543 - accuracy: 0.9826 - val_loss: 0.6951 - val_accuracy: 0.8490\n",
      "Epoch 5412/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0548 - accuracy: 0.9829 - val_loss: 0.6882 - val_accuracy: 0.8509\n",
      "Epoch 5413/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0533 - accuracy: 0.9829 - val_loss: 0.7106 - val_accuracy: 0.8450\n",
      "Epoch 5414/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0522 - accuracy: 0.9836 - val_loss: 0.7529 - val_accuracy: 0.8363\n",
      "Epoch 5415/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0553 - accuracy: 0.9823 - val_loss: 0.6868 - val_accuracy: 0.8512\n",
      "Epoch 5416/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0578 - accuracy: 0.9814 - val_loss: 0.7659 - val_accuracy: 0.8359\n",
      "Epoch 5417/8000\n",
      "1463/1463 [==============================] - 15s 11ms/step - loss: 0.0555 - accuracy: 0.9829 - val_loss: 0.7756 - val_accuracy: 0.8363\n",
      "Epoch 5418/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0518 - accuracy: 0.9837 - val_loss: 0.6901 - val_accuracy: 0.8517\n",
      "Epoch 5419/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0557 - accuracy: 0.9824 - val_loss: 0.6768 - val_accuracy: 0.8538\n",
      "Epoch 5420/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0523 - accuracy: 0.9843 - val_loss: 0.6578 - val_accuracy: 0.8558\n",
      "Epoch 5421/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0515 - accuracy: 0.9835 - val_loss: 0.6543 - val_accuracy: 0.8533\n",
      "Epoch 5422/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0578 - accuracy: 0.9822 - val_loss: 0.6976 - val_accuracy: 0.8504\n",
      "Epoch 5423/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0680 - accuracy: 0.9788 - val_loss: 0.7351 - val_accuracy: 0.8400\n",
      "Epoch 5424/8000\n",
      "1463/1463 [==============================] - 15s 11ms/step - loss: 0.0549 - accuracy: 0.9829 - val_loss: 0.6976 - val_accuracy: 0.8494\n",
      "Epoch 5425/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0506 - accuracy: 0.9840 - val_loss: 0.6973 - val_accuracy: 0.8538\n",
      "Epoch 5426/8000\n",
      "1463/1463 [==============================] - 19s 13ms/step - loss: 0.0559 - accuracy: 0.9823 - val_loss: 0.9006 - val_accuracy: 0.8197\n",
      "Epoch 5427/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0533 - accuracy: 0.9829 - val_loss: 0.7808 - val_accuracy: 0.8409\n",
      "Epoch 5428/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0584 - accuracy: 0.9816 - val_loss: 0.6540 - val_accuracy: 0.8556\n",
      "Epoch 5429/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0513 - accuracy: 0.9840 - val_loss: 0.6783 - val_accuracy: 0.8489\n",
      "Epoch 5430/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0557 - accuracy: 0.9825 - val_loss: 0.7102 - val_accuracy: 0.8466\n",
      "Epoch 5431/8000\n",
      "1463/1463 [==============================] - 17s 11ms/step - loss: 0.0546 - accuracy: 0.9824 - val_loss: 0.6634 - val_accuracy: 0.8528\n",
      "Epoch 5432/8000\n",
      "1463/1463 [==============================] - 17s 11ms/step - loss: 0.0496 - accuracy: 0.9843 - val_loss: 0.6302 - val_accuracy: 0.8590\n",
      "Epoch 5433/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0602 - accuracy: 0.9816 - val_loss: 0.7083 - val_accuracy: 0.8453\n",
      "Epoch 5434/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0498 - accuracy: 0.9844 - val_loss: 0.6763 - val_accuracy: 0.8505\n",
      "Epoch 5435/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0589 - accuracy: 0.9810 - val_loss: 0.7076 - val_accuracy: 0.8507\n",
      "Epoch 5436/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0548 - accuracy: 0.9829 - val_loss: 0.6986 - val_accuracy: 0.8455\n",
      "Epoch 5437/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0522 - accuracy: 0.9831 - val_loss: 0.6960 - val_accuracy: 0.8500\n",
      "Epoch 5438/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0534 - accuracy: 0.9829 - val_loss: 0.6621 - val_accuracy: 0.8529\n",
      "Epoch 5439/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0557 - accuracy: 0.9823 - val_loss: 0.6953 - val_accuracy: 0.8471\n",
      "Epoch 5440/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0538 - accuracy: 0.9831 - val_loss: 0.7260 - val_accuracy: 0.8434\n",
      "Epoch 5441/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0521 - accuracy: 0.9836 - val_loss: 0.6814 - val_accuracy: 0.8526\n",
      "Epoch 5442/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0552 - accuracy: 0.9827 - val_loss: 0.6391 - val_accuracy: 0.8568\n",
      "Epoch 5443/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0492 - accuracy: 0.9848 - val_loss: 0.7016 - val_accuracy: 0.8491\n",
      "Epoch 5444/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0519 - accuracy: 0.9832 - val_loss: 0.6907 - val_accuracy: 0.8490\n",
      "Epoch 5445/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0539 - accuracy: 0.9829 - val_loss: 0.6675 - val_accuracy: 0.8538\n",
      "Epoch 5446/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0612 - accuracy: 0.9813 - val_loss: 0.6883 - val_accuracy: 0.8495\n",
      "Epoch 5447/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0589 - accuracy: 0.9810 - val_loss: 0.6756 - val_accuracy: 0.8503\n",
      "Epoch 5448/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0532 - accuracy: 0.9825 - val_loss: 0.7608 - val_accuracy: 0.8328\n",
      "Epoch 5449/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0627 - accuracy: 0.9799 - val_loss: 0.6702 - val_accuracy: 0.8533\n",
      "Epoch 5450/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0511 - accuracy: 0.9835 - val_loss: 0.7038 - val_accuracy: 0.8476\n",
      "Epoch 5451/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0522 - accuracy: 0.9834 - val_loss: 0.6828 - val_accuracy: 0.8537\n",
      "Epoch 5452/8000\n",
      "1463/1463 [==============================] - 19s 13ms/step - loss: 0.0585 - accuracy: 0.9817 - val_loss: 0.7040 - val_accuracy: 0.8496\n",
      "Epoch 5453/8000\n",
      "1463/1463 [==============================] - 18s 12ms/step - loss: 0.0492 - accuracy: 0.9846 - val_loss: 0.6650 - val_accuracy: 0.8526\n",
      "Epoch 5454/8000\n",
      "1463/1463 [==============================] - 18s 12ms/step - loss: 0.0566 - accuracy: 0.9826 - val_loss: 0.6509 - val_accuracy: 0.8562\n",
      "Epoch 5455/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0510 - accuracy: 0.9842 - val_loss: 0.6887 - val_accuracy: 0.8517\n",
      "Epoch 5456/8000\n",
      "1463/1463 [==============================] - 20s 13ms/step - loss: 0.0492 - accuracy: 0.9845 - val_loss: 0.6886 - val_accuracy: 0.8491\n",
      "Epoch 5457/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0478 - accuracy: 0.9845 - val_loss: 0.7211 - val_accuracy: 0.8433\n",
      "Epoch 5458/8000\n",
      "1463/1463 [==============================] - 18s 12ms/step - loss: 0.0591 - accuracy: 0.9816 - val_loss: 0.6792 - val_accuracy: 0.8514\n",
      "Epoch 5459/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0538 - accuracy: 0.9826 - val_loss: 0.7215 - val_accuracy: 0.8450\n",
      "Epoch 5460/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0511 - accuracy: 0.9836 - val_loss: 0.7424 - val_accuracy: 0.8478\n",
      "Epoch 5461/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0532 - accuracy: 0.9831 - val_loss: 0.7599 - val_accuracy: 0.8399\n",
      "Epoch 5462/8000\n",
      "1463/1463 [==============================] - 15s 11ms/step - loss: 0.0604 - accuracy: 0.9814 - val_loss: 0.6890 - val_accuracy: 0.8498\n",
      "Epoch 5463/8000\n",
      "1463/1463 [==============================] - 18s 12ms/step - loss: 0.0552 - accuracy: 0.9829 - val_loss: 0.6961 - val_accuracy: 0.8493\n",
      "Epoch 5464/8000\n",
      "1463/1463 [==============================] - 18s 12ms/step - loss: 0.0492 - accuracy: 0.9841 - val_loss: 0.6642 - val_accuracy: 0.8535\n",
      "Epoch 5465/8000\n",
      "1463/1463 [==============================] - 18s 12ms/step - loss: 0.0556 - accuracy: 0.9824 - val_loss: 0.6388 - val_accuracy: 0.8596\n",
      "Epoch 5466/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0526 - accuracy: 0.9836 - val_loss: 0.6631 - val_accuracy: 0.8555\n",
      "Epoch 5467/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0572 - accuracy: 0.9820 - val_loss: 0.6890 - val_accuracy: 0.8501\n",
      "Epoch 5468/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0560 - accuracy: 0.9825 - val_loss: 0.7698 - val_accuracy: 0.8382\n",
      "Epoch 5469/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0531 - accuracy: 0.9831 - val_loss: 0.6629 - val_accuracy: 0.8511\n",
      "Epoch 5470/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0519 - accuracy: 0.9834 - val_loss: 0.7076 - val_accuracy: 0.8475\n",
      "Epoch 5471/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0528 - accuracy: 0.9835 - val_loss: 0.7269 - val_accuracy: 0.8445\n",
      "Epoch 5472/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0562 - accuracy: 0.9825 - val_loss: 0.6476 - val_accuracy: 0.8595\n",
      "Epoch 5473/8000\n",
      "1463/1463 [==============================] - 21s 15ms/step - loss: 0.0562 - accuracy: 0.9824 - val_loss: 0.6872 - val_accuracy: 0.8494\n",
      "Epoch 5474/8000\n",
      "1463/1463 [==============================] - 18s 12ms/step - loss: 0.0517 - accuracy: 0.9840 - val_loss: 0.7140 - val_accuracy: 0.8498\n",
      "Epoch 5475/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0513 - accuracy: 0.9841 - val_loss: 0.7470 - val_accuracy: 0.8412\n",
      "Epoch 5476/8000\n",
      "1463/1463 [==============================] - 18s 12ms/step - loss: 0.0595 - accuracy: 0.9809 - val_loss: 0.7585 - val_accuracy: 0.8416\n",
      "Epoch 5477/8000\n",
      "1463/1463 [==============================] - 18s 12ms/step - loss: 0.0570 - accuracy: 0.9819 - val_loss: 0.7127 - val_accuracy: 0.8453\n",
      "Epoch 5478/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0571 - accuracy: 0.9824 - val_loss: 0.6908 - val_accuracy: 0.8504\n",
      "Epoch 5479/8000\n",
      "1463/1463 [==============================] - 18s 12ms/step - loss: 0.0537 - accuracy: 0.9836 - val_loss: 0.6972 - val_accuracy: 0.8500\n",
      "Epoch 5480/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0499 - accuracy: 0.9842 - val_loss: 0.6951 - val_accuracy: 0.8459\n",
      "Epoch 5481/8000\n",
      "1463/1463 [==============================] - 19s 13ms/step - loss: 0.0511 - accuracy: 0.9838 - val_loss: 0.6496 - val_accuracy: 0.8556\n",
      "Epoch 5482/8000\n",
      "1463/1463 [==============================] - 20s 14ms/step - loss: 0.0531 - accuracy: 0.9834 - val_loss: 0.7657 - val_accuracy: 0.8363\n",
      "Epoch 5483/8000\n",
      "1463/1463 [==============================] - 24s 16ms/step - loss: 0.0623 - accuracy: 0.9804 - val_loss: 0.7369 - val_accuracy: 0.8388\n",
      "Epoch 5484/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0497 - accuracy: 0.9843 - val_loss: 0.7625 - val_accuracy: 0.8345\n",
      "Epoch 5485/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0519 - accuracy: 0.9834 - val_loss: 0.6497 - val_accuracy: 0.8558\n",
      "Epoch 5486/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0479 - accuracy: 0.9850 - val_loss: 0.6746 - val_accuracy: 0.8548\n",
      "Epoch 5487/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0577 - accuracy: 0.9822 - val_loss: 0.7499 - val_accuracy: 0.8438\n",
      "Epoch 5488/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0499 - accuracy: 0.9841 - val_loss: 0.6780 - val_accuracy: 0.8543\n",
      "Epoch 5489/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0510 - accuracy: 0.9840 - val_loss: 0.8659 - val_accuracy: 0.8325\n",
      "Epoch 5490/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0518 - accuracy: 0.9836 - val_loss: 0.6597 - val_accuracy: 0.8545\n",
      "Epoch 5491/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0546 - accuracy: 0.9826 - val_loss: 0.7046 - val_accuracy: 0.8485\n",
      "Epoch 5492/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0510 - accuracy: 0.9838 - val_loss: 0.7176 - val_accuracy: 0.8458\n",
      "Epoch 5493/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0578 - accuracy: 0.9814 - val_loss: 0.7395 - val_accuracy: 0.8426\n",
      "Epoch 5494/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0512 - accuracy: 0.9837 - val_loss: 0.6726 - val_accuracy: 0.8521\n",
      "Epoch 5495/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0525 - accuracy: 0.9833 - val_loss: 0.7721 - val_accuracy: 0.8356\n",
      "Epoch 5496/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0545 - accuracy: 0.9819 - val_loss: 0.6624 - val_accuracy: 0.8529\n",
      "Epoch 5497/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0506 - accuracy: 0.9843 - val_loss: 0.6914 - val_accuracy: 0.8494\n",
      "Epoch 5498/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0493 - accuracy: 0.9842 - val_loss: 0.7051 - val_accuracy: 0.8460\n",
      "Epoch 5499/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0559 - accuracy: 0.9823 - val_loss: 0.7251 - val_accuracy: 0.8460\n",
      "Epoch 5500/8000\n",
      "1462/1463 [============================>.] - ETA: 0s - loss: 0.0488 - accuracy: 0.9841\n",
      "Epoch 5500: saving model to ./training_ckpt_20240109205949_v8_240109_d10000_n4096_b64_e8000_c100_Adamax\\cp-000005500.ckpt\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0488 - accuracy: 0.9840 - val_loss: 0.7148 - val_accuracy: 0.8477\n",
      "Epoch 5501/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0627 - accuracy: 0.9801 - val_loss: 0.6828 - val_accuracy: 0.8482\n",
      "Epoch 5502/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0475 - accuracy: 0.9851 - val_loss: 0.6920 - val_accuracy: 0.8485\n",
      "Epoch 5503/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0524 - accuracy: 0.9835 - val_loss: 0.6892 - val_accuracy: 0.8516\n",
      "Epoch 5504/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0547 - accuracy: 0.9833 - val_loss: 0.6544 - val_accuracy: 0.8552\n",
      "Epoch 5505/8000\n",
      "1463/1463 [==============================] - 12s 9ms/step - loss: 0.0508 - accuracy: 0.9839 - val_loss: 0.6594 - val_accuracy: 0.8577\n",
      "Epoch 5506/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0591 - accuracy: 0.9822 - val_loss: 0.7531 - val_accuracy: 0.8373\n",
      "Epoch 5507/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0547 - accuracy: 0.9829 - val_loss: 0.6667 - val_accuracy: 0.8512\n",
      "Epoch 5508/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0522 - accuracy: 0.9835 - val_loss: 0.7026 - val_accuracy: 0.8494\n",
      "Epoch 5509/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0578 - accuracy: 0.9817 - val_loss: 0.7563 - val_accuracy: 0.8414\n",
      "Epoch 5510/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0513 - accuracy: 0.9839 - val_loss: 0.7005 - val_accuracy: 0.8507\n",
      "Epoch 5511/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0504 - accuracy: 0.9838 - val_loss: 0.6628 - val_accuracy: 0.8533\n",
      "Epoch 5512/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0487 - accuracy: 0.9843 - val_loss: 0.7009 - val_accuracy: 0.8512\n",
      "Epoch 5513/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0529 - accuracy: 0.9837 - val_loss: 0.7061 - val_accuracy: 0.8461\n",
      "Epoch 5514/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0523 - accuracy: 0.9833 - val_loss: 0.7269 - val_accuracy: 0.8438\n",
      "Epoch 5515/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0548 - accuracy: 0.9826 - val_loss: 0.7070 - val_accuracy: 0.8438\n",
      "Epoch 5516/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0519 - accuracy: 0.9839 - val_loss: 0.7629 - val_accuracy: 0.8413\n",
      "Epoch 5517/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0497 - accuracy: 0.9838 - val_loss: 0.7204 - val_accuracy: 0.8441\n",
      "Epoch 5518/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0523 - accuracy: 0.9831 - val_loss: 0.7229 - val_accuracy: 0.8496\n",
      "Epoch 5519/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0491 - accuracy: 0.9844 - val_loss: 0.6920 - val_accuracy: 0.8500\n",
      "Epoch 5520/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0566 - accuracy: 0.9823 - val_loss: 0.6685 - val_accuracy: 0.8515\n",
      "Epoch 5521/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0543 - accuracy: 0.9834 - val_loss: 0.6692 - val_accuracy: 0.8542\n",
      "Epoch 5522/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0524 - accuracy: 0.9831 - val_loss: 0.6595 - val_accuracy: 0.8529\n",
      "Epoch 5523/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0537 - accuracy: 0.9828 - val_loss: 0.7327 - val_accuracy: 0.8419\n",
      "Epoch 5524/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0605 - accuracy: 0.9822 - val_loss: 0.6876 - val_accuracy: 0.8499\n",
      "Epoch 5525/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0534 - accuracy: 0.9835 - val_loss: 0.7046 - val_accuracy: 0.8456\n",
      "Epoch 5526/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0525 - accuracy: 0.9831 - val_loss: 0.7525 - val_accuracy: 0.8438\n",
      "Epoch 5527/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0572 - accuracy: 0.9814 - val_loss: 0.6784 - val_accuracy: 0.8531\n",
      "Epoch 5528/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0556 - accuracy: 0.9826 - val_loss: 0.6720 - val_accuracy: 0.8551\n",
      "Epoch 5529/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0520 - accuracy: 0.9835 - val_loss: 0.6866 - val_accuracy: 0.8518\n",
      "Epoch 5530/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0530 - accuracy: 0.9830 - val_loss: 0.6830 - val_accuracy: 0.8524\n",
      "Epoch 5531/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0514 - accuracy: 0.9839 - val_loss: 0.7224 - val_accuracy: 0.8439\n",
      "Epoch 5532/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0550 - accuracy: 0.9824 - val_loss: 0.7267 - val_accuracy: 0.8481\n",
      "Epoch 5533/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0553 - accuracy: 0.9824 - val_loss: 0.6572 - val_accuracy: 0.8518\n",
      "Epoch 5534/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0514 - accuracy: 0.9840 - val_loss: 0.6924 - val_accuracy: 0.8468\n",
      "Epoch 5535/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0530 - accuracy: 0.9833 - val_loss: 0.7409 - val_accuracy: 0.8417\n",
      "Epoch 5536/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0543 - accuracy: 0.9821 - val_loss: 0.6406 - val_accuracy: 0.8558\n",
      "Epoch 5537/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0476 - accuracy: 0.9850 - val_loss: 0.6871 - val_accuracy: 0.8483\n",
      "Epoch 5538/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0613 - accuracy: 0.9806 - val_loss: 0.7741 - val_accuracy: 0.8364\n",
      "Epoch 5539/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0597 - accuracy: 0.9811 - val_loss: 0.8789 - val_accuracy: 0.8325\n",
      "Epoch 5540/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0493 - accuracy: 0.9845 - val_loss: 0.6831 - val_accuracy: 0.8526\n",
      "Epoch 5541/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0534 - accuracy: 0.9833 - val_loss: 0.6585 - val_accuracy: 0.8552\n",
      "Epoch 5542/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0518 - accuracy: 0.9830 - val_loss: 0.6824 - val_accuracy: 0.8548\n",
      "Epoch 5543/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0588 - accuracy: 0.9823 - val_loss: 0.7094 - val_accuracy: 0.8503\n",
      "Epoch 5544/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0515 - accuracy: 0.9836 - val_loss: 0.6895 - val_accuracy: 0.8542\n",
      "Epoch 5545/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0552 - accuracy: 0.9830 - val_loss: 0.6665 - val_accuracy: 0.8554\n",
      "Epoch 5546/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0524 - accuracy: 0.9833 - val_loss: 0.6480 - val_accuracy: 0.8576\n",
      "Epoch 5547/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0467 - accuracy: 0.9857 - val_loss: 0.7098 - val_accuracy: 0.8459\n",
      "Epoch 5548/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0547 - accuracy: 0.9822 - val_loss: 0.7056 - val_accuracy: 0.8482\n",
      "Epoch 5549/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0570 - accuracy: 0.9827 - val_loss: 0.6853 - val_accuracy: 0.8511\n",
      "Epoch 5550/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0552 - accuracy: 0.9823 - val_loss: 0.6976 - val_accuracy: 0.8453\n",
      "Epoch 5551/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0587 - accuracy: 0.9817 - val_loss: 0.7289 - val_accuracy: 0.8426\n",
      "Epoch 5552/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0524 - accuracy: 0.9837 - val_loss: 0.7036 - val_accuracy: 0.8490\n",
      "Epoch 5553/8000\n",
      "1463/1463 [==============================] - 17s 11ms/step - loss: 0.0509 - accuracy: 0.9840 - val_loss: 0.6726 - val_accuracy: 0.8552\n",
      "Epoch 5554/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0536 - accuracy: 0.9831 - val_loss: 0.6748 - val_accuracy: 0.8552\n",
      "Epoch 5555/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0535 - accuracy: 0.9834 - val_loss: 0.6773 - val_accuracy: 0.8499\n",
      "Epoch 5556/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0526 - accuracy: 0.9834 - val_loss: 0.7038 - val_accuracy: 0.8438\n",
      "Epoch 5557/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0507 - accuracy: 0.9839 - val_loss: 0.6707 - val_accuracy: 0.8509\n",
      "Epoch 5558/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0524 - accuracy: 0.9833 - val_loss: 0.7126 - val_accuracy: 0.8471\n",
      "Epoch 5559/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0602 - accuracy: 0.9804 - val_loss: 0.6913 - val_accuracy: 0.8522\n",
      "Epoch 5560/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0482 - accuracy: 0.9845 - val_loss: 0.7159 - val_accuracy: 0.8490\n",
      "Epoch 5561/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0538 - accuracy: 0.9825 - val_loss: 0.6617 - val_accuracy: 0.8519\n",
      "Epoch 5562/8000\n",
      "1463/1463 [==============================] - 17s 11ms/step - loss: 0.0515 - accuracy: 0.9832 - val_loss: 0.6545 - val_accuracy: 0.8567\n",
      "Epoch 5563/8000\n",
      "1463/1463 [==============================] - 18s 12ms/step - loss: 0.0514 - accuracy: 0.9837 - val_loss: 0.6722 - val_accuracy: 0.8508\n",
      "Epoch 5564/8000\n",
      "1463/1463 [==============================] - 18s 13ms/step - loss: 0.0538 - accuracy: 0.9830 - val_loss: 0.6680 - val_accuracy: 0.8562\n",
      "Epoch 5565/8000\n",
      "1463/1463 [==============================] - 18s 12ms/step - loss: 0.0496 - accuracy: 0.9839 - val_loss: 0.6734 - val_accuracy: 0.8535\n",
      "Epoch 5566/8000\n",
      "1463/1463 [==============================] - 19s 13ms/step - loss: 0.0531 - accuracy: 0.9831 - val_loss: 0.6738 - val_accuracy: 0.8517\n",
      "Epoch 5567/8000\n",
      "1463/1463 [==============================] - 20s 14ms/step - loss: 0.0530 - accuracy: 0.9831 - val_loss: 0.6656 - val_accuracy: 0.8516\n",
      "Epoch 5568/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0517 - accuracy: 0.9840 - val_loss: 0.7029 - val_accuracy: 0.8451\n",
      "Epoch 5569/8000\n",
      "1463/1463 [==============================] - 18s 12ms/step - loss: 0.0518 - accuracy: 0.9835 - val_loss: 0.7204 - val_accuracy: 0.8485\n",
      "Epoch 5570/8000\n",
      "1463/1463 [==============================] - 17s 11ms/step - loss: 0.0513 - accuracy: 0.9840 - val_loss: 0.6785 - val_accuracy: 0.8511\n",
      "Epoch 5571/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0524 - accuracy: 0.9835 - val_loss: 0.7432 - val_accuracy: 0.8428\n",
      "Epoch 5572/8000\n",
      "1463/1463 [==============================] - 18s 12ms/step - loss: 0.0541 - accuracy: 0.9832 - val_loss: 0.7348 - val_accuracy: 0.8422\n",
      "Epoch 5573/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0537 - accuracy: 0.9833 - val_loss: 0.6819 - val_accuracy: 0.8528\n",
      "Epoch 5574/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0507 - accuracy: 0.9838 - val_loss: 0.6863 - val_accuracy: 0.8538\n",
      "Epoch 5575/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0508 - accuracy: 0.9843 - val_loss: 0.6885 - val_accuracy: 0.8486\n",
      "Epoch 5576/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0509 - accuracy: 0.9837 - val_loss: 0.6610 - val_accuracy: 0.8562\n",
      "Epoch 5577/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0529 - accuracy: 0.9827 - val_loss: 0.7000 - val_accuracy: 0.8476\n",
      "Epoch 5578/8000\n",
      "1463/1463 [==============================] - 17s 11ms/step - loss: 0.0492 - accuracy: 0.9848 - val_loss: 0.6528 - val_accuracy: 0.8594\n",
      "Epoch 5579/8000\n",
      "1463/1463 [==============================] - 17s 11ms/step - loss: 0.0534 - accuracy: 0.9835 - val_loss: 0.7106 - val_accuracy: 0.8506\n",
      "Epoch 5580/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0580 - accuracy: 0.9820 - val_loss: 0.7204 - val_accuracy: 0.8437\n",
      "Epoch 5581/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0469 - accuracy: 0.9851 - val_loss: 0.6593 - val_accuracy: 0.8547\n",
      "Epoch 5582/8000\n",
      "1463/1463 [==============================] - 18s 12ms/step - loss: 0.0518 - accuracy: 0.9839 - val_loss: 0.6429 - val_accuracy: 0.8575\n",
      "Epoch 5583/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0524 - accuracy: 0.9836 - val_loss: 0.7163 - val_accuracy: 0.8450\n",
      "Epoch 5584/8000\n",
      "1463/1463 [==============================] - 18s 12ms/step - loss: 0.0582 - accuracy: 0.9817 - val_loss: 0.6934 - val_accuracy: 0.8483\n",
      "Epoch 5585/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0495 - accuracy: 0.9844 - val_loss: 0.6862 - val_accuracy: 0.8512\n",
      "Epoch 5586/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0509 - accuracy: 0.9843 - val_loss: 0.6769 - val_accuracy: 0.8569\n",
      "Epoch 5587/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0549 - accuracy: 0.9831 - val_loss: 0.7052 - val_accuracy: 0.8496\n",
      "Epoch 5588/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0538 - accuracy: 0.9826 - val_loss: 0.7124 - val_accuracy: 0.8470\n",
      "Epoch 5589/8000\n",
      "1463/1463 [==============================] - 12s 9ms/step - loss: 0.0531 - accuracy: 0.9836 - val_loss: 0.6689 - val_accuracy: 0.8530\n",
      "Epoch 5590/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0542 - accuracy: 0.9823 - val_loss: 0.6835 - val_accuracy: 0.8492\n",
      "Epoch 5591/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0515 - accuracy: 0.9834 - val_loss: 0.6834 - val_accuracy: 0.8499\n",
      "Epoch 5592/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0569 - accuracy: 0.9821 - val_loss: 0.7517 - val_accuracy: 0.8429\n",
      "Epoch 5593/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0520 - accuracy: 0.9841 - val_loss: 0.6468 - val_accuracy: 0.8568\n",
      "Epoch 5594/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0509 - accuracy: 0.9846 - val_loss: 0.6306 - val_accuracy: 0.8604\n",
      "Epoch 5595/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0519 - accuracy: 0.9832 - val_loss: 0.6552 - val_accuracy: 0.8574\n",
      "Epoch 5596/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0566 - accuracy: 0.9821 - val_loss: 0.6798 - val_accuracy: 0.8510\n",
      "Epoch 5597/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0516 - accuracy: 0.9834 - val_loss: 0.6875 - val_accuracy: 0.8503\n",
      "Epoch 5598/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0528 - accuracy: 0.9836 - val_loss: 0.6889 - val_accuracy: 0.8516\n",
      "Epoch 5599/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0567 - accuracy: 0.9825 - val_loss: 0.6911 - val_accuracy: 0.8512\n",
      "Epoch 5600/8000\n",
      "1462/1463 [============================>.] - ETA: 0s - loss: 0.0541 - accuracy: 0.9833\n",
      "Epoch 5600: saving model to ./training_ckpt_20240109205949_v8_240109_d10000_n4096_b64_e8000_c100_Adamax\\cp-000005600.ckpt\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0541 - accuracy: 0.9833 - val_loss: 0.7295 - val_accuracy: 0.8467\n",
      "Epoch 5601/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0488 - accuracy: 0.9851 - val_loss: 0.6693 - val_accuracy: 0.8544\n",
      "Epoch 5602/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0517 - accuracy: 0.9834 - val_loss: 0.6646 - val_accuracy: 0.8530\n",
      "Epoch 5603/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0573 - accuracy: 0.9821 - val_loss: 0.7027 - val_accuracy: 0.8454\n",
      "Epoch 5604/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0535 - accuracy: 0.9826 - val_loss: 0.7251 - val_accuracy: 0.8446\n",
      "Epoch 5605/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0551 - accuracy: 0.9826 - val_loss: 0.6451 - val_accuracy: 0.8565\n",
      "Epoch 5606/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0500 - accuracy: 0.9844 - val_loss: 0.6678 - val_accuracy: 0.8532\n",
      "Epoch 5607/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0571 - accuracy: 0.9823 - val_loss: 0.6699 - val_accuracy: 0.8540\n",
      "Epoch 5608/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0492 - accuracy: 0.9843 - val_loss: 0.7723 - val_accuracy: 0.8389\n",
      "Epoch 5609/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0559 - accuracy: 0.9826 - val_loss: 0.7100 - val_accuracy: 0.8489\n",
      "Epoch 5610/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0526 - accuracy: 0.9832 - val_loss: 0.7195 - val_accuracy: 0.8452\n",
      "Epoch 5611/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0547 - accuracy: 0.9826 - val_loss: 0.7397 - val_accuracy: 0.8370\n",
      "Epoch 5612/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0539 - accuracy: 0.9831 - val_loss: 0.7785 - val_accuracy: 0.8376\n",
      "Epoch 5613/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0532 - accuracy: 0.9831 - val_loss: 0.7699 - val_accuracy: 0.8406\n",
      "Epoch 5614/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0545 - accuracy: 0.9830 - val_loss: 0.6549 - val_accuracy: 0.8527\n",
      "Epoch 5615/8000\n",
      "1463/1463 [==============================] - 15s 11ms/step - loss: 0.0506 - accuracy: 0.9841 - val_loss: 0.7152 - val_accuracy: 0.8485\n",
      "Epoch 5616/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0612 - accuracy: 0.9805 - val_loss: 0.7356 - val_accuracy: 0.8472\n",
      "Epoch 5617/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0534 - accuracy: 0.9834 - val_loss: 0.6575 - val_accuracy: 0.8559\n",
      "Epoch 5618/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0504 - accuracy: 0.9836 - val_loss: 0.6883 - val_accuracy: 0.8490\n",
      "Epoch 5619/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0500 - accuracy: 0.9839 - val_loss: 0.9043 - val_accuracy: 0.8300\n",
      "Epoch 5620/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0550 - accuracy: 0.9829 - val_loss: 0.6853 - val_accuracy: 0.8541\n",
      "Epoch 5621/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0498 - accuracy: 0.9843 - val_loss: 0.6925 - val_accuracy: 0.8520\n",
      "Epoch 5622/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0529 - accuracy: 0.9839 - val_loss: 0.6344 - val_accuracy: 0.8578\n",
      "Epoch 5623/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0533 - accuracy: 0.9828 - val_loss: 0.7481 - val_accuracy: 0.8393\n",
      "Epoch 5624/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0526 - accuracy: 0.9832 - val_loss: 0.6911 - val_accuracy: 0.8527\n",
      "Epoch 5625/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0514 - accuracy: 0.9837 - val_loss: 0.7004 - val_accuracy: 0.8486\n",
      "Epoch 5626/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0544 - accuracy: 0.9834 - val_loss: 0.6989 - val_accuracy: 0.8513\n",
      "Epoch 5627/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0515 - accuracy: 0.9837 - val_loss: 0.7247 - val_accuracy: 0.8479\n",
      "Epoch 5628/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0537 - accuracy: 0.9823 - val_loss: 0.7085 - val_accuracy: 0.8520\n",
      "Epoch 5629/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0515 - accuracy: 0.9839 - val_loss: 0.6773 - val_accuracy: 0.8518\n",
      "Epoch 5630/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0468 - accuracy: 0.9855 - val_loss: 0.7220 - val_accuracy: 0.8508\n",
      "Epoch 5631/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0562 - accuracy: 0.9831 - val_loss: 0.7073 - val_accuracy: 0.8494\n",
      "Epoch 5632/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0511 - accuracy: 0.9842 - val_loss: 0.6659 - val_accuracy: 0.8557\n",
      "Epoch 5633/8000\n",
      "1463/1463 [==============================] - 15s 11ms/step - loss: 0.0469 - accuracy: 0.9855 - val_loss: 0.7092 - val_accuracy: 0.8454\n",
      "Epoch 5634/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0551 - accuracy: 0.9828 - val_loss: 0.6908 - val_accuracy: 0.8501\n",
      "Epoch 5635/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0519 - accuracy: 0.9838 - val_loss: 0.7522 - val_accuracy: 0.8411\n",
      "Epoch 5636/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0521 - accuracy: 0.9828 - val_loss: 0.6929 - val_accuracy: 0.8484\n",
      "Epoch 5637/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0546 - accuracy: 0.9830 - val_loss: 0.6605 - val_accuracy: 0.8563\n",
      "Epoch 5638/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0519 - accuracy: 0.9839 - val_loss: 0.7947 - val_accuracy: 0.8385\n",
      "Epoch 5639/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0482 - accuracy: 0.9846 - val_loss: 0.6826 - val_accuracy: 0.8520\n",
      "Epoch 5640/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0551 - accuracy: 0.9826 - val_loss: 0.6661 - val_accuracy: 0.8549\n",
      "Epoch 5641/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0528 - accuracy: 0.9840 - val_loss: 0.7206 - val_accuracy: 0.8454\n",
      "Epoch 5642/8000\n",
      "1463/1463 [==============================] - 17s 11ms/step - loss: 0.0557 - accuracy: 0.9825 - val_loss: 0.6600 - val_accuracy: 0.8570\n",
      "Epoch 5643/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0578 - accuracy: 0.9825 - val_loss: 0.7277 - val_accuracy: 0.8441\n",
      "Epoch 5644/8000\n",
      "1463/1463 [==============================] - 18s 12ms/step - loss: 0.0515 - accuracy: 0.9841 - val_loss: 0.6554 - val_accuracy: 0.8585\n",
      "Epoch 5645/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0490 - accuracy: 0.9846 - val_loss: 0.6639 - val_accuracy: 0.8592\n",
      "Epoch 5646/8000\n",
      "1463/1463 [==============================] - 17s 11ms/step - loss: 0.0578 - accuracy: 0.9820 - val_loss: 0.7262 - val_accuracy: 0.8449\n",
      "Epoch 5647/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0520 - accuracy: 0.9831 - val_loss: 0.7426 - val_accuracy: 0.8399\n",
      "Epoch 5648/8000\n",
      "1463/1463 [==============================] - 17s 11ms/step - loss: 0.0534 - accuracy: 0.9837 - val_loss: 0.6603 - val_accuracy: 0.8564\n",
      "Epoch 5649/8000\n",
      "1463/1463 [==============================] - 25s 17ms/step - loss: 0.0530 - accuracy: 0.9837 - val_loss: 0.7406 - val_accuracy: 0.8396\n",
      "Epoch 5650/8000\n",
      "1463/1463 [==============================] - 21s 14ms/step - loss: 0.0519 - accuracy: 0.9841 - val_loss: 0.6951 - val_accuracy: 0.8504\n",
      "Epoch 5651/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0550 - accuracy: 0.9836 - val_loss: 0.6909 - val_accuracy: 0.8516\n",
      "Epoch 5652/8000\n",
      "1463/1463 [==============================] - 18s 12ms/step - loss: 0.0497 - accuracy: 0.9843 - val_loss: 0.7339 - val_accuracy: 0.8460\n",
      "Epoch 5653/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0542 - accuracy: 0.9829 - val_loss: 0.6619 - val_accuracy: 0.8560\n",
      "Epoch 5654/8000\n",
      "1463/1463 [==============================] - 18s 12ms/step - loss: 0.0455 - accuracy: 0.9862 - val_loss: 0.6843 - val_accuracy: 0.8501\n",
      "Epoch 5655/8000\n",
      "1463/1463 [==============================] - 18s 12ms/step - loss: 0.0503 - accuracy: 0.9838 - val_loss: 0.6917 - val_accuracy: 0.8498\n",
      "Epoch 5656/8000\n",
      "1463/1463 [==============================] - 19s 13ms/step - loss: 0.0490 - accuracy: 0.9849 - val_loss: 0.6394 - val_accuracy: 0.8594\n",
      "Epoch 5657/8000\n",
      "1463/1463 [==============================] - 18s 12ms/step - loss: 0.0474 - accuracy: 0.9852 - val_loss: 0.6761 - val_accuracy: 0.8543\n",
      "Epoch 5658/8000\n",
      "1463/1463 [==============================] - 19s 13ms/step - loss: 0.0502 - accuracy: 0.9844 - val_loss: 0.9351 - val_accuracy: 0.8215\n",
      "Epoch 5659/8000\n",
      "1463/1463 [==============================] - 21s 14ms/step - loss: 0.0506 - accuracy: 0.9837 - val_loss: 0.6908 - val_accuracy: 0.8539\n",
      "Epoch 5660/8000\n",
      "1463/1463 [==============================] - 18s 12ms/step - loss: 0.0486 - accuracy: 0.9849 - val_loss: 0.6875 - val_accuracy: 0.8488\n",
      "Epoch 5661/8000\n",
      "1463/1463 [==============================] - 20s 13ms/step - loss: 0.0506 - accuracy: 0.9840 - val_loss: 0.6861 - val_accuracy: 0.8512\n",
      "Epoch 5662/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0554 - accuracy: 0.9823 - val_loss: 0.7011 - val_accuracy: 0.8495\n",
      "Epoch 5663/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0526 - accuracy: 0.9834 - val_loss: 0.7075 - val_accuracy: 0.8486\n",
      "Epoch 5664/8000\n",
      "1463/1463 [==============================] - 17s 11ms/step - loss: 0.0477 - accuracy: 0.9854 - val_loss: 0.7296 - val_accuracy: 0.8465\n",
      "Epoch 5665/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0590 - accuracy: 0.9823 - val_loss: 0.6773 - val_accuracy: 0.8522\n",
      "Epoch 5666/8000\n",
      "1463/1463 [==============================] - 21s 14ms/step - loss: 0.0582 - accuracy: 0.9814 - val_loss: 0.7436 - val_accuracy: 0.8445\n",
      "Epoch 5667/8000\n",
      "1463/1463 [==============================] - 20s 14ms/step - loss: 0.0562 - accuracy: 0.9821 - val_loss: 0.6827 - val_accuracy: 0.8508\n",
      "Epoch 5668/8000\n",
      "1463/1463 [==============================] - 18s 13ms/step - loss: 0.0484 - accuracy: 0.9853 - val_loss: 0.7033 - val_accuracy: 0.8420\n",
      "Epoch 5669/8000\n",
      "1463/1463 [==============================] - 18s 12ms/step - loss: 0.0540 - accuracy: 0.9828 - val_loss: 0.6976 - val_accuracy: 0.8498\n",
      "Epoch 5670/8000\n",
      "1463/1463 [==============================] - 18s 12ms/step - loss: 0.0530 - accuracy: 0.9836 - val_loss: 0.6721 - val_accuracy: 0.8543\n",
      "Epoch 5671/8000\n",
      "1463/1463 [==============================] - 18s 12ms/step - loss: 0.0559 - accuracy: 0.9832 - val_loss: 0.7023 - val_accuracy: 0.8529\n",
      "Epoch 5672/8000\n",
      "1463/1463 [==============================] - 18s 12ms/step - loss: 0.0528 - accuracy: 0.9838 - val_loss: 0.6942 - val_accuracy: 0.8528\n",
      "Epoch 5673/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0452 - accuracy: 0.9858 - val_loss: 0.7001 - val_accuracy: 0.8497\n",
      "Epoch 5674/8000\n",
      "1463/1463 [==============================] - 20s 14ms/step - loss: 0.0512 - accuracy: 0.9837 - val_loss: 0.7104 - val_accuracy: 0.8481\n",
      "Epoch 5675/8000\n",
      "1463/1463 [==============================] - 18s 12ms/step - loss: 0.0547 - accuracy: 0.9831 - val_loss: 0.7689 - val_accuracy: 0.8420\n",
      "Epoch 5676/8000\n",
      "1463/1463 [==============================] - 19s 13ms/step - loss: 0.0477 - accuracy: 0.9846 - val_loss: 0.6806 - val_accuracy: 0.8508\n",
      "Epoch 5677/8000\n",
      "1463/1463 [==============================] - 19s 13ms/step - loss: 0.0486 - accuracy: 0.9849 - val_loss: 0.7371 - val_accuracy: 0.8439\n",
      "Epoch 5678/8000\n",
      "1463/1463 [==============================] - 19s 13ms/step - loss: 0.0490 - accuracy: 0.9848 - val_loss: 0.6815 - val_accuracy: 0.8515\n",
      "Epoch 5679/8000\n",
      "1463/1463 [==============================] - 18s 12ms/step - loss: 0.0551 - accuracy: 0.9829 - val_loss: 0.7517 - val_accuracy: 0.8389\n",
      "Epoch 5680/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0514 - accuracy: 0.9841 - val_loss: 0.6747 - val_accuracy: 0.8546\n",
      "Epoch 5681/8000\n",
      "1463/1463 [==============================] - 20s 14ms/step - loss: 0.0524 - accuracy: 0.9838 - val_loss: 0.6620 - val_accuracy: 0.8550\n",
      "Epoch 5682/8000\n",
      "1463/1463 [==============================] - 19s 13ms/step - loss: 0.0524 - accuracy: 0.9834 - val_loss: 0.6518 - val_accuracy: 0.8548\n",
      "Epoch 5683/8000\n",
      "1463/1463 [==============================] - 19s 13ms/step - loss: 0.0525 - accuracy: 0.9839 - val_loss: 0.6627 - val_accuracy: 0.8550\n",
      "Epoch 5684/8000\n",
      "1463/1463 [==============================] - 18s 12ms/step - loss: 0.0534 - accuracy: 0.9831 - val_loss: 0.6778 - val_accuracy: 0.8529\n",
      "Epoch 5685/8000\n",
      "1463/1463 [==============================] - 18s 12ms/step - loss: 0.0488 - accuracy: 0.9844 - val_loss: 0.6466 - val_accuracy: 0.8639\n",
      "Epoch 5686/8000\n",
      "1463/1463 [==============================] - 19s 13ms/step - loss: 0.0537 - accuracy: 0.9831 - val_loss: 0.7347 - val_accuracy: 0.8439\n",
      "Epoch 5687/8000\n",
      "1463/1463 [==============================] - 19s 13ms/step - loss: 0.0599 - accuracy: 0.9821 - val_loss: 0.6945 - val_accuracy: 0.8489\n",
      "Epoch 5688/8000\n",
      "1463/1463 [==============================] - 18s 12ms/step - loss: 0.0519 - accuracy: 0.9838 - val_loss: 0.7080 - val_accuracy: 0.8492\n",
      "Epoch 5689/8000\n",
      "1463/1463 [==============================] - 21s 15ms/step - loss: 0.0534 - accuracy: 0.9828 - val_loss: 0.6969 - val_accuracy: 0.8525\n",
      "Epoch 5690/8000\n",
      "1463/1463 [==============================] - 21s 14ms/step - loss: 0.0518 - accuracy: 0.9837 - val_loss: 0.6669 - val_accuracy: 0.8533\n",
      "Epoch 5691/8000\n",
      "1463/1463 [==============================] - 20s 14ms/step - loss: 0.0578 - accuracy: 0.9818 - val_loss: 0.6795 - val_accuracy: 0.8533\n",
      "Epoch 5692/8000\n",
      "1463/1463 [==============================] - 20s 14ms/step - loss: 0.0467 - accuracy: 0.9850 - val_loss: 0.6797 - val_accuracy: 0.8533\n",
      "Epoch 5693/8000\n",
      "1463/1463 [==============================] - 22s 15ms/step - loss: 0.0529 - accuracy: 0.9835 - val_loss: 0.7279 - val_accuracy: 0.8457\n",
      "Epoch 5694/8000\n",
      "1463/1463 [==============================] - 30s 20ms/step - loss: 0.0473 - accuracy: 0.9847 - val_loss: 0.6888 - val_accuracy: 0.8506\n",
      "Epoch 5695/8000\n",
      "1463/1463 [==============================] - 22s 15ms/step - loss: 0.0552 - accuracy: 0.9830 - val_loss: 0.7595 - val_accuracy: 0.8413\n",
      "Epoch 5696/8000\n",
      "1463/1463 [==============================] - 18s 12ms/step - loss: 0.0546 - accuracy: 0.9824 - val_loss: 0.6946 - val_accuracy: 0.8535\n",
      "Epoch 5697/8000\n",
      "1463/1463 [==============================] - 20s 14ms/step - loss: 0.0530 - accuracy: 0.9838 - val_loss: 0.6914 - val_accuracy: 0.8504\n",
      "Epoch 5698/8000\n",
      "1463/1463 [==============================] - 20s 14ms/step - loss: 0.0457 - accuracy: 0.9860 - val_loss: 0.6788 - val_accuracy: 0.8535\n",
      "Epoch 5699/8000\n",
      "1463/1463 [==============================] - 19s 13ms/step - loss: 0.0545 - accuracy: 0.9833 - val_loss: 0.7222 - val_accuracy: 0.8478\n",
      "Epoch 5700/8000\n",
      "1459/1463 [============================>.] - ETA: 0s - loss: 0.0479 - accuracy: 0.9844\n",
      "Epoch 5700: saving model to ./training_ckpt_20240109205949_v8_240109_d10000_n4096_b64_e8000_c100_Adamax\\cp-000005700.ckpt\n",
      "1463/1463 [==============================] - 19s 13ms/step - loss: 0.0479 - accuracy: 0.9844 - val_loss: 0.7074 - val_accuracy: 0.8456\n",
      "Epoch 5701/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0524 - accuracy: 0.9836 - val_loss: 0.6767 - val_accuracy: 0.8549\n",
      "Epoch 5702/8000\n",
      "1463/1463 [==============================] - 15s 11ms/step - loss: 0.0489 - accuracy: 0.9850 - val_loss: 0.7511 - val_accuracy: 0.8383\n",
      "Epoch 5703/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0488 - accuracy: 0.9846 - val_loss: 0.6846 - val_accuracy: 0.8534\n",
      "Epoch 5704/8000\n",
      "1463/1463 [==============================] - 17s 11ms/step - loss: 0.0501 - accuracy: 0.9841 - val_loss: 0.6626 - val_accuracy: 0.8564\n",
      "Epoch 5705/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0534 - accuracy: 0.9839 - val_loss: 0.8238 - val_accuracy: 0.8291\n",
      "Epoch 5706/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0515 - accuracy: 0.9842 - val_loss: 0.6733 - val_accuracy: 0.8543\n",
      "Epoch 5707/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0515 - accuracy: 0.9842 - val_loss: 0.6785 - val_accuracy: 0.8533\n",
      "Epoch 5708/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0519 - accuracy: 0.9840 - val_loss: 0.7161 - val_accuracy: 0.8467\n",
      "Epoch 5709/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0551 - accuracy: 0.9828 - val_loss: 0.6877 - val_accuracy: 0.8501\n",
      "Epoch 5710/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0482 - accuracy: 0.9851 - val_loss: 0.7768 - val_accuracy: 0.8431\n",
      "Epoch 5711/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0478 - accuracy: 0.9850 - val_loss: 0.6846 - val_accuracy: 0.8517\n",
      "Epoch 5712/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0479 - accuracy: 0.9846 - val_loss: 0.8981 - val_accuracy: 0.8182\n",
      "Epoch 5713/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0544 - accuracy: 0.9828 - val_loss: 0.7029 - val_accuracy: 0.8473\n",
      "Epoch 5714/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0550 - accuracy: 0.9832 - val_loss: 0.7707 - val_accuracy: 0.8369\n",
      "Epoch 5715/8000\n",
      "1463/1463 [==============================] - 18s 12ms/step - loss: 0.0489 - accuracy: 0.9845 - val_loss: 0.6843 - val_accuracy: 0.8532\n",
      "Epoch 5716/8000\n",
      "1463/1463 [==============================] - 18s 12ms/step - loss: 0.0487 - accuracy: 0.9845 - val_loss: 0.6401 - val_accuracy: 0.8611\n",
      "Epoch 5717/8000\n",
      "1463/1463 [==============================] - 18s 12ms/step - loss: 0.0530 - accuracy: 0.9832 - val_loss: 0.7993 - val_accuracy: 0.8400\n",
      "Epoch 5718/8000\n",
      "1463/1463 [==============================] - 20s 14ms/step - loss: 0.0541 - accuracy: 0.9830 - val_loss: 0.7186 - val_accuracy: 0.8442\n",
      "Epoch 5719/8000\n",
      "1463/1463 [==============================] - 23s 15ms/step - loss: 0.0527 - accuracy: 0.9838 - val_loss: 0.7659 - val_accuracy: 0.8392\n",
      "Epoch 5720/8000\n",
      "1463/1463 [==============================] - 18s 12ms/step - loss: 0.0504 - accuracy: 0.9846 - val_loss: 0.6591 - val_accuracy: 0.8573\n",
      "Epoch 5721/8000\n",
      "1463/1463 [==============================] - 19s 13ms/step - loss: 0.0556 - accuracy: 0.9827 - val_loss: 0.7156 - val_accuracy: 0.8481\n",
      "Epoch 5722/8000\n",
      "1463/1463 [==============================] - 19s 13ms/step - loss: 0.0556 - accuracy: 0.9833 - val_loss: 0.6661 - val_accuracy: 0.8565\n",
      "Epoch 5723/8000\n",
      "1463/1463 [==============================] - 20s 13ms/step - loss: 0.0463 - accuracy: 0.9854 - val_loss: 0.7004 - val_accuracy: 0.8486\n",
      "Epoch 5724/8000\n",
      "1463/1463 [==============================] - 24s 16ms/step - loss: 0.0541 - accuracy: 0.9832 - val_loss: 0.6924 - val_accuracy: 0.8503\n",
      "Epoch 5725/8000\n",
      "1463/1463 [==============================] - 20s 13ms/step - loss: 0.0534 - accuracy: 0.9839 - val_loss: 0.7278 - val_accuracy: 0.8436\n",
      "Epoch 5726/8000\n",
      "1463/1463 [==============================] - 18s 12ms/step - loss: 0.0489 - accuracy: 0.9842 - val_loss: 0.7478 - val_accuracy: 0.8428\n",
      "Epoch 5727/8000\n",
      "1463/1463 [==============================] - 20s 14ms/step - loss: 0.0475 - accuracy: 0.9847 - val_loss: 0.6619 - val_accuracy: 0.8548\n",
      "Epoch 5728/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0500 - accuracy: 0.9844 - val_loss: 0.7169 - val_accuracy: 0.8469\n",
      "Epoch 5729/8000\n",
      "1463/1463 [==============================] - 20s 13ms/step - loss: 0.0516 - accuracy: 0.9840 - val_loss: 0.7169 - val_accuracy: 0.8464\n",
      "Epoch 5730/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0594 - accuracy: 0.9823 - val_loss: 0.7063 - val_accuracy: 0.8482\n",
      "Epoch 5731/8000\n",
      "1463/1463 [==============================] - 19s 13ms/step - loss: 0.0450 - accuracy: 0.9857 - val_loss: 0.6445 - val_accuracy: 0.8589\n",
      "Epoch 5732/8000\n",
      "1463/1463 [==============================] - 19s 13ms/step - loss: 0.0613 - accuracy: 0.9802 - val_loss: 0.7057 - val_accuracy: 0.8508\n",
      "Epoch 5733/8000\n",
      "1463/1463 [==============================] - 20s 13ms/step - loss: 0.0529 - accuracy: 0.9835 - val_loss: 0.6863 - val_accuracy: 0.8496\n",
      "Epoch 5734/8000\n",
      "1463/1463 [==============================] - 21s 14ms/step - loss: 0.0519 - accuracy: 0.9838 - val_loss: 0.7183 - val_accuracy: 0.8502\n",
      "Epoch 5735/8000\n",
      "1463/1463 [==============================] - 19s 13ms/step - loss: 0.0481 - accuracy: 0.9847 - val_loss: 0.6720 - val_accuracy: 0.8582\n",
      "Epoch 5736/8000\n",
      "1463/1463 [==============================] - 19s 13ms/step - loss: 0.0480 - accuracy: 0.9853 - val_loss: 0.7396 - val_accuracy: 0.8430\n",
      "Epoch 5737/8000\n",
      "1463/1463 [==============================] - 20s 14ms/step - loss: 0.0519 - accuracy: 0.9832 - val_loss: 0.6950 - val_accuracy: 0.8489\n",
      "Epoch 5738/8000\n",
      "1463/1463 [==============================] - 20s 13ms/step - loss: 0.0563 - accuracy: 0.9828 - val_loss: 0.6845 - val_accuracy: 0.8503\n",
      "Epoch 5739/8000\n",
      "1463/1463 [==============================] - 19s 13ms/step - loss: 0.0478 - accuracy: 0.9849 - val_loss: 0.7036 - val_accuracy: 0.8512\n",
      "Epoch 5740/8000\n",
      "1463/1463 [==============================] - 19s 13ms/step - loss: 0.0582 - accuracy: 0.9812 - val_loss: 0.6569 - val_accuracy: 0.8575\n",
      "Epoch 5741/8000\n",
      "1463/1463 [==============================] - 20s 14ms/step - loss: 0.0492 - accuracy: 0.9842 - val_loss: 0.6652 - val_accuracy: 0.8551\n",
      "Epoch 5742/8000\n",
      "1463/1463 [==============================] - 22s 15ms/step - loss: 0.0541 - accuracy: 0.9829 - val_loss: 0.7466 - val_accuracy: 0.8384\n",
      "Epoch 5743/8000\n",
      "1463/1463 [==============================] - 21s 14ms/step - loss: 0.0551 - accuracy: 0.9824 - val_loss: 0.7731 - val_accuracy: 0.8468\n",
      "Epoch 5744/8000\n",
      "1463/1463 [==============================] - 21s 14ms/step - loss: 0.0599 - accuracy: 0.9821 - val_loss: 0.7221 - val_accuracy: 0.8504\n",
      "Epoch 5745/8000\n",
      "1463/1463 [==============================] - 19s 13ms/step - loss: 0.0503 - accuracy: 0.9843 - val_loss: 0.7816 - val_accuracy: 0.8375\n",
      "Epoch 5746/8000\n",
      "1463/1463 [==============================] - 19s 13ms/step - loss: 0.0457 - accuracy: 0.9858 - val_loss: 0.6798 - val_accuracy: 0.8542\n",
      "Epoch 5747/8000\n",
      "1463/1463 [==============================] - 22s 15ms/step - loss: 0.0473 - accuracy: 0.9851 - val_loss: 0.6502 - val_accuracy: 0.8590\n",
      "Epoch 5748/8000\n",
      "1463/1463 [==============================] - 20s 14ms/step - loss: 0.0511 - accuracy: 0.9833 - val_loss: 0.6944 - val_accuracy: 0.8485\n",
      "Epoch 5749/8000\n",
      "1463/1463 [==============================] - 20s 14ms/step - loss: 0.0553 - accuracy: 0.9824 - val_loss: 0.7201 - val_accuracy: 0.8477\n",
      "Epoch 5750/8000\n",
      "1463/1463 [==============================] - 20s 14ms/step - loss: 0.0509 - accuracy: 0.9846 - val_loss: 0.6518 - val_accuracy: 0.8552\n",
      "Epoch 5751/8000\n",
      "1463/1463 [==============================] - 22s 15ms/step - loss: 0.0488 - accuracy: 0.9847 - val_loss: 0.7272 - val_accuracy: 0.8451\n",
      "Epoch 5752/8000\n",
      "1463/1463 [==============================] - 18s 12ms/step - loss: 0.0553 - accuracy: 0.9831 - val_loss: 0.6999 - val_accuracy: 0.8463\n",
      "Epoch 5753/8000\n",
      "1463/1463 [==============================] - 20s 14ms/step - loss: 0.0567 - accuracy: 0.9830 - val_loss: 0.7075 - val_accuracy: 0.8480\n",
      "Epoch 5754/8000\n",
      "1463/1463 [==============================] - 30s 20ms/step - loss: 0.0513 - accuracy: 0.9837 - val_loss: 0.6872 - val_accuracy: 0.8512\n",
      "Epoch 5755/8000\n",
      "1463/1463 [==============================] - 20s 14ms/step - loss: 0.0535 - accuracy: 0.9832 - val_loss: 0.7051 - val_accuracy: 0.8499\n",
      "Epoch 5756/8000\n",
      "1463/1463 [==============================] - 15s 11ms/step - loss: 0.0496 - accuracy: 0.9852 - val_loss: 0.6590 - val_accuracy: 0.8573\n",
      "Epoch 5757/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0521 - accuracy: 0.9839 - val_loss: 0.7026 - val_accuracy: 0.8476\n",
      "Epoch 5758/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0485 - accuracy: 0.9850 - val_loss: 0.6673 - val_accuracy: 0.8535\n",
      "Epoch 5759/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0460 - accuracy: 0.9856 - val_loss: 0.7383 - val_accuracy: 0.8435\n",
      "Epoch 5760/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0547 - accuracy: 0.9829 - val_loss: 0.7060 - val_accuracy: 0.8498\n",
      "Epoch 5761/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0490 - accuracy: 0.9848 - val_loss: 0.7299 - val_accuracy: 0.8438\n",
      "Epoch 5762/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0483 - accuracy: 0.9848 - val_loss: 0.9256 - val_accuracy: 0.8320\n",
      "Epoch 5763/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0447 - accuracy: 0.9859 - val_loss: 0.7638 - val_accuracy: 0.8395\n",
      "Epoch 5764/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0554 - accuracy: 0.9829 - val_loss: 0.7222 - val_accuracy: 0.8473\n",
      "Epoch 5765/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0487 - accuracy: 0.9848 - val_loss: 0.6675 - val_accuracy: 0.8562\n",
      "Epoch 5766/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0500 - accuracy: 0.9839 - val_loss: 0.6775 - val_accuracy: 0.8566\n",
      "Epoch 5767/8000\n",
      "1463/1463 [==============================] - 15s 11ms/step - loss: 0.0483 - accuracy: 0.9847 - val_loss: 0.7170 - val_accuracy: 0.8482\n",
      "Epoch 5768/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0557 - accuracy: 0.9821 - val_loss: 0.7775 - val_accuracy: 0.8456\n",
      "Epoch 5769/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0479 - accuracy: 0.9852 - val_loss: 0.6725 - val_accuracy: 0.8542\n",
      "Epoch 5770/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0492 - accuracy: 0.9848 - val_loss: 0.7687 - val_accuracy: 0.8414\n",
      "Epoch 5771/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0514 - accuracy: 0.9839 - val_loss: 0.6845 - val_accuracy: 0.8547\n",
      "Epoch 5772/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0499 - accuracy: 0.9840 - val_loss: 0.6918 - val_accuracy: 0.8549\n",
      "Epoch 5773/8000\n",
      "1463/1463 [==============================] - 18s 13ms/step - loss: 0.0542 - accuracy: 0.9831 - val_loss: 0.6695 - val_accuracy: 0.8579\n",
      "Epoch 5774/8000\n",
      "1463/1463 [==============================] - 19s 13ms/step - loss: 0.0499 - accuracy: 0.9840 - val_loss: 0.9140 - val_accuracy: 0.8275\n",
      "Epoch 5775/8000\n",
      "1463/1463 [==============================] - 20s 13ms/step - loss: 0.0528 - accuracy: 0.9834 - val_loss: 0.6422 - val_accuracy: 0.8580\n",
      "Epoch 5776/8000\n",
      "1463/1463 [==============================] - 19s 13ms/step - loss: 0.0555 - accuracy: 0.9827 - val_loss: 0.6425 - val_accuracy: 0.8596\n",
      "Epoch 5777/8000\n",
      "1463/1463 [==============================] - 19s 13ms/step - loss: 0.0497 - accuracy: 0.9843 - val_loss: 0.6554 - val_accuracy: 0.8566\n",
      "Epoch 5778/8000\n",
      "1463/1463 [==============================] - 18s 12ms/step - loss: 0.0466 - accuracy: 0.9861 - val_loss: 0.7168 - val_accuracy: 0.8488\n",
      "Epoch 5779/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0491 - accuracy: 0.9847 - val_loss: 0.7120 - val_accuracy: 0.8536\n",
      "Epoch 5780/8000\n",
      "1463/1463 [==============================] - 17s 11ms/step - loss: 0.0490 - accuracy: 0.9843 - val_loss: 0.6736 - val_accuracy: 0.8555\n",
      "Epoch 5781/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0512 - accuracy: 0.9839 - val_loss: 0.7021 - val_accuracy: 0.8501\n",
      "Epoch 5782/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0558 - accuracy: 0.9821 - val_loss: 0.6840 - val_accuracy: 0.8526\n",
      "Epoch 5783/8000\n",
      "1463/1463 [==============================] - 18s 12ms/step - loss: 0.0490 - accuracy: 0.9845 - val_loss: 0.6421 - val_accuracy: 0.8619\n",
      "Epoch 5784/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0529 - accuracy: 0.9839 - val_loss: 0.6571 - val_accuracy: 0.8602\n",
      "Epoch 5785/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0454 - accuracy: 0.9854 - val_loss: 0.6892 - val_accuracy: 0.8531\n",
      "Epoch 5786/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0473 - accuracy: 0.9852 - val_loss: 0.7206 - val_accuracy: 0.8514\n",
      "Epoch 5787/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0517 - accuracy: 0.9837 - val_loss: 0.6809 - val_accuracy: 0.8542\n",
      "Epoch 5788/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0488 - accuracy: 0.9849 - val_loss: 0.6646 - val_accuracy: 0.8578\n",
      "Epoch 5789/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0515 - accuracy: 0.9841 - val_loss: 0.6399 - val_accuracy: 0.8609\n",
      "Epoch 5790/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0502 - accuracy: 0.9843 - val_loss: 0.7059 - val_accuracy: 0.8508\n",
      "Epoch 5791/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0539 - accuracy: 0.9834 - val_loss: 0.6844 - val_accuracy: 0.8548\n",
      "Epoch 5792/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0516 - accuracy: 0.9842 - val_loss: 0.7223 - val_accuracy: 0.8481\n",
      "Epoch 5793/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0450 - accuracy: 0.9857 - val_loss: 0.6478 - val_accuracy: 0.8590\n",
      "Epoch 5794/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0549 - accuracy: 0.9829 - val_loss: 0.6875 - val_accuracy: 0.8512\n",
      "Epoch 5795/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0583 - accuracy: 0.9826 - val_loss: 0.7801 - val_accuracy: 0.8409\n",
      "Epoch 5796/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0478 - accuracy: 0.9854 - val_loss: 0.6923 - val_accuracy: 0.8517\n",
      "Epoch 5797/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0518 - accuracy: 0.9841 - val_loss: 0.7087 - val_accuracy: 0.8467\n",
      "Epoch 5798/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0488 - accuracy: 0.9847 - val_loss: 0.6686 - val_accuracy: 0.8596\n",
      "Epoch 5799/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0487 - accuracy: 0.9853 - val_loss: 0.6755 - val_accuracy: 0.8541\n",
      "Epoch 5800/8000\n",
      "1460/1463 [============================>.] - ETA: 0s - loss: 0.0497 - accuracy: 0.9846\n",
      "Epoch 5800: saving model to ./training_ckpt_20240109205949_v8_240109_d10000_n4096_b64_e8000_c100_Adamax\\cp-000005800.ckpt\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0497 - accuracy: 0.9846 - val_loss: 0.6805 - val_accuracy: 0.8565\n",
      "Epoch 5801/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0481 - accuracy: 0.9849 - val_loss: 0.6514 - val_accuracy: 0.8596\n",
      "Epoch 5802/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0504 - accuracy: 0.9849 - val_loss: 0.6543 - val_accuracy: 0.8565\n",
      "Epoch 5803/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0480 - accuracy: 0.9851 - val_loss: 0.6782 - val_accuracy: 0.8556\n",
      "Epoch 5804/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0487 - accuracy: 0.9845 - val_loss: 0.6596 - val_accuracy: 0.8583\n",
      "Epoch 5805/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0518 - accuracy: 0.9838 - val_loss: 0.6783 - val_accuracy: 0.8539\n",
      "Epoch 5806/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0535 - accuracy: 0.9834 - val_loss: 0.6729 - val_accuracy: 0.8552\n",
      "Epoch 5807/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0525 - accuracy: 0.9835 - val_loss: 0.6626 - val_accuracy: 0.8566\n",
      "Epoch 5808/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0662 - accuracy: 0.9799 - val_loss: 0.7018 - val_accuracy: 0.8474\n",
      "Epoch 5809/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0511 - accuracy: 0.9842 - val_loss: 0.7949 - val_accuracy: 0.8368\n",
      "Epoch 5810/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0483 - accuracy: 0.9847 - val_loss: 0.7120 - val_accuracy: 0.8477\n",
      "Epoch 5811/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0548 - accuracy: 0.9830 - val_loss: 0.7586 - val_accuracy: 0.8421\n",
      "Epoch 5812/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0542 - accuracy: 0.9829 - val_loss: 0.6592 - val_accuracy: 0.8557\n",
      "Epoch 5813/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0501 - accuracy: 0.9842 - val_loss: 0.7460 - val_accuracy: 0.8430\n",
      "Epoch 5814/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0502 - accuracy: 0.9845 - val_loss: 0.6876 - val_accuracy: 0.8570\n",
      "Epoch 5815/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0548 - accuracy: 0.9822 - val_loss: 0.6623 - val_accuracy: 0.8609\n",
      "Epoch 5816/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0529 - accuracy: 0.9835 - val_loss: 0.6633 - val_accuracy: 0.8564\n",
      "Epoch 5817/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0562 - accuracy: 0.9821 - val_loss: 0.7256 - val_accuracy: 0.8452\n",
      "Epoch 5818/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0493 - accuracy: 0.9842 - val_loss: 0.6904 - val_accuracy: 0.8511\n",
      "Epoch 5819/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0563 - accuracy: 0.9822 - val_loss: 0.7351 - val_accuracy: 0.8439\n",
      "Epoch 5820/8000\n",
      "1463/1463 [==============================] - 17s 11ms/step - loss: 0.0473 - accuracy: 0.9852 - val_loss: 0.7896 - val_accuracy: 0.8441\n",
      "Epoch 5821/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0551 - accuracy: 0.9828 - val_loss: 0.7175 - val_accuracy: 0.8502\n",
      "Epoch 5822/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0537 - accuracy: 0.9834 - val_loss: 0.7559 - val_accuracy: 0.8440\n",
      "Epoch 5823/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0481 - accuracy: 0.9848 - val_loss: 0.7076 - val_accuracy: 0.8504\n",
      "Epoch 5824/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0497 - accuracy: 0.9843 - val_loss: 0.6455 - val_accuracy: 0.8597\n",
      "Epoch 5825/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0488 - accuracy: 0.9845 - val_loss: 0.7368 - val_accuracy: 0.8455\n",
      "Epoch 5826/8000\n",
      "1463/1463 [==============================] - 17s 11ms/step - loss: 0.0553 - accuracy: 0.9830 - val_loss: 0.6446 - val_accuracy: 0.8583\n",
      "Epoch 5827/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0528 - accuracy: 0.9837 - val_loss: 0.6674 - val_accuracy: 0.8544\n",
      "Epoch 5828/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0512 - accuracy: 0.9841 - val_loss: 0.7358 - val_accuracy: 0.8469\n",
      "Epoch 5829/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0538 - accuracy: 0.9827 - val_loss: 0.6833 - val_accuracy: 0.8545\n",
      "Epoch 5830/8000\n",
      "1463/1463 [==============================] - 15s 11ms/step - loss: 0.0536 - accuracy: 0.9833 - val_loss: 0.9233 - val_accuracy: 0.8284\n",
      "Epoch 5831/8000\n",
      "1463/1463 [==============================] - 15s 11ms/step - loss: 0.0532 - accuracy: 0.9832 - val_loss: 0.6800 - val_accuracy: 0.8534\n",
      "Epoch 5832/8000\n",
      "1463/1463 [==============================] - 15s 11ms/step - loss: 0.0577 - accuracy: 0.9824 - val_loss: 0.6423 - val_accuracy: 0.8584\n",
      "Epoch 5833/8000\n",
      "1463/1463 [==============================] - 17s 11ms/step - loss: 0.0455 - accuracy: 0.9855 - val_loss: 0.6889 - val_accuracy: 0.8575\n",
      "Epoch 5834/8000\n",
      "1463/1463 [==============================] - 18s 12ms/step - loss: 0.0516 - accuracy: 0.9840 - val_loss: 0.6504 - val_accuracy: 0.8604\n",
      "Epoch 5835/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0494 - accuracy: 0.9845 - val_loss: 0.7192 - val_accuracy: 0.8489\n",
      "Epoch 5836/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0484 - accuracy: 0.9843 - val_loss: 0.6882 - val_accuracy: 0.8507\n",
      "Epoch 5837/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0498 - accuracy: 0.9845 - val_loss: 0.7159 - val_accuracy: 0.8477\n",
      "Epoch 5838/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0597 - accuracy: 0.9819 - val_loss: 0.7845 - val_accuracy: 0.8427\n",
      "Epoch 5839/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0511 - accuracy: 0.9836 - val_loss: 0.6547 - val_accuracy: 0.8555\n",
      "Epoch 5840/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0513 - accuracy: 0.9837 - val_loss: 0.6568 - val_accuracy: 0.8581\n",
      "Epoch 5841/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0593 - accuracy: 0.9824 - val_loss: 0.7355 - val_accuracy: 0.8486\n",
      "Epoch 5842/8000\n",
      "1463/1463 [==============================] - 17s 11ms/step - loss: 0.0524 - accuracy: 0.9834 - val_loss: 0.6948 - val_accuracy: 0.8503\n",
      "Epoch 5843/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0548 - accuracy: 0.9825 - val_loss: 0.7452 - val_accuracy: 0.8476\n",
      "Epoch 5844/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0473 - accuracy: 0.9849 - val_loss: 0.6711 - val_accuracy: 0.8595\n",
      "Epoch 5845/8000\n",
      "1463/1463 [==============================] - 19s 13ms/step - loss: 0.0516 - accuracy: 0.9836 - val_loss: 0.6638 - val_accuracy: 0.8592\n",
      "Epoch 5846/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0481 - accuracy: 0.9847 - val_loss: 0.7148 - val_accuracy: 0.8471\n",
      "Epoch 5847/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0496 - accuracy: 0.9847 - val_loss: 0.6716 - val_accuracy: 0.8552\n",
      "Epoch 5848/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0525 - accuracy: 0.9837 - val_loss: 0.6964 - val_accuracy: 0.8510\n",
      "Epoch 5849/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0569 - accuracy: 0.9822 - val_loss: 0.6711 - val_accuracy: 0.8568\n",
      "Epoch 5850/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0570 - accuracy: 0.9820 - val_loss: 0.6972 - val_accuracy: 0.8527\n",
      "Epoch 5851/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0512 - accuracy: 0.9843 - val_loss: 0.6678 - val_accuracy: 0.8529\n",
      "Epoch 5852/8000\n",
      "1463/1463 [==============================] - 18s 12ms/step - loss: 0.0486 - accuracy: 0.9846 - val_loss: 0.6862 - val_accuracy: 0.8531\n",
      "Epoch 5853/8000\n",
      "1463/1463 [==============================] - 17s 11ms/step - loss: 0.0489 - accuracy: 0.9848 - val_loss: 0.6921 - val_accuracy: 0.8487\n",
      "Epoch 5854/8000\n",
      "1463/1463 [==============================] - 18s 12ms/step - loss: 0.0483 - accuracy: 0.9847 - val_loss: 0.7040 - val_accuracy: 0.8513\n",
      "Epoch 5855/8000\n",
      "1463/1463 [==============================] - 22s 15ms/step - loss: 0.0488 - accuracy: 0.9849 - val_loss: 0.7062 - val_accuracy: 0.8475\n",
      "Epoch 5856/8000\n",
      "1463/1463 [==============================] - 18s 12ms/step - loss: 0.0560 - accuracy: 0.9821 - val_loss: 0.6646 - val_accuracy: 0.8557\n",
      "Epoch 5857/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0446 - accuracy: 0.9850 - val_loss: 0.7031 - val_accuracy: 0.8519\n",
      "Epoch 5858/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0531 - accuracy: 0.9834 - val_loss: 0.7178 - val_accuracy: 0.8468\n",
      "Epoch 5859/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0536 - accuracy: 0.9832 - val_loss: 0.7086 - val_accuracy: 0.8500\n",
      "Epoch 5860/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0528 - accuracy: 0.9837 - val_loss: 0.7121 - val_accuracy: 0.8490\n",
      "Epoch 5861/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0509 - accuracy: 0.9846 - val_loss: 0.9342 - val_accuracy: 0.8348\n",
      "Epoch 5862/8000\n",
      "1463/1463 [==============================] - 17s 11ms/step - loss: 0.0512 - accuracy: 0.9838 - val_loss: 0.7275 - val_accuracy: 0.8466\n",
      "Epoch 5863/8000\n",
      "1463/1463 [==============================] - 17s 11ms/step - loss: 0.0559 - accuracy: 0.9828 - val_loss: 0.7516 - val_accuracy: 0.8402\n",
      "Epoch 5864/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0497 - accuracy: 0.9844 - val_loss: 0.6847 - val_accuracy: 0.8562\n",
      "Epoch 5865/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0494 - accuracy: 0.9842 - val_loss: 0.7321 - val_accuracy: 0.8413\n",
      "Epoch 5866/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0512 - accuracy: 0.9841 - val_loss: 0.6664 - val_accuracy: 0.8546\n",
      "Epoch 5867/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0532 - accuracy: 0.9833 - val_loss: 0.6764 - val_accuracy: 0.8575\n",
      "Epoch 5868/8000\n",
      "1463/1463 [==============================] - 17s 11ms/step - loss: 0.0505 - accuracy: 0.9839 - val_loss: 0.6754 - val_accuracy: 0.8553\n",
      "Epoch 5869/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0458 - accuracy: 0.9851 - val_loss: 0.7004 - val_accuracy: 0.8506\n",
      "Epoch 5870/8000\n",
      "1463/1463 [==============================] - 17s 11ms/step - loss: 0.0536 - accuracy: 0.9831 - val_loss: 0.6647 - val_accuracy: 0.8557\n",
      "Epoch 5871/8000\n",
      "1463/1463 [==============================] - 15s 11ms/step - loss: 0.0571 - accuracy: 0.9832 - val_loss: 0.6532 - val_accuracy: 0.8597\n",
      "Epoch 5872/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0449 - accuracy: 0.9857 - val_loss: 0.7391 - val_accuracy: 0.8463\n",
      "Epoch 5873/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0557 - accuracy: 0.9826 - val_loss: 0.6817 - val_accuracy: 0.8518\n",
      "Epoch 5874/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0456 - accuracy: 0.9861 - val_loss: 0.7363 - val_accuracy: 0.8492\n",
      "Epoch 5875/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0489 - accuracy: 0.9848 - val_loss: 0.7620 - val_accuracy: 0.8376\n",
      "Epoch 5876/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0479 - accuracy: 0.9851 - val_loss: 0.6773 - val_accuracy: 0.8546\n",
      "Epoch 5877/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0525 - accuracy: 0.9838 - val_loss: 0.6920 - val_accuracy: 0.8532\n",
      "Epoch 5878/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0526 - accuracy: 0.9837 - val_loss: 0.6651 - val_accuracy: 0.8565\n",
      "Epoch 5879/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0485 - accuracy: 0.9847 - val_loss: 0.6464 - val_accuracy: 0.8616\n",
      "Epoch 5880/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0478 - accuracy: 0.9851 - val_loss: 0.8741 - val_accuracy: 0.8350\n",
      "Epoch 5881/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0518 - accuracy: 0.9838 - val_loss: 0.6972 - val_accuracy: 0.8512\n",
      "Epoch 5882/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0499 - accuracy: 0.9839 - val_loss: 0.6934 - val_accuracy: 0.8512\n",
      "Epoch 5883/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0481 - accuracy: 0.9850 - val_loss: 0.6640 - val_accuracy: 0.8575\n",
      "Epoch 5884/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0472 - accuracy: 0.9850 - val_loss: 0.6940 - val_accuracy: 0.8503\n",
      "Epoch 5885/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0537 - accuracy: 0.9831 - val_loss: 0.6675 - val_accuracy: 0.8555\n",
      "Epoch 5886/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0512 - accuracy: 0.9840 - val_loss: 0.6975 - val_accuracy: 0.8497\n",
      "Epoch 5887/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0518 - accuracy: 0.9840 - val_loss: 0.6754 - val_accuracy: 0.8563\n",
      "Epoch 5888/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0483 - accuracy: 0.9842 - val_loss: 0.7107 - val_accuracy: 0.8506\n",
      "Epoch 5889/8000\n",
      "1463/1463 [==============================] - 15s 11ms/step - loss: 0.0458 - accuracy: 0.9855 - val_loss: 0.6609 - val_accuracy: 0.8568\n",
      "Epoch 5890/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0503 - accuracy: 0.9840 - val_loss: 0.7554 - val_accuracy: 0.8484\n",
      "Epoch 5891/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0511 - accuracy: 0.9840 - val_loss: 0.6397 - val_accuracy: 0.8622\n",
      "Epoch 5892/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0438 - accuracy: 0.9861 - val_loss: 0.6842 - val_accuracy: 0.8531\n",
      "Epoch 5893/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0483 - accuracy: 0.9848 - val_loss: 0.7518 - val_accuracy: 0.8483\n",
      "Epoch 5894/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0529 - accuracy: 0.9837 - val_loss: 0.7403 - val_accuracy: 0.8480\n",
      "Epoch 5895/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0461 - accuracy: 0.9851 - val_loss: 0.6681 - val_accuracy: 0.8552\n",
      "Epoch 5896/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0568 - accuracy: 0.9822 - val_loss: 0.6708 - val_accuracy: 0.8561\n",
      "Epoch 5897/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0484 - accuracy: 0.9851 - val_loss: 0.6814 - val_accuracy: 0.8569\n",
      "Epoch 5898/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0522 - accuracy: 0.9835 - val_loss: 0.6842 - val_accuracy: 0.8559\n",
      "Epoch 5899/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0524 - accuracy: 0.9837 - val_loss: 0.6878 - val_accuracy: 0.8524\n",
      "Epoch 5900/8000\n",
      "1460/1463 [============================>.] - ETA: 0s - loss: 0.0533 - accuracy: 0.9836\n",
      "Epoch 5900: saving model to ./training_ckpt_20240109205949_v8_240109_d10000_n4096_b64_e8000_c100_Adamax\\cp-000005900.ckpt\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0534 - accuracy: 0.9836 - val_loss: 0.6917 - val_accuracy: 0.8563\n",
      "Epoch 5901/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0468 - accuracy: 0.9852 - val_loss: 0.6379 - val_accuracy: 0.8640\n",
      "Epoch 5902/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0489 - accuracy: 0.9848 - val_loss: 0.6564 - val_accuracy: 0.8575\n",
      "Epoch 5903/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0493 - accuracy: 0.9845 - val_loss: 0.6456 - val_accuracy: 0.8614\n",
      "Epoch 5904/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0520 - accuracy: 0.9836 - val_loss: 0.7553 - val_accuracy: 0.8493\n",
      "Epoch 5905/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0533 - accuracy: 0.9834 - val_loss: 0.7591 - val_accuracy: 0.8462\n",
      "Epoch 5906/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0573 - accuracy: 0.9827 - val_loss: 0.6981 - val_accuracy: 0.8523\n",
      "Epoch 5907/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0475 - accuracy: 0.9845 - val_loss: 0.7251 - val_accuracy: 0.8504\n",
      "Epoch 5908/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0504 - accuracy: 0.9839 - val_loss: 0.6819 - val_accuracy: 0.8536\n",
      "Epoch 5909/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0538 - accuracy: 0.9832 - val_loss: 0.7322 - val_accuracy: 0.8454\n",
      "Epoch 5910/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0491 - accuracy: 0.9842 - val_loss: 0.7287 - val_accuracy: 0.8467\n",
      "Epoch 5911/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0548 - accuracy: 0.9829 - val_loss: 0.7068 - val_accuracy: 0.8502\n",
      "Epoch 5912/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0538 - accuracy: 0.9835 - val_loss: 0.7138 - val_accuracy: 0.8507\n",
      "Epoch 5913/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0493 - accuracy: 0.9845 - val_loss: 0.6725 - val_accuracy: 0.8593\n",
      "Epoch 5914/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0525 - accuracy: 0.9834 - val_loss: 0.7206 - val_accuracy: 0.8465\n",
      "Epoch 5915/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0494 - accuracy: 0.9842 - val_loss: 0.7476 - val_accuracy: 0.8512\n",
      "Epoch 5916/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0552 - accuracy: 0.9829 - val_loss: 0.6662 - val_accuracy: 0.8581\n",
      "Epoch 5917/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0504 - accuracy: 0.9840 - val_loss: 0.7322 - val_accuracy: 0.8448\n",
      "Epoch 5918/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0533 - accuracy: 0.9834 - val_loss: 0.6464 - val_accuracy: 0.8595\n",
      "Epoch 5919/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0571 - accuracy: 0.9825 - val_loss: 0.7126 - val_accuracy: 0.8538\n",
      "Epoch 5920/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0522 - accuracy: 0.9839 - val_loss: 0.7164 - val_accuracy: 0.8497\n",
      "Epoch 5921/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0408 - accuracy: 0.9875 - val_loss: 0.7284 - val_accuracy: 0.8489\n",
      "Epoch 5922/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0531 - accuracy: 0.9832 - val_loss: 0.8459 - val_accuracy: 0.8317\n",
      "Epoch 5923/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0497 - accuracy: 0.9844 - val_loss: 0.6508 - val_accuracy: 0.8599\n",
      "Epoch 5924/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0545 - accuracy: 0.9827 - val_loss: 0.6948 - val_accuracy: 0.8532\n",
      "Epoch 5925/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0531 - accuracy: 0.9829 - val_loss: 0.7075 - val_accuracy: 0.8494\n",
      "Epoch 5926/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0528 - accuracy: 0.9831 - val_loss: 0.6837 - val_accuracy: 0.8544\n",
      "Epoch 5927/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0477 - accuracy: 0.9852 - val_loss: 0.7874 - val_accuracy: 0.8437\n",
      "Epoch 5928/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0503 - accuracy: 0.9846 - val_loss: 0.6499 - val_accuracy: 0.8634\n",
      "Epoch 5929/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0535 - accuracy: 0.9846 - val_loss: 0.7194 - val_accuracy: 0.8486\n",
      "Epoch 5930/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0512 - accuracy: 0.9838 - val_loss: 0.7496 - val_accuracy: 0.8447\n",
      "Epoch 5931/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0473 - accuracy: 0.9854 - val_loss: 0.7135 - val_accuracy: 0.8477\n",
      "Epoch 5932/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0555 - accuracy: 0.9834 - val_loss: 0.6476 - val_accuracy: 0.8604\n",
      "Epoch 5933/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0470 - accuracy: 0.9849 - val_loss: 0.7224 - val_accuracy: 0.8484\n",
      "Epoch 5934/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0528 - accuracy: 0.9835 - val_loss: 0.7436 - val_accuracy: 0.8493\n",
      "Epoch 5935/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0478 - accuracy: 0.9846 - val_loss: 0.6900 - val_accuracy: 0.8532\n",
      "Epoch 5936/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0580 - accuracy: 0.9813 - val_loss: 0.6760 - val_accuracy: 0.8537\n",
      "Epoch 5937/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0533 - accuracy: 0.9839 - val_loss: 0.6867 - val_accuracy: 0.8568\n",
      "Epoch 5938/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0487 - accuracy: 0.9840 - val_loss: 0.6645 - val_accuracy: 0.8527\n",
      "Epoch 5939/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0498 - accuracy: 0.9844 - val_loss: 0.7141 - val_accuracy: 0.8462\n",
      "Epoch 5940/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0562 - accuracy: 0.9828 - val_loss: 0.7682 - val_accuracy: 0.8389\n",
      "Epoch 5941/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0451 - accuracy: 0.9854 - val_loss: 0.6331 - val_accuracy: 0.8607\n",
      "Epoch 5942/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0483 - accuracy: 0.9849 - val_loss: 0.7286 - val_accuracy: 0.8488\n",
      "Epoch 5943/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0469 - accuracy: 0.9851 - val_loss: 0.7087 - val_accuracy: 0.8514\n",
      "Epoch 5944/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0506 - accuracy: 0.9838 - val_loss: 0.7119 - val_accuracy: 0.8511\n",
      "Epoch 5945/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0510 - accuracy: 0.9842 - val_loss: 0.7380 - val_accuracy: 0.8441\n",
      "Epoch 5946/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0516 - accuracy: 0.9841 - val_loss: 0.8771 - val_accuracy: 0.8299\n",
      "Epoch 5947/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0458 - accuracy: 0.9859 - val_loss: 0.7053 - val_accuracy: 0.8497\n",
      "Epoch 5948/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0485 - accuracy: 0.9843 - val_loss: 0.7319 - val_accuracy: 0.8434\n",
      "Epoch 5949/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0498 - accuracy: 0.9846 - val_loss: 0.7064 - val_accuracy: 0.8472\n",
      "Epoch 5950/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0472 - accuracy: 0.9854 - val_loss: 0.7341 - val_accuracy: 0.8478\n",
      "Epoch 5951/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0465 - accuracy: 0.9853 - val_loss: 0.7091 - val_accuracy: 0.8513\n",
      "Epoch 5952/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0462 - accuracy: 0.9857 - val_loss: 0.6511 - val_accuracy: 0.8583\n",
      "Epoch 5953/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0482 - accuracy: 0.9853 - val_loss: 0.6564 - val_accuracy: 0.8569\n",
      "Epoch 5954/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0469 - accuracy: 0.9857 - val_loss: 0.6801 - val_accuracy: 0.8547\n",
      "Epoch 5955/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0479 - accuracy: 0.9848 - val_loss: 0.7884 - val_accuracy: 0.8375\n",
      "Epoch 5956/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0450 - accuracy: 0.9856 - val_loss: 0.7160 - val_accuracy: 0.8481\n",
      "Epoch 5957/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0460 - accuracy: 0.9859 - val_loss: 0.6921 - val_accuracy: 0.8553\n",
      "Epoch 5958/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0534 - accuracy: 0.9840 - val_loss: 0.7016 - val_accuracy: 0.8478\n",
      "Epoch 5959/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0433 - accuracy: 0.9868 - val_loss: 0.6822 - val_accuracy: 0.8527\n",
      "Epoch 5960/8000\n",
      "1463/1463 [==============================] - 20s 14ms/step - loss: 0.0524 - accuracy: 0.9835 - val_loss: 0.6679 - val_accuracy: 0.8555\n",
      "Epoch 5961/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0442 - accuracy: 0.9865 - val_loss: 0.6845 - val_accuracy: 0.8553\n",
      "Epoch 5962/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0506 - accuracy: 0.9842 - val_loss: 0.7017 - val_accuracy: 0.8539\n",
      "Epoch 5963/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0543 - accuracy: 0.9835 - val_loss: 0.7021 - val_accuracy: 0.8502\n",
      "Epoch 5964/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0522 - accuracy: 0.9835 - val_loss: 0.6777 - val_accuracy: 0.8533\n",
      "Epoch 5965/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0504 - accuracy: 0.9843 - val_loss: 0.7392 - val_accuracy: 0.8476\n",
      "Epoch 5966/8000\n",
      "1463/1463 [==============================] - 17s 11ms/step - loss: 0.0499 - accuracy: 0.9841 - val_loss: 0.6946 - val_accuracy: 0.8515\n",
      "Epoch 5967/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0491 - accuracy: 0.9846 - val_loss: 0.6699 - val_accuracy: 0.8568\n",
      "Epoch 5968/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0536 - accuracy: 0.9836 - val_loss: 0.6527 - val_accuracy: 0.8607\n",
      "Epoch 5969/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0505 - accuracy: 0.9843 - val_loss: 0.7491 - val_accuracy: 0.8411\n",
      "Epoch 5970/8000\n",
      "1463/1463 [==============================] - 17s 11ms/step - loss: 0.0487 - accuracy: 0.9847 - val_loss: 0.6601 - val_accuracy: 0.8588\n",
      "Epoch 5971/8000\n",
      "1463/1463 [==============================] - 17s 11ms/step - loss: 0.0508 - accuracy: 0.9838 - val_loss: 0.6779 - val_accuracy: 0.8551\n",
      "Epoch 5972/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0547 - accuracy: 0.9830 - val_loss: 0.6842 - val_accuracy: 0.8549\n",
      "Epoch 5973/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0506 - accuracy: 0.9838 - val_loss: 0.6954 - val_accuracy: 0.8525\n",
      "Epoch 5974/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0530 - accuracy: 0.9841 - val_loss: 0.7344 - val_accuracy: 0.8430\n",
      "Epoch 5975/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0501 - accuracy: 0.9842 - val_loss: 0.7494 - val_accuracy: 0.8446\n",
      "Epoch 5976/8000\n",
      "1463/1463 [==============================] - 18s 12ms/step - loss: 0.0489 - accuracy: 0.9848 - val_loss: 0.6957 - val_accuracy: 0.8538\n",
      "Epoch 5977/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0553 - accuracy: 0.9835 - val_loss: 0.7130 - val_accuracy: 0.8508\n",
      "Epoch 5978/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0465 - accuracy: 0.9852 - val_loss: 0.6900 - val_accuracy: 0.8548\n",
      "Epoch 5979/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0471 - accuracy: 0.9848 - val_loss: 0.6696 - val_accuracy: 0.8552\n",
      "Epoch 5980/8000\n",
      "1463/1463 [==============================] - 17s 11ms/step - loss: 0.0505 - accuracy: 0.9838 - val_loss: 0.7239 - val_accuracy: 0.8465\n",
      "Epoch 5981/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0491 - accuracy: 0.9842 - val_loss: 0.7347 - val_accuracy: 0.8468\n",
      "Epoch 5982/8000\n",
      "1463/1463 [==============================] - 17s 11ms/step - loss: 0.0500 - accuracy: 0.9842 - val_loss: 0.7629 - val_accuracy: 0.8449\n",
      "Epoch 5983/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0476 - accuracy: 0.9847 - val_loss: 0.6351 - val_accuracy: 0.8599\n",
      "Epoch 5984/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0555 - accuracy: 0.9832 - val_loss: 0.7213 - val_accuracy: 0.8511\n",
      "Epoch 5985/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0533 - accuracy: 0.9833 - val_loss: 0.7566 - val_accuracy: 0.8438\n",
      "Epoch 5986/8000\n",
      "1463/1463 [==============================] - 17s 11ms/step - loss: 0.0494 - accuracy: 0.9844 - val_loss: 0.6571 - val_accuracy: 0.8577\n",
      "Epoch 5987/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0493 - accuracy: 0.9840 - val_loss: 0.7258 - val_accuracy: 0.8502\n",
      "Epoch 5988/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0496 - accuracy: 0.9843 - val_loss: 0.6887 - val_accuracy: 0.8525\n",
      "Epoch 5989/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0464 - accuracy: 0.9858 - val_loss: 0.6498 - val_accuracy: 0.8592\n",
      "Epoch 5990/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0471 - accuracy: 0.9854 - val_loss: 0.6985 - val_accuracy: 0.8495\n",
      "Epoch 5991/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0473 - accuracy: 0.9854 - val_loss: 0.6559 - val_accuracy: 0.8624\n",
      "Epoch 5992/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0532 - accuracy: 0.9835 - val_loss: 0.6665 - val_accuracy: 0.8559\n",
      "Epoch 5993/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0503 - accuracy: 0.9845 - val_loss: 0.6621 - val_accuracy: 0.8567\n",
      "Epoch 5994/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0476 - accuracy: 0.9849 - val_loss: 0.7147 - val_accuracy: 0.8497\n",
      "Epoch 5995/8000\n",
      "1463/1463 [==============================] - 19s 13ms/step - loss: 0.0551 - accuracy: 0.9829 - val_loss: 0.6684 - val_accuracy: 0.8572\n",
      "Epoch 5996/8000\n",
      "1463/1463 [==============================] - 18s 12ms/step - loss: 0.0480 - accuracy: 0.9851 - val_loss: 0.7536 - val_accuracy: 0.8446\n",
      "Epoch 5997/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0450 - accuracy: 0.9860 - val_loss: 0.6424 - val_accuracy: 0.8617\n",
      "Epoch 5998/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0488 - accuracy: 0.9849 - val_loss: 0.7055 - val_accuracy: 0.8523\n",
      "Epoch 5999/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0538 - accuracy: 0.9833 - val_loss: 0.7195 - val_accuracy: 0.8479\n",
      "Epoch 6000/8000\n",
      "1463/1463 [==============================] - ETA: 0s - loss: 0.0495 - accuracy: 0.9846\n",
      "Epoch 6000: saving model to ./training_ckpt_20240109205949_v8_240109_d10000_n4096_b64_e8000_c100_Adamax\\cp-000006000.ckpt\n",
      "1463/1463 [==============================] - 15s 11ms/step - loss: 0.0495 - accuracy: 0.9846 - val_loss: 0.6596 - val_accuracy: 0.8606\n",
      "Epoch 6001/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0438 - accuracy: 0.9864 - val_loss: 0.6814 - val_accuracy: 0.8537\n",
      "Epoch 6002/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0592 - accuracy: 0.9818 - val_loss: 0.7074 - val_accuracy: 0.8522\n",
      "Epoch 6003/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0535 - accuracy: 0.9833 - val_loss: 0.6744 - val_accuracy: 0.8560\n",
      "Epoch 6004/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0487 - accuracy: 0.9861 - val_loss: 0.6234 - val_accuracy: 0.8649\n",
      "Epoch 6005/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0538 - accuracy: 0.9834 - val_loss: 0.6695 - val_accuracy: 0.8534\n",
      "Epoch 6006/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0489 - accuracy: 0.9851 - val_loss: 0.7006 - val_accuracy: 0.8529\n",
      "Epoch 6007/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0540 - accuracy: 0.9832 - val_loss: 0.7848 - val_accuracy: 0.8411\n",
      "Epoch 6008/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0508 - accuracy: 0.9842 - val_loss: 0.6777 - val_accuracy: 0.8542\n",
      "Epoch 6009/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0502 - accuracy: 0.9844 - val_loss: 0.6902 - val_accuracy: 0.8504\n",
      "Epoch 6010/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0558 - accuracy: 0.9830 - val_loss: 0.7478 - val_accuracy: 0.8473\n",
      "Epoch 6011/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0471 - accuracy: 0.9855 - val_loss: 0.7101 - val_accuracy: 0.8523\n",
      "Epoch 6012/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0529 - accuracy: 0.9835 - val_loss: 0.6853 - val_accuracy: 0.8528\n",
      "Epoch 6013/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0531 - accuracy: 0.9835 - val_loss: 0.6992 - val_accuracy: 0.8561\n",
      "Epoch 6014/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0522 - accuracy: 0.9832 - val_loss: 0.7058 - val_accuracy: 0.8530\n",
      "Epoch 6015/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0495 - accuracy: 0.9850 - val_loss: 0.7161 - val_accuracy: 0.8517\n",
      "Epoch 6016/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0498 - accuracy: 0.9848 - val_loss: 0.7627 - val_accuracy: 0.8442\n",
      "Epoch 6017/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0517 - accuracy: 0.9836 - val_loss: 0.6815 - val_accuracy: 0.8541\n",
      "Epoch 6018/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0522 - accuracy: 0.9841 - val_loss: 0.6827 - val_accuracy: 0.8545\n",
      "Epoch 6019/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0482 - accuracy: 0.9849 - val_loss: 0.7459 - val_accuracy: 0.8448\n",
      "Epoch 6020/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0474 - accuracy: 0.9854 - val_loss: 0.7937 - val_accuracy: 0.8393\n",
      "Epoch 6021/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0551 - accuracy: 0.9830 - val_loss: 0.7147 - val_accuracy: 0.8490\n",
      "Epoch 6022/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0429 - accuracy: 0.9866 - val_loss: 0.6952 - val_accuracy: 0.8521\n",
      "Epoch 6023/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0526 - accuracy: 0.9829 - val_loss: 0.6949 - val_accuracy: 0.8534\n",
      "Epoch 6024/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0468 - accuracy: 0.9857 - val_loss: 0.6975 - val_accuracy: 0.8517\n",
      "Epoch 6025/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0496 - accuracy: 0.9839 - val_loss: 0.7764 - val_accuracy: 0.8426\n",
      "Epoch 6026/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0500 - accuracy: 0.9846 - val_loss: 0.6617 - val_accuracy: 0.8565\n",
      "Epoch 6027/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0478 - accuracy: 0.9849 - val_loss: 0.6976 - val_accuracy: 0.8511\n",
      "Epoch 6028/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0493 - accuracy: 0.9844 - val_loss: 0.7717 - val_accuracy: 0.8426\n",
      "Epoch 6029/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0458 - accuracy: 0.9854 - val_loss: 0.6828 - val_accuracy: 0.8539\n",
      "Epoch 6030/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0488 - accuracy: 0.9847 - val_loss: 0.6834 - val_accuracy: 0.8518\n",
      "Epoch 6031/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0523 - accuracy: 0.9839 - val_loss: 0.6543 - val_accuracy: 0.8583\n",
      "Epoch 6032/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0504 - accuracy: 0.9839 - val_loss: 0.7109 - val_accuracy: 0.8539\n",
      "Epoch 6033/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0543 - accuracy: 0.9826 - val_loss: 0.8509 - val_accuracy: 0.8350\n",
      "Epoch 6034/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0513 - accuracy: 0.9842 - val_loss: 0.7115 - val_accuracy: 0.8537\n",
      "Epoch 6035/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0532 - accuracy: 0.9836 - val_loss: 0.6893 - val_accuracy: 0.8547\n",
      "Epoch 6036/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0514 - accuracy: 0.9843 - val_loss: 0.7187 - val_accuracy: 0.8508\n",
      "Epoch 6037/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0651 - accuracy: 0.9808 - val_loss: 0.7491 - val_accuracy: 0.8460\n",
      "Epoch 6038/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0430 - accuracy: 0.9861 - val_loss: 0.6485 - val_accuracy: 0.8624\n",
      "Epoch 6039/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0471 - accuracy: 0.9854 - val_loss: 0.6395 - val_accuracy: 0.8613\n",
      "Epoch 6040/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0450 - accuracy: 0.9863 - val_loss: 0.6849 - val_accuracy: 0.8576\n",
      "Epoch 6041/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0527 - accuracy: 0.9841 - val_loss: 0.7160 - val_accuracy: 0.8488\n",
      "Epoch 6042/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0511 - accuracy: 0.9841 - val_loss: 0.7235 - val_accuracy: 0.8433\n",
      "Epoch 6043/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0535 - accuracy: 0.9838 - val_loss: 0.6990 - val_accuracy: 0.8514\n",
      "Epoch 6044/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0524 - accuracy: 0.9835 - val_loss: 0.6573 - val_accuracy: 0.8571\n",
      "Epoch 6045/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0500 - accuracy: 0.9846 - val_loss: 0.7767 - val_accuracy: 0.8395\n",
      "Epoch 6046/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0491 - accuracy: 0.9846 - val_loss: 0.7205 - val_accuracy: 0.8508\n",
      "Epoch 6047/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0500 - accuracy: 0.9844 - val_loss: 0.6828 - val_accuracy: 0.8555\n",
      "Epoch 6048/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0505 - accuracy: 0.9840 - val_loss: 0.6596 - val_accuracy: 0.8587\n",
      "Epoch 6049/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0505 - accuracy: 0.9839 - val_loss: 0.6977 - val_accuracy: 0.8510\n",
      "Epoch 6050/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0423 - accuracy: 0.9868 - val_loss: 0.7482 - val_accuracy: 0.8496\n",
      "Epoch 6051/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0506 - accuracy: 0.9845 - val_loss: 0.6925 - val_accuracy: 0.8533\n",
      "Epoch 6052/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0574 - accuracy: 0.9823 - val_loss: 0.7396 - val_accuracy: 0.8462\n",
      "Epoch 6053/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0467 - accuracy: 0.9855 - val_loss: 0.6572 - val_accuracy: 0.8573\n",
      "Epoch 6054/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0536 - accuracy: 0.9835 - val_loss: 0.6555 - val_accuracy: 0.8615\n",
      "Epoch 6055/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0474 - accuracy: 0.9851 - val_loss: 0.7605 - val_accuracy: 0.8445\n",
      "Epoch 6056/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0503 - accuracy: 0.9842 - val_loss: 0.6867 - val_accuracy: 0.8538\n",
      "Epoch 6057/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0462 - accuracy: 0.9855 - val_loss: 0.7053 - val_accuracy: 0.8542\n",
      "Epoch 6058/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0499 - accuracy: 0.9851 - val_loss: 0.6518 - val_accuracy: 0.8603\n",
      "Epoch 6059/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0601 - accuracy: 0.9818 - val_loss: 0.7032 - val_accuracy: 0.8502\n",
      "Epoch 6060/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0484 - accuracy: 0.9850 - val_loss: 0.7291 - val_accuracy: 0.8477\n",
      "Epoch 6061/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0503 - accuracy: 0.9847 - val_loss: 0.6708 - val_accuracy: 0.8576\n",
      "Epoch 6062/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0484 - accuracy: 0.9851 - val_loss: 0.7093 - val_accuracy: 0.8527\n",
      "Epoch 6063/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0513 - accuracy: 0.9842 - val_loss: 0.7401 - val_accuracy: 0.8527\n",
      "Epoch 6064/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0507 - accuracy: 0.9835 - val_loss: 0.7784 - val_accuracy: 0.8419\n",
      "Epoch 6065/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0507 - accuracy: 0.9839 - val_loss: 0.6923 - val_accuracy: 0.8513\n",
      "Epoch 6066/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0519 - accuracy: 0.9835 - val_loss: 0.6375 - val_accuracy: 0.8631\n",
      "Epoch 6067/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0467 - accuracy: 0.9858 - val_loss: 0.6722 - val_accuracy: 0.8570\n",
      "Epoch 6068/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0495 - accuracy: 0.9842 - val_loss: 0.6919 - val_accuracy: 0.8549\n",
      "Epoch 6069/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0496 - accuracy: 0.9852 - val_loss: 0.6884 - val_accuracy: 0.8571\n",
      "Epoch 6070/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0490 - accuracy: 0.9847 - val_loss: 0.7817 - val_accuracy: 0.8439\n",
      "Epoch 6071/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0479 - accuracy: 0.9851 - val_loss: 0.7032 - val_accuracy: 0.8524\n",
      "Epoch 6072/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0502 - accuracy: 0.9842 - val_loss: 0.6972 - val_accuracy: 0.8531\n",
      "Epoch 6073/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0469 - accuracy: 0.9850 - val_loss: 0.7382 - val_accuracy: 0.8470\n",
      "Epoch 6074/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0501 - accuracy: 0.9839 - val_loss: 0.7325 - val_accuracy: 0.8445\n",
      "Epoch 6075/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0497 - accuracy: 0.9847 - val_loss: 0.6467 - val_accuracy: 0.8580\n",
      "Epoch 6076/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0440 - accuracy: 0.9861 - val_loss: 0.6586 - val_accuracy: 0.8593\n",
      "Epoch 6077/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0455 - accuracy: 0.9853 - val_loss: 0.7018 - val_accuracy: 0.8556\n",
      "Epoch 6078/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0511 - accuracy: 0.9841 - val_loss: 0.7017 - val_accuracy: 0.8538\n",
      "Epoch 6079/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0496 - accuracy: 0.9848 - val_loss: 0.6611 - val_accuracy: 0.8603\n",
      "Epoch 6080/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0536 - accuracy: 0.9845 - val_loss: 0.6866 - val_accuracy: 0.8529\n",
      "Epoch 6081/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0486 - accuracy: 0.9847 - val_loss: 0.7527 - val_accuracy: 0.8470\n",
      "Epoch 6082/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0480 - accuracy: 0.9850 - val_loss: 0.6828 - val_accuracy: 0.8556\n",
      "Epoch 6083/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0473 - accuracy: 0.9854 - val_loss: 0.6752 - val_accuracy: 0.8538\n",
      "Epoch 6084/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0481 - accuracy: 0.9848 - val_loss: 0.6843 - val_accuracy: 0.8535\n",
      "Epoch 6085/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0518 - accuracy: 0.9835 - val_loss: 0.7171 - val_accuracy: 0.8483\n",
      "Epoch 6086/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0514 - accuracy: 0.9839 - val_loss: 0.6770 - val_accuracy: 0.8559\n",
      "Epoch 6087/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0524 - accuracy: 0.9835 - val_loss: 0.6627 - val_accuracy: 0.8565\n",
      "Epoch 6088/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0468 - accuracy: 0.9851 - val_loss: 0.6843 - val_accuracy: 0.8542\n",
      "Epoch 6089/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0489 - accuracy: 0.9846 - val_loss: 0.7009 - val_accuracy: 0.8533\n",
      "Epoch 6090/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0501 - accuracy: 0.9840 - val_loss: 0.7062 - val_accuracy: 0.8496\n",
      "Epoch 6091/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0464 - accuracy: 0.9848 - val_loss: 0.6540 - val_accuracy: 0.8612\n",
      "Epoch 6092/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0510 - accuracy: 0.9837 - val_loss: 0.7041 - val_accuracy: 0.8505\n",
      "Epoch 6093/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0519 - accuracy: 0.9839 - val_loss: 0.6658 - val_accuracy: 0.8607\n",
      "Epoch 6094/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0444 - accuracy: 0.9866 - val_loss: 0.6933 - val_accuracy: 0.8540\n",
      "Epoch 6095/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0538 - accuracy: 0.9834 - val_loss: 0.6338 - val_accuracy: 0.8634\n",
      "Epoch 6096/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0475 - accuracy: 0.9851 - val_loss: 0.7360 - val_accuracy: 0.8488\n",
      "Epoch 6097/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0547 - accuracy: 0.9829 - val_loss: 0.6872 - val_accuracy: 0.8507\n",
      "Epoch 6098/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0441 - accuracy: 0.9864 - val_loss: 0.6584 - val_accuracy: 0.8591\n",
      "Epoch 6099/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0499 - accuracy: 0.9847 - val_loss: 0.7555 - val_accuracy: 0.8438\n",
      "Epoch 6100/8000\n",
      "1457/1463 [============================>.] - ETA: 0s - loss: 0.0567 - accuracy: 0.9817\n",
      "Epoch 6100: saving model to ./training_ckpt_20240109205949_v8_240109_d10000_n4096_b64_e8000_c100_Adamax\\cp-000006100.ckpt\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0567 - accuracy: 0.9817 - val_loss: 0.6482 - val_accuracy: 0.8601\n",
      "Epoch 6101/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0468 - accuracy: 0.9858 - val_loss: 0.6997 - val_accuracy: 0.8534\n",
      "Epoch 6102/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0525 - accuracy: 0.9835 - val_loss: 0.7479 - val_accuracy: 0.8482\n",
      "Epoch 6103/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0507 - accuracy: 0.9833 - val_loss: 0.6953 - val_accuracy: 0.8590\n",
      "Epoch 6104/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0463 - accuracy: 0.9857 - val_loss: 0.6530 - val_accuracy: 0.8584\n",
      "Epoch 6105/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0504 - accuracy: 0.9843 - val_loss: 0.6924 - val_accuracy: 0.8562\n",
      "Epoch 6106/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0513 - accuracy: 0.9843 - val_loss: 0.6530 - val_accuracy: 0.8591\n",
      "Epoch 6107/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0454 - accuracy: 0.9857 - val_loss: 0.6753 - val_accuracy: 0.8566\n",
      "Epoch 6108/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0446 - accuracy: 0.9861 - val_loss: 0.6962 - val_accuracy: 0.8536\n",
      "Epoch 6109/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0450 - accuracy: 0.9859 - val_loss: 0.6894 - val_accuracy: 0.8555\n",
      "Epoch 6110/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0429 - accuracy: 0.9867 - val_loss: 0.7870 - val_accuracy: 0.8490\n",
      "Epoch 6111/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0517 - accuracy: 0.9846 - val_loss: 0.6755 - val_accuracy: 0.8579\n",
      "Epoch 6112/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0500 - accuracy: 0.9843 - val_loss: 0.6632 - val_accuracy: 0.8567\n",
      "Epoch 6113/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0504 - accuracy: 0.9841 - val_loss: 0.7094 - val_accuracy: 0.8533\n",
      "Epoch 6114/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0453 - accuracy: 0.9858 - val_loss: 0.6548 - val_accuracy: 0.8572\n",
      "Epoch 6115/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0532 - accuracy: 0.9838 - val_loss: 0.6413 - val_accuracy: 0.8593\n",
      "Epoch 6116/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0440 - accuracy: 0.9862 - val_loss: 0.7053 - val_accuracy: 0.8529\n",
      "Epoch 6117/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0457 - accuracy: 0.9856 - val_loss: 0.7520 - val_accuracy: 0.8455\n",
      "Epoch 6118/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0492 - accuracy: 0.9850 - val_loss: 0.6584 - val_accuracy: 0.8610\n",
      "Epoch 6119/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0530 - accuracy: 0.9832 - val_loss: 0.7977 - val_accuracy: 0.8360\n",
      "Epoch 6120/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0456 - accuracy: 0.9859 - val_loss: 0.6844 - val_accuracy: 0.8556\n",
      "Epoch 6121/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0516 - accuracy: 0.9843 - val_loss: 0.7133 - val_accuracy: 0.8485\n",
      "Epoch 6122/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0541 - accuracy: 0.9839 - val_loss: 0.7024 - val_accuracy: 0.8540\n",
      "Epoch 6123/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0465 - accuracy: 0.9857 - val_loss: 0.6700 - val_accuracy: 0.8559\n",
      "Epoch 6124/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0460 - accuracy: 0.9851 - val_loss: 0.7676 - val_accuracy: 0.8442\n",
      "Epoch 6125/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0444 - accuracy: 0.9859 - val_loss: 0.6531 - val_accuracy: 0.8598\n",
      "Epoch 6126/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0524 - accuracy: 0.9845 - val_loss: 0.6760 - val_accuracy: 0.8557\n",
      "Epoch 6127/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0516 - accuracy: 0.9832 - val_loss: 0.7095 - val_accuracy: 0.8487\n",
      "Epoch 6128/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0452 - accuracy: 0.9860 - val_loss: 0.6538 - val_accuracy: 0.8606\n",
      "Epoch 6129/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0463 - accuracy: 0.9864 - val_loss: 0.6597 - val_accuracy: 0.8603\n",
      "Epoch 6130/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0463 - accuracy: 0.9860 - val_loss: 0.7072 - val_accuracy: 0.8501\n",
      "Epoch 6131/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0446 - accuracy: 0.9859 - val_loss: 0.7948 - val_accuracy: 0.8370\n",
      "Epoch 6132/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0522 - accuracy: 0.9837 - val_loss: 0.6984 - val_accuracy: 0.8528\n",
      "Epoch 6133/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0511 - accuracy: 0.9841 - val_loss: 0.7164 - val_accuracy: 0.8512\n",
      "Epoch 6134/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0481 - accuracy: 0.9854 - val_loss: 0.7071 - val_accuracy: 0.8548\n",
      "Epoch 6135/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0510 - accuracy: 0.9842 - val_loss: 0.7093 - val_accuracy: 0.8462\n",
      "Epoch 6136/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0518 - accuracy: 0.9838 - val_loss: 0.7150 - val_accuracy: 0.8505\n",
      "Epoch 6137/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0505 - accuracy: 0.9836 - val_loss: 0.7028 - val_accuracy: 0.8522\n",
      "Epoch 6138/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0520 - accuracy: 0.9842 - val_loss: 0.6854 - val_accuracy: 0.8554\n",
      "Epoch 6139/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0484 - accuracy: 0.9852 - val_loss: 0.6812 - val_accuracy: 0.8569\n",
      "Epoch 6140/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0454 - accuracy: 0.9856 - val_loss: 0.6901 - val_accuracy: 0.8529\n",
      "Epoch 6141/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0554 - accuracy: 0.9832 - val_loss: 0.6954 - val_accuracy: 0.8536\n",
      "Epoch 6142/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0473 - accuracy: 0.9855 - val_loss: 0.7073 - val_accuracy: 0.8501\n",
      "Epoch 6143/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0427 - accuracy: 0.9864 - val_loss: 0.6870 - val_accuracy: 0.8562\n",
      "Epoch 6144/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0517 - accuracy: 0.9838 - val_loss: 0.7322 - val_accuracy: 0.8480\n",
      "Epoch 6145/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0545 - accuracy: 0.9829 - val_loss: 0.6961 - val_accuracy: 0.8519\n",
      "Epoch 6146/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0511 - accuracy: 0.9844 - val_loss: 0.7072 - val_accuracy: 0.8535\n",
      "Epoch 6147/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0501 - accuracy: 0.9849 - val_loss: 0.7158 - val_accuracy: 0.8517\n",
      "Epoch 6148/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0451 - accuracy: 0.9857 - val_loss: 0.6612 - val_accuracy: 0.8583\n",
      "Epoch 6149/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0495 - accuracy: 0.9848 - val_loss: 0.6700 - val_accuracy: 0.8561\n",
      "Epoch 6150/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0448 - accuracy: 0.9859 - val_loss: 0.7579 - val_accuracy: 0.8474\n",
      "Epoch 6151/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0557 - accuracy: 0.9822 - val_loss: 0.7888 - val_accuracy: 0.8376\n",
      "Epoch 6152/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0469 - accuracy: 0.9859 - val_loss: 0.6529 - val_accuracy: 0.8608\n",
      "Epoch 6153/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0493 - accuracy: 0.9850 - val_loss: 0.6420 - val_accuracy: 0.8652\n",
      "Epoch 6154/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0453 - accuracy: 0.9857 - val_loss: 0.6817 - val_accuracy: 0.8587\n",
      "Epoch 6155/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0481 - accuracy: 0.9847 - val_loss: 0.7428 - val_accuracy: 0.8444\n",
      "Epoch 6156/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0494 - accuracy: 0.9845 - val_loss: 0.7143 - val_accuracy: 0.8498\n",
      "Epoch 6157/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0455 - accuracy: 0.9854 - val_loss: 0.7136 - val_accuracy: 0.8519\n",
      "Epoch 6158/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0496 - accuracy: 0.9853 - val_loss: 0.7124 - val_accuracy: 0.8528\n",
      "Epoch 6159/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0494 - accuracy: 0.9847 - val_loss: 0.7241 - val_accuracy: 0.8479\n",
      "Epoch 6160/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0515 - accuracy: 0.9848 - val_loss: 0.6731 - val_accuracy: 0.8546\n",
      "Epoch 6161/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0508 - accuracy: 0.9834 - val_loss: 0.7923 - val_accuracy: 0.8465\n",
      "Epoch 6162/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0457 - accuracy: 0.9855 - val_loss: 0.6769 - val_accuracy: 0.8573\n",
      "Epoch 6163/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0489 - accuracy: 0.9847 - val_loss: 0.6730 - val_accuracy: 0.8586\n",
      "Epoch 6164/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0474 - accuracy: 0.9852 - val_loss: 0.7497 - val_accuracy: 0.8495\n",
      "Epoch 6165/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0532 - accuracy: 0.9835 - val_loss: 0.7300 - val_accuracy: 0.8481\n",
      "Epoch 6166/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0446 - accuracy: 0.9862 - val_loss: 0.8855 - val_accuracy: 0.8346\n",
      "Epoch 6167/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0480 - accuracy: 0.9852 - val_loss: 0.6821 - val_accuracy: 0.8603\n",
      "Epoch 6168/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0468 - accuracy: 0.9857 - val_loss: 0.7064 - val_accuracy: 0.8520\n",
      "Epoch 6169/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0472 - accuracy: 0.9854 - val_loss: 0.6916 - val_accuracy: 0.8535\n",
      "Epoch 6170/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0451 - accuracy: 0.9861 - val_loss: 0.6858 - val_accuracy: 0.8563\n",
      "Epoch 6171/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0438 - accuracy: 0.9865 - val_loss: 0.6775 - val_accuracy: 0.8570\n",
      "Epoch 6172/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0488 - accuracy: 0.9850 - val_loss: 0.6715 - val_accuracy: 0.8572\n",
      "Epoch 6173/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0501 - accuracy: 0.9849 - val_loss: 0.6908 - val_accuracy: 0.8560\n",
      "Epoch 6174/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0474 - accuracy: 0.9853 - val_loss: 0.7477 - val_accuracy: 0.8479\n",
      "Epoch 6175/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0513 - accuracy: 0.9840 - val_loss: 0.7771 - val_accuracy: 0.8429\n",
      "Epoch 6176/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0473 - accuracy: 0.9852 - val_loss: 0.6643 - val_accuracy: 0.8610\n",
      "Epoch 6177/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0498 - accuracy: 0.9845 - val_loss: 0.7341 - val_accuracy: 0.8507\n",
      "Epoch 6178/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0517 - accuracy: 0.9846 - val_loss: 0.6569 - val_accuracy: 0.8542\n",
      "Epoch 6179/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0473 - accuracy: 0.9856 - val_loss: 0.6621 - val_accuracy: 0.8587\n",
      "Epoch 6180/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0474 - accuracy: 0.9851 - val_loss: 0.6841 - val_accuracy: 0.8537\n",
      "Epoch 6181/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0448 - accuracy: 0.9866 - val_loss: 0.6798 - val_accuracy: 0.8555\n",
      "Epoch 6182/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0479 - accuracy: 0.9851 - val_loss: 0.7091 - val_accuracy: 0.8506\n",
      "Epoch 6183/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0483 - accuracy: 0.9856 - val_loss: 0.7120 - val_accuracy: 0.8487\n",
      "Epoch 6184/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0514 - accuracy: 0.9842 - val_loss: 0.7189 - val_accuracy: 0.8512\n",
      "Epoch 6185/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0520 - accuracy: 0.9840 - val_loss: 0.6691 - val_accuracy: 0.8597\n",
      "Epoch 6186/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0543 - accuracy: 0.9835 - val_loss: 0.6973 - val_accuracy: 0.8539\n",
      "Epoch 6187/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0470 - accuracy: 0.9855 - val_loss: 0.7375 - val_accuracy: 0.8512\n",
      "Epoch 6188/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0482 - accuracy: 0.9853 - val_loss: 0.7156 - val_accuracy: 0.8515\n",
      "Epoch 6189/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0469 - accuracy: 0.9853 - val_loss: 0.6542 - val_accuracy: 0.8628\n",
      "Epoch 6190/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0476 - accuracy: 0.9850 - val_loss: 0.7061 - val_accuracy: 0.8542\n",
      "Epoch 6191/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0500 - accuracy: 0.9846 - val_loss: 0.6762 - val_accuracy: 0.8585\n",
      "Epoch 6192/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0452 - accuracy: 0.9859 - val_loss: 0.6845 - val_accuracy: 0.8562\n",
      "Epoch 6193/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0488 - accuracy: 0.9849 - val_loss: 0.6721 - val_accuracy: 0.8597\n",
      "Epoch 6194/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0500 - accuracy: 0.9847 - val_loss: 0.6972 - val_accuracy: 0.8579\n",
      "Epoch 6195/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0477 - accuracy: 0.9850 - val_loss: 0.7880 - val_accuracy: 0.8393\n",
      "Epoch 6196/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0489 - accuracy: 0.9849 - val_loss: 0.6858 - val_accuracy: 0.8550\n",
      "Epoch 6197/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0478 - accuracy: 0.9854 - val_loss: 0.7032 - val_accuracy: 0.8544\n",
      "Epoch 6198/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0513 - accuracy: 0.9838 - val_loss: 0.7076 - val_accuracy: 0.8491\n",
      "Epoch 6199/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0503 - accuracy: 0.9841 - val_loss: 0.7015 - val_accuracy: 0.8563\n",
      "Epoch 6200/8000\n",
      "1460/1463 [============================>.] - ETA: 0s - loss: 0.0464 - accuracy: 0.9854\n",
      "Epoch 6200: saving model to ./training_ckpt_20240109205949_v8_240109_d10000_n4096_b64_e8000_c100_Adamax\\cp-000006200.ckpt\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0465 - accuracy: 0.9853 - val_loss: 0.7791 - val_accuracy: 0.8486\n",
      "Epoch 6201/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0539 - accuracy: 0.9840 - val_loss: 0.6902 - val_accuracy: 0.8575\n",
      "Epoch 6202/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0493 - accuracy: 0.9850 - val_loss: 0.7027 - val_accuracy: 0.8553\n",
      "Epoch 6203/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0468 - accuracy: 0.9849 - val_loss: 0.6817 - val_accuracy: 0.8564\n",
      "Epoch 6204/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0514 - accuracy: 0.9839 - val_loss: 0.7388 - val_accuracy: 0.8445\n",
      "Epoch 6205/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0464 - accuracy: 0.9862 - val_loss: 0.7368 - val_accuracy: 0.8487\n",
      "Epoch 6206/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0500 - accuracy: 0.9843 - val_loss: 0.6735 - val_accuracy: 0.8593\n",
      "Epoch 6207/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0499 - accuracy: 0.9842 - val_loss: 0.7260 - val_accuracy: 0.8514\n",
      "Epoch 6208/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0444 - accuracy: 0.9859 - val_loss: 0.7165 - val_accuracy: 0.8507\n",
      "Epoch 6209/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0455 - accuracy: 0.9853 - val_loss: 0.6929 - val_accuracy: 0.8516\n",
      "Epoch 6210/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0481 - accuracy: 0.9848 - val_loss: 0.6738 - val_accuracy: 0.8537\n",
      "Epoch 6211/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0488 - accuracy: 0.9841 - val_loss: 0.6721 - val_accuracy: 0.8582\n",
      "Epoch 6212/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0472 - accuracy: 0.9847 - val_loss: 0.6734 - val_accuracy: 0.8585\n",
      "Epoch 6213/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0488 - accuracy: 0.9850 - val_loss: 0.6738 - val_accuracy: 0.8586\n",
      "Epoch 6214/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0533 - accuracy: 0.9840 - val_loss: 0.7391 - val_accuracy: 0.8432\n",
      "Epoch 6215/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0486 - accuracy: 0.9846 - val_loss: 0.7656 - val_accuracy: 0.8456\n",
      "Epoch 6216/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0526 - accuracy: 0.9839 - val_loss: 0.6885 - val_accuracy: 0.8572\n",
      "Epoch 6217/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0426 - accuracy: 0.9866 - val_loss: 0.6547 - val_accuracy: 0.8605\n",
      "Epoch 6218/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0454 - accuracy: 0.9856 - val_loss: 0.6560 - val_accuracy: 0.8606\n",
      "Epoch 6219/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0537 - accuracy: 0.9843 - val_loss: 0.6993 - val_accuracy: 0.8561\n",
      "Epoch 6220/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0495 - accuracy: 0.9846 - val_loss: 0.6705 - val_accuracy: 0.8588\n",
      "Epoch 6221/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0495 - accuracy: 0.9851 - val_loss: 0.7323 - val_accuracy: 0.8483\n",
      "Epoch 6222/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0542 - accuracy: 0.9829 - val_loss: 0.6761 - val_accuracy: 0.8614\n",
      "Epoch 6223/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0457 - accuracy: 0.9859 - val_loss: 0.7572 - val_accuracy: 0.8429\n",
      "Epoch 6224/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0487 - accuracy: 0.9847 - val_loss: 0.7354 - val_accuracy: 0.8500\n",
      "Epoch 6225/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0503 - accuracy: 0.9847 - val_loss: 0.6818 - val_accuracy: 0.8559\n",
      "Epoch 6226/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0538 - accuracy: 0.9832 - val_loss: 0.7147 - val_accuracy: 0.8502\n",
      "Epoch 6227/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0503 - accuracy: 0.9845 - val_loss: 0.7090 - val_accuracy: 0.8537\n",
      "Epoch 6228/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0517 - accuracy: 0.9835 - val_loss: 0.6666 - val_accuracy: 0.8590\n",
      "Epoch 6229/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0443 - accuracy: 0.9866 - val_loss: 0.7175 - val_accuracy: 0.8532\n",
      "Epoch 6230/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0519 - accuracy: 0.9837 - val_loss: 0.6791 - val_accuracy: 0.8562\n",
      "Epoch 6231/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0489 - accuracy: 0.9848 - val_loss: 0.6954 - val_accuracy: 0.8523\n",
      "Epoch 6232/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0476 - accuracy: 0.9857 - val_loss: 0.7198 - val_accuracy: 0.8481\n",
      "Epoch 6233/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0472 - accuracy: 0.9849 - val_loss: 0.8101 - val_accuracy: 0.8378\n",
      "Epoch 6234/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0471 - accuracy: 0.9855 - val_loss: 0.6981 - val_accuracy: 0.8528\n",
      "Epoch 6235/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0514 - accuracy: 0.9836 - val_loss: 0.6498 - val_accuracy: 0.8621\n",
      "Epoch 6236/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0463 - accuracy: 0.9857 - val_loss: 0.6490 - val_accuracy: 0.8641\n",
      "Epoch 6237/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0498 - accuracy: 0.9846 - val_loss: 0.7305 - val_accuracy: 0.8491\n",
      "Epoch 6238/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0477 - accuracy: 0.9852 - val_loss: 0.6666 - val_accuracy: 0.8611\n",
      "Epoch 6239/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0505 - accuracy: 0.9847 - val_loss: 0.7120 - val_accuracy: 0.8494\n",
      "Epoch 6240/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0486 - accuracy: 0.9855 - val_loss: 0.6839 - val_accuracy: 0.8537\n",
      "Epoch 6241/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0440 - accuracy: 0.9860 - val_loss: 0.6758 - val_accuracy: 0.8571\n",
      "Epoch 6242/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0455 - accuracy: 0.9862 - val_loss: 0.7420 - val_accuracy: 0.8441\n",
      "Epoch 6243/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0478 - accuracy: 0.9848 - val_loss: 0.6897 - val_accuracy: 0.8556\n",
      "Epoch 6244/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0444 - accuracy: 0.9863 - val_loss: 0.7333 - val_accuracy: 0.8491\n",
      "Epoch 6245/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0521 - accuracy: 0.9839 - val_loss: 0.7280 - val_accuracy: 0.8496\n",
      "Epoch 6246/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0507 - accuracy: 0.9840 - val_loss: 0.6913 - val_accuracy: 0.8564\n",
      "Epoch 6247/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0493 - accuracy: 0.9851 - val_loss: 0.6947 - val_accuracy: 0.8530\n",
      "Epoch 6248/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0480 - accuracy: 0.9848 - val_loss: 0.6948 - val_accuracy: 0.8579\n",
      "Epoch 6249/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0491 - accuracy: 0.9847 - val_loss: 0.6738 - val_accuracy: 0.8551\n",
      "Epoch 6250/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0427 - accuracy: 0.9867 - val_loss: 0.6543 - val_accuracy: 0.8615\n",
      "Epoch 6251/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0449 - accuracy: 0.9862 - val_loss: 0.7547 - val_accuracy: 0.8464\n",
      "Epoch 6252/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0427 - accuracy: 0.9868 - val_loss: 0.6941 - val_accuracy: 0.8538\n",
      "Epoch 6253/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0475 - accuracy: 0.9853 - val_loss: 0.6935 - val_accuracy: 0.8589\n",
      "Epoch 6254/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0458 - accuracy: 0.9859 - val_loss: 0.6591 - val_accuracy: 0.8601\n",
      "Epoch 6255/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0436 - accuracy: 0.9865 - val_loss: 0.6670 - val_accuracy: 0.8599\n",
      "Epoch 6256/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0465 - accuracy: 0.9858 - val_loss: 0.7055 - val_accuracy: 0.8536\n",
      "Epoch 6257/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0521 - accuracy: 0.9843 - val_loss: 0.6730 - val_accuracy: 0.8566\n",
      "Epoch 6258/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0434 - accuracy: 0.9866 - val_loss: 0.7199 - val_accuracy: 0.8496\n",
      "Epoch 6259/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0486 - accuracy: 0.9851 - val_loss: 0.6918 - val_accuracy: 0.8523\n",
      "Epoch 6260/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0473 - accuracy: 0.9848 - val_loss: 0.6789 - val_accuracy: 0.8607\n",
      "Epoch 6261/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0453 - accuracy: 0.9860 - val_loss: 0.7109 - val_accuracy: 0.8529\n",
      "Epoch 6262/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0489 - accuracy: 0.9848 - val_loss: 0.6553 - val_accuracy: 0.8636\n",
      "Epoch 6263/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0401 - accuracy: 0.9870 - val_loss: 0.7170 - val_accuracy: 0.8537\n",
      "Epoch 6264/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0496 - accuracy: 0.9843 - val_loss: 0.7583 - val_accuracy: 0.8444\n",
      "Epoch 6265/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0430 - accuracy: 0.9864 - val_loss: 0.7265 - val_accuracy: 0.8497\n",
      "Epoch 6266/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0554 - accuracy: 0.9827 - val_loss: 0.7087 - val_accuracy: 0.8507\n",
      "Epoch 6267/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0518 - accuracy: 0.9846 - val_loss: 0.6812 - val_accuracy: 0.8588\n",
      "Epoch 6268/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0488 - accuracy: 0.9855 - val_loss: 0.7297 - val_accuracy: 0.8487\n",
      "Epoch 6269/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0508 - accuracy: 0.9850 - val_loss: 0.7934 - val_accuracy: 0.8416\n",
      "Epoch 6270/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0487 - accuracy: 0.9851 - val_loss: 0.9373 - val_accuracy: 0.8399\n",
      "Epoch 6271/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0520 - accuracy: 0.9835 - val_loss: 0.6592 - val_accuracy: 0.8567\n",
      "Epoch 6272/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0431 - accuracy: 0.9865 - val_loss: 0.6563 - val_accuracy: 0.8588\n",
      "Epoch 6273/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0495 - accuracy: 0.9851 - val_loss: 0.6920 - val_accuracy: 0.8542\n",
      "Epoch 6274/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0428 - accuracy: 0.9866 - val_loss: 0.6731 - val_accuracy: 0.8572\n",
      "Epoch 6275/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0505 - accuracy: 0.9843 - val_loss: 0.7045 - val_accuracy: 0.8547\n",
      "Epoch 6276/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0491 - accuracy: 0.9845 - val_loss: 0.6959 - val_accuracy: 0.8596\n",
      "Epoch 6277/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0458 - accuracy: 0.9857 - val_loss: 0.7142 - val_accuracy: 0.8552\n",
      "Epoch 6278/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0493 - accuracy: 0.9848 - val_loss: 0.7245 - val_accuracy: 0.8478\n",
      "Epoch 6279/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0455 - accuracy: 0.9860 - val_loss: 0.6677 - val_accuracy: 0.8612\n",
      "Epoch 6280/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0488 - accuracy: 0.9849 - val_loss: 0.7844 - val_accuracy: 0.8422\n",
      "Epoch 6281/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0485 - accuracy: 0.9855 - val_loss: 0.6814 - val_accuracy: 0.8554\n",
      "Epoch 6282/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0431 - accuracy: 0.9870 - val_loss: 0.7103 - val_accuracy: 0.8539\n",
      "Epoch 6283/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0502 - accuracy: 0.9842 - val_loss: 0.7110 - val_accuracy: 0.8518\n",
      "Epoch 6284/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0415 - accuracy: 0.9871 - val_loss: 0.7071 - val_accuracy: 0.8546\n",
      "Epoch 6285/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0510 - accuracy: 0.9846 - val_loss: 0.7606 - val_accuracy: 0.8498\n",
      "Epoch 6286/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0459 - accuracy: 0.9859 - val_loss: 0.6777 - val_accuracy: 0.8597\n",
      "Epoch 6287/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0487 - accuracy: 0.9853 - val_loss: 0.7563 - val_accuracy: 0.8489\n",
      "Epoch 6288/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0490 - accuracy: 0.9844 - val_loss: 0.7547 - val_accuracy: 0.8502\n",
      "Epoch 6289/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0472 - accuracy: 0.9849 - val_loss: 0.6822 - val_accuracy: 0.8599\n",
      "Epoch 6290/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0525 - accuracy: 0.9840 - val_loss: 0.7648 - val_accuracy: 0.8456\n",
      "Epoch 6291/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0472 - accuracy: 0.9851 - val_loss: 0.6976 - val_accuracy: 0.8529\n",
      "Epoch 6292/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0525 - accuracy: 0.9844 - val_loss: 0.6798 - val_accuracy: 0.8560\n",
      "Epoch 6293/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0474 - accuracy: 0.9854 - val_loss: 0.6996 - val_accuracy: 0.8558\n",
      "Epoch 6294/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0509 - accuracy: 0.9837 - val_loss: 0.6853 - val_accuracy: 0.8579\n",
      "Epoch 6295/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0477 - accuracy: 0.9851 - val_loss: 0.7075 - val_accuracy: 0.8555\n",
      "Epoch 6296/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0455 - accuracy: 0.9858 - val_loss: 0.7142 - val_accuracy: 0.8500\n",
      "Epoch 6297/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0449 - accuracy: 0.9864 - val_loss: 0.7569 - val_accuracy: 0.8449\n",
      "Epoch 6298/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0489 - accuracy: 0.9841 - val_loss: 0.7064 - val_accuracy: 0.8539\n",
      "Epoch 6299/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0474 - accuracy: 0.9848 - val_loss: 0.7198 - val_accuracy: 0.8537\n",
      "Epoch 6300/8000\n",
      "1461/1463 [============================>.] - ETA: 0s - loss: 0.0475 - accuracy: 0.9859\n",
      "Epoch 6300: saving model to ./training_ckpt_20240109205949_v8_240109_d10000_n4096_b64_e8000_c100_Adamax\\cp-000006300.ckpt\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0475 - accuracy: 0.9859 - val_loss: 0.7164 - val_accuracy: 0.8534\n",
      "Epoch 6301/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0478 - accuracy: 0.9846 - val_loss: 0.6940 - val_accuracy: 0.8552\n",
      "Epoch 6302/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0474 - accuracy: 0.9860 - val_loss: 0.6938 - val_accuracy: 0.8543\n",
      "Epoch 6303/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0422 - accuracy: 0.9868 - val_loss: 0.7195 - val_accuracy: 0.8523\n",
      "Epoch 6304/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0457 - accuracy: 0.9856 - val_loss: 0.7041 - val_accuracy: 0.8562\n",
      "Epoch 6305/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0500 - accuracy: 0.9847 - val_loss: 0.7170 - val_accuracy: 0.8557\n",
      "Epoch 6306/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0502 - accuracy: 0.9844 - val_loss: 0.7236 - val_accuracy: 0.8485\n",
      "Epoch 6307/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0555 - accuracy: 0.9830 - val_loss: 0.6898 - val_accuracy: 0.8540\n",
      "Epoch 6308/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0424 - accuracy: 0.9869 - val_loss: 0.7616 - val_accuracy: 0.8466\n",
      "Epoch 6309/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0473 - accuracy: 0.9858 - val_loss: 0.7003 - val_accuracy: 0.8527\n",
      "Epoch 6310/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0485 - accuracy: 0.9850 - val_loss: 0.7211 - val_accuracy: 0.8545\n",
      "Epoch 6311/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0540 - accuracy: 0.9832 - val_loss: 0.7143 - val_accuracy: 0.8530\n",
      "Epoch 6312/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0442 - accuracy: 0.9865 - val_loss: 0.7182 - val_accuracy: 0.8527\n",
      "Epoch 6313/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0482 - accuracy: 0.9850 - val_loss: 0.6837 - val_accuracy: 0.8596\n",
      "Epoch 6314/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0479 - accuracy: 0.9851 - val_loss: 0.6880 - val_accuracy: 0.8548\n",
      "Epoch 6315/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0433 - accuracy: 0.9863 - val_loss: 0.6515 - val_accuracy: 0.8660\n",
      "Epoch 6316/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0493 - accuracy: 0.9847 - val_loss: 0.6634 - val_accuracy: 0.8602\n",
      "Epoch 6317/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0522 - accuracy: 0.9840 - val_loss: 0.7357 - val_accuracy: 0.8489\n",
      "Epoch 6318/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0439 - accuracy: 0.9860 - val_loss: 0.6636 - val_accuracy: 0.8592\n",
      "Epoch 6319/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0488 - accuracy: 0.9848 - val_loss: 0.6298 - val_accuracy: 0.8658\n",
      "Epoch 6320/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0479 - accuracy: 0.9857 - val_loss: 0.6556 - val_accuracy: 0.8616\n",
      "Epoch 6321/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0484 - accuracy: 0.9850 - val_loss: 0.7657 - val_accuracy: 0.8469\n",
      "Epoch 6322/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0421 - accuracy: 0.9872 - val_loss: 0.7562 - val_accuracy: 0.8415\n",
      "Epoch 6323/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0405 - accuracy: 0.9871 - val_loss: 0.7387 - val_accuracy: 0.8472\n",
      "Epoch 6324/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0441 - accuracy: 0.9860 - val_loss: 0.7638 - val_accuracy: 0.8469\n",
      "Epoch 6325/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0508 - accuracy: 0.9848 - val_loss: 0.7369 - val_accuracy: 0.8482\n",
      "Epoch 6326/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0513 - accuracy: 0.9840 - val_loss: 0.7207 - val_accuracy: 0.8468\n",
      "Epoch 6327/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0454 - accuracy: 0.9859 - val_loss: 0.7002 - val_accuracy: 0.8562\n",
      "Epoch 6328/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0481 - accuracy: 0.9847 - val_loss: 0.7394 - val_accuracy: 0.8460\n",
      "Epoch 6329/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0464 - accuracy: 0.9853 - val_loss: 0.7066 - val_accuracy: 0.8526\n",
      "Epoch 6330/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0583 - accuracy: 0.9821 - val_loss: 0.7238 - val_accuracy: 0.8493\n",
      "Epoch 6331/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0458 - accuracy: 0.9856 - val_loss: 0.6513 - val_accuracy: 0.8638\n",
      "Epoch 6332/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0409 - accuracy: 0.9876 - val_loss: 0.6959 - val_accuracy: 0.8552\n",
      "Epoch 6333/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0498 - accuracy: 0.9846 - val_loss: 0.7405 - val_accuracy: 0.8477\n",
      "Epoch 6334/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0404 - accuracy: 0.9874 - val_loss: 0.7254 - val_accuracy: 0.8487\n",
      "Epoch 6335/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0459 - accuracy: 0.9855 - val_loss: 0.7122 - val_accuracy: 0.8549\n",
      "Epoch 6336/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0456 - accuracy: 0.9855 - val_loss: 0.6784 - val_accuracy: 0.8573\n",
      "Epoch 6337/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0515 - accuracy: 0.9843 - val_loss: 0.7156 - val_accuracy: 0.8509\n",
      "Epoch 6338/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0560 - accuracy: 0.9836 - val_loss: 0.6709 - val_accuracy: 0.8579\n",
      "Epoch 6339/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0485 - accuracy: 0.9862 - val_loss: 0.7492 - val_accuracy: 0.8459\n",
      "Epoch 6340/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0448 - accuracy: 0.9866 - val_loss: 0.6883 - val_accuracy: 0.8550\n",
      "Epoch 6341/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0532 - accuracy: 0.9835 - val_loss: 0.6772 - val_accuracy: 0.8587\n",
      "Epoch 6342/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0482 - accuracy: 0.9856 - val_loss: 0.6382 - val_accuracy: 0.8647\n",
      "Epoch 6343/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0554 - accuracy: 0.9833 - val_loss: 0.7257 - val_accuracy: 0.8473\n",
      "Epoch 6344/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0469 - accuracy: 0.9857 - val_loss: 0.7173 - val_accuracy: 0.8526\n",
      "Epoch 6345/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0458 - accuracy: 0.9860 - val_loss: 0.6370 - val_accuracy: 0.8669\n",
      "Epoch 6346/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0486 - accuracy: 0.9846 - val_loss: 0.6900 - val_accuracy: 0.8600\n",
      "Epoch 6347/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0447 - accuracy: 0.9861 - val_loss: 0.6947 - val_accuracy: 0.8549\n",
      "Epoch 6348/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0515 - accuracy: 0.9839 - val_loss: 0.6820 - val_accuracy: 0.8582\n",
      "Epoch 6349/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0479 - accuracy: 0.9847 - val_loss: 0.7190 - val_accuracy: 0.8520\n",
      "Epoch 6350/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0457 - accuracy: 0.9857 - val_loss: 0.6647 - val_accuracy: 0.8608\n",
      "Epoch 6351/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0446 - accuracy: 0.9860 - val_loss: 0.7061 - val_accuracy: 0.8504\n",
      "Epoch 6352/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0497 - accuracy: 0.9849 - val_loss: 0.7329 - val_accuracy: 0.8527\n",
      "Epoch 6353/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0454 - accuracy: 0.9860 - val_loss: 0.7248 - val_accuracy: 0.8488\n",
      "Epoch 6354/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0541 - accuracy: 0.9843 - val_loss: 0.7084 - val_accuracy: 0.8561\n",
      "Epoch 6355/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0457 - accuracy: 0.9860 - val_loss: 0.7187 - val_accuracy: 0.8508\n",
      "Epoch 6356/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0473 - accuracy: 0.9855 - val_loss: 0.7553 - val_accuracy: 0.8471\n",
      "Epoch 6357/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0464 - accuracy: 0.9855 - val_loss: 0.6881 - val_accuracy: 0.8575\n",
      "Epoch 6358/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0498 - accuracy: 0.9843 - val_loss: 0.6991 - val_accuracy: 0.8556\n",
      "Epoch 6359/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0479 - accuracy: 0.9855 - val_loss: 0.6842 - val_accuracy: 0.8583\n",
      "Epoch 6360/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0460 - accuracy: 0.9856 - val_loss: 0.6528 - val_accuracy: 0.8622\n",
      "Epoch 6361/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0548 - accuracy: 0.9832 - val_loss: 0.6958 - val_accuracy: 0.8575\n",
      "Epoch 6362/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0476 - accuracy: 0.9857 - val_loss: 0.7128 - val_accuracy: 0.8549\n",
      "Epoch 6363/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0479 - accuracy: 0.9855 - val_loss: 0.7098 - val_accuracy: 0.8520\n",
      "Epoch 6364/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0449 - accuracy: 0.9863 - val_loss: 0.7638 - val_accuracy: 0.8439\n",
      "Epoch 6365/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0511 - accuracy: 0.9837 - val_loss: 0.6913 - val_accuracy: 0.8530\n",
      "Epoch 6366/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0509 - accuracy: 0.9846 - val_loss: 0.6982 - val_accuracy: 0.8550\n",
      "Epoch 6367/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0393 - accuracy: 0.9884 - val_loss: 0.6632 - val_accuracy: 0.8610\n",
      "Epoch 6368/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0451 - accuracy: 0.9862 - val_loss: 0.7590 - val_accuracy: 0.8471\n",
      "Epoch 6369/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0478 - accuracy: 0.9849 - val_loss: 0.6783 - val_accuracy: 0.8597\n",
      "Epoch 6370/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0422 - accuracy: 0.9872 - val_loss: 0.7101 - val_accuracy: 0.8560\n",
      "Epoch 6371/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0457 - accuracy: 0.9857 - val_loss: 0.7366 - val_accuracy: 0.8491\n",
      "Epoch 6372/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0493 - accuracy: 0.9852 - val_loss: 0.6766 - val_accuracy: 0.8614\n",
      "Epoch 6373/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0459 - accuracy: 0.9856 - val_loss: 0.6940 - val_accuracy: 0.8582\n",
      "Epoch 6374/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0451 - accuracy: 0.9858 - val_loss: 0.7190 - val_accuracy: 0.8508\n",
      "Epoch 6375/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0488 - accuracy: 0.9844 - val_loss: 0.6617 - val_accuracy: 0.8619\n",
      "Epoch 6376/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0468 - accuracy: 0.9851 - val_loss: 0.6916 - val_accuracy: 0.8576\n",
      "Epoch 6377/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0471 - accuracy: 0.9849 - val_loss: 0.7188 - val_accuracy: 0.8521\n",
      "Epoch 6378/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0487 - accuracy: 0.9853 - val_loss: 0.6866 - val_accuracy: 0.8569\n",
      "Epoch 6379/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0465 - accuracy: 0.9857 - val_loss: 0.6753 - val_accuracy: 0.8596\n",
      "Epoch 6380/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0424 - accuracy: 0.9875 - val_loss: 0.6708 - val_accuracy: 0.8618\n",
      "Epoch 6381/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0476 - accuracy: 0.9854 - val_loss: 0.7609 - val_accuracy: 0.8460\n",
      "Epoch 6382/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0477 - accuracy: 0.9855 - val_loss: 0.6806 - val_accuracy: 0.8602\n",
      "Epoch 6383/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0441 - accuracy: 0.9862 - val_loss: 0.7199 - val_accuracy: 0.8535\n",
      "Epoch 6384/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0457 - accuracy: 0.9857 - val_loss: 0.7320 - val_accuracy: 0.8525\n",
      "Epoch 6385/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0503 - accuracy: 0.9847 - val_loss: 0.6962 - val_accuracy: 0.8572\n",
      "Epoch 6386/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0461 - accuracy: 0.9855 - val_loss: 0.7475 - val_accuracy: 0.8479\n",
      "Epoch 6387/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0486 - accuracy: 0.9852 - val_loss: 0.7167 - val_accuracy: 0.8575\n",
      "Epoch 6388/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0426 - accuracy: 0.9865 - val_loss: 0.6782 - val_accuracy: 0.8578\n",
      "Epoch 6389/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0457 - accuracy: 0.9862 - val_loss: 0.7263 - val_accuracy: 0.8492\n",
      "Epoch 6390/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0524 - accuracy: 0.9844 - val_loss: 0.7182 - val_accuracy: 0.8514\n",
      "Epoch 6391/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0472 - accuracy: 0.9847 - val_loss: 0.7112 - val_accuracy: 0.8515\n",
      "Epoch 6392/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0452 - accuracy: 0.9863 - val_loss: 0.7015 - val_accuracy: 0.8592\n",
      "Epoch 6393/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0494 - accuracy: 0.9851 - val_loss: 0.8381 - val_accuracy: 0.8367\n",
      "Epoch 6394/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0515 - accuracy: 0.9834 - val_loss: 0.7586 - val_accuracy: 0.8433\n",
      "Epoch 6395/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0474 - accuracy: 0.9852 - val_loss: 0.7383 - val_accuracy: 0.8457\n",
      "Epoch 6396/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0473 - accuracy: 0.9856 - val_loss: 0.6596 - val_accuracy: 0.8638\n",
      "Epoch 6397/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0484 - accuracy: 0.9851 - val_loss: 0.7702 - val_accuracy: 0.8452\n",
      "Epoch 6398/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0488 - accuracy: 0.9848 - val_loss: 0.6852 - val_accuracy: 0.8562\n",
      "Epoch 6399/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0458 - accuracy: 0.9858 - val_loss: 0.7222 - val_accuracy: 0.8523\n",
      "Epoch 6400/8000\n",
      "1458/1463 [============================>.] - ETA: 0s - loss: 0.0449 - accuracy: 0.9857\n",
      "Epoch 6400: saving model to ./training_ckpt_20240109205949_v8_240109_d10000_n4096_b64_e8000_c100_Adamax\\cp-000006400.ckpt\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0448 - accuracy: 0.9857 - val_loss: 0.6756 - val_accuracy: 0.8598\n",
      "Epoch 6401/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0429 - accuracy: 0.9862 - val_loss: 0.7372 - val_accuracy: 0.8472\n",
      "Epoch 6402/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0452 - accuracy: 0.9859 - val_loss: 0.6995 - val_accuracy: 0.8517\n",
      "Epoch 6403/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0460 - accuracy: 0.9860 - val_loss: 0.6561 - val_accuracy: 0.8635\n",
      "Epoch 6404/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0467 - accuracy: 0.9859 - val_loss: 0.7125 - val_accuracy: 0.8573\n",
      "Epoch 6405/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0465 - accuracy: 0.9857 - val_loss: 0.7272 - val_accuracy: 0.8505\n",
      "Epoch 6406/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0472 - accuracy: 0.9855 - val_loss: 0.7087 - val_accuracy: 0.8561\n",
      "Epoch 6407/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0487 - accuracy: 0.9844 - val_loss: 0.7154 - val_accuracy: 0.8519\n",
      "Epoch 6408/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0481 - accuracy: 0.9849 - val_loss: 0.7261 - val_accuracy: 0.8509\n",
      "Epoch 6409/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0487 - accuracy: 0.9856 - val_loss: 0.6992 - val_accuracy: 0.8558\n",
      "Epoch 6410/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0437 - accuracy: 0.9867 - val_loss: 0.7053 - val_accuracy: 0.8559\n",
      "Epoch 6411/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0431 - accuracy: 0.9866 - val_loss: 0.7848 - val_accuracy: 0.8489\n",
      "Epoch 6412/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0533 - accuracy: 0.9840 - val_loss: 0.7255 - val_accuracy: 0.8482\n",
      "Epoch 6413/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0422 - accuracy: 0.9873 - val_loss: 0.8227 - val_accuracy: 0.8355\n",
      "Epoch 6414/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0471 - accuracy: 0.9857 - val_loss: 0.7368 - val_accuracy: 0.8509\n",
      "Epoch 6415/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0448 - accuracy: 0.9864 - val_loss: 0.7874 - val_accuracy: 0.8443\n",
      "Epoch 6416/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0443 - accuracy: 0.9861 - val_loss: 0.6918 - val_accuracy: 0.8562\n",
      "Epoch 6417/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0453 - accuracy: 0.9856 - val_loss: 0.7597 - val_accuracy: 0.8514\n",
      "Epoch 6418/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0493 - accuracy: 0.9849 - val_loss: 0.7328 - val_accuracy: 0.8502\n",
      "Epoch 6419/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0537 - accuracy: 0.9844 - val_loss: 0.7384 - val_accuracy: 0.8508\n",
      "Epoch 6420/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0465 - accuracy: 0.9856 - val_loss: 0.7032 - val_accuracy: 0.8552\n",
      "Epoch 6421/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0445 - accuracy: 0.9857 - val_loss: 0.6753 - val_accuracy: 0.8585\n",
      "Epoch 6422/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0447 - accuracy: 0.9860 - val_loss: 0.7252 - val_accuracy: 0.8504\n",
      "Epoch 6423/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0431 - accuracy: 0.9870 - val_loss: 0.6737 - val_accuracy: 0.8599\n",
      "Epoch 6424/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0481 - accuracy: 0.9848 - val_loss: 0.6935 - val_accuracy: 0.8559\n",
      "Epoch 6425/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0484 - accuracy: 0.9853 - val_loss: 0.7425 - val_accuracy: 0.8487\n",
      "Epoch 6426/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0503 - accuracy: 0.9842 - val_loss: 0.7100 - val_accuracy: 0.8531\n",
      "Epoch 6427/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0465 - accuracy: 0.9857 - val_loss: 0.6730 - val_accuracy: 0.8572\n",
      "Epoch 6428/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0484 - accuracy: 0.9850 - val_loss: 0.7473 - val_accuracy: 0.8479\n",
      "Epoch 6429/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0474 - accuracy: 0.9853 - val_loss: 0.7478 - val_accuracy: 0.8502\n",
      "Epoch 6430/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0459 - accuracy: 0.9859 - val_loss: 0.7468 - val_accuracy: 0.8438\n",
      "Epoch 6431/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0462 - accuracy: 0.9855 - val_loss: 0.6719 - val_accuracy: 0.8596\n",
      "Epoch 6432/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0396 - accuracy: 0.9874 - val_loss: 0.6727 - val_accuracy: 0.8622\n",
      "Epoch 6433/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0470 - accuracy: 0.9855 - val_loss: 0.7017 - val_accuracy: 0.8552\n",
      "Epoch 6434/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0453 - accuracy: 0.9862 - val_loss: 0.6889 - val_accuracy: 0.8589\n",
      "Epoch 6435/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0517 - accuracy: 0.9837 - val_loss: 0.6899 - val_accuracy: 0.8599\n",
      "Epoch 6436/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0468 - accuracy: 0.9847 - val_loss: 0.6998 - val_accuracy: 0.8567\n",
      "Epoch 6437/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0417 - accuracy: 0.9868 - val_loss: 0.7126 - val_accuracy: 0.8570\n",
      "Epoch 6438/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0451 - accuracy: 0.9868 - val_loss: 0.7324 - val_accuracy: 0.8523\n",
      "Epoch 6439/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0482 - accuracy: 0.9848 - val_loss: 0.6963 - val_accuracy: 0.8560\n",
      "Epoch 6440/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0504 - accuracy: 0.9850 - val_loss: 0.7065 - val_accuracy: 0.8546\n",
      "Epoch 6441/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0472 - accuracy: 0.9852 - val_loss: 0.7189 - val_accuracy: 0.8522\n",
      "Epoch 6442/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0537 - accuracy: 0.9838 - val_loss: 0.7264 - val_accuracy: 0.8492\n",
      "Epoch 6443/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0459 - accuracy: 0.9857 - val_loss: 0.6533 - val_accuracy: 0.8623\n",
      "Epoch 6444/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0456 - accuracy: 0.9858 - val_loss: 0.7084 - val_accuracy: 0.8546\n",
      "Epoch 6445/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0463 - accuracy: 0.9858 - val_loss: 0.7102 - val_accuracy: 0.8525\n",
      "Epoch 6446/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0530 - accuracy: 0.9830 - val_loss: 0.8367 - val_accuracy: 0.8362\n",
      "Epoch 6447/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0455 - accuracy: 0.9858 - val_loss: 0.7223 - val_accuracy: 0.8546\n",
      "Epoch 6448/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0477 - accuracy: 0.9850 - val_loss: 0.7696 - val_accuracy: 0.8456\n",
      "Epoch 6449/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0446 - accuracy: 0.9861 - val_loss: 0.7068 - val_accuracy: 0.8532\n",
      "Epoch 6450/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0511 - accuracy: 0.9841 - val_loss: 0.7556 - val_accuracy: 0.8462\n",
      "Epoch 6451/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0418 - accuracy: 0.9868 - val_loss: 0.7156 - val_accuracy: 0.8513\n",
      "Epoch 6452/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0439 - accuracy: 0.9860 - val_loss: 0.7441 - val_accuracy: 0.8514\n",
      "Epoch 6453/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0487 - accuracy: 0.9850 - val_loss: 0.7209 - val_accuracy: 0.8559\n",
      "Epoch 6454/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0469 - accuracy: 0.9852 - val_loss: 0.8077 - val_accuracy: 0.8409\n",
      "Epoch 6455/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0528 - accuracy: 0.9835 - val_loss: 0.7576 - val_accuracy: 0.8501\n",
      "Epoch 6456/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0453 - accuracy: 0.9859 - val_loss: 0.7540 - val_accuracy: 0.8499\n",
      "Epoch 6457/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0433 - accuracy: 0.9864 - val_loss: 0.6982 - val_accuracy: 0.8566\n",
      "Epoch 6458/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0510 - accuracy: 0.9836 - val_loss: 0.6893 - val_accuracy: 0.8558\n",
      "Epoch 6459/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0453 - accuracy: 0.9862 - val_loss: 0.6754 - val_accuracy: 0.8587\n",
      "Epoch 6460/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0456 - accuracy: 0.9852 - val_loss: 0.6573 - val_accuracy: 0.8606\n",
      "Epoch 6461/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0495 - accuracy: 0.9842 - val_loss: 0.6622 - val_accuracy: 0.8582\n",
      "Epoch 6462/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0418 - accuracy: 0.9870 - val_loss: 0.6788 - val_accuracy: 0.8594\n",
      "Epoch 6463/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0435 - accuracy: 0.9861 - val_loss: 0.7003 - val_accuracy: 0.8568\n",
      "Epoch 6464/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0498 - accuracy: 0.9849 - val_loss: 0.6927 - val_accuracy: 0.8601\n",
      "Epoch 6465/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0453 - accuracy: 0.9858 - val_loss: 0.6453 - val_accuracy: 0.8654\n",
      "Epoch 6466/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0514 - accuracy: 0.9844 - val_loss: 0.6889 - val_accuracy: 0.8566\n",
      "Epoch 6467/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0443 - accuracy: 0.9868 - val_loss: 0.6877 - val_accuracy: 0.8612\n",
      "Epoch 6468/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0467 - accuracy: 0.9854 - val_loss: 0.6828 - val_accuracy: 0.8609\n",
      "Epoch 6469/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0404 - accuracy: 0.9870 - val_loss: 0.7407 - val_accuracy: 0.8492\n",
      "Epoch 6470/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0472 - accuracy: 0.9855 - val_loss: 0.6980 - val_accuracy: 0.8575\n",
      "Epoch 6471/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0442 - accuracy: 0.9861 - val_loss: 0.7216 - val_accuracy: 0.8529\n",
      "Epoch 6472/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0445 - accuracy: 0.9862 - val_loss: 0.6916 - val_accuracy: 0.8568\n",
      "Epoch 6473/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0427 - accuracy: 0.9873 - val_loss: 0.7364 - val_accuracy: 0.8487\n",
      "Epoch 6474/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0499 - accuracy: 0.9846 - val_loss: 0.6985 - val_accuracy: 0.8562\n",
      "Epoch 6475/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0477 - accuracy: 0.9856 - val_loss: 0.7506 - val_accuracy: 0.8475\n",
      "Epoch 6476/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0466 - accuracy: 0.9860 - val_loss: 0.6726 - val_accuracy: 0.8599\n",
      "Epoch 6477/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0403 - accuracy: 0.9871 - val_loss: 0.7011 - val_accuracy: 0.8604\n",
      "Epoch 6478/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0479 - accuracy: 0.9852 - val_loss: 0.7919 - val_accuracy: 0.8418\n",
      "Epoch 6479/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0481 - accuracy: 0.9853 - val_loss: 0.7282 - val_accuracy: 0.8506\n",
      "Epoch 6480/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0485 - accuracy: 0.9849 - val_loss: 0.8355 - val_accuracy: 0.8404\n",
      "Epoch 6481/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0478 - accuracy: 0.9854 - val_loss: 0.7514 - val_accuracy: 0.8502\n",
      "Epoch 6482/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0481 - accuracy: 0.9849 - val_loss: 0.7069 - val_accuracy: 0.8587\n",
      "Epoch 6483/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0470 - accuracy: 0.9861 - val_loss: 0.6651 - val_accuracy: 0.8619\n",
      "Epoch 6484/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0456 - accuracy: 0.9857 - val_loss: 0.6934 - val_accuracy: 0.8562\n",
      "Epoch 6485/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0488 - accuracy: 0.9843 - val_loss: 0.6812 - val_accuracy: 0.8598\n",
      "Epoch 6486/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0434 - accuracy: 0.9869 - val_loss: 0.7377 - val_accuracy: 0.8489\n",
      "Epoch 6487/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0456 - accuracy: 0.9861 - val_loss: 0.6999 - val_accuracy: 0.8567\n",
      "Epoch 6488/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0478 - accuracy: 0.9857 - val_loss: 0.6505 - val_accuracy: 0.8632\n",
      "Epoch 6489/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0444 - accuracy: 0.9864 - val_loss: 0.7409 - val_accuracy: 0.8513\n",
      "Epoch 6490/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0403 - accuracy: 0.9876 - val_loss: 0.7120 - val_accuracy: 0.8541\n",
      "Epoch 6491/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0506 - accuracy: 0.9849 - val_loss: 0.6996 - val_accuracy: 0.8562\n",
      "Epoch 6492/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0447 - accuracy: 0.9864 - val_loss: 0.7238 - val_accuracy: 0.8539\n",
      "Epoch 6493/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0538 - accuracy: 0.9835 - val_loss: 0.7069 - val_accuracy: 0.8578\n",
      "Epoch 6494/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0459 - accuracy: 0.9857 - val_loss: 0.6791 - val_accuracy: 0.8590\n",
      "Epoch 6495/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0417 - accuracy: 0.9875 - val_loss: 0.7446 - val_accuracy: 0.8452\n",
      "Epoch 6496/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0458 - accuracy: 0.9855 - val_loss: 0.6632 - val_accuracy: 0.8628\n",
      "Epoch 6497/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0445 - accuracy: 0.9861 - val_loss: 1.3097 - val_accuracy: 0.8073\n",
      "Epoch 6498/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0543 - accuracy: 0.9839 - val_loss: 0.7039 - val_accuracy: 0.8569\n",
      "Epoch 6499/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0444 - accuracy: 0.9863 - val_loss: 0.7133 - val_accuracy: 0.8557\n",
      "Epoch 6500/8000\n",
      "1459/1463 [============================>.] - ETA: 0s - loss: 0.0514 - accuracy: 0.9839\n",
      "Epoch 6500: saving model to ./training_ckpt_20240109205949_v8_240109_d10000_n4096_b64_e8000_c100_Adamax\\cp-000006500.ckpt\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0513 - accuracy: 0.9840 - val_loss: 0.6556 - val_accuracy: 0.8611\n",
      "Epoch 6501/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0419 - accuracy: 0.9870 - val_loss: 0.6982 - val_accuracy: 0.8537\n",
      "Epoch 6502/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0459 - accuracy: 0.9864 - val_loss: 0.6735 - val_accuracy: 0.8595\n",
      "Epoch 6503/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0445 - accuracy: 0.9863 - val_loss: 0.8203 - val_accuracy: 0.8426\n",
      "Epoch 6504/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0460 - accuracy: 0.9862 - val_loss: 0.6676 - val_accuracy: 0.8590\n",
      "Epoch 6505/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0378 - accuracy: 0.9883 - val_loss: 0.7324 - val_accuracy: 0.8505\n",
      "Epoch 6506/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0492 - accuracy: 0.9850 - val_loss: 0.6876 - val_accuracy: 0.8595\n",
      "Epoch 6507/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0481 - accuracy: 0.9849 - val_loss: 0.7621 - val_accuracy: 0.8475\n",
      "Epoch 6508/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0440 - accuracy: 0.9859 - val_loss: 0.7048 - val_accuracy: 0.8563\n",
      "Epoch 6509/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0477 - accuracy: 0.9856 - val_loss: 0.6794 - val_accuracy: 0.8587\n",
      "Epoch 6510/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0527 - accuracy: 0.9845 - val_loss: 0.7063 - val_accuracy: 0.8562\n",
      "Epoch 6511/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0473 - accuracy: 0.9854 - val_loss: 0.7677 - val_accuracy: 0.8444\n",
      "Epoch 6512/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0471 - accuracy: 0.9859 - val_loss: 0.7189 - val_accuracy: 0.8555\n",
      "Epoch 6513/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0464 - accuracy: 0.9857 - val_loss: 0.7422 - val_accuracy: 0.8501\n",
      "Epoch 6514/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0429 - accuracy: 0.9868 - val_loss: 0.7284 - val_accuracy: 0.8547\n",
      "Epoch 6515/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0481 - accuracy: 0.9852 - val_loss: 0.6647 - val_accuracy: 0.8606\n",
      "Epoch 6516/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0402 - accuracy: 0.9878 - val_loss: 0.7160 - val_accuracy: 0.8562\n",
      "Epoch 6517/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0453 - accuracy: 0.9859 - val_loss: 0.7412 - val_accuracy: 0.8487\n",
      "Epoch 6518/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0427 - accuracy: 0.9866 - val_loss: 0.7372 - val_accuracy: 0.8527\n",
      "Epoch 6519/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0497 - accuracy: 0.9856 - val_loss: 0.7193 - val_accuracy: 0.8532\n",
      "Epoch 6520/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0458 - accuracy: 0.9858 - val_loss: 0.7234 - val_accuracy: 0.8532\n",
      "Epoch 6521/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0452 - accuracy: 0.9857 - val_loss: 0.7196 - val_accuracy: 0.8547\n",
      "Epoch 6522/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0429 - accuracy: 0.9869 - val_loss: 0.6574 - val_accuracy: 0.8626\n",
      "Epoch 6523/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0445 - accuracy: 0.9863 - val_loss: 0.7866 - val_accuracy: 0.8405\n",
      "Epoch 6524/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0466 - accuracy: 0.9858 - val_loss: 0.7072 - val_accuracy: 0.8570\n",
      "Epoch 6525/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0464 - accuracy: 0.9861 - val_loss: 0.7874 - val_accuracy: 0.8499\n",
      "Epoch 6526/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0483 - accuracy: 0.9855 - val_loss: 0.7084 - val_accuracy: 0.8573\n",
      "Epoch 6527/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0470 - accuracy: 0.9853 - val_loss: 0.6727 - val_accuracy: 0.8610\n",
      "Epoch 6528/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0477 - accuracy: 0.9856 - val_loss: 0.7334 - val_accuracy: 0.8492\n",
      "Epoch 6529/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0484 - accuracy: 0.9849 - val_loss: 0.7062 - val_accuracy: 0.8538\n",
      "Epoch 6530/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0474 - accuracy: 0.9857 - val_loss: 0.7128 - val_accuracy: 0.8551\n",
      "Epoch 6531/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0456 - accuracy: 0.9865 - val_loss: 0.7629 - val_accuracy: 0.8489\n",
      "Epoch 6532/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0446 - accuracy: 0.9867 - val_loss: 0.7162 - val_accuracy: 0.8533\n",
      "Epoch 6533/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0474 - accuracy: 0.9853 - val_loss: 0.7658 - val_accuracy: 0.8484\n",
      "Epoch 6534/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0452 - accuracy: 0.9855 - val_loss: 0.7002 - val_accuracy: 0.8554\n",
      "Epoch 6535/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0459 - accuracy: 0.9860 - val_loss: 0.7460 - val_accuracy: 0.8519\n",
      "Epoch 6536/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0460 - accuracy: 0.9854 - val_loss: 0.7428 - val_accuracy: 0.8503\n",
      "Epoch 6537/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0505 - accuracy: 0.9840 - val_loss: 0.7952 - val_accuracy: 0.8473\n",
      "Epoch 6538/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0490 - accuracy: 0.9849 - val_loss: 0.7349 - val_accuracy: 0.8494\n",
      "Epoch 6539/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0504 - accuracy: 0.9846 - val_loss: 0.6860 - val_accuracy: 0.8565\n",
      "Epoch 6540/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0451 - accuracy: 0.9862 - val_loss: 0.7160 - val_accuracy: 0.8569\n",
      "Epoch 6541/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0481 - accuracy: 0.9851 - val_loss: 0.6629 - val_accuracy: 0.8611\n",
      "Epoch 6542/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0423 - accuracy: 0.9873 - val_loss: 0.7866 - val_accuracy: 0.8486\n",
      "Epoch 6543/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0476 - accuracy: 0.9853 - val_loss: 0.7418 - val_accuracy: 0.8513\n",
      "Epoch 6544/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0450 - accuracy: 0.9863 - val_loss: 0.7475 - val_accuracy: 0.8501\n",
      "Epoch 6545/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0476 - accuracy: 0.9853 - val_loss: 0.6708 - val_accuracy: 0.8612\n",
      "Epoch 6546/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0433 - accuracy: 0.9866 - val_loss: 0.7337 - val_accuracy: 0.8545\n",
      "Epoch 6547/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0483 - accuracy: 0.9849 - val_loss: 0.7814 - val_accuracy: 0.8425\n",
      "Epoch 6548/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0445 - accuracy: 0.9867 - val_loss: 0.7052 - val_accuracy: 0.8558\n",
      "Epoch 6549/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0515 - accuracy: 0.9844 - val_loss: 0.7248 - val_accuracy: 0.8532\n",
      "Epoch 6550/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0503 - accuracy: 0.9848 - val_loss: 0.7102 - val_accuracy: 0.8552\n",
      "Epoch 6551/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0497 - accuracy: 0.9849 - val_loss: 0.7371 - val_accuracy: 0.8506\n",
      "Epoch 6552/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0483 - accuracy: 0.9864 - val_loss: 0.6775 - val_accuracy: 0.8638\n",
      "Epoch 6553/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0425 - accuracy: 0.9870 - val_loss: 0.6982 - val_accuracy: 0.8561\n",
      "Epoch 6554/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0455 - accuracy: 0.9861 - val_loss: 0.6852 - val_accuracy: 0.8551\n",
      "Epoch 6555/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0440 - accuracy: 0.9863 - val_loss: 0.6916 - val_accuracy: 0.8590\n",
      "Epoch 6556/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0453 - accuracy: 0.9862 - val_loss: 0.7070 - val_accuracy: 0.8570\n",
      "Epoch 6557/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0460 - accuracy: 0.9856 - val_loss: 0.7086 - val_accuracy: 0.8565\n",
      "Epoch 6558/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0448 - accuracy: 0.9858 - val_loss: 0.7924 - val_accuracy: 0.8420\n",
      "Epoch 6559/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0492 - accuracy: 0.9850 - val_loss: 0.6994 - val_accuracy: 0.8581\n",
      "Epoch 6560/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0427 - accuracy: 0.9867 - val_loss: 0.7136 - val_accuracy: 0.8553\n",
      "Epoch 6561/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0483 - accuracy: 0.9850 - val_loss: 0.6840 - val_accuracy: 0.8584\n",
      "Epoch 6562/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0449 - accuracy: 0.9859 - val_loss: 0.6689 - val_accuracy: 0.8607\n",
      "Epoch 6563/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0454 - accuracy: 0.9861 - val_loss: 0.7098 - val_accuracy: 0.8574\n",
      "Epoch 6564/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0533 - accuracy: 0.9842 - val_loss: 0.8045 - val_accuracy: 0.8345\n",
      "Epoch 6565/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0499 - accuracy: 0.9843 - val_loss: 0.7280 - val_accuracy: 0.8515\n",
      "Epoch 6566/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0455 - accuracy: 0.9861 - val_loss: 0.8703 - val_accuracy: 0.8325\n",
      "Epoch 6567/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0433 - accuracy: 0.9867 - val_loss: 0.6889 - val_accuracy: 0.8567\n",
      "Epoch 6568/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0565 - accuracy: 0.9835 - val_loss: 0.6758 - val_accuracy: 0.8624\n",
      "Epoch 6569/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0425 - accuracy: 0.9865 - val_loss: 0.6953 - val_accuracy: 0.8564\n",
      "Epoch 6570/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0439 - accuracy: 0.9871 - val_loss: 0.7117 - val_accuracy: 0.8537\n",
      "Epoch 6571/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0455 - accuracy: 0.9863 - val_loss: 0.7449 - val_accuracy: 0.8521\n",
      "Epoch 6572/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0499 - accuracy: 0.9849 - val_loss: 0.7150 - val_accuracy: 0.8534\n",
      "Epoch 6573/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0574 - accuracy: 0.9834 - val_loss: 0.6778 - val_accuracy: 0.8600\n",
      "Epoch 6574/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0462 - accuracy: 0.9860 - val_loss: 0.7211 - val_accuracy: 0.8542\n",
      "Epoch 6575/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0432 - accuracy: 0.9863 - val_loss: 0.7101 - val_accuracy: 0.8542\n",
      "Epoch 6576/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0424 - accuracy: 0.9865 - val_loss: 0.8211 - val_accuracy: 0.8370\n",
      "Epoch 6577/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0493 - accuracy: 0.9855 - val_loss: 0.6871 - val_accuracy: 0.8601\n",
      "Epoch 6578/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0433 - accuracy: 0.9867 - val_loss: 0.7051 - val_accuracy: 0.8516\n",
      "Epoch 6579/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0434 - accuracy: 0.9863 - val_loss: 0.6489 - val_accuracy: 0.8633\n",
      "Epoch 6580/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0412 - accuracy: 0.9873 - val_loss: 0.7398 - val_accuracy: 0.8521\n",
      "Epoch 6581/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0429 - accuracy: 0.9872 - val_loss: 0.6621 - val_accuracy: 0.8631\n",
      "Epoch 6582/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0437 - accuracy: 0.9861 - val_loss: 0.7508 - val_accuracy: 0.8488\n",
      "Epoch 6583/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0527 - accuracy: 0.9837 - val_loss: 0.7228 - val_accuracy: 0.8547\n",
      "Epoch 6584/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0489 - accuracy: 0.9848 - val_loss: 0.7006 - val_accuracy: 0.8569\n",
      "Epoch 6585/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0491 - accuracy: 0.9851 - val_loss: 0.7105 - val_accuracy: 0.8592\n",
      "Epoch 6586/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0519 - accuracy: 0.9837 - val_loss: 0.8133 - val_accuracy: 0.8372\n",
      "Epoch 6587/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0431 - accuracy: 0.9866 - val_loss: 0.6870 - val_accuracy: 0.8605\n",
      "Epoch 6588/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0460 - accuracy: 0.9854 - val_loss: 0.7229 - val_accuracy: 0.8566\n",
      "Epoch 6589/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0457 - accuracy: 0.9863 - val_loss: 0.7540 - val_accuracy: 0.8469\n",
      "Epoch 6590/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0503 - accuracy: 0.9847 - val_loss: 0.7515 - val_accuracy: 0.8531\n",
      "Epoch 6591/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0461 - accuracy: 0.9858 - val_loss: 0.7321 - val_accuracy: 0.8537\n",
      "Epoch 6592/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0434 - accuracy: 0.9863 - val_loss: 0.7609 - val_accuracy: 0.8522\n",
      "Epoch 6593/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0444 - accuracy: 0.9865 - val_loss: 0.6736 - val_accuracy: 0.8598\n",
      "Epoch 6594/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0438 - accuracy: 0.9865 - val_loss: 0.7452 - val_accuracy: 0.8523\n",
      "Epoch 6595/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0458 - accuracy: 0.9860 - val_loss: 0.7655 - val_accuracy: 0.8526\n",
      "Epoch 6596/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0468 - accuracy: 0.9857 - val_loss: 0.7065 - val_accuracy: 0.8579\n",
      "Epoch 6597/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0420 - accuracy: 0.9873 - val_loss: 0.7001 - val_accuracy: 0.8586\n",
      "Epoch 6598/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0478 - accuracy: 0.9854 - val_loss: 0.6765 - val_accuracy: 0.8615\n",
      "Epoch 6599/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0460 - accuracy: 0.9859 - val_loss: 0.7350 - val_accuracy: 0.8551\n",
      "Epoch 6600/8000\n",
      "1458/1463 [============================>.] - ETA: 0s - loss: 0.0493 - accuracy: 0.9849\n",
      "Epoch 6600: saving model to ./training_ckpt_20240109205949_v8_240109_d10000_n4096_b64_e8000_c100_Adamax\\cp-000006600.ckpt\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0492 - accuracy: 0.9849 - val_loss: 0.6619 - val_accuracy: 0.8620\n",
      "Epoch 6601/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0405 - accuracy: 0.9877 - val_loss: 0.6783 - val_accuracy: 0.8598\n",
      "Epoch 6602/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0459 - accuracy: 0.9862 - val_loss: 0.6913 - val_accuracy: 0.8587\n",
      "Epoch 6603/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0460 - accuracy: 0.9851 - val_loss: 0.7107 - val_accuracy: 0.8526\n",
      "Epoch 6604/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0427 - accuracy: 0.9866 - val_loss: 0.7044 - val_accuracy: 0.8546\n",
      "Epoch 6605/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0444 - accuracy: 0.9866 - val_loss: 0.9227 - val_accuracy: 0.8223\n",
      "Epoch 6606/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0476 - accuracy: 0.9851 - val_loss: 0.7365 - val_accuracy: 0.8512\n",
      "Epoch 6607/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0432 - accuracy: 0.9869 - val_loss: 0.6969 - val_accuracy: 0.8587\n",
      "Epoch 6608/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0516 - accuracy: 0.9848 - val_loss: 0.6809 - val_accuracy: 0.8602\n",
      "Epoch 6609/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0453 - accuracy: 0.9863 - val_loss: 0.6934 - val_accuracy: 0.8609\n",
      "Epoch 6610/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0467 - accuracy: 0.9858 - val_loss: 0.6918 - val_accuracy: 0.8570\n",
      "Epoch 6611/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0437 - accuracy: 0.9867 - val_loss: 0.7697 - val_accuracy: 0.8459\n",
      "Epoch 6612/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0429 - accuracy: 0.9867 - val_loss: 0.6870 - val_accuracy: 0.8578\n",
      "Epoch 6613/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0434 - accuracy: 0.9861 - val_loss: 0.7836 - val_accuracy: 0.8483\n",
      "Epoch 6614/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0414 - accuracy: 0.9870 - val_loss: 0.6799 - val_accuracy: 0.8610\n",
      "Epoch 6615/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0459 - accuracy: 0.9860 - val_loss: 0.7100 - val_accuracy: 0.8568\n",
      "Epoch 6616/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0506 - accuracy: 0.9842 - val_loss: 0.6922 - val_accuracy: 0.8579\n",
      "Epoch 6617/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0408 - accuracy: 0.9875 - val_loss: 0.7312 - val_accuracy: 0.8530\n",
      "Epoch 6618/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0418 - accuracy: 0.9873 - val_loss: 0.7436 - val_accuracy: 0.8492\n",
      "Epoch 6619/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0444 - accuracy: 0.9864 - val_loss: 0.7186 - val_accuracy: 0.8566\n",
      "Epoch 6620/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0475 - accuracy: 0.9859 - val_loss: 0.6635 - val_accuracy: 0.8613\n",
      "Epoch 6621/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0424 - accuracy: 0.9871 - val_loss: 0.7712 - val_accuracy: 0.8498\n",
      "Epoch 6622/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0453 - accuracy: 0.9861 - val_loss: 0.8081 - val_accuracy: 0.8402\n",
      "Epoch 6623/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0422 - accuracy: 0.9869 - val_loss: 0.7369 - val_accuracy: 0.8534\n",
      "Epoch 6624/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0586 - accuracy: 0.9828 - val_loss: 0.7403 - val_accuracy: 0.8530\n",
      "Epoch 6625/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0549 - accuracy: 0.9833 - val_loss: 0.7328 - val_accuracy: 0.8545\n",
      "Epoch 6626/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0468 - accuracy: 0.9854 - val_loss: 0.7636 - val_accuracy: 0.8450\n",
      "Epoch 6627/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0443 - accuracy: 0.9861 - val_loss: 0.7639 - val_accuracy: 0.8490\n",
      "Epoch 6628/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0441 - accuracy: 0.9864 - val_loss: 0.7072 - val_accuracy: 0.8579\n",
      "Epoch 6629/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0465 - accuracy: 0.9858 - val_loss: 0.9883 - val_accuracy: 0.8261\n",
      "Epoch 6630/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0461 - accuracy: 0.9861 - val_loss: 0.6883 - val_accuracy: 0.8605\n",
      "Epoch 6631/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0473 - accuracy: 0.9858 - val_loss: 0.6800 - val_accuracy: 0.8620\n",
      "Epoch 6632/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0493 - accuracy: 0.9844 - val_loss: 0.7373 - val_accuracy: 0.8511\n",
      "Epoch 6633/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0441 - accuracy: 0.9863 - val_loss: 0.7451 - val_accuracy: 0.8501\n",
      "Epoch 6634/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0463 - accuracy: 0.9860 - val_loss: 0.7957 - val_accuracy: 0.8450\n",
      "Epoch 6635/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0463 - accuracy: 0.9851 - val_loss: 0.7355 - val_accuracy: 0.8515\n",
      "Epoch 6636/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0391 - accuracy: 0.9876 - val_loss: 0.7272 - val_accuracy: 0.8541\n",
      "Epoch 6637/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0481 - accuracy: 0.9853 - val_loss: 0.6880 - val_accuracy: 0.8608\n",
      "Epoch 6638/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0462 - accuracy: 0.9858 - val_loss: 0.7243 - val_accuracy: 0.8527\n",
      "Epoch 6639/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0440 - accuracy: 0.9868 - val_loss: 0.6543 - val_accuracy: 0.8643\n",
      "Epoch 6640/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0480 - accuracy: 0.9852 - val_loss: 0.6870 - val_accuracy: 0.8587\n",
      "Epoch 6641/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0478 - accuracy: 0.9849 - val_loss: 0.7301 - val_accuracy: 0.8547\n",
      "Epoch 6642/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0437 - accuracy: 0.9863 - val_loss: 0.6908 - val_accuracy: 0.8596\n",
      "Epoch 6643/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0450 - accuracy: 0.9860 - val_loss: 0.6633 - val_accuracy: 0.8631\n",
      "Epoch 6644/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0434 - accuracy: 0.9868 - val_loss: 0.7302 - val_accuracy: 0.8508\n",
      "Epoch 6645/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0484 - accuracy: 0.9848 - val_loss: 0.6516 - val_accuracy: 0.8636\n",
      "Epoch 6646/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0461 - accuracy: 0.9861 - val_loss: 0.9438 - val_accuracy: 0.8249\n",
      "Epoch 6647/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0468 - accuracy: 0.9853 - val_loss: 0.6858 - val_accuracy: 0.8589\n",
      "Epoch 6648/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0465 - accuracy: 0.9859 - val_loss: 0.6823 - val_accuracy: 0.8592\n",
      "Epoch 6649/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0444 - accuracy: 0.9869 - val_loss: 0.7300 - val_accuracy: 0.8559\n",
      "Epoch 6650/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0528 - accuracy: 0.9838 - val_loss: 0.8123 - val_accuracy: 0.8412\n",
      "Epoch 6651/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0427 - accuracy: 0.9865 - val_loss: 0.7011 - val_accuracy: 0.8586\n",
      "Epoch 6652/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0474 - accuracy: 0.9853 - val_loss: 0.6838 - val_accuracy: 0.8574\n",
      "Epoch 6653/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0398 - accuracy: 0.9879 - val_loss: 0.7432 - val_accuracy: 0.8537\n",
      "Epoch 6654/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0443 - accuracy: 0.9862 - val_loss: 0.6876 - val_accuracy: 0.8598\n",
      "Epoch 6655/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0489 - accuracy: 0.9851 - val_loss: 0.6558 - val_accuracy: 0.8652\n",
      "Epoch 6656/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0416 - accuracy: 0.9873 - val_loss: 0.7195 - val_accuracy: 0.8543\n",
      "Epoch 6657/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0488 - accuracy: 0.9847 - val_loss: 0.6864 - val_accuracy: 0.8607\n",
      "Epoch 6658/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0469 - accuracy: 0.9855 - val_loss: 0.6854 - val_accuracy: 0.8619\n",
      "Epoch 6659/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0446 - accuracy: 0.9859 - val_loss: 0.6708 - val_accuracy: 0.8621\n",
      "Epoch 6660/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0435 - accuracy: 0.9867 - val_loss: 0.6910 - val_accuracy: 0.8588\n",
      "Epoch 6661/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0507 - accuracy: 0.9853 - val_loss: 0.7819 - val_accuracy: 0.8456\n",
      "Epoch 6662/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0482 - accuracy: 0.9852 - val_loss: 0.7471 - val_accuracy: 0.8502\n",
      "Epoch 6663/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0421 - accuracy: 0.9875 - val_loss: 0.7071 - val_accuracy: 0.8563\n",
      "Epoch 6664/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0441 - accuracy: 0.9859 - val_loss: 0.6957 - val_accuracy: 0.8576\n",
      "Epoch 6665/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0518 - accuracy: 0.9843 - val_loss: 0.7070 - val_accuracy: 0.8582\n",
      "Epoch 6666/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0459 - accuracy: 0.9858 - val_loss: 0.7050 - val_accuracy: 0.8568\n",
      "Epoch 6667/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0519 - accuracy: 0.9838 - val_loss: 0.8450 - val_accuracy: 0.8343\n",
      "Epoch 6668/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0469 - accuracy: 0.9860 - val_loss: 0.6727 - val_accuracy: 0.8633\n",
      "Epoch 6669/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0407 - accuracy: 0.9877 - val_loss: 0.7614 - val_accuracy: 0.8515\n",
      "Epoch 6670/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0450 - accuracy: 0.9866 - val_loss: 0.7173 - val_accuracy: 0.8539\n",
      "Epoch 6671/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0423 - accuracy: 0.9865 - val_loss: 0.7012 - val_accuracy: 0.8569\n",
      "Epoch 6672/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0484 - accuracy: 0.9848 - val_loss: 0.7229 - val_accuracy: 0.8552\n",
      "Epoch 6673/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0477 - accuracy: 0.9851 - val_loss: 0.7718 - val_accuracy: 0.8439\n",
      "Epoch 6674/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0432 - accuracy: 0.9865 - val_loss: 0.6898 - val_accuracy: 0.8568\n",
      "Epoch 6675/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0536 - accuracy: 0.9836 - val_loss: 0.7058 - val_accuracy: 0.8562\n",
      "Epoch 6676/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0406 - accuracy: 0.9875 - val_loss: 0.7244 - val_accuracy: 0.8538\n",
      "Epoch 6677/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0486 - accuracy: 0.9843 - val_loss: 0.7261 - val_accuracy: 0.8545\n",
      "Epoch 6678/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0445 - accuracy: 0.9864 - val_loss: 0.7036 - val_accuracy: 0.8568\n",
      "Epoch 6679/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0529 - accuracy: 0.9846 - val_loss: 0.7212 - val_accuracy: 0.8506\n",
      "Epoch 6680/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0458 - accuracy: 0.9860 - val_loss: 0.7063 - val_accuracy: 0.8575\n",
      "Epoch 6681/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0476 - accuracy: 0.9851 - val_loss: 0.7182 - val_accuracy: 0.8557\n",
      "Epoch 6682/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0420 - accuracy: 0.9866 - val_loss: 0.6976 - val_accuracy: 0.8605\n",
      "Epoch 6683/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0464 - accuracy: 0.9856 - val_loss: 0.7527 - val_accuracy: 0.8497\n",
      "Epoch 6684/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0478 - accuracy: 0.9852 - val_loss: 0.6987 - val_accuracy: 0.8590\n",
      "Epoch 6685/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0465 - accuracy: 0.9855 - val_loss: 0.7466 - val_accuracy: 0.8478\n",
      "Epoch 6686/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0446 - accuracy: 0.9860 - val_loss: 0.7036 - val_accuracy: 0.8570\n",
      "Epoch 6687/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0422 - accuracy: 0.9870 - val_loss: 0.7367 - val_accuracy: 0.8512\n",
      "Epoch 6688/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0456 - accuracy: 0.9858 - val_loss: 0.6762 - val_accuracy: 0.8603\n",
      "Epoch 6689/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0418 - accuracy: 0.9868 - val_loss: 0.6739 - val_accuracy: 0.8643\n",
      "Epoch 6690/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0467 - accuracy: 0.9855 - val_loss: 0.7199 - val_accuracy: 0.8521\n",
      "Epoch 6691/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0484 - accuracy: 0.9851 - val_loss: 0.7927 - val_accuracy: 0.8489\n",
      "Epoch 6692/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0447 - accuracy: 0.9860 - val_loss: 0.7207 - val_accuracy: 0.8541\n",
      "Epoch 6693/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0482 - accuracy: 0.9848 - val_loss: 0.6722 - val_accuracy: 0.8634\n",
      "Epoch 6694/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0508 - accuracy: 0.9850 - val_loss: 0.7235 - val_accuracy: 0.8575\n",
      "Epoch 6695/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0468 - accuracy: 0.9855 - val_loss: 0.7227 - val_accuracy: 0.8543\n",
      "Epoch 6696/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0477 - accuracy: 0.9855 - val_loss: 0.6962 - val_accuracy: 0.8597\n",
      "Epoch 6697/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0459 - accuracy: 0.9857 - val_loss: 0.7237 - val_accuracy: 0.8562\n",
      "Epoch 6698/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0464 - accuracy: 0.9858 - val_loss: 0.7269 - val_accuracy: 0.8574\n",
      "Epoch 6699/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0438 - accuracy: 0.9866 - val_loss: 0.6636 - val_accuracy: 0.8614\n",
      "Epoch 6700/8000\n",
      "1458/1463 [============================>.] - ETA: 0s - loss: 0.0464 - accuracy: 0.9853\n",
      "Epoch 6700: saving model to ./training_ckpt_20240109205949_v8_240109_d10000_n4096_b64_e8000_c100_Adamax\\cp-000006700.ckpt\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0464 - accuracy: 0.9853 - val_loss: 0.6699 - val_accuracy: 0.8650\n",
      "Epoch 6701/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0440 - accuracy: 0.9866 - val_loss: 0.7287 - val_accuracy: 0.8517\n",
      "Epoch 6702/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0484 - accuracy: 0.9853 - val_loss: 0.7247 - val_accuracy: 0.8524\n",
      "Epoch 6703/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0461 - accuracy: 0.9859 - val_loss: 0.7263 - val_accuracy: 0.8534\n",
      "Epoch 6704/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0394 - accuracy: 0.9878 - val_loss: 0.7276 - val_accuracy: 0.8509\n",
      "Epoch 6705/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0447 - accuracy: 0.9864 - val_loss: 0.6738 - val_accuracy: 0.8642\n",
      "Epoch 6706/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0433 - accuracy: 0.9867 - val_loss: 0.7119 - val_accuracy: 0.8574\n",
      "Epoch 6707/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0460 - accuracy: 0.9857 - val_loss: 0.7175 - val_accuracy: 0.8544\n",
      "Epoch 6708/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0436 - accuracy: 0.9865 - val_loss: 0.7366 - val_accuracy: 0.8507\n",
      "Epoch 6709/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0465 - accuracy: 0.9859 - val_loss: 0.7356 - val_accuracy: 0.8517\n",
      "Epoch 6710/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0470 - accuracy: 0.9854 - val_loss: 0.7112 - val_accuracy: 0.8542\n",
      "Epoch 6711/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0445 - accuracy: 0.9859 - val_loss: 0.7677 - val_accuracy: 0.8501\n",
      "Epoch 6712/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0452 - accuracy: 0.9864 - val_loss: 0.6899 - val_accuracy: 0.8605\n",
      "Epoch 6713/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0489 - accuracy: 0.9849 - val_loss: 0.7775 - val_accuracy: 0.8473\n",
      "Epoch 6714/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0471 - accuracy: 0.9854 - val_loss: 0.7250 - val_accuracy: 0.8555\n",
      "Epoch 6715/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0440 - accuracy: 0.9864 - val_loss: 0.7828 - val_accuracy: 0.8471\n",
      "Epoch 6716/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0430 - accuracy: 0.9865 - val_loss: 0.7184 - val_accuracy: 0.8565\n",
      "Epoch 6717/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0450 - accuracy: 0.9862 - val_loss: 0.7262 - val_accuracy: 0.8573\n",
      "Epoch 6718/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0414 - accuracy: 0.9870 - val_loss: 0.7030 - val_accuracy: 0.8566\n",
      "Epoch 6719/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0456 - accuracy: 0.9861 - val_loss: 0.7505 - val_accuracy: 0.8514\n",
      "Epoch 6720/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0470 - accuracy: 0.9857 - val_loss: 0.7279 - val_accuracy: 0.8559\n",
      "Epoch 6721/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0487 - accuracy: 0.9855 - val_loss: 0.7254 - val_accuracy: 0.8560\n",
      "Epoch 6722/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0470 - accuracy: 0.9851 - val_loss: 0.6589 - val_accuracy: 0.8665\n",
      "Epoch 6723/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0427 - accuracy: 0.9872 - val_loss: 0.7281 - val_accuracy: 0.8553\n",
      "Epoch 6724/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0451 - accuracy: 0.9863 - val_loss: 0.7002 - val_accuracy: 0.8560\n",
      "Epoch 6725/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0435 - accuracy: 0.9865 - val_loss: 0.6734 - val_accuracy: 0.8613\n",
      "Epoch 6726/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0478 - accuracy: 0.9849 - val_loss: 0.7438 - val_accuracy: 0.8516\n",
      "Epoch 6727/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0498 - accuracy: 0.9848 - val_loss: 0.7278 - val_accuracy: 0.8536\n",
      "Epoch 6728/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0418 - accuracy: 0.9873 - val_loss: 0.6929 - val_accuracy: 0.8647\n",
      "Epoch 6729/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0465 - accuracy: 0.9856 - val_loss: 0.7186 - val_accuracy: 0.8566\n",
      "Epoch 6730/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0484 - accuracy: 0.9847 - val_loss: 0.6913 - val_accuracy: 0.8604\n",
      "Epoch 6731/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0461 - accuracy: 0.9852 - val_loss: 0.7136 - val_accuracy: 0.8522\n",
      "Epoch 6732/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0442 - accuracy: 0.9859 - val_loss: 0.7223 - val_accuracy: 0.8521\n",
      "Epoch 6733/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0488 - accuracy: 0.9851 - val_loss: 0.7950 - val_accuracy: 0.8458\n",
      "Epoch 6734/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0435 - accuracy: 0.9866 - val_loss: 0.7187 - val_accuracy: 0.8573\n",
      "Epoch 6735/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0459 - accuracy: 0.9857 - val_loss: 0.7054 - val_accuracy: 0.8594\n",
      "Epoch 6736/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0487 - accuracy: 0.9855 - val_loss: 0.6995 - val_accuracy: 0.8592\n",
      "Epoch 6737/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0453 - accuracy: 0.9861 - val_loss: 0.7473 - val_accuracy: 0.8518\n",
      "Epoch 6738/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0473 - accuracy: 0.9853 - val_loss: 0.6865 - val_accuracy: 0.8612\n",
      "Epoch 6739/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0415 - accuracy: 0.9871 - val_loss: 0.7248 - val_accuracy: 0.8526\n",
      "Epoch 6740/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0451 - accuracy: 0.9860 - val_loss: 0.7122 - val_accuracy: 0.8619\n",
      "Epoch 6741/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0431 - accuracy: 0.9871 - val_loss: 0.7927 - val_accuracy: 0.8456\n",
      "Epoch 6742/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0451 - accuracy: 0.9859 - val_loss: 0.7024 - val_accuracy: 0.8570\n",
      "Epoch 6743/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0443 - accuracy: 0.9868 - val_loss: 0.8549 - val_accuracy: 0.8396\n",
      "Epoch 6744/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0424 - accuracy: 0.9870 - val_loss: 0.7707 - val_accuracy: 0.8462\n",
      "Epoch 6745/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0428 - accuracy: 0.9869 - val_loss: 0.6748 - val_accuracy: 0.8620\n",
      "Epoch 6746/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0459 - accuracy: 0.9863 - val_loss: 0.6835 - val_accuracy: 0.8613\n",
      "Epoch 6747/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0462 - accuracy: 0.9861 - val_loss: 0.7311 - val_accuracy: 0.8551\n",
      "Epoch 6748/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0425 - accuracy: 0.9875 - val_loss: 0.7232 - val_accuracy: 0.8582\n",
      "Epoch 6749/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0551 - accuracy: 0.9828 - val_loss: 0.7139 - val_accuracy: 0.8549\n",
      "Epoch 6750/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0447 - accuracy: 0.9858 - val_loss: 0.6840 - val_accuracy: 0.8590\n",
      "Epoch 6751/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0452 - accuracy: 0.9864 - val_loss: 0.7477 - val_accuracy: 0.8508\n",
      "Epoch 6752/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0398 - accuracy: 0.9878 - val_loss: 0.7149 - val_accuracy: 0.8554\n",
      "Epoch 6753/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0450 - accuracy: 0.9860 - val_loss: 0.7231 - val_accuracy: 0.8533\n",
      "Epoch 6754/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0509 - accuracy: 0.9840 - val_loss: 0.7117 - val_accuracy: 0.8556\n",
      "Epoch 6755/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0488 - accuracy: 0.9851 - val_loss: 0.7423 - val_accuracy: 0.8532\n",
      "Epoch 6756/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0387 - accuracy: 0.9879 - val_loss: 0.7261 - val_accuracy: 0.8539\n",
      "Epoch 6757/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0477 - accuracy: 0.9851 - val_loss: 0.7257 - val_accuracy: 0.8541\n",
      "Epoch 6758/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0470 - accuracy: 0.9854 - val_loss: 0.7214 - val_accuracy: 0.8548\n",
      "Epoch 6759/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0437 - accuracy: 0.9862 - val_loss: 0.7178 - val_accuracy: 0.8551\n",
      "Epoch 6760/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0444 - accuracy: 0.9857 - val_loss: 0.7399 - val_accuracy: 0.8527\n",
      "Epoch 6761/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0520 - accuracy: 0.9843 - val_loss: 0.7035 - val_accuracy: 0.8563\n",
      "Epoch 6762/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0467 - accuracy: 0.9858 - val_loss: 0.7111 - val_accuracy: 0.8548\n",
      "Epoch 6763/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0457 - accuracy: 0.9860 - val_loss: 0.7455 - val_accuracy: 0.8498\n",
      "Epoch 6764/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0445 - accuracy: 0.9865 - val_loss: 0.7075 - val_accuracy: 0.8562\n",
      "Epoch 6765/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0504 - accuracy: 0.9843 - val_loss: 0.7209 - val_accuracy: 0.8544\n",
      "Epoch 6766/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0428 - accuracy: 0.9868 - val_loss: 0.7014 - val_accuracy: 0.8591\n",
      "Epoch 6767/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0436 - accuracy: 0.9868 - val_loss: 0.7055 - val_accuracy: 0.8557\n",
      "Epoch 6768/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0437 - accuracy: 0.9862 - val_loss: 0.7675 - val_accuracy: 0.8519\n",
      "Epoch 6769/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0444 - accuracy: 0.9860 - val_loss: 0.6626 - val_accuracy: 0.8657\n",
      "Epoch 6770/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0498 - accuracy: 0.9853 - val_loss: 0.7054 - val_accuracy: 0.8593\n",
      "Epoch 6771/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0437 - accuracy: 0.9867 - val_loss: 0.7311 - val_accuracy: 0.8531\n",
      "Epoch 6772/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0396 - accuracy: 0.9873 - val_loss: 0.7354 - val_accuracy: 0.8532\n",
      "Epoch 6773/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0497 - accuracy: 0.9849 - val_loss: 0.7863 - val_accuracy: 0.8455\n",
      "Epoch 6774/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0481 - accuracy: 0.9855 - val_loss: 0.6914 - val_accuracy: 0.8585\n",
      "Epoch 6775/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0388 - accuracy: 0.9880 - val_loss: 0.7200 - val_accuracy: 0.8577\n",
      "Epoch 6776/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0451 - accuracy: 0.9862 - val_loss: 0.7507 - val_accuracy: 0.8536\n",
      "Epoch 6777/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0399 - accuracy: 0.9879 - val_loss: 0.7161 - val_accuracy: 0.8560\n",
      "Epoch 6778/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0460 - accuracy: 0.9865 - val_loss: 0.7634 - val_accuracy: 0.8479\n",
      "Epoch 6779/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0430 - accuracy: 0.9867 - val_loss: 0.7262 - val_accuracy: 0.8581\n",
      "Epoch 6780/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0483 - accuracy: 0.9846 - val_loss: 0.6908 - val_accuracy: 0.8588\n",
      "Epoch 6781/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0422 - accuracy: 0.9867 - val_loss: 0.6850 - val_accuracy: 0.8594\n",
      "Epoch 6782/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0458 - accuracy: 0.9856 - val_loss: 0.7590 - val_accuracy: 0.8489\n",
      "Epoch 6783/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0409 - accuracy: 0.9877 - val_loss: 0.7272 - val_accuracy: 0.8526\n",
      "Epoch 6784/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0425 - accuracy: 0.9870 - val_loss: 0.7320 - val_accuracy: 0.8528\n",
      "Epoch 6785/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0432 - accuracy: 0.9867 - val_loss: 0.7249 - val_accuracy: 0.8507\n",
      "Epoch 6786/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0459 - accuracy: 0.9858 - val_loss: 0.7102 - val_accuracy: 0.8585\n",
      "Epoch 6787/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0470 - accuracy: 0.9856 - val_loss: 0.6847 - val_accuracy: 0.8634\n",
      "Epoch 6788/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0420 - accuracy: 0.9873 - val_loss: 0.8354 - val_accuracy: 0.8385\n",
      "Epoch 6789/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0503 - accuracy: 0.9847 - val_loss: 0.7580 - val_accuracy: 0.8509\n",
      "Epoch 6790/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0453 - accuracy: 0.9863 - val_loss: 0.7283 - val_accuracy: 0.8534\n",
      "Epoch 6791/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0472 - accuracy: 0.9854 - val_loss: 0.7893 - val_accuracy: 0.8432\n",
      "Epoch 6792/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0475 - accuracy: 0.9852 - val_loss: 0.7571 - val_accuracy: 0.8530\n",
      "Epoch 6793/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0419 - accuracy: 0.9873 - val_loss: 0.7443 - val_accuracy: 0.8516\n",
      "Epoch 6794/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0433 - accuracy: 0.9868 - val_loss: 0.7356 - val_accuracy: 0.8552\n",
      "Epoch 6795/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0463 - accuracy: 0.9859 - val_loss: 0.7064 - val_accuracy: 0.8574\n",
      "Epoch 6796/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0440 - accuracy: 0.9861 - val_loss: 0.7458 - val_accuracy: 0.8515\n",
      "Epoch 6797/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0474 - accuracy: 0.9853 - val_loss: 0.7508 - val_accuracy: 0.8529\n",
      "Epoch 6798/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0455 - accuracy: 0.9866 - val_loss: 0.7357 - val_accuracy: 0.8555\n",
      "Epoch 6799/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0524 - accuracy: 0.9853 - val_loss: 0.7692 - val_accuracy: 0.8531\n",
      "Epoch 6800/8000\n",
      "1460/1463 [============================>.] - ETA: 0s - loss: 0.0490 - accuracy: 0.9843\n",
      "Epoch 6800: saving model to ./training_ckpt_20240109205949_v8_240109_d10000_n4096_b64_e8000_c100_Adamax\\cp-000006800.ckpt\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0491 - accuracy: 0.9843 - val_loss: 0.7351 - val_accuracy: 0.8515\n",
      "Epoch 6801/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0509 - accuracy: 0.9836 - val_loss: 0.7234 - val_accuracy: 0.8543\n",
      "Epoch 6802/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0564 - accuracy: 0.9826 - val_loss: 0.7134 - val_accuracy: 0.8550\n",
      "Epoch 6803/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0424 - accuracy: 0.9871 - val_loss: 0.7331 - val_accuracy: 0.8491\n",
      "Epoch 6804/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0465 - accuracy: 0.9847 - val_loss: 0.6824 - val_accuracy: 0.8579\n",
      "Epoch 6805/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0417 - accuracy: 0.9868 - val_loss: 0.7349 - val_accuracy: 0.8500\n",
      "Epoch 6806/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0476 - accuracy: 0.9852 - val_loss: 0.6800 - val_accuracy: 0.8594\n",
      "Epoch 6807/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0495 - accuracy: 0.9848 - val_loss: 0.7018 - val_accuracy: 0.8596\n",
      "Epoch 6808/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0492 - accuracy: 0.9855 - val_loss: 0.7229 - val_accuracy: 0.8537\n",
      "Epoch 6809/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0546 - accuracy: 0.9835 - val_loss: 0.7237 - val_accuracy: 0.8596\n",
      "Epoch 6810/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0486 - accuracy: 0.9849 - val_loss: 0.7253 - val_accuracy: 0.8514\n",
      "Epoch 6811/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0482 - accuracy: 0.9851 - val_loss: 0.7893 - val_accuracy: 0.8427\n",
      "Epoch 6812/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0459 - accuracy: 0.9853 - val_loss: 0.7144 - val_accuracy: 0.8569\n",
      "Epoch 6813/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0469 - accuracy: 0.9851 - val_loss: 0.7360 - val_accuracy: 0.8498\n",
      "Epoch 6814/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0438 - accuracy: 0.9859 - val_loss: 0.6840 - val_accuracy: 0.8604\n",
      "Epoch 6815/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0477 - accuracy: 0.9853 - val_loss: 0.6859 - val_accuracy: 0.8582\n",
      "Epoch 6816/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0476 - accuracy: 0.9851 - val_loss: 0.7635 - val_accuracy: 0.8479\n",
      "Epoch 6817/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0426 - accuracy: 0.9866 - val_loss: 0.7850 - val_accuracy: 0.8459\n",
      "Epoch 6818/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0546 - accuracy: 0.9827 - val_loss: 0.7772 - val_accuracy: 0.8441\n",
      "Epoch 6819/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0450 - accuracy: 0.9861 - val_loss: 0.7619 - val_accuracy: 0.8522\n",
      "Epoch 6820/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0496 - accuracy: 0.9844 - val_loss: 0.7341 - val_accuracy: 0.8538\n",
      "Epoch 6821/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0450 - accuracy: 0.9857 - val_loss: 0.7349 - val_accuracy: 0.8563\n",
      "Epoch 6822/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0499 - accuracy: 0.9845 - val_loss: 0.7463 - val_accuracy: 0.8497\n",
      "Epoch 6823/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0507 - accuracy: 0.9845 - val_loss: 0.8065 - val_accuracy: 0.8416\n",
      "Epoch 6824/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0456 - accuracy: 0.9855 - val_loss: 0.7292 - val_accuracy: 0.8538\n",
      "Epoch 6825/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0397 - accuracy: 0.9875 - val_loss: 0.7041 - val_accuracy: 0.8582\n",
      "Epoch 6826/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0502 - accuracy: 0.9852 - val_loss: 0.7240 - val_accuracy: 0.8530\n",
      "Epoch 6827/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0475 - accuracy: 0.9850 - val_loss: 0.6994 - val_accuracy: 0.8590\n",
      "Epoch 6828/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0434 - accuracy: 0.9864 - val_loss: 0.7620 - val_accuracy: 0.8468\n",
      "Epoch 6829/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0546 - accuracy: 0.9839 - val_loss: 0.7253 - val_accuracy: 0.8525\n",
      "Epoch 6830/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0464 - accuracy: 0.9851 - val_loss: 0.7170 - val_accuracy: 0.8552\n",
      "Epoch 6831/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0509 - accuracy: 0.9843 - val_loss: 0.7049 - val_accuracy: 0.8554\n",
      "Epoch 6832/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0424 - accuracy: 0.9870 - val_loss: 0.7569 - val_accuracy: 0.8537\n",
      "Epoch 6833/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0512 - accuracy: 0.9844 - val_loss: 0.7414 - val_accuracy: 0.8556\n",
      "Epoch 6834/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0502 - accuracy: 0.9846 - val_loss: 0.7591 - val_accuracy: 0.8500\n",
      "Epoch 6835/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0462 - accuracy: 0.9858 - val_loss: 0.7546 - val_accuracy: 0.8496\n",
      "Epoch 6836/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0537 - accuracy: 0.9849 - val_loss: 0.7606 - val_accuracy: 0.8514\n",
      "Epoch 6837/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0472 - accuracy: 0.9854 - val_loss: 0.7129 - val_accuracy: 0.8563\n",
      "Epoch 6838/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0521 - accuracy: 0.9836 - val_loss: 0.7317 - val_accuracy: 0.8515\n",
      "Epoch 6839/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0510 - accuracy: 0.9845 - val_loss: 0.8130 - val_accuracy: 0.8442\n",
      "Epoch 6840/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0465 - accuracy: 0.9849 - val_loss: 0.7772 - val_accuracy: 0.8483\n",
      "Epoch 6841/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0520 - accuracy: 0.9839 - val_loss: 0.7919 - val_accuracy: 0.8508\n",
      "Epoch 6842/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0474 - accuracy: 0.9857 - val_loss: 0.9034 - val_accuracy: 0.8409\n",
      "Epoch 6843/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0449 - accuracy: 0.9859 - val_loss: 0.7070 - val_accuracy: 0.8593\n",
      "Epoch 6844/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0424 - accuracy: 0.9866 - val_loss: 0.7564 - val_accuracy: 0.8506\n",
      "Epoch 6845/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0475 - accuracy: 0.9850 - val_loss: 0.6922 - val_accuracy: 0.8594\n",
      "Epoch 6846/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0489 - accuracy: 0.9848 - val_loss: 0.7801 - val_accuracy: 0.8478\n",
      "Epoch 6847/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0463 - accuracy: 0.9856 - val_loss: 0.7867 - val_accuracy: 0.8438\n",
      "Epoch 6848/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0466 - accuracy: 0.9854 - val_loss: 0.7483 - val_accuracy: 0.8525\n",
      "Epoch 6849/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0455 - accuracy: 0.9859 - val_loss: 0.7268 - val_accuracy: 0.8588\n",
      "Epoch 6850/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0475 - accuracy: 0.9848 - val_loss: 0.7830 - val_accuracy: 0.8494\n",
      "Epoch 6851/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0484 - accuracy: 0.9845 - val_loss: 0.7161 - val_accuracy: 0.8570\n",
      "Epoch 6852/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0509 - accuracy: 0.9843 - val_loss: 0.6850 - val_accuracy: 0.8603\n",
      "Epoch 6853/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0481 - accuracy: 0.9847 - val_loss: 0.7818 - val_accuracy: 0.8470\n",
      "Epoch 6854/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0519 - accuracy: 0.9836 - val_loss: 0.7520 - val_accuracy: 0.8512\n",
      "Epoch 6855/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0419 - accuracy: 0.9868 - val_loss: 0.7414 - val_accuracy: 0.8517\n",
      "Epoch 6856/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0487 - accuracy: 0.9847 - val_loss: 0.7916 - val_accuracy: 0.8477\n",
      "Epoch 6857/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0481 - accuracy: 0.9851 - val_loss: 0.6922 - val_accuracy: 0.8597\n",
      "Epoch 6858/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0514 - accuracy: 0.9839 - val_loss: 0.6936 - val_accuracy: 0.8564\n",
      "Epoch 6859/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0483 - accuracy: 0.9846 - val_loss: 0.7001 - val_accuracy: 0.8581\n",
      "Epoch 6860/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0444 - accuracy: 0.9861 - val_loss: 0.7495 - val_accuracy: 0.8531\n",
      "Epoch 6861/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0427 - accuracy: 0.9868 - val_loss: 0.7357 - val_accuracy: 0.8533\n",
      "Epoch 6862/8000\n",
      "1463/1463 [==============================] - 22s 15ms/step - loss: 0.0501 - accuracy: 0.9844 - val_loss: 0.7229 - val_accuracy: 0.8547\n",
      "Epoch 6863/8000\n",
      "1463/1463 [==============================] - 21s 15ms/step - loss: 0.0424 - accuracy: 0.9865 - val_loss: 0.7349 - val_accuracy: 0.8506\n",
      "Epoch 6864/8000\n",
      "1463/1463 [==============================] - 21s 15ms/step - loss: 0.0478 - accuracy: 0.9855 - val_loss: 0.8157 - val_accuracy: 0.8397\n",
      "Epoch 6865/8000\n",
      "1463/1463 [==============================] - 19s 13ms/step - loss: 0.0483 - accuracy: 0.9848 - val_loss: 0.7860 - val_accuracy: 0.8486\n",
      "Epoch 6866/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0471 - accuracy: 0.9855 - val_loss: 0.7206 - val_accuracy: 0.8562\n",
      "Epoch 6867/8000\n",
      "1463/1463 [==============================] - 18s 12ms/step - loss: 0.0473 - accuracy: 0.9851 - val_loss: 0.7621 - val_accuracy: 0.8456\n",
      "Epoch 6868/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0467 - accuracy: 0.9852 - val_loss: 0.7043 - val_accuracy: 0.8580\n",
      "Epoch 6869/8000\n",
      "1463/1463 [==============================] - 21s 14ms/step - loss: 0.0513 - accuracy: 0.9841 - val_loss: 0.7479 - val_accuracy: 0.8527\n",
      "Epoch 6870/8000\n",
      "1463/1463 [==============================] - 21s 14ms/step - loss: 0.0418 - accuracy: 0.9869 - val_loss: 0.7257 - val_accuracy: 0.8550\n",
      "Epoch 6871/8000\n",
      "1463/1463 [==============================] - 23s 16ms/step - loss: 0.0431 - accuracy: 0.9868 - val_loss: 0.7543 - val_accuracy: 0.8494\n",
      "Epoch 6872/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0430 - accuracy: 0.9860 - val_loss: 0.7273 - val_accuracy: 0.8536\n",
      "Epoch 6873/8000\n",
      "1463/1463 [==============================] - 17s 11ms/step - loss: 0.0470 - accuracy: 0.9854 - val_loss: 0.7247 - val_accuracy: 0.8561\n",
      "Epoch 6874/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0472 - accuracy: 0.9855 - val_loss: 0.8106 - val_accuracy: 0.8449\n",
      "Epoch 6875/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0510 - accuracy: 0.9843 - val_loss: 0.7200 - val_accuracy: 0.8586\n",
      "Epoch 6876/8000\n",
      "1463/1463 [==============================] - 19s 13ms/step - loss: 0.0439 - accuracy: 0.9870 - val_loss: 0.7184 - val_accuracy: 0.8549\n",
      "Epoch 6877/8000\n",
      "1463/1463 [==============================] - 19s 13ms/step - loss: 0.0432 - accuracy: 0.9864 - val_loss: 0.7563 - val_accuracy: 0.8522\n",
      "Epoch 6878/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0594 - accuracy: 0.9833 - val_loss: 0.7155 - val_accuracy: 0.8535\n",
      "Epoch 6879/8000\n",
      "1463/1463 [==============================] - 18s 12ms/step - loss: 0.0428 - accuracy: 0.9870 - val_loss: 0.7480 - val_accuracy: 0.8513\n",
      "Epoch 6880/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0472 - accuracy: 0.9852 - val_loss: 0.7642 - val_accuracy: 0.8463\n",
      "Epoch 6881/8000\n",
      "1463/1463 [==============================] - 21s 14ms/step - loss: 0.0435 - accuracy: 0.9861 - val_loss: 0.7697 - val_accuracy: 0.8491\n",
      "Epoch 6882/8000\n",
      "1463/1463 [==============================] - 21s 15ms/step - loss: 0.0464 - accuracy: 0.9859 - val_loss: 0.7868 - val_accuracy: 0.8464\n",
      "Epoch 6883/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0394 - accuracy: 0.9877 - val_loss: 0.7569 - val_accuracy: 0.8543\n",
      "Epoch 6884/8000\n",
      "1463/1463 [==============================] - 18s 12ms/step - loss: 0.0478 - accuracy: 0.9856 - val_loss: 0.7139 - val_accuracy: 0.8568\n",
      "Epoch 6885/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0524 - accuracy: 0.9842 - val_loss: 0.7496 - val_accuracy: 0.8499\n",
      "Epoch 6886/8000\n",
      "1463/1463 [==============================] - 18s 12ms/step - loss: 0.0454 - accuracy: 0.9856 - val_loss: 0.6978 - val_accuracy: 0.8613\n",
      "Epoch 6887/8000\n",
      "1463/1463 [==============================] - 15s 11ms/step - loss: 0.0498 - accuracy: 0.9847 - val_loss: 0.7762 - val_accuracy: 0.8483\n",
      "Epoch 6888/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0453 - accuracy: 0.9854 - val_loss: 0.7334 - val_accuracy: 0.8524\n",
      "Epoch 6889/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0449 - accuracy: 0.9859 - val_loss: 0.7598 - val_accuracy: 0.8499\n",
      "Epoch 6890/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0435 - accuracy: 0.9866 - val_loss: 0.7416 - val_accuracy: 0.8523\n",
      "Epoch 6891/8000\n",
      "1463/1463 [==============================] - 15s 11ms/step - loss: 0.0452 - accuracy: 0.9864 - val_loss: 0.7145 - val_accuracy: 0.8545\n",
      "Epoch 6892/8000\n",
      "1463/1463 [==============================] - 15s 11ms/step - loss: 0.0465 - accuracy: 0.9851 - val_loss: 0.7276 - val_accuracy: 0.8514\n",
      "Epoch 6893/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0434 - accuracy: 0.9865 - val_loss: 0.7874 - val_accuracy: 0.8415\n",
      "Epoch 6894/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0445 - accuracy: 0.9867 - val_loss: 0.6838 - val_accuracy: 0.8600\n",
      "Epoch 6895/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0483 - accuracy: 0.9856 - val_loss: 0.7290 - val_accuracy: 0.8561\n",
      "Epoch 6896/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0479 - accuracy: 0.9852 - val_loss: 0.7328 - val_accuracy: 0.8514\n",
      "Epoch 6897/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0438 - accuracy: 0.9860 - val_loss: 0.7546 - val_accuracy: 0.8544\n",
      "Epoch 6898/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0463 - accuracy: 0.9850 - val_loss: 0.7156 - val_accuracy: 0.8586\n",
      "Epoch 6899/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0465 - accuracy: 0.9859 - val_loss: 0.7385 - val_accuracy: 0.8520\n",
      "Epoch 6900/8000\n",
      "1459/1463 [============================>.] - ETA: 0s - loss: 0.0416 - accuracy: 0.9865\n",
      "Epoch 6900: saving model to ./training_ckpt_20240109205949_v8_240109_d10000_n4096_b64_e8000_c100_Adamax\\cp-000006900.ckpt\n",
      "1463/1463 [==============================] - 18s 12ms/step - loss: 0.0417 - accuracy: 0.9864 - val_loss: 0.7725 - val_accuracy: 0.8488\n",
      "Epoch 6901/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0391 - accuracy: 0.9876 - val_loss: 0.7583 - val_accuracy: 0.8504\n",
      "Epoch 6902/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0470 - accuracy: 0.9855 - val_loss: 0.7196 - val_accuracy: 0.8579\n",
      "Epoch 6903/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0454 - accuracy: 0.9858 - val_loss: 0.7271 - val_accuracy: 0.8566\n",
      "Epoch 6904/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0481 - accuracy: 0.9848 - val_loss: 0.7196 - val_accuracy: 0.8589\n",
      "Epoch 6905/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0469 - accuracy: 0.9851 - val_loss: 0.7268 - val_accuracy: 0.8545\n",
      "Epoch 6906/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0412 - accuracy: 0.9873 - val_loss: 0.7372 - val_accuracy: 0.8542\n",
      "Epoch 6907/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0654 - accuracy: 0.9815 - val_loss: 0.7852 - val_accuracy: 0.8510\n",
      "Epoch 6908/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.7148 - val_accuracy: 0.8572\n",
      "Epoch 6909/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0499 - accuracy: 0.9852 - val_loss: 0.8000 - val_accuracy: 0.8434\n",
      "Epoch 6910/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0427 - accuracy: 0.9868 - val_loss: 0.7244 - val_accuracy: 0.8582\n",
      "Epoch 6911/8000\n",
      "1463/1463 [==============================] - 17s 12ms/step - loss: 0.0479 - accuracy: 0.9852 - val_loss: 0.7333 - val_accuracy: 0.8543\n",
      "Epoch 6912/8000\n",
      "1463/1463 [==============================] - 20s 14ms/step - loss: 0.0515 - accuracy: 0.9840 - val_loss: 0.7744 - val_accuracy: 0.8512\n",
      "Epoch 6913/8000\n",
      "1463/1463 [==============================] - 22s 15ms/step - loss: 0.0453 - accuracy: 0.9855 - val_loss: 0.7325 - val_accuracy: 0.8525\n",
      "Epoch 6914/8000\n",
      "1463/1463 [==============================] - 18s 12ms/step - loss: 0.0481 - accuracy: 0.9850 - val_loss: 0.7438 - val_accuracy: 0.8524\n",
      "Epoch 6915/8000\n",
      "1463/1463 [==============================] - 15s 11ms/step - loss: 0.0458 - accuracy: 0.9857 - val_loss: 0.8205 - val_accuracy: 0.8394\n",
      "Epoch 6916/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0480 - accuracy: 0.9858 - val_loss: 0.6982 - val_accuracy: 0.8590\n",
      "Epoch 6917/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0480 - accuracy: 0.9848 - val_loss: 0.7442 - val_accuracy: 0.8534\n",
      "Epoch 6918/8000\n",
      "1463/1463 [==============================] - 16s 11ms/step - loss: 0.0453 - accuracy: 0.9856 - val_loss: 0.7420 - val_accuracy: 0.8551\n",
      "Epoch 6919/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0480 - accuracy: 0.9851 - val_loss: 0.7355 - val_accuracy: 0.8529\n",
      "Epoch 6920/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0457 - accuracy: 0.9859 - val_loss: 0.7879 - val_accuracy: 0.8455\n",
      "Epoch 6921/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0438 - accuracy: 0.9866 - val_loss: 0.7107 - val_accuracy: 0.8572\n",
      "Epoch 6922/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0469 - accuracy: 0.9853 - val_loss: 0.7300 - val_accuracy: 0.8523\n",
      "Epoch 6923/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0439 - accuracy: 0.9865 - val_loss: 0.7547 - val_accuracy: 0.8504\n",
      "Epoch 6924/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0470 - accuracy: 0.9850 - val_loss: 0.8254 - val_accuracy: 0.8405\n",
      "Epoch 6925/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0516 - accuracy: 0.9842 - val_loss: 0.7729 - val_accuracy: 0.8499\n",
      "Epoch 6926/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0422 - accuracy: 0.9870 - val_loss: 0.7413 - val_accuracy: 0.8526\n",
      "Epoch 6927/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0475 - accuracy: 0.9852 - val_loss: 0.7781 - val_accuracy: 0.8494\n",
      "Epoch 6928/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0470 - accuracy: 0.9851 - val_loss: 0.7276 - val_accuracy: 0.8521\n",
      "Epoch 6929/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0528 - accuracy: 0.9837 - val_loss: 0.7090 - val_accuracy: 0.8558\n",
      "Epoch 6930/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0462 - accuracy: 0.9855 - val_loss: 0.8872 - val_accuracy: 0.8375\n",
      "Epoch 6931/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0452 - accuracy: 0.9859 - val_loss: 0.7075 - val_accuracy: 0.8564\n",
      "Epoch 6932/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0424 - accuracy: 0.9871 - val_loss: 0.8256 - val_accuracy: 0.8445\n",
      "Epoch 6933/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0433 - accuracy: 0.9868 - val_loss: 0.9293 - val_accuracy: 0.8322\n",
      "Epoch 6934/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0474 - accuracy: 0.9854 - val_loss: 0.7275 - val_accuracy: 0.8536\n",
      "Epoch 6935/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0467 - accuracy: 0.9853 - val_loss: 0.7314 - val_accuracy: 0.8562\n",
      "Epoch 6936/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0419 - accuracy: 0.9867 - val_loss: 0.8533 - val_accuracy: 0.8397\n",
      "Epoch 6937/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0541 - accuracy: 0.9834 - val_loss: 0.7611 - val_accuracy: 0.8486\n",
      "Epoch 6938/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0411 - accuracy: 0.9868 - val_loss: 0.6880 - val_accuracy: 0.8635\n",
      "Epoch 6939/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0487 - accuracy: 0.9849 - val_loss: 0.7158 - val_accuracy: 0.8610\n",
      "Epoch 6940/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0430 - accuracy: 0.9868 - val_loss: 0.7343 - val_accuracy: 0.8563\n",
      "Epoch 6941/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0437 - accuracy: 0.9862 - val_loss: 0.7377 - val_accuracy: 0.8531\n",
      "Epoch 6942/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0434 - accuracy: 0.9861 - val_loss: 0.6974 - val_accuracy: 0.8611\n",
      "Epoch 6943/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0390 - accuracy: 0.9885 - val_loss: 0.7716 - val_accuracy: 0.8502\n",
      "Epoch 6944/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0479 - accuracy: 0.9852 - val_loss: 0.7765 - val_accuracy: 0.8438\n",
      "Epoch 6945/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0444 - accuracy: 0.9859 - val_loss: 0.8051 - val_accuracy: 0.8460\n",
      "Epoch 6946/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0478 - accuracy: 0.9847 - val_loss: 0.7859 - val_accuracy: 0.8453\n",
      "Epoch 6947/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0455 - accuracy: 0.9855 - val_loss: 0.7225 - val_accuracy: 0.8562\n",
      "Epoch 6948/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0423 - accuracy: 0.9870 - val_loss: 0.7823 - val_accuracy: 0.8465\n",
      "Epoch 6949/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0508 - accuracy: 0.9843 - val_loss: 0.7139 - val_accuracy: 0.8585\n",
      "Epoch 6950/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0498 - accuracy: 0.9850 - val_loss: 0.7394 - val_accuracy: 0.8570\n",
      "Epoch 6951/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0394 - accuracy: 0.9877 - val_loss: 0.7504 - val_accuracy: 0.8520\n",
      "Epoch 6952/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0469 - accuracy: 0.9857 - val_loss: 0.7008 - val_accuracy: 0.8579\n",
      "Epoch 6953/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0434 - accuracy: 0.9870 - val_loss: 0.6723 - val_accuracy: 0.8655\n",
      "Epoch 6954/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0457 - accuracy: 0.9855 - val_loss: 0.8012 - val_accuracy: 0.8449\n",
      "Epoch 6955/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0477 - accuracy: 0.9849 - val_loss: 0.6928 - val_accuracy: 0.8600\n",
      "Epoch 6956/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0416 - accuracy: 0.9871 - val_loss: 0.7871 - val_accuracy: 0.8491\n",
      "Epoch 6957/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0507 - accuracy: 0.9836 - val_loss: 0.7257 - val_accuracy: 0.8550\n",
      "Epoch 6958/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0431 - accuracy: 0.9863 - val_loss: 0.6894 - val_accuracy: 0.8606\n",
      "Epoch 6959/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0452 - accuracy: 0.9860 - val_loss: 0.7130 - val_accuracy: 0.8597\n",
      "Epoch 6960/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0453 - accuracy: 0.9860 - val_loss: 0.6923 - val_accuracy: 0.8609\n",
      "Epoch 6961/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0458 - accuracy: 0.9857 - val_loss: 0.7471 - val_accuracy: 0.8546\n",
      "Epoch 6962/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0451 - accuracy: 0.9860 - val_loss: 0.6965 - val_accuracy: 0.8595\n",
      "Epoch 6963/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0494 - accuracy: 0.9850 - val_loss: 0.7058 - val_accuracy: 0.8596\n",
      "Epoch 6964/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0451 - accuracy: 0.9863 - val_loss: 0.6937 - val_accuracy: 0.8585\n",
      "Epoch 6965/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0434 - accuracy: 0.9867 - val_loss: 0.7881 - val_accuracy: 0.8502\n",
      "Epoch 6966/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0478 - accuracy: 0.9851 - val_loss: 0.8301 - val_accuracy: 0.8400\n",
      "Epoch 6967/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0449 - accuracy: 0.9865 - val_loss: 0.7549 - val_accuracy: 0.8483\n",
      "Epoch 6968/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0421 - accuracy: 0.9869 - val_loss: 0.6845 - val_accuracy: 0.8574\n",
      "Epoch 6969/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0492 - accuracy: 0.9850 - val_loss: 0.7179 - val_accuracy: 0.8575\n",
      "Epoch 6970/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0469 - accuracy: 0.9860 - val_loss: 0.6742 - val_accuracy: 0.8632\n",
      "Epoch 6971/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0483 - accuracy: 0.9849 - val_loss: 0.7142 - val_accuracy: 0.8563\n",
      "Epoch 6972/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0415 - accuracy: 0.9870 - val_loss: 0.7105 - val_accuracy: 0.8595\n",
      "Epoch 6973/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0485 - accuracy: 0.9855 - val_loss: 0.6913 - val_accuracy: 0.8609\n",
      "Epoch 6974/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0430 - accuracy: 0.9862 - val_loss: 0.7010 - val_accuracy: 0.8608\n",
      "Epoch 6975/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0484 - accuracy: 0.9848 - val_loss: 0.7322 - val_accuracy: 0.8582\n",
      "Epoch 6976/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0531 - accuracy: 0.9837 - val_loss: 0.7341 - val_accuracy: 0.8545\n",
      "Epoch 6977/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0451 - accuracy: 0.9858 - val_loss: 0.7456 - val_accuracy: 0.8498\n",
      "Epoch 6978/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0468 - accuracy: 0.9854 - val_loss: 0.8168 - val_accuracy: 0.8410\n",
      "Epoch 6979/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0476 - accuracy: 0.9852 - val_loss: 0.7302 - val_accuracy: 0.8562\n",
      "Epoch 6980/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0442 - accuracy: 0.9863 - val_loss: 0.7014 - val_accuracy: 0.8605\n",
      "Epoch 6981/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0425 - accuracy: 0.9869 - val_loss: 0.7099 - val_accuracy: 0.8576\n",
      "Epoch 6982/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0502 - accuracy: 0.9849 - val_loss: 0.7298 - val_accuracy: 0.8527\n",
      "Epoch 6983/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0402 - accuracy: 0.9879 - val_loss: 0.6964 - val_accuracy: 0.8603\n",
      "Epoch 6984/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0474 - accuracy: 0.9859 - val_loss: 0.7167 - val_accuracy: 0.8587\n",
      "Epoch 6985/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0438 - accuracy: 0.9860 - val_loss: 0.7099 - val_accuracy: 0.8591\n",
      "Epoch 6986/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0497 - accuracy: 0.9854 - val_loss: 0.7156 - val_accuracy: 0.8583\n",
      "Epoch 6987/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0501 - accuracy: 0.9849 - val_loss: 0.7045 - val_accuracy: 0.8577\n",
      "Epoch 6988/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0448 - accuracy: 0.9860 - val_loss: 0.7401 - val_accuracy: 0.8518\n",
      "Epoch 6989/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0443 - accuracy: 0.9859 - val_loss: 0.7367 - val_accuracy: 0.8552\n",
      "Epoch 6990/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0497 - accuracy: 0.9853 - val_loss: 0.6995 - val_accuracy: 0.8581\n",
      "Epoch 6991/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0462 - accuracy: 0.9854 - val_loss: 0.7074 - val_accuracy: 0.8578\n",
      "Epoch 6992/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0449 - accuracy: 0.9858 - val_loss: 0.7586 - val_accuracy: 0.8493\n",
      "Epoch 6993/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0520 - accuracy: 0.9846 - val_loss: 0.7389 - val_accuracy: 0.8523\n",
      "Epoch 6994/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0414 - accuracy: 0.9870 - val_loss: 0.7199 - val_accuracy: 0.8543\n",
      "Epoch 6995/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0462 - accuracy: 0.9859 - val_loss: 0.7040 - val_accuracy: 0.8583\n",
      "Epoch 6996/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0430 - accuracy: 0.9869 - val_loss: 0.7670 - val_accuracy: 0.8482\n",
      "Epoch 6997/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0482 - accuracy: 0.9852 - val_loss: 0.7589 - val_accuracy: 0.8536\n",
      "Epoch 6998/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0445 - accuracy: 0.9864 - val_loss: 0.6962 - val_accuracy: 0.8627\n",
      "Epoch 6999/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0470 - accuracy: 0.9856 - val_loss: 0.7786 - val_accuracy: 0.8503\n",
      "Epoch 7000/8000\n",
      "1460/1463 [============================>.] - ETA: 0s - loss: 0.0423 - accuracy: 0.9872\n",
      "Epoch 7000: saving model to ./training_ckpt_20240109205949_v8_240109_d10000_n4096_b64_e8000_c100_Adamax\\cp-000007000.ckpt\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0423 - accuracy: 0.9872 - val_loss: 0.7336 - val_accuracy: 0.8515\n",
      "Epoch 7001/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0474 - accuracy: 0.9855 - val_loss: 0.7435 - val_accuracy: 0.8556\n",
      "Epoch 7002/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0470 - accuracy: 0.9853 - val_loss: 0.7353 - val_accuracy: 0.8536\n",
      "Epoch 7003/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0505 - accuracy: 0.9850 - val_loss: 0.7396 - val_accuracy: 0.8489\n",
      "Epoch 7004/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0474 - accuracy: 0.9852 - val_loss: 0.7906 - val_accuracy: 0.8491\n",
      "Epoch 7005/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0531 - accuracy: 0.9842 - val_loss: 0.7488 - val_accuracy: 0.8514\n",
      "Epoch 7006/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0417 - accuracy: 0.9873 - val_loss: 0.7749 - val_accuracy: 0.8515\n",
      "Epoch 7007/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0574 - accuracy: 0.9825 - val_loss: 0.7412 - val_accuracy: 0.8542\n",
      "Epoch 7008/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0456 - accuracy: 0.9861 - val_loss: 0.7813 - val_accuracy: 0.8470\n",
      "Epoch 7009/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0469 - accuracy: 0.9851 - val_loss: 0.7181 - val_accuracy: 0.8536\n",
      "Epoch 7010/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0445 - accuracy: 0.9863 - val_loss: 0.7005 - val_accuracy: 0.8583\n",
      "Epoch 7011/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0494 - accuracy: 0.9852 - val_loss: 0.7261 - val_accuracy: 0.8562\n",
      "Epoch 7012/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0411 - accuracy: 0.9871 - val_loss: 0.7717 - val_accuracy: 0.8483\n",
      "Epoch 7013/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0515 - accuracy: 0.9845 - val_loss: 0.7460 - val_accuracy: 0.8483\n",
      "Epoch 7014/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0525 - accuracy: 0.9840 - val_loss: 0.7171 - val_accuracy: 0.8572\n",
      "Epoch 7015/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0415 - accuracy: 0.9872 - val_loss: 0.7242 - val_accuracy: 0.8573\n",
      "Epoch 7016/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0467 - accuracy: 0.9854 - val_loss: 0.6976 - val_accuracy: 0.8574\n",
      "Epoch 7017/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0447 - accuracy: 0.9860 - val_loss: 0.7069 - val_accuracy: 0.8588\n",
      "Epoch 7018/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0429 - accuracy: 0.9871 - val_loss: 0.6877 - val_accuracy: 0.8620\n",
      "Epoch 7019/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0469 - accuracy: 0.9858 - val_loss: 0.8200 - val_accuracy: 0.8441\n",
      "Epoch 7020/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0419 - accuracy: 0.9867 - val_loss: 0.7258 - val_accuracy: 0.8523\n",
      "Epoch 7021/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0495 - accuracy: 0.9846 - val_loss: 0.8339 - val_accuracy: 0.8378\n",
      "Epoch 7022/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0460 - accuracy: 0.9855 - val_loss: 0.7408 - val_accuracy: 0.8524\n",
      "Epoch 7023/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0499 - accuracy: 0.9848 - val_loss: 0.7146 - val_accuracy: 0.8592\n",
      "Epoch 7024/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0430 - accuracy: 0.9867 - val_loss: 0.7033 - val_accuracy: 0.8608\n",
      "Epoch 7025/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0472 - accuracy: 0.9857 - val_loss: 0.7301 - val_accuracy: 0.8572\n",
      "Epoch 7026/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0428 - accuracy: 0.9863 - val_loss: 0.7242 - val_accuracy: 0.8565\n",
      "Epoch 7027/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0405 - accuracy: 0.9871 - val_loss: 0.7053 - val_accuracy: 0.8590\n",
      "Epoch 7028/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0514 - accuracy: 0.9837 - val_loss: 0.7146 - val_accuracy: 0.8568\n",
      "Epoch 7029/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0402 - accuracy: 0.9877 - val_loss: 0.6900 - val_accuracy: 0.8634\n",
      "Epoch 7030/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0471 - accuracy: 0.9855 - val_loss: 0.7754 - val_accuracy: 0.8484\n",
      "Epoch 7031/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0449 - accuracy: 0.9864 - val_loss: 0.7051 - val_accuracy: 0.8614\n",
      "Epoch 7032/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0429 - accuracy: 0.9866 - val_loss: 0.7206 - val_accuracy: 0.8578\n",
      "Epoch 7033/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0412 - accuracy: 0.9873 - val_loss: 0.6877 - val_accuracy: 0.8621\n",
      "Epoch 7034/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0404 - accuracy: 0.9872 - val_loss: 0.6883 - val_accuracy: 0.8611\n",
      "Epoch 7035/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0485 - accuracy: 0.9852 - val_loss: 0.8159 - val_accuracy: 0.8462\n",
      "Epoch 7036/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0456 - accuracy: 0.9857 - val_loss: 0.8329 - val_accuracy: 0.8430\n",
      "Epoch 7037/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0461 - accuracy: 0.9852 - val_loss: 0.8197 - val_accuracy: 0.8413\n",
      "Epoch 7038/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0433 - accuracy: 0.9865 - val_loss: 0.7316 - val_accuracy: 0.8559\n",
      "Epoch 7039/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0469 - accuracy: 0.9856 - val_loss: 0.7189 - val_accuracy: 0.8574\n",
      "Epoch 7040/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0500 - accuracy: 0.9849 - val_loss: 0.7212 - val_accuracy: 0.8543\n",
      "Epoch 7041/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0440 - accuracy: 0.9864 - val_loss: 0.7185 - val_accuracy: 0.8586\n",
      "Epoch 7042/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0463 - accuracy: 0.9855 - val_loss: 0.7312 - val_accuracy: 0.8523\n",
      "Epoch 7043/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0496 - accuracy: 0.9843 - val_loss: 0.7238 - val_accuracy: 0.8570\n",
      "Epoch 7044/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0374 - accuracy: 0.9883 - val_loss: 0.7680 - val_accuracy: 0.8505\n",
      "Epoch 7045/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0448 - accuracy: 0.9857 - val_loss: 0.7474 - val_accuracy: 0.8481\n",
      "Epoch 7046/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0434 - accuracy: 0.9866 - val_loss: 0.7495 - val_accuracy: 0.8529\n",
      "Epoch 7047/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0448 - accuracy: 0.9862 - val_loss: 0.7529 - val_accuracy: 0.8541\n",
      "Epoch 7048/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0468 - accuracy: 0.9854 - val_loss: 0.7403 - val_accuracy: 0.8556\n",
      "Epoch 7049/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0390 - accuracy: 0.9881 - val_loss: 0.7214 - val_accuracy: 0.8551\n",
      "Epoch 7050/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0483 - accuracy: 0.9853 - val_loss: 0.7746 - val_accuracy: 0.8484\n",
      "Epoch 7051/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0413 - accuracy: 0.9876 - val_loss: 0.6911 - val_accuracy: 0.8627\n",
      "Epoch 7052/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0495 - accuracy: 0.9845 - val_loss: 0.7146 - val_accuracy: 0.8578\n",
      "Epoch 7053/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0439 - accuracy: 0.9864 - val_loss: 0.7179 - val_accuracy: 0.8563\n",
      "Epoch 7054/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0428 - accuracy: 0.9870 - val_loss: 0.7423 - val_accuracy: 0.8529\n",
      "Epoch 7055/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0508 - accuracy: 0.9845 - val_loss: 0.7180 - val_accuracy: 0.8578\n",
      "Epoch 7056/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0435 - accuracy: 0.9866 - val_loss: 0.7600 - val_accuracy: 0.8508\n",
      "Epoch 7057/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0440 - accuracy: 0.9861 - val_loss: 0.7207 - val_accuracy: 0.8558\n",
      "Epoch 7058/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0484 - accuracy: 0.9855 - val_loss: 0.8086 - val_accuracy: 0.8480\n",
      "Epoch 7059/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0454 - accuracy: 0.9861 - val_loss: 0.6826 - val_accuracy: 0.8603\n",
      "Epoch 7060/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0489 - accuracy: 0.9851 - val_loss: 0.7701 - val_accuracy: 0.8500\n",
      "Epoch 7061/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0427 - accuracy: 0.9863 - val_loss: 0.8604 - val_accuracy: 0.8383\n",
      "Epoch 7062/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0410 - accuracy: 0.9874 - val_loss: 0.8068 - val_accuracy: 0.8445\n",
      "Epoch 7063/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0465 - accuracy: 0.9849 - val_loss: 0.7724 - val_accuracy: 0.8491\n",
      "Epoch 7064/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0449 - accuracy: 0.9858 - val_loss: 0.7187 - val_accuracy: 0.8549\n",
      "Epoch 7065/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0452 - accuracy: 0.9861 - val_loss: 0.6955 - val_accuracy: 0.8633\n",
      "Epoch 7066/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0415 - accuracy: 0.9868 - val_loss: 0.7512 - val_accuracy: 0.8534\n",
      "Epoch 7067/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0444 - accuracy: 0.9858 - val_loss: 0.8100 - val_accuracy: 0.8438\n",
      "Epoch 7068/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0436 - accuracy: 0.9865 - val_loss: 0.7988 - val_accuracy: 0.8432\n",
      "Epoch 7069/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0489 - accuracy: 0.9848 - val_loss: 0.8716 - val_accuracy: 0.8319\n",
      "Epoch 7070/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0450 - accuracy: 0.9859 - val_loss: 0.7315 - val_accuracy: 0.8550\n",
      "Epoch 7071/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0509 - accuracy: 0.9851 - val_loss: 0.7149 - val_accuracy: 0.8579\n",
      "Epoch 7072/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0426 - accuracy: 0.9863 - val_loss: 0.6947 - val_accuracy: 0.8623\n",
      "Epoch 7073/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0449 - accuracy: 0.9860 - val_loss: 0.7332 - val_accuracy: 0.8545\n",
      "Epoch 7074/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0460 - accuracy: 0.9859 - val_loss: 0.7206 - val_accuracy: 0.8553\n",
      "Epoch 7075/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0458 - accuracy: 0.9855 - val_loss: 0.6946 - val_accuracy: 0.8606\n",
      "Epoch 7076/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0523 - accuracy: 0.9844 - val_loss: 0.7472 - val_accuracy: 0.8541\n",
      "Epoch 7077/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0481 - accuracy: 0.9855 - val_loss: 0.7450 - val_accuracy: 0.8537\n",
      "Epoch 7078/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0449 - accuracy: 0.9860 - val_loss: 0.6957 - val_accuracy: 0.8632\n",
      "Epoch 7079/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0466 - accuracy: 0.9859 - val_loss: 0.7937 - val_accuracy: 0.8474\n",
      "Epoch 7080/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0421 - accuracy: 0.9867 - val_loss: 0.7771 - val_accuracy: 0.8523\n",
      "Epoch 7081/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0488 - accuracy: 0.9853 - val_loss: 1.1367 - val_accuracy: 0.8316\n",
      "Epoch 7082/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0546 - accuracy: 0.9846 - val_loss: 0.7245 - val_accuracy: 0.8542\n",
      "Epoch 7083/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0465 - accuracy: 0.9849 - val_loss: 0.7095 - val_accuracy: 0.8567\n",
      "Epoch 7084/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0479 - accuracy: 0.9855 - val_loss: 0.7434 - val_accuracy: 0.8550\n",
      "Epoch 7085/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0477 - accuracy: 0.9853 - val_loss: 0.7666 - val_accuracy: 0.8479\n",
      "Epoch 7086/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0448 - accuracy: 0.9862 - val_loss: 0.7494 - val_accuracy: 0.8558\n",
      "Epoch 7087/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0426 - accuracy: 0.9867 - val_loss: 0.7301 - val_accuracy: 0.8568\n",
      "Epoch 7088/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0460 - accuracy: 0.9859 - val_loss: 0.7633 - val_accuracy: 0.8509\n",
      "Epoch 7089/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0486 - accuracy: 0.9844 - val_loss: 0.7717 - val_accuracy: 0.8549\n",
      "Epoch 7090/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0430 - accuracy: 0.9869 - val_loss: 0.8527 - val_accuracy: 0.8418\n",
      "Epoch 7091/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0462 - accuracy: 0.9854 - val_loss: 0.7478 - val_accuracy: 0.8517\n",
      "Epoch 7092/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0472 - accuracy: 0.9856 - val_loss: 0.7887 - val_accuracy: 0.8480\n",
      "Epoch 7093/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0468 - accuracy: 0.9853 - val_loss: 0.7611 - val_accuracy: 0.8502\n",
      "Epoch 7094/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0454 - accuracy: 0.9856 - val_loss: 0.7285 - val_accuracy: 0.8554\n",
      "Epoch 7095/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0504 - accuracy: 0.9840 - val_loss: 0.8322 - val_accuracy: 0.8404\n",
      "Epoch 7096/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0427 - accuracy: 0.9871 - val_loss: 0.7386 - val_accuracy: 0.8558\n",
      "Epoch 7097/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0469 - accuracy: 0.9852 - val_loss: 0.7288 - val_accuracy: 0.8540\n",
      "Epoch 7098/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0465 - accuracy: 0.9851 - val_loss: 0.7776 - val_accuracy: 0.8482\n",
      "Epoch 7099/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0454 - accuracy: 0.9861 - val_loss: 0.7528 - val_accuracy: 0.8526\n",
      "Epoch 7100/8000\n",
      "1461/1463 [============================>.] - ETA: 0s - loss: 0.0501 - accuracy: 0.9847\n",
      "Epoch 7100: saving model to ./training_ckpt_20240109205949_v8_240109_d10000_n4096_b64_e8000_c100_Adamax\\cp-000007100.ckpt\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0501 - accuracy: 0.9847 - val_loss: 0.7660 - val_accuracy: 0.8497\n",
      "Epoch 7101/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0495 - accuracy: 0.9842 - val_loss: 0.7674 - val_accuracy: 0.8485\n",
      "Epoch 7102/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0483 - accuracy: 0.9848 - val_loss: 0.7249 - val_accuracy: 0.8541\n",
      "Epoch 7103/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0419 - accuracy: 0.9868 - val_loss: 0.7544 - val_accuracy: 0.8537\n",
      "Epoch 7104/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0463 - accuracy: 0.9857 - val_loss: 0.7558 - val_accuracy: 0.8523\n",
      "Epoch 7105/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0427 - accuracy: 0.9868 - val_loss: 0.7324 - val_accuracy: 0.8545\n",
      "Epoch 7106/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0493 - accuracy: 0.9845 - val_loss: 0.8029 - val_accuracy: 0.8449\n",
      "Epoch 7107/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0440 - accuracy: 0.9860 - val_loss: 0.7117 - val_accuracy: 0.8589\n",
      "Epoch 7108/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0455 - accuracy: 0.9857 - val_loss: 0.7099 - val_accuracy: 0.8587\n",
      "Epoch 7109/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0461 - accuracy: 0.9853 - val_loss: 0.7131 - val_accuracy: 0.8559\n",
      "Epoch 7110/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0460 - accuracy: 0.9859 - val_loss: 0.7189 - val_accuracy: 0.8568\n",
      "Epoch 7111/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0459 - accuracy: 0.9851 - val_loss: 0.6972 - val_accuracy: 0.8641\n",
      "Epoch 7112/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0455 - accuracy: 0.9856 - val_loss: 0.7340 - val_accuracy: 0.8530\n",
      "Epoch 7113/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0472 - accuracy: 0.9855 - val_loss: 0.7173 - val_accuracy: 0.8570\n",
      "Epoch 7114/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0390 - accuracy: 0.9876 - val_loss: 0.7706 - val_accuracy: 0.8496\n",
      "Epoch 7115/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0454 - accuracy: 0.9860 - val_loss: 0.7072 - val_accuracy: 0.8548\n",
      "Epoch 7116/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0498 - accuracy: 0.9846 - val_loss: 0.6882 - val_accuracy: 0.8612\n",
      "Epoch 7117/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0471 - accuracy: 0.9851 - val_loss: 0.7779 - val_accuracy: 0.8454\n",
      "Epoch 7118/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0443 - accuracy: 0.9862 - val_loss: 0.7375 - val_accuracy: 0.8572\n",
      "Epoch 7119/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0445 - accuracy: 0.9856 - val_loss: 0.7636 - val_accuracy: 0.8491\n",
      "Epoch 7120/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0481 - accuracy: 0.9852 - val_loss: 0.7258 - val_accuracy: 0.8556\n",
      "Epoch 7121/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0454 - accuracy: 0.9862 - val_loss: 0.7971 - val_accuracy: 0.8435\n",
      "Epoch 7122/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0476 - accuracy: 0.9855 - val_loss: 0.7252 - val_accuracy: 0.8565\n",
      "Epoch 7123/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0512 - accuracy: 0.9836 - val_loss: 0.7702 - val_accuracy: 0.8504\n",
      "Epoch 7124/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0438 - accuracy: 0.9859 - val_loss: 0.7888 - val_accuracy: 0.8480\n",
      "Epoch 7125/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0479 - accuracy: 0.9853 - val_loss: 0.7590 - val_accuracy: 0.8517\n",
      "Epoch 7126/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0437 - accuracy: 0.9862 - val_loss: 0.7147 - val_accuracy: 0.8548\n",
      "Epoch 7127/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0430 - accuracy: 0.9865 - val_loss: 0.6827 - val_accuracy: 0.8638\n",
      "Epoch 7128/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0434 - accuracy: 0.9863 - val_loss: 0.7133 - val_accuracy: 0.8604\n",
      "Epoch 7129/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0453 - accuracy: 0.9859 - val_loss: 0.7025 - val_accuracy: 0.8594\n",
      "Epoch 7130/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0444 - accuracy: 0.9863 - val_loss: 0.7921 - val_accuracy: 0.8470\n",
      "Epoch 7131/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0462 - accuracy: 0.9853 - val_loss: 0.7769 - val_accuracy: 0.8482\n",
      "Epoch 7132/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0451 - accuracy: 0.9862 - val_loss: 0.7461 - val_accuracy: 0.8537\n",
      "Epoch 7133/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0472 - accuracy: 0.9847 - val_loss: 0.7288 - val_accuracy: 0.8528\n",
      "Epoch 7134/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0387 - accuracy: 0.9882 - val_loss: 0.7069 - val_accuracy: 0.8592\n",
      "Epoch 7135/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0403 - accuracy: 0.9873 - val_loss: 0.7033 - val_accuracy: 0.8622\n",
      "Epoch 7136/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0470 - accuracy: 0.9858 - val_loss: 0.7467 - val_accuracy: 0.8539\n",
      "Epoch 7137/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0470 - accuracy: 0.9852 - val_loss: 0.7483 - val_accuracy: 0.8514\n",
      "Epoch 7138/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0479 - accuracy: 0.9849 - val_loss: 0.7318 - val_accuracy: 0.8558\n",
      "Epoch 7139/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0467 - accuracy: 0.9853 - val_loss: 0.7301 - val_accuracy: 0.8568\n",
      "Epoch 7140/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0507 - accuracy: 0.9842 - val_loss: 0.7981 - val_accuracy: 0.8492\n",
      "Epoch 7141/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0504 - accuracy: 0.9846 - val_loss: 0.7319 - val_accuracy: 0.8565\n",
      "Epoch 7142/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0494 - accuracy: 0.9850 - val_loss: 0.7457 - val_accuracy: 0.8557\n",
      "Epoch 7143/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0461 - accuracy: 0.9854 - val_loss: 0.7539 - val_accuracy: 0.8530\n",
      "Epoch 7144/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0447 - accuracy: 0.9862 - val_loss: 0.7412 - val_accuracy: 0.8584\n",
      "Epoch 7145/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0448 - accuracy: 0.9857 - val_loss: 0.7469 - val_accuracy: 0.8547\n",
      "Epoch 7146/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0453 - accuracy: 0.9859 - val_loss: 0.7625 - val_accuracy: 0.8496\n",
      "Epoch 7147/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0479 - accuracy: 0.9853 - val_loss: 0.6830 - val_accuracy: 0.8660\n",
      "Epoch 7148/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0442 - accuracy: 0.9864 - val_loss: 0.7243 - val_accuracy: 0.8554\n",
      "Epoch 7149/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0414 - accuracy: 0.9869 - val_loss: 0.7868 - val_accuracy: 0.8469\n",
      "Epoch 7150/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0422 - accuracy: 0.9866 - val_loss: 0.7173 - val_accuracy: 0.8545\n",
      "Epoch 7151/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0461 - accuracy: 0.9856 - val_loss: 0.8014 - val_accuracy: 0.8487\n",
      "Epoch 7152/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0427 - accuracy: 0.9867 - val_loss: 0.7323 - val_accuracy: 0.8569\n",
      "Epoch 7153/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0471 - accuracy: 0.9864 - val_loss: 0.7301 - val_accuracy: 0.8521\n",
      "Epoch 7154/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0437 - accuracy: 0.9864 - val_loss: 0.7647 - val_accuracy: 0.8537\n",
      "Epoch 7155/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0481 - accuracy: 0.9848 - val_loss: 0.8106 - val_accuracy: 0.8451\n",
      "Epoch 7156/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0451 - accuracy: 0.9858 - val_loss: 0.8017 - val_accuracy: 0.8509\n",
      "Epoch 7157/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0391 - accuracy: 0.9881 - val_loss: 0.7780 - val_accuracy: 0.8473\n",
      "Epoch 7158/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0458 - accuracy: 0.9858 - val_loss: 0.7878 - val_accuracy: 0.8458\n",
      "Epoch 7159/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0457 - accuracy: 0.9860 - val_loss: 0.7454 - val_accuracy: 0.8538\n",
      "Epoch 7160/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0493 - accuracy: 0.9851 - val_loss: 0.7321 - val_accuracy: 0.8537\n",
      "Epoch 7161/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0467 - accuracy: 0.9855 - val_loss: 0.7626 - val_accuracy: 0.8493\n",
      "Epoch 7162/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0476 - accuracy: 0.9846 - val_loss: 0.9985 - val_accuracy: 0.8319\n",
      "Epoch 7163/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0467 - accuracy: 0.9853 - val_loss: 0.7389 - val_accuracy: 0.8520\n",
      "Epoch 7164/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0436 - accuracy: 0.9864 - val_loss: 0.7070 - val_accuracy: 0.8576\n",
      "Epoch 7165/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0446 - accuracy: 0.9863 - val_loss: 0.7075 - val_accuracy: 0.8575\n",
      "Epoch 7166/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0455 - accuracy: 0.9860 - val_loss: 0.7339 - val_accuracy: 0.8582\n",
      "Epoch 7167/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0384 - accuracy: 0.9881 - val_loss: 0.7026 - val_accuracy: 0.8594\n",
      "Epoch 7168/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0438 - accuracy: 0.9863 - val_loss: 0.7105 - val_accuracy: 0.8583\n",
      "Epoch 7169/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0427 - accuracy: 0.9866 - val_loss: 0.8200 - val_accuracy: 0.8458\n",
      "Epoch 7170/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0496 - accuracy: 0.9852 - val_loss: 0.7026 - val_accuracy: 0.8603\n",
      "Epoch 7171/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0445 - accuracy: 0.9860 - val_loss: 0.6986 - val_accuracy: 0.8618\n",
      "Epoch 7172/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0405 - accuracy: 0.9872 - val_loss: 0.7041 - val_accuracy: 0.8596\n",
      "Epoch 7173/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0461 - accuracy: 0.9852 - val_loss: 0.7754 - val_accuracy: 0.8475\n",
      "Epoch 7174/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0417 - accuracy: 0.9875 - val_loss: 0.7591 - val_accuracy: 0.8525\n",
      "Epoch 7175/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0498 - accuracy: 0.9844 - val_loss: 0.7704 - val_accuracy: 0.8508\n",
      "Epoch 7176/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0466 - accuracy: 0.9857 - val_loss: 0.7650 - val_accuracy: 0.8516\n",
      "Epoch 7177/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0404 - accuracy: 0.9872 - val_loss: 0.7418 - val_accuracy: 0.8553\n",
      "Epoch 7178/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0445 - accuracy: 0.9864 - val_loss: 0.8012 - val_accuracy: 0.8453\n",
      "Epoch 7179/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0480 - accuracy: 0.9850 - val_loss: 0.7380 - val_accuracy: 0.8559\n",
      "Epoch 7180/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0459 - accuracy: 0.9861 - val_loss: 0.7499 - val_accuracy: 0.8550\n",
      "Epoch 7181/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0446 - accuracy: 0.9857 - val_loss: 0.7473 - val_accuracy: 0.8556\n",
      "Epoch 7182/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0446 - accuracy: 0.9861 - val_loss: 0.7428 - val_accuracy: 0.8532\n",
      "Epoch 7183/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0487 - accuracy: 0.9847 - val_loss: 0.8054 - val_accuracy: 0.8447\n",
      "Epoch 7184/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0482 - accuracy: 0.9856 - val_loss: 0.7306 - val_accuracy: 0.8563\n",
      "Epoch 7185/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0435 - accuracy: 0.9864 - val_loss: 0.7235 - val_accuracy: 0.8568\n",
      "Epoch 7186/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0481 - accuracy: 0.9852 - val_loss: 0.7440 - val_accuracy: 0.8546\n",
      "Epoch 7187/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0448 - accuracy: 0.9862 - val_loss: 0.7826 - val_accuracy: 0.8527\n",
      "Epoch 7188/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0489 - accuracy: 0.9854 - val_loss: 0.7283 - val_accuracy: 0.8550\n",
      "Epoch 7189/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0447 - accuracy: 0.9863 - val_loss: 0.7825 - val_accuracy: 0.8502\n",
      "Epoch 7190/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0442 - accuracy: 0.9861 - val_loss: 0.7341 - val_accuracy: 0.8559\n",
      "Epoch 7191/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0421 - accuracy: 0.9863 - val_loss: 0.7298 - val_accuracy: 0.8529\n",
      "Epoch 7192/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0462 - accuracy: 0.9857 - val_loss: 0.6943 - val_accuracy: 0.8623\n",
      "Epoch 7193/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0391 - accuracy: 0.9875 - val_loss: 0.7793 - val_accuracy: 0.8472\n",
      "Epoch 7194/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0413 - accuracy: 0.9867 - val_loss: 0.7144 - val_accuracy: 0.8578\n",
      "Epoch 7195/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0421 - accuracy: 0.9868 - val_loss: 0.7693 - val_accuracy: 0.8483\n",
      "Epoch 7196/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0512 - accuracy: 0.9839 - val_loss: 0.7738 - val_accuracy: 0.8463\n",
      "Epoch 7197/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0376 - accuracy: 0.9884 - val_loss: 0.7569 - val_accuracy: 0.8534\n",
      "Epoch 7198/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0468 - accuracy: 0.9854 - val_loss: 0.7157 - val_accuracy: 0.8564\n",
      "Epoch 7199/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0573 - accuracy: 0.9843 - val_loss: 0.7620 - val_accuracy: 0.8542\n",
      "Epoch 7200/8000\n",
      "1458/1463 [============================>.] - ETA: 0s - loss: 0.0488 - accuracy: 0.9846\n",
      "Epoch 7200: saving model to ./training_ckpt_20240109205949_v8_240109_d10000_n4096_b64_e8000_c100_Adamax\\cp-000007200.ckpt\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0488 - accuracy: 0.9847 - val_loss: 0.7376 - val_accuracy: 0.8571\n",
      "Epoch 7201/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0441 - accuracy: 0.9866 - val_loss: 0.7007 - val_accuracy: 0.8589\n",
      "Epoch 7202/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0473 - accuracy: 0.9856 - val_loss: 0.7514 - val_accuracy: 0.8564\n",
      "Epoch 7203/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0409 - accuracy: 0.9869 - val_loss: 0.7550 - val_accuracy: 0.8507\n",
      "Epoch 7204/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0517 - accuracy: 0.9837 - val_loss: 0.6967 - val_accuracy: 0.8610\n",
      "Epoch 7205/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0452 - accuracy: 0.9858 - val_loss: 0.7047 - val_accuracy: 0.8610\n",
      "Epoch 7206/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0412 - accuracy: 0.9869 - val_loss: 0.7400 - val_accuracy: 0.8575\n",
      "Epoch 7207/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0449 - accuracy: 0.9856 - val_loss: 0.7133 - val_accuracy: 0.8580\n",
      "Epoch 7208/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0468 - accuracy: 0.9857 - val_loss: 0.7470 - val_accuracy: 0.8530\n",
      "Epoch 7209/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0442 - accuracy: 0.9862 - val_loss: 0.7561 - val_accuracy: 0.8538\n",
      "Epoch 7210/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0470 - accuracy: 0.9854 - val_loss: 0.6756 - val_accuracy: 0.8660\n",
      "Epoch 7211/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0441 - accuracy: 0.9866 - val_loss: 0.7289 - val_accuracy: 0.8568\n",
      "Epoch 7212/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0508 - accuracy: 0.9845 - val_loss: 0.7004 - val_accuracy: 0.8580\n",
      "Epoch 7213/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0449 - accuracy: 0.9858 - val_loss: 0.8260 - val_accuracy: 0.8400\n",
      "Epoch 7214/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0470 - accuracy: 0.9852 - val_loss: 0.7632 - val_accuracy: 0.8501\n",
      "Epoch 7215/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0469 - accuracy: 0.9861 - val_loss: 0.7807 - val_accuracy: 0.8508\n",
      "Epoch 7216/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0405 - accuracy: 0.9873 - val_loss: 0.7312 - val_accuracy: 0.8534\n",
      "Epoch 7217/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0433 - accuracy: 0.9864 - val_loss: 0.7201 - val_accuracy: 0.8593\n",
      "Epoch 7218/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0459 - accuracy: 0.9857 - val_loss: 0.7011 - val_accuracy: 0.8606\n",
      "Epoch 7219/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0464 - accuracy: 0.9855 - val_loss: 0.7668 - val_accuracy: 0.8520\n",
      "Epoch 7220/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0430 - accuracy: 0.9863 - val_loss: 0.6974 - val_accuracy: 0.8617\n",
      "Epoch 7221/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0438 - accuracy: 0.9868 - val_loss: 0.7139 - val_accuracy: 0.8586\n",
      "Epoch 7222/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0430 - accuracy: 0.9866 - val_loss: 0.7825 - val_accuracy: 0.8508\n",
      "Epoch 7223/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0510 - accuracy: 0.9844 - val_loss: 0.7684 - val_accuracy: 0.8493\n",
      "Epoch 7224/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0400 - accuracy: 0.9880 - val_loss: 0.6982 - val_accuracy: 0.8620\n",
      "Epoch 7225/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0446 - accuracy: 0.9864 - val_loss: 0.7816 - val_accuracy: 0.8474\n",
      "Epoch 7226/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0439 - accuracy: 0.9862 - val_loss: 0.7337 - val_accuracy: 0.8587\n",
      "Epoch 7227/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0414 - accuracy: 0.9874 - val_loss: 0.7028 - val_accuracy: 0.8633\n",
      "Epoch 7228/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0450 - accuracy: 0.9860 - val_loss: 0.6898 - val_accuracy: 0.8628\n",
      "Epoch 7229/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0456 - accuracy: 0.9860 - val_loss: 0.7519 - val_accuracy: 0.8492\n",
      "Epoch 7230/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0447 - accuracy: 0.9863 - val_loss: 0.7259 - val_accuracy: 0.8590\n",
      "Epoch 7231/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0462 - accuracy: 0.9855 - val_loss: 0.6869 - val_accuracy: 0.8634\n",
      "Epoch 7232/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0457 - accuracy: 0.9860 - val_loss: 0.7106 - val_accuracy: 0.8600\n",
      "Epoch 7233/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0456 - accuracy: 0.9858 - val_loss: 0.7365 - val_accuracy: 0.8544\n",
      "Epoch 7234/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0470 - accuracy: 0.9857 - val_loss: 0.7630 - val_accuracy: 0.8567\n",
      "Epoch 7235/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0418 - accuracy: 0.9870 - val_loss: 0.6965 - val_accuracy: 0.8633\n",
      "Epoch 7236/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0395 - accuracy: 0.9874 - val_loss: 0.7404 - val_accuracy: 0.8569\n",
      "Epoch 7237/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0445 - accuracy: 0.9859 - val_loss: 0.7293 - val_accuracy: 0.8568\n",
      "Epoch 7238/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0468 - accuracy: 0.9856 - val_loss: 0.7375 - val_accuracy: 0.8561\n",
      "Epoch 7239/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0459 - accuracy: 0.9860 - val_loss: 0.7081 - val_accuracy: 0.8604\n",
      "Epoch 7240/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0443 - accuracy: 0.9864 - val_loss: 0.6783 - val_accuracy: 0.8629\n",
      "Epoch 7241/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0399 - accuracy: 0.9877 - val_loss: 0.7192 - val_accuracy: 0.8587\n",
      "Epoch 7242/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0467 - accuracy: 0.9854 - val_loss: 0.7687 - val_accuracy: 0.8488\n",
      "Epoch 7243/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0441 - accuracy: 0.9861 - val_loss: 0.7204 - val_accuracy: 0.8592\n",
      "Epoch 7244/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0473 - accuracy: 0.9848 - val_loss: 0.8254 - val_accuracy: 0.8424\n",
      "Epoch 7245/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0450 - accuracy: 0.9860 - val_loss: 0.7467 - val_accuracy: 0.8562\n",
      "Epoch 7246/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0424 - accuracy: 0.9866 - val_loss: 0.7087 - val_accuracy: 0.8603\n",
      "Epoch 7247/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0438 - accuracy: 0.9863 - val_loss: 0.7305 - val_accuracy: 0.8584\n",
      "Epoch 7248/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0443 - accuracy: 0.9866 - val_loss: 0.7654 - val_accuracy: 0.8500\n",
      "Epoch 7249/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0475 - accuracy: 0.9855 - val_loss: 0.7643 - val_accuracy: 0.8547\n",
      "Epoch 7250/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0439 - accuracy: 0.9873 - val_loss: 0.7843 - val_accuracy: 0.8478\n",
      "Epoch 7251/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0434 - accuracy: 0.9871 - val_loss: 0.7281 - val_accuracy: 0.8559\n",
      "Epoch 7252/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0445 - accuracy: 0.9862 - val_loss: 0.7523 - val_accuracy: 0.8530\n",
      "Epoch 7253/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0429 - accuracy: 0.9862 - val_loss: 0.7246 - val_accuracy: 0.8587\n",
      "Epoch 7254/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0434 - accuracy: 0.9864 - val_loss: 0.7109 - val_accuracy: 0.8596\n",
      "Epoch 7255/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0406 - accuracy: 0.9872 - val_loss: 0.7446 - val_accuracy: 0.8547\n",
      "Epoch 7256/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0490 - accuracy: 0.9852 - val_loss: 0.7254 - val_accuracy: 0.8563\n",
      "Epoch 7257/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0496 - accuracy: 0.9848 - val_loss: 0.7280 - val_accuracy: 0.8538\n",
      "Epoch 7258/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0428 - accuracy: 0.9869 - val_loss: 0.7218 - val_accuracy: 0.8584\n",
      "Epoch 7259/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0394 - accuracy: 0.9879 - val_loss: 0.7540 - val_accuracy: 0.8562\n",
      "Epoch 7260/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0441 - accuracy: 0.9864 - val_loss: 0.7036 - val_accuracy: 0.8607\n",
      "Epoch 7261/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0462 - accuracy: 0.9861 - val_loss: 0.7262 - val_accuracy: 0.8555\n",
      "Epoch 7262/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0569 - accuracy: 0.9825 - val_loss: 0.7118 - val_accuracy: 0.8546\n",
      "Epoch 7263/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0430 - accuracy: 0.9864 - val_loss: 0.7525 - val_accuracy: 0.8533\n",
      "Epoch 7264/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0488 - accuracy: 0.9853 - val_loss: 0.7598 - val_accuracy: 0.8513\n",
      "Epoch 7265/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0447 - accuracy: 0.9859 - val_loss: 0.7032 - val_accuracy: 0.8601\n",
      "Epoch 7266/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0443 - accuracy: 0.9867 - val_loss: 0.7416 - val_accuracy: 0.8565\n",
      "Epoch 7267/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0460 - accuracy: 0.9858 - val_loss: 0.7411 - val_accuracy: 0.8549\n",
      "Epoch 7268/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0455 - accuracy: 0.9856 - val_loss: 0.7487 - val_accuracy: 0.8558\n",
      "Epoch 7269/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0537 - accuracy: 0.9838 - val_loss: 0.7529 - val_accuracy: 0.8513\n",
      "Epoch 7270/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0449 - accuracy: 0.9860 - val_loss: 0.7205 - val_accuracy: 0.8603\n",
      "Epoch 7271/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0438 - accuracy: 0.9865 - val_loss: 0.7345 - val_accuracy: 0.8557\n",
      "Epoch 7272/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0466 - accuracy: 0.9854 - val_loss: 0.7186 - val_accuracy: 0.8586\n",
      "Epoch 7273/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0471 - accuracy: 0.9854 - val_loss: 0.7601 - val_accuracy: 0.8496\n",
      "Epoch 7274/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0474 - accuracy: 0.9850 - val_loss: 0.7472 - val_accuracy: 0.8523\n",
      "Epoch 7275/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0462 - accuracy: 0.9857 - val_loss: 0.7182 - val_accuracy: 0.8595\n",
      "Epoch 7276/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0449 - accuracy: 0.9863 - val_loss: 0.6847 - val_accuracy: 0.8628\n",
      "Epoch 7277/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0481 - accuracy: 0.9846 - val_loss: 0.7523 - val_accuracy: 0.8537\n",
      "Epoch 7278/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0478 - accuracy: 0.9844 - val_loss: 0.7590 - val_accuracy: 0.8498\n",
      "Epoch 7279/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0455 - accuracy: 0.9859 - val_loss: 0.7297 - val_accuracy: 0.8590\n",
      "Epoch 7280/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0427 - accuracy: 0.9869 - val_loss: 0.7623 - val_accuracy: 0.8518\n",
      "Epoch 7281/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0403 - accuracy: 0.9875 - val_loss: 0.7750 - val_accuracy: 0.8497\n",
      "Epoch 7282/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0416 - accuracy: 0.9874 - val_loss: 0.7964 - val_accuracy: 0.8506\n",
      "Epoch 7283/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0438 - accuracy: 0.9861 - val_loss: 0.8383 - val_accuracy: 0.8459\n",
      "Epoch 7284/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0400 - accuracy: 0.9871 - val_loss: 0.7274 - val_accuracy: 0.8617\n",
      "Epoch 7285/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0420 - accuracy: 0.9870 - val_loss: 0.7349 - val_accuracy: 0.8575\n",
      "Epoch 7286/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0453 - accuracy: 0.9860 - val_loss: 0.7893 - val_accuracy: 0.8520\n",
      "Epoch 7287/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0448 - accuracy: 0.9866 - val_loss: 0.7167 - val_accuracy: 0.8576\n",
      "Epoch 7288/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0499 - accuracy: 0.9844 - val_loss: 0.8265 - val_accuracy: 0.8454\n",
      "Epoch 7289/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0513 - accuracy: 0.9844 - val_loss: 0.7130 - val_accuracy: 0.8576\n",
      "Epoch 7290/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0441 - accuracy: 0.9860 - val_loss: 0.6995 - val_accuracy: 0.8629\n",
      "Epoch 7291/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0445 - accuracy: 0.9867 - val_loss: 0.7366 - val_accuracy: 0.8565\n",
      "Epoch 7292/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0425 - accuracy: 0.9870 - val_loss: 0.7335 - val_accuracy: 0.8562\n",
      "Epoch 7293/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0477 - accuracy: 0.9848 - val_loss: 0.7507 - val_accuracy: 0.8532\n",
      "Epoch 7294/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0470 - accuracy: 0.9852 - val_loss: 0.7095 - val_accuracy: 0.8565\n",
      "Epoch 7295/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0427 - accuracy: 0.9864 - val_loss: 0.7075 - val_accuracy: 0.8594\n",
      "Epoch 7296/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0416 - accuracy: 0.9869 - val_loss: 0.7533 - val_accuracy: 0.8512\n",
      "Epoch 7297/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0445 - accuracy: 0.9866 - val_loss: 0.7301 - val_accuracy: 0.8561\n",
      "Epoch 7298/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0443 - accuracy: 0.9860 - val_loss: 0.7354 - val_accuracy: 0.8593\n",
      "Epoch 7299/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0420 - accuracy: 0.9870 - val_loss: 0.7103 - val_accuracy: 0.8592\n",
      "Epoch 7300/8000\n",
      "1458/1463 [============================>.] - ETA: 0s - loss: 0.0445 - accuracy: 0.9866\n",
      "Epoch 7300: saving model to ./training_ckpt_20240109205949_v8_240109_d10000_n4096_b64_e8000_c100_Adamax\\cp-000007300.ckpt\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0445 - accuracy: 0.9866 - val_loss: 0.7260 - val_accuracy: 0.8578\n",
      "Epoch 7301/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0444 - accuracy: 0.9860 - val_loss: 0.7803 - val_accuracy: 0.8477\n",
      "Epoch 7302/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0449 - accuracy: 0.9862 - val_loss: 0.8090 - val_accuracy: 0.8448\n",
      "Epoch 7303/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0462 - accuracy: 0.9852 - val_loss: 0.7247 - val_accuracy: 0.8555\n",
      "Epoch 7304/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0440 - accuracy: 0.9861 - val_loss: 0.7695 - val_accuracy: 0.8536\n",
      "Epoch 7305/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0483 - accuracy: 0.9848 - val_loss: 0.7417 - val_accuracy: 0.8534\n",
      "Epoch 7306/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0463 - accuracy: 0.9854 - val_loss: 0.7469 - val_accuracy: 0.8542\n",
      "Epoch 7307/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0438 - accuracy: 0.9868 - val_loss: 0.8024 - val_accuracy: 0.8507\n",
      "Epoch 7308/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0492 - accuracy: 0.9847 - val_loss: 0.7451 - val_accuracy: 0.8550\n",
      "Epoch 7309/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0464 - accuracy: 0.9856 - val_loss: 0.7822 - val_accuracy: 0.8487\n",
      "Epoch 7310/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0409 - accuracy: 0.9873 - val_loss: 0.8534 - val_accuracy: 0.8393\n",
      "Epoch 7311/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0480 - accuracy: 0.9848 - val_loss: 0.7213 - val_accuracy: 0.8557\n",
      "Epoch 7312/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0438 - accuracy: 0.9862 - val_loss: 0.7138 - val_accuracy: 0.8583\n",
      "Epoch 7313/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0469 - accuracy: 0.9859 - val_loss: 0.7435 - val_accuracy: 0.8556\n",
      "Epoch 7314/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0428 - accuracy: 0.9873 - val_loss: 0.7197 - val_accuracy: 0.8557\n",
      "Epoch 7315/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0428 - accuracy: 0.9866 - val_loss: 0.6965 - val_accuracy: 0.8603\n",
      "Epoch 7316/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0430 - accuracy: 0.9869 - val_loss: 0.7015 - val_accuracy: 0.8595\n",
      "Epoch 7317/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0427 - accuracy: 0.9867 - val_loss: 0.8538 - val_accuracy: 0.8441\n",
      "Epoch 7318/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0470 - accuracy: 0.9853 - val_loss: 0.7330 - val_accuracy: 0.8537\n",
      "Epoch 7319/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0492 - accuracy: 0.9847 - val_loss: 0.7303 - val_accuracy: 0.8569\n",
      "Epoch 7320/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0466 - accuracy: 0.9852 - val_loss: 0.7627 - val_accuracy: 0.8520\n",
      "Epoch 7321/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0499 - accuracy: 0.9851 - val_loss: 0.6874 - val_accuracy: 0.8637\n",
      "Epoch 7322/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0463 - accuracy: 0.9860 - val_loss: 0.7052 - val_accuracy: 0.8613\n",
      "Epoch 7323/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0446 - accuracy: 0.9860 - val_loss: 0.7144 - val_accuracy: 0.8588\n",
      "Epoch 7324/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0416 - accuracy: 0.9870 - val_loss: 0.6921 - val_accuracy: 0.8603\n",
      "Epoch 7325/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0431 - accuracy: 0.9867 - val_loss: 0.7344 - val_accuracy: 0.8612\n",
      "Epoch 7326/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0420 - accuracy: 0.9869 - val_loss: 0.7438 - val_accuracy: 0.8579\n",
      "Epoch 7327/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0451 - accuracy: 0.9860 - val_loss: 0.7064 - val_accuracy: 0.8582\n",
      "Epoch 7328/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0509 - accuracy: 0.9852 - val_loss: 0.7108 - val_accuracy: 0.8594\n",
      "Epoch 7329/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0407 - accuracy: 0.9876 - val_loss: 0.7017 - val_accuracy: 0.8620\n",
      "Epoch 7330/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0462 - accuracy: 0.9851 - val_loss: 0.7839 - val_accuracy: 0.8470\n",
      "Epoch 7331/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0454 - accuracy: 0.9858 - val_loss: 0.7163 - val_accuracy: 0.8601\n",
      "Epoch 7332/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0480 - accuracy: 0.9856 - val_loss: 0.7805 - val_accuracy: 0.8496\n",
      "Epoch 7333/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0373 - accuracy: 0.9886 - val_loss: 0.7956 - val_accuracy: 0.8499\n",
      "Epoch 7334/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0444 - accuracy: 0.9862 - val_loss: 0.7084 - val_accuracy: 0.8593\n",
      "Epoch 7335/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0437 - accuracy: 0.9863 - val_loss: 0.7308 - val_accuracy: 0.8566\n",
      "Epoch 7336/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0415 - accuracy: 0.9868 - val_loss: 0.7415 - val_accuracy: 0.8606\n",
      "Epoch 7337/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0424 - accuracy: 0.9863 - val_loss: 0.7132 - val_accuracy: 0.8602\n",
      "Epoch 7338/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0434 - accuracy: 0.9862 - val_loss: 0.7665 - val_accuracy: 0.8506\n",
      "Epoch 7339/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0456 - accuracy: 0.9857 - val_loss: 0.6973 - val_accuracy: 0.8641\n",
      "Epoch 7340/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0444 - accuracy: 0.9862 - val_loss: 0.7359 - val_accuracy: 0.8542\n",
      "Epoch 7341/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0433 - accuracy: 0.9870 - val_loss: 0.6971 - val_accuracy: 0.8597\n",
      "Epoch 7342/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0392 - accuracy: 0.9878 - val_loss: 0.7483 - val_accuracy: 0.8568\n",
      "Epoch 7343/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0457 - accuracy: 0.9860 - val_loss: 0.7501 - val_accuracy: 0.8531\n",
      "Epoch 7344/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0428 - accuracy: 0.9864 - val_loss: 0.7390 - val_accuracy: 0.8562\n",
      "Epoch 7345/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0437 - accuracy: 0.9862 - val_loss: 0.7411 - val_accuracy: 0.8558\n",
      "Epoch 7346/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0393 - accuracy: 0.9877 - val_loss: 0.7597 - val_accuracy: 0.8563\n",
      "Epoch 7347/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0501 - accuracy: 0.9850 - val_loss: 0.7292 - val_accuracy: 0.8599\n",
      "Epoch 7348/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0399 - accuracy: 0.9873 - val_loss: 0.7500 - val_accuracy: 0.8588\n",
      "Epoch 7349/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0445 - accuracy: 0.9858 - val_loss: 0.7704 - val_accuracy: 0.8518\n",
      "Epoch 7350/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0486 - accuracy: 0.9849 - val_loss: 0.7145 - val_accuracy: 0.8609\n",
      "Epoch 7351/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0415 - accuracy: 0.9871 - val_loss: 0.7626 - val_accuracy: 0.8560\n",
      "Epoch 7352/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0399 - accuracy: 0.9880 - val_loss: 0.7102 - val_accuracy: 0.8581\n",
      "Epoch 7353/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0452 - accuracy: 0.9862 - val_loss: 0.7521 - val_accuracy: 0.8532\n",
      "Epoch 7354/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0459 - accuracy: 0.9857 - val_loss: 0.7907 - val_accuracy: 0.8477\n",
      "Epoch 7355/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0430 - accuracy: 0.9865 - val_loss: 0.7616 - val_accuracy: 0.8503\n",
      "Epoch 7356/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0398 - accuracy: 0.9878 - val_loss: 0.7329 - val_accuracy: 0.8572\n",
      "Epoch 7357/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0424 - accuracy: 0.9868 - val_loss: 0.7387 - val_accuracy: 0.8579\n",
      "Epoch 7358/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0418 - accuracy: 0.9869 - val_loss: 0.8236 - val_accuracy: 0.8437\n",
      "Epoch 7359/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0444 - accuracy: 0.9860 - val_loss: 0.7548 - val_accuracy: 0.8522\n",
      "Epoch 7360/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0464 - accuracy: 0.9856 - val_loss: 0.7347 - val_accuracy: 0.8594\n",
      "Epoch 7361/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0444 - accuracy: 0.9864 - val_loss: 0.7241 - val_accuracy: 0.8576\n",
      "Epoch 7362/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0461 - accuracy: 0.9856 - val_loss: 0.7452 - val_accuracy: 0.8540\n",
      "Epoch 7363/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0459 - accuracy: 0.9856 - val_loss: 0.7578 - val_accuracy: 0.8513\n",
      "Epoch 7364/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0412 - accuracy: 0.9871 - val_loss: 0.7871 - val_accuracy: 0.8491\n",
      "Epoch 7365/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0438 - accuracy: 0.9862 - val_loss: 0.7649 - val_accuracy: 0.8562\n",
      "Epoch 7366/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0407 - accuracy: 0.9876 - val_loss: 0.7421 - val_accuracy: 0.8547\n",
      "Epoch 7367/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0527 - accuracy: 0.9843 - val_loss: 0.7640 - val_accuracy: 0.8498\n",
      "Epoch 7368/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0470 - accuracy: 0.9852 - val_loss: 0.7365 - val_accuracy: 0.8580\n",
      "Epoch 7369/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0411 - accuracy: 0.9868 - val_loss: 0.7150 - val_accuracy: 0.8604\n",
      "Epoch 7370/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0449 - accuracy: 0.9863 - val_loss: 0.7393 - val_accuracy: 0.8575\n",
      "Epoch 7371/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0396 - accuracy: 0.9875 - val_loss: 0.7113 - val_accuracy: 0.8592\n",
      "Epoch 7372/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0496 - accuracy: 0.9845 - val_loss: 0.7146 - val_accuracy: 0.8559\n",
      "Epoch 7373/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0465 - accuracy: 0.9861 - val_loss: 0.7263 - val_accuracy: 0.8553\n",
      "Epoch 7374/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0445 - accuracy: 0.9866 - val_loss: 0.7990 - val_accuracy: 0.8506\n",
      "Epoch 7375/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0435 - accuracy: 0.9867 - val_loss: 0.7446 - val_accuracy: 0.8554\n",
      "Epoch 7376/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0423 - accuracy: 0.9866 - val_loss: 0.8315 - val_accuracy: 0.8460\n",
      "Epoch 7377/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0448 - accuracy: 0.9856 - val_loss: 0.6936 - val_accuracy: 0.8630\n",
      "Epoch 7378/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0464 - accuracy: 0.9858 - val_loss: 0.7354 - val_accuracy: 0.8570\n",
      "Epoch 7379/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0371 - accuracy: 0.9886 - val_loss: 0.7162 - val_accuracy: 0.8599\n",
      "Epoch 7380/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0471 - accuracy: 0.9853 - val_loss: 0.7523 - val_accuracy: 0.8526\n",
      "Epoch 7381/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0421 - accuracy: 0.9868 - val_loss: 0.7703 - val_accuracy: 0.8496\n",
      "Epoch 7382/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0490 - accuracy: 0.9843 - val_loss: 0.7974 - val_accuracy: 0.8492\n",
      "Epoch 7383/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0467 - accuracy: 0.9851 - val_loss: 0.7742 - val_accuracy: 0.8508\n",
      "Epoch 7384/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0472 - accuracy: 0.9854 - val_loss: 0.8436 - val_accuracy: 0.8405\n",
      "Epoch 7385/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0440 - accuracy: 0.9861 - val_loss: 0.7152 - val_accuracy: 0.8601\n",
      "Epoch 7386/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0456 - accuracy: 0.9860 - val_loss: 0.7483 - val_accuracy: 0.8532\n",
      "Epoch 7387/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0434 - accuracy: 0.9867 - val_loss: 0.7783 - val_accuracy: 0.8494\n",
      "Epoch 7388/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0439 - accuracy: 0.9860 - val_loss: 0.7458 - val_accuracy: 0.8610\n",
      "Epoch 7389/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0389 - accuracy: 0.9879 - val_loss: 0.7602 - val_accuracy: 0.8511\n",
      "Epoch 7390/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0505 - accuracy: 0.9851 - val_loss: 0.8073 - val_accuracy: 0.8461\n",
      "Epoch 7391/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0461 - accuracy: 0.9856 - val_loss: 0.7288 - val_accuracy: 0.8593\n",
      "Epoch 7392/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0440 - accuracy: 0.9857 - val_loss: 0.7143 - val_accuracy: 0.8589\n",
      "Epoch 7393/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0426 - accuracy: 0.9869 - val_loss: 0.7215 - val_accuracy: 0.8587\n",
      "Epoch 7394/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0415 - accuracy: 0.9869 - val_loss: 0.7461 - val_accuracy: 0.8561\n",
      "Epoch 7395/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0414 - accuracy: 0.9874 - val_loss: 0.7143 - val_accuracy: 0.8607\n",
      "Epoch 7396/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0421 - accuracy: 0.9872 - val_loss: 0.7081 - val_accuracy: 0.8587\n",
      "Epoch 7397/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0381 - accuracy: 0.9881 - val_loss: 0.7845 - val_accuracy: 0.8485\n",
      "Epoch 7398/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0429 - accuracy: 0.9871 - val_loss: 0.7089 - val_accuracy: 0.8617\n",
      "Epoch 7399/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0482 - accuracy: 0.9861 - val_loss: 0.7925 - val_accuracy: 0.8451\n",
      "Epoch 7400/8000\n",
      "1463/1463 [==============================] - ETA: 0s - loss: 0.0423 - accuracy: 0.9867\n",
      "Epoch 7400: saving model to ./training_ckpt_20240109205949_v8_240109_d10000_n4096_b64_e8000_c100_Adamax\\cp-000007400.ckpt\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0423 - accuracy: 0.9867 - val_loss: 0.6895 - val_accuracy: 0.8603\n",
      "Epoch 7401/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0467 - accuracy: 0.9858 - val_loss: 0.7140 - val_accuracy: 0.8611\n",
      "Epoch 7402/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0480 - accuracy: 0.9853 - val_loss: 0.7368 - val_accuracy: 0.8564\n",
      "Epoch 7403/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0443 - accuracy: 0.9856 - val_loss: 0.7170 - val_accuracy: 0.8577\n",
      "Epoch 7404/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0427 - accuracy: 0.9868 - val_loss: 0.8166 - val_accuracy: 0.8486\n",
      "Epoch 7405/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0414 - accuracy: 0.9872 - val_loss: 0.7576 - val_accuracy: 0.8558\n",
      "Epoch 7406/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0439 - accuracy: 0.9861 - val_loss: 0.7060 - val_accuracy: 0.8599\n",
      "Epoch 7407/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0414 - accuracy: 0.9874 - val_loss: 0.7570 - val_accuracy: 0.8538\n",
      "Epoch 7408/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0429 - accuracy: 0.9871 - val_loss: 0.6965 - val_accuracy: 0.8599\n",
      "Epoch 7409/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0451 - accuracy: 0.9862 - val_loss: 0.7209 - val_accuracy: 0.8595\n",
      "Epoch 7410/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0445 - accuracy: 0.9867 - val_loss: 0.7412 - val_accuracy: 0.8562\n",
      "Epoch 7411/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0425 - accuracy: 0.9871 - val_loss: 0.6946 - val_accuracy: 0.8612\n",
      "Epoch 7412/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0443 - accuracy: 0.9864 - val_loss: 0.7545 - val_accuracy: 0.8553\n",
      "Epoch 7413/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0470 - accuracy: 0.9857 - val_loss: 0.7482 - val_accuracy: 0.8547\n",
      "Epoch 7414/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0479 - accuracy: 0.9855 - val_loss: 0.8174 - val_accuracy: 0.8456\n",
      "Epoch 7415/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0442 - accuracy: 0.9858 - val_loss: 0.7357 - val_accuracy: 0.8546\n",
      "Epoch 7416/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0396 - accuracy: 0.9874 - val_loss: 0.7345 - val_accuracy: 0.8556\n",
      "Epoch 7417/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0451 - accuracy: 0.9863 - val_loss: 0.7455 - val_accuracy: 0.8537\n",
      "Epoch 7418/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0473 - accuracy: 0.9856 - val_loss: 0.7535 - val_accuracy: 0.8538\n",
      "Epoch 7419/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0402 - accuracy: 0.9876 - val_loss: 0.7938 - val_accuracy: 0.8457\n",
      "Epoch 7420/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0478 - accuracy: 0.9848 - val_loss: 0.8031 - val_accuracy: 0.8465\n",
      "Epoch 7421/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0470 - accuracy: 0.9852 - val_loss: 0.6757 - val_accuracy: 0.8631\n",
      "Epoch 7422/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0427 - accuracy: 0.9866 - val_loss: 0.7642 - val_accuracy: 0.8507\n",
      "Epoch 7423/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0372 - accuracy: 0.9881 - val_loss: 0.7360 - val_accuracy: 0.8569\n",
      "Epoch 7424/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0463 - accuracy: 0.9858 - val_loss: 0.7906 - val_accuracy: 0.8523\n",
      "Epoch 7425/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0416 - accuracy: 0.9866 - val_loss: 0.7925 - val_accuracy: 0.8525\n",
      "Epoch 7426/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0403 - accuracy: 0.9875 - val_loss: 0.6988 - val_accuracy: 0.8654\n",
      "Epoch 7427/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0532 - accuracy: 0.9836 - val_loss: 0.7181 - val_accuracy: 0.8583\n",
      "Epoch 7428/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0492 - accuracy: 0.9855 - val_loss: 0.7315 - val_accuracy: 0.8583\n",
      "Epoch 7429/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0426 - accuracy: 0.9868 - val_loss: 0.7598 - val_accuracy: 0.8536\n",
      "Epoch 7430/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0572 - accuracy: 0.9822 - val_loss: 0.7479 - val_accuracy: 0.8557\n",
      "Epoch 7431/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0405 - accuracy: 0.9870 - val_loss: 0.7503 - val_accuracy: 0.8550\n",
      "Epoch 7432/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0454 - accuracy: 0.9862 - val_loss: 0.7019 - val_accuracy: 0.8623\n",
      "Epoch 7433/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0408 - accuracy: 0.9875 - val_loss: 0.7165 - val_accuracy: 0.8583\n",
      "Epoch 7434/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0448 - accuracy: 0.9864 - val_loss: 0.7511 - val_accuracy: 0.8519\n",
      "Epoch 7435/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0450 - accuracy: 0.9865 - val_loss: 0.7156 - val_accuracy: 0.8598\n",
      "Epoch 7436/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0402 - accuracy: 0.9876 - val_loss: 0.7536 - val_accuracy: 0.8543\n",
      "Epoch 7437/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0434 - accuracy: 0.9863 - val_loss: 0.7510 - val_accuracy: 0.8553\n",
      "Epoch 7438/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0480 - accuracy: 0.9851 - val_loss: 0.7666 - val_accuracy: 0.8510\n",
      "Epoch 7439/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0426 - accuracy: 0.9870 - val_loss: 0.7156 - val_accuracy: 0.8569\n",
      "Epoch 7440/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0414 - accuracy: 0.9873 - val_loss: 0.7612 - val_accuracy: 0.8543\n",
      "Epoch 7441/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0412 - accuracy: 0.9870 - val_loss: 0.8444 - val_accuracy: 0.8465\n",
      "Epoch 7442/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0429 - accuracy: 0.9864 - val_loss: 0.8454 - val_accuracy: 0.8515\n",
      "Epoch 7443/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0412 - accuracy: 0.9867 - val_loss: 0.7428 - val_accuracy: 0.8574\n",
      "Epoch 7444/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0433 - accuracy: 0.9866 - val_loss: 0.7391 - val_accuracy: 0.8564\n",
      "Epoch 7445/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0411 - accuracy: 0.9871 - val_loss: 0.7057 - val_accuracy: 0.8627\n",
      "Epoch 7446/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0460 - accuracy: 0.9856 - val_loss: 0.7165 - val_accuracy: 0.8580\n",
      "Epoch 7447/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0441 - accuracy: 0.9862 - val_loss: 0.7597 - val_accuracy: 0.8537\n",
      "Epoch 7448/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0457 - accuracy: 0.9858 - val_loss: 0.7315 - val_accuracy: 0.8572\n",
      "Epoch 7449/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0432 - accuracy: 0.9867 - val_loss: 0.7505 - val_accuracy: 0.8544\n",
      "Epoch 7450/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0416 - accuracy: 0.9873 - val_loss: 0.7907 - val_accuracy: 0.8474\n",
      "Epoch 7451/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0417 - accuracy: 0.9864 - val_loss: 0.7590 - val_accuracy: 0.8527\n",
      "Epoch 7452/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0436 - accuracy: 0.9866 - val_loss: 0.6817 - val_accuracy: 0.8607\n",
      "Epoch 7453/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0443 - accuracy: 0.9866 - val_loss: 0.7448 - val_accuracy: 0.8552\n",
      "Epoch 7454/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0412 - accuracy: 0.9874 - val_loss: 0.7442 - val_accuracy: 0.8559\n",
      "Epoch 7455/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0408 - accuracy: 0.9870 - val_loss: 0.7251 - val_accuracy: 0.8573\n",
      "Epoch 7456/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0422 - accuracy: 0.9870 - val_loss: 0.7343 - val_accuracy: 0.8562\n",
      "Epoch 7457/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0432 - accuracy: 0.9868 - val_loss: 0.7669 - val_accuracy: 0.8525\n",
      "Epoch 7458/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0423 - accuracy: 0.9871 - val_loss: 0.7615 - val_accuracy: 0.8502\n",
      "Epoch 7459/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0426 - accuracy: 0.9866 - val_loss: 0.7752 - val_accuracy: 0.8514\n",
      "Epoch 7460/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0458 - accuracy: 0.9861 - val_loss: 0.7299 - val_accuracy: 0.8574\n",
      "Epoch 7461/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0416 - accuracy: 0.9869 - val_loss: 0.7440 - val_accuracy: 0.8568\n",
      "Epoch 7462/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0478 - accuracy: 0.9852 - val_loss: 0.7363 - val_accuracy: 0.8577\n",
      "Epoch 7463/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0401 - accuracy: 0.9875 - val_loss: 0.7313 - val_accuracy: 0.8583\n",
      "Epoch 7464/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0423 - accuracy: 0.9866 - val_loss: 0.7849 - val_accuracy: 0.8502\n",
      "Epoch 7465/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0445 - accuracy: 0.9862 - val_loss: 0.7421 - val_accuracy: 0.8531\n",
      "Epoch 7466/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0440 - accuracy: 0.9862 - val_loss: 0.6991 - val_accuracy: 0.8618\n",
      "Epoch 7467/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0451 - accuracy: 0.9861 - val_loss: 0.7656 - val_accuracy: 0.8535\n",
      "Epoch 7468/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0401 - accuracy: 0.9873 - val_loss: 0.7085 - val_accuracy: 0.8617\n",
      "Epoch 7469/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0412 - accuracy: 0.9873 - val_loss: 0.7300 - val_accuracy: 0.8591\n",
      "Epoch 7470/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0446 - accuracy: 0.9863 - val_loss: 1.0348 - val_accuracy: 0.8370\n",
      "Epoch 7471/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0459 - accuracy: 0.9856 - val_loss: 0.7855 - val_accuracy: 0.8480\n",
      "Epoch 7472/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0461 - accuracy: 0.9862 - val_loss: 0.7305 - val_accuracy: 0.8556\n",
      "Epoch 7473/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0438 - accuracy: 0.9863 - val_loss: 0.7495 - val_accuracy: 0.8580\n",
      "Epoch 7474/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0407 - accuracy: 0.9869 - val_loss: 0.7268 - val_accuracy: 0.8570\n",
      "Epoch 7475/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0440 - accuracy: 0.9865 - val_loss: 0.7134 - val_accuracy: 0.8597\n",
      "Epoch 7476/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0461 - accuracy: 0.9849 - val_loss: 0.7670 - val_accuracy: 0.8519\n",
      "Epoch 7477/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0457 - accuracy: 0.9856 - val_loss: 0.7310 - val_accuracy: 0.8566\n",
      "Epoch 7478/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0433 - accuracy: 0.9866 - val_loss: 0.8231 - val_accuracy: 0.8503\n",
      "Epoch 7479/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0394 - accuracy: 0.9880 - val_loss: 0.8607 - val_accuracy: 0.8456\n",
      "Epoch 7480/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0485 - accuracy: 0.9862 - val_loss: 0.7192 - val_accuracy: 0.8620\n",
      "Epoch 7481/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0440 - accuracy: 0.9862 - val_loss: 0.7452 - val_accuracy: 0.8536\n",
      "Epoch 7482/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0451 - accuracy: 0.9858 - val_loss: 0.7153 - val_accuracy: 0.8564\n",
      "Epoch 7483/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0419 - accuracy: 0.9866 - val_loss: 0.7233 - val_accuracy: 0.8602\n",
      "Epoch 7484/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0494 - accuracy: 0.9850 - val_loss: 0.7099 - val_accuracy: 0.8640\n",
      "Epoch 7485/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0476 - accuracy: 0.9850 - val_loss: 0.7469 - val_accuracy: 0.8583\n",
      "Epoch 7486/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0434 - accuracy: 0.9864 - val_loss: 0.7412 - val_accuracy: 0.8586\n",
      "Epoch 7487/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0435 - accuracy: 0.9864 - val_loss: 0.7498 - val_accuracy: 0.8552\n",
      "Epoch 7488/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0429 - accuracy: 0.9868 - val_loss: 0.7662 - val_accuracy: 0.8505\n",
      "Epoch 7489/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0437 - accuracy: 0.9865 - val_loss: 0.8094 - val_accuracy: 0.8468\n",
      "Epoch 7490/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0456 - accuracy: 0.9855 - val_loss: 0.8223 - val_accuracy: 0.8435\n",
      "Epoch 7491/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0468 - accuracy: 0.9859 - val_loss: 0.7962 - val_accuracy: 0.8490\n",
      "Epoch 7492/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0467 - accuracy: 0.9851 - val_loss: 0.7435 - val_accuracy: 0.8566\n",
      "Epoch 7493/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0471 - accuracy: 0.9860 - val_loss: 0.7145 - val_accuracy: 0.8603\n",
      "Epoch 7494/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0415 - accuracy: 0.9871 - val_loss: 0.8159 - val_accuracy: 0.8457\n",
      "Epoch 7495/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0445 - accuracy: 0.9861 - val_loss: 0.8079 - val_accuracy: 0.8483\n",
      "Epoch 7496/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0439 - accuracy: 0.9866 - val_loss: 0.7385 - val_accuracy: 0.8567\n",
      "Epoch 7497/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0456 - accuracy: 0.9859 - val_loss: 0.7041 - val_accuracy: 0.8628\n",
      "Epoch 7498/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0456 - accuracy: 0.9862 - val_loss: 0.7494 - val_accuracy: 0.8539\n",
      "Epoch 7499/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0418 - accuracy: 0.9870 - val_loss: 0.8162 - val_accuracy: 0.8516\n",
      "Epoch 7500/8000\n",
      "1463/1463 [==============================] - ETA: 0s - loss: 0.0440 - accuracy: 0.9865\n",
      "Epoch 7500: saving model to ./training_ckpt_20240109205949_v8_240109_d10000_n4096_b64_e8000_c100_Adamax\\cp-000007500.ckpt\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0440 - accuracy: 0.9865 - val_loss: 0.7373 - val_accuracy: 0.8561\n",
      "Epoch 7501/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0434 - accuracy: 0.9863 - val_loss: 0.6934 - val_accuracy: 0.8624\n",
      "Epoch 7502/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0416 - accuracy: 0.9871 - val_loss: 0.7505 - val_accuracy: 0.8562\n",
      "Epoch 7503/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0405 - accuracy: 0.9874 - val_loss: 0.7200 - val_accuracy: 0.8587\n",
      "Epoch 7504/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0506 - accuracy: 0.9842 - val_loss: 0.7531 - val_accuracy: 0.8555\n",
      "Epoch 7505/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0435 - accuracy: 0.9867 - val_loss: 0.7106 - val_accuracy: 0.8595\n",
      "Epoch 7506/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0400 - accuracy: 0.9876 - val_loss: 0.8161 - val_accuracy: 0.8446\n",
      "Epoch 7507/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0469 - accuracy: 0.9852 - val_loss: 0.7381 - val_accuracy: 0.8585\n",
      "Epoch 7508/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0450 - accuracy: 0.9861 - val_loss: 0.6830 - val_accuracy: 0.8664\n",
      "Epoch 7509/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0419 - accuracy: 0.9869 - val_loss: 0.7429 - val_accuracy: 0.8546\n",
      "Epoch 7510/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0381 - accuracy: 0.9878 - val_loss: 0.7473 - val_accuracy: 0.8563\n",
      "Epoch 7511/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0391 - accuracy: 0.9882 - val_loss: 0.7078 - val_accuracy: 0.8624\n",
      "Epoch 7512/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0441 - accuracy: 0.9869 - val_loss: 0.7027 - val_accuracy: 0.8614\n",
      "Epoch 7513/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0460 - accuracy: 0.9863 - val_loss: 0.7829 - val_accuracy: 0.8472\n",
      "Epoch 7514/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0408 - accuracy: 0.9874 - val_loss: 0.7707 - val_accuracy: 0.8482\n",
      "Epoch 7515/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0453 - accuracy: 0.9862 - val_loss: 0.7369 - val_accuracy: 0.8581\n",
      "Epoch 7516/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0426 - accuracy: 0.9872 - val_loss: 0.6871 - val_accuracy: 0.8628\n",
      "Epoch 7517/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0434 - accuracy: 0.9865 - val_loss: 0.6978 - val_accuracy: 0.8612\n",
      "Epoch 7518/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0470 - accuracy: 0.9860 - val_loss: 0.7187 - val_accuracy: 0.8594\n",
      "Epoch 7519/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0406 - accuracy: 0.9874 - val_loss: 0.7715 - val_accuracy: 0.8505\n",
      "Epoch 7520/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0569 - accuracy: 0.9835 - val_loss: 0.7267 - val_accuracy: 0.8573\n",
      "Epoch 7521/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0406 - accuracy: 0.9874 - val_loss: 0.7289 - val_accuracy: 0.8590\n",
      "Epoch 7522/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0433 - accuracy: 0.9864 - val_loss: 0.7472 - val_accuracy: 0.8560\n",
      "Epoch 7523/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0436 - accuracy: 0.9867 - val_loss: 0.8232 - val_accuracy: 0.8463\n",
      "Epoch 7524/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0423 - accuracy: 0.9867 - val_loss: 0.7311 - val_accuracy: 0.8576\n",
      "Epoch 7525/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0451 - accuracy: 0.9864 - val_loss: 0.9065 - val_accuracy: 0.8416\n",
      "Epoch 7526/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0479 - accuracy: 0.9852 - val_loss: 0.7300 - val_accuracy: 0.8628\n",
      "Epoch 7527/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0458 - accuracy: 0.9861 - val_loss: 0.7619 - val_accuracy: 0.8539\n",
      "Epoch 7528/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0449 - accuracy: 0.9860 - val_loss: 0.8002 - val_accuracy: 0.8495\n",
      "Epoch 7529/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0444 - accuracy: 0.9861 - val_loss: 0.8318 - val_accuracy: 0.8483\n",
      "Epoch 7530/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0431 - accuracy: 0.9862 - val_loss: 0.7541 - val_accuracy: 0.8550\n",
      "Epoch 7531/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0450 - accuracy: 0.9866 - val_loss: 0.7497 - val_accuracy: 0.8563\n",
      "Epoch 7532/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0383 - accuracy: 0.9877 - val_loss: 0.7585 - val_accuracy: 0.8557\n",
      "Epoch 7533/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0494 - accuracy: 0.9845 - val_loss: 0.7421 - val_accuracy: 0.8558\n",
      "Epoch 7534/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0457 - accuracy: 0.9859 - val_loss: 0.7203 - val_accuracy: 0.8603\n",
      "Epoch 7535/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0437 - accuracy: 0.9862 - val_loss: 0.7233 - val_accuracy: 0.8609\n",
      "Epoch 7536/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0404 - accuracy: 0.9876 - val_loss: 0.8107 - val_accuracy: 0.8464\n",
      "Epoch 7537/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0390 - accuracy: 0.9878 - val_loss: 0.7413 - val_accuracy: 0.8570\n",
      "Epoch 7538/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0482 - accuracy: 0.9861 - val_loss: 0.7370 - val_accuracy: 0.8571\n",
      "Epoch 7539/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0414 - accuracy: 0.9870 - val_loss: 0.7449 - val_accuracy: 0.8587\n",
      "Epoch 7540/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0396 - accuracy: 0.9874 - val_loss: 0.7075 - val_accuracy: 0.8622\n",
      "Epoch 7541/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0390 - accuracy: 0.9882 - val_loss: 0.7001 - val_accuracy: 0.8645\n",
      "Epoch 7542/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0406 - accuracy: 0.9876 - val_loss: 0.7838 - val_accuracy: 0.8490\n",
      "Epoch 7543/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0451 - accuracy: 0.9858 - val_loss: 0.7493 - val_accuracy: 0.8549\n",
      "Epoch 7544/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0405 - accuracy: 0.9874 - val_loss: 0.7710 - val_accuracy: 0.8526\n",
      "Epoch 7545/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0471 - accuracy: 0.9849 - val_loss: 0.7714 - val_accuracy: 0.8525\n",
      "Epoch 7546/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0453 - accuracy: 0.9857 - val_loss: 0.7729 - val_accuracy: 0.8483\n",
      "Epoch 7547/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0429 - accuracy: 0.9869 - val_loss: 0.7486 - val_accuracy: 0.8537\n",
      "Epoch 7548/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0382 - accuracy: 0.9879 - val_loss: 0.7417 - val_accuracy: 0.8586\n",
      "Epoch 7549/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0452 - accuracy: 0.9861 - val_loss: 0.7321 - val_accuracy: 0.8560\n",
      "Epoch 7550/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0435 - accuracy: 0.9870 - val_loss: 0.7383 - val_accuracy: 0.8595\n",
      "Epoch 7551/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0367 - accuracy: 0.9885 - val_loss: 0.7237 - val_accuracy: 0.8596\n",
      "Epoch 7552/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0495 - accuracy: 0.9843 - val_loss: 0.7138 - val_accuracy: 0.8635\n",
      "Epoch 7553/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0414 - accuracy: 0.9871 - val_loss: 0.7081 - val_accuracy: 0.8582\n",
      "Epoch 7554/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0410 - accuracy: 0.9874 - val_loss: 0.8060 - val_accuracy: 0.8473\n",
      "Epoch 7555/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0435 - accuracy: 0.9865 - val_loss: 0.7295 - val_accuracy: 0.8555\n",
      "Epoch 7556/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0430 - accuracy: 0.9868 - val_loss: 0.7766 - val_accuracy: 0.8545\n",
      "Epoch 7557/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0431 - accuracy: 0.9870 - val_loss: 0.7431 - val_accuracy: 0.8556\n",
      "Epoch 7558/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0437 - accuracy: 0.9867 - val_loss: 0.7434 - val_accuracy: 0.8564\n",
      "Epoch 7559/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0399 - accuracy: 0.9875 - val_loss: 0.7121 - val_accuracy: 0.8610\n",
      "Epoch 7560/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0445 - accuracy: 0.9861 - val_loss: 0.7291 - val_accuracy: 0.8573\n",
      "Epoch 7561/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0442 - accuracy: 0.9862 - val_loss: 0.7459 - val_accuracy: 0.8547\n",
      "Epoch 7562/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0437 - accuracy: 0.9862 - val_loss: 0.8107 - val_accuracy: 0.8454\n",
      "Epoch 7563/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0418 - accuracy: 0.9873 - val_loss: 0.7813 - val_accuracy: 0.8512\n",
      "Epoch 7564/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0452 - accuracy: 0.9863 - val_loss: 0.7512 - val_accuracy: 0.8591\n",
      "Epoch 7565/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0402 - accuracy: 0.9876 - val_loss: 0.7353 - val_accuracy: 0.8561\n",
      "Epoch 7566/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0389 - accuracy: 0.9876 - val_loss: 0.6898 - val_accuracy: 0.8625\n",
      "Epoch 7567/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0470 - accuracy: 0.9860 - val_loss: 0.7675 - val_accuracy: 0.8525\n",
      "Epoch 7568/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0462 - accuracy: 0.9854 - val_loss: 0.7618 - val_accuracy: 0.8540\n",
      "Epoch 7569/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0388 - accuracy: 0.9877 - val_loss: 0.7836 - val_accuracy: 0.8498\n",
      "Epoch 7570/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0469 - accuracy: 0.9851 - val_loss: 0.7801 - val_accuracy: 0.8469\n",
      "Epoch 7571/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0432 - accuracy: 0.9868 - val_loss: 0.7226 - val_accuracy: 0.8600\n",
      "Epoch 7572/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0428 - accuracy: 0.9867 - val_loss: 0.8475 - val_accuracy: 0.8460\n",
      "Epoch 7573/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0503 - accuracy: 0.9852 - val_loss: 0.7847 - val_accuracy: 0.8458\n",
      "Epoch 7574/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0419 - accuracy: 0.9867 - val_loss: 0.7732 - val_accuracy: 0.8520\n",
      "Epoch 7575/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0446 - accuracy: 0.9859 - val_loss: 0.7776 - val_accuracy: 0.8501\n",
      "Epoch 7576/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0442 - accuracy: 0.9859 - val_loss: 0.7626 - val_accuracy: 0.8537\n",
      "Epoch 7577/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0346 - accuracy: 0.9892 - val_loss: 0.7471 - val_accuracy: 0.8581\n",
      "Epoch 7578/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0465 - accuracy: 0.9851 - val_loss: 0.7432 - val_accuracy: 0.8593\n",
      "Epoch 7579/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0435 - accuracy: 0.9866 - val_loss: 0.7849 - val_accuracy: 0.8512\n",
      "Epoch 7580/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0386 - accuracy: 0.9881 - val_loss: 0.7415 - val_accuracy: 0.8603\n",
      "Epoch 7581/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0415 - accuracy: 0.9872 - val_loss: 0.7038 - val_accuracy: 0.8628\n",
      "Epoch 7582/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0456 - accuracy: 0.9859 - val_loss: 0.8022 - val_accuracy: 0.8484\n",
      "Epoch 7583/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0415 - accuracy: 0.9870 - val_loss: 0.7583 - val_accuracy: 0.8558\n",
      "Epoch 7584/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0460 - accuracy: 0.9856 - val_loss: 0.7509 - val_accuracy: 0.8558\n",
      "Epoch 7585/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0433 - accuracy: 0.9864 - val_loss: 0.7461 - val_accuracy: 0.8539\n",
      "Epoch 7586/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0423 - accuracy: 0.9870 - val_loss: 0.7233 - val_accuracy: 0.8605\n",
      "Epoch 7587/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0425 - accuracy: 0.9870 - val_loss: 0.7121 - val_accuracy: 0.8597\n",
      "Epoch 7588/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0452 - accuracy: 0.9864 - val_loss: 0.6829 - val_accuracy: 0.8634\n",
      "Epoch 7589/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0422 - accuracy: 0.9869 - val_loss: 0.8758 - val_accuracy: 0.8449\n",
      "Epoch 7590/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0446 - accuracy: 0.9856 - val_loss: 0.7281 - val_accuracy: 0.8563\n",
      "Epoch 7591/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0477 - accuracy: 0.9860 - val_loss: 0.8862 - val_accuracy: 0.8338\n",
      "Epoch 7592/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0507 - accuracy: 0.9848 - val_loss: 0.7934 - val_accuracy: 0.8523\n",
      "Epoch 7593/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0387 - accuracy: 0.9878 - val_loss: 0.7254 - val_accuracy: 0.8585\n",
      "Epoch 7594/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0444 - accuracy: 0.9861 - val_loss: 0.7017 - val_accuracy: 0.8632\n",
      "Epoch 7595/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0420 - accuracy: 0.9870 - val_loss: 0.7511 - val_accuracy: 0.8530\n",
      "Epoch 7596/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0423 - accuracy: 0.9868 - val_loss: 0.7759 - val_accuracy: 0.8549\n",
      "Epoch 7597/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0390 - accuracy: 0.9874 - val_loss: 0.7476 - val_accuracy: 0.8565\n",
      "Epoch 7598/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0444 - accuracy: 0.9863 - val_loss: 0.7587 - val_accuracy: 0.8545\n",
      "Epoch 7599/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0495 - accuracy: 0.9843 - val_loss: 0.7168 - val_accuracy: 0.8635\n",
      "Epoch 7600/8000\n",
      "1460/1463 [============================>.] - ETA: 0s - loss: 0.0404 - accuracy: 0.9872\n",
      "Epoch 7600: saving model to ./training_ckpt_20240109205949_v8_240109_d10000_n4096_b64_e8000_c100_Adamax\\cp-000007600.ckpt\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0404 - accuracy: 0.9872 - val_loss: 0.7896 - val_accuracy: 0.8497\n",
      "Epoch 7601/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0428 - accuracy: 0.9870 - val_loss: 0.7056 - val_accuracy: 0.8627\n",
      "Epoch 7602/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0431 - accuracy: 0.9866 - val_loss: 0.7801 - val_accuracy: 0.8528\n",
      "Epoch 7603/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0427 - accuracy: 0.9869 - val_loss: 0.8231 - val_accuracy: 0.8529\n",
      "Epoch 7604/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0378 - accuracy: 0.9882 - val_loss: 0.7773 - val_accuracy: 0.8570\n",
      "Epoch 7605/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0420 - accuracy: 0.9869 - val_loss: 0.7640 - val_accuracy: 0.8536\n",
      "Epoch 7606/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0399 - accuracy: 0.9881 - val_loss: 0.7328 - val_accuracy: 0.8625\n",
      "Epoch 7607/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0396 - accuracy: 0.9875 - val_loss: 0.7829 - val_accuracy: 0.8528\n",
      "Epoch 7608/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0419 - accuracy: 0.9870 - val_loss: 0.8019 - val_accuracy: 0.8468\n",
      "Epoch 7609/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0429 - accuracy: 0.9863 - val_loss: 0.7232 - val_accuracy: 0.8604\n",
      "Epoch 7610/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0387 - accuracy: 0.9879 - val_loss: 0.7336 - val_accuracy: 0.8559\n",
      "Epoch 7611/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0403 - accuracy: 0.9877 - val_loss: 0.7802 - val_accuracy: 0.8539\n",
      "Epoch 7612/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0429 - accuracy: 0.9866 - val_loss: 0.7249 - val_accuracy: 0.8590\n",
      "Epoch 7613/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0386 - accuracy: 0.9882 - val_loss: 0.7428 - val_accuracy: 0.8578\n",
      "Epoch 7614/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0464 - accuracy: 0.9855 - val_loss: 0.7382 - val_accuracy: 0.8597\n",
      "Epoch 7615/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0464 - accuracy: 0.9854 - val_loss: 0.8519 - val_accuracy: 0.8408\n",
      "Epoch 7616/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0390 - accuracy: 0.9876 - val_loss: 0.7831 - val_accuracy: 0.8512\n",
      "Epoch 7617/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0424 - accuracy: 0.9868 - val_loss: 0.7430 - val_accuracy: 0.8583\n",
      "Epoch 7618/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0427 - accuracy: 0.9869 - val_loss: 0.7327 - val_accuracy: 0.8575\n",
      "Epoch 7619/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0435 - accuracy: 0.9872 - val_loss: 0.7447 - val_accuracy: 0.8558\n",
      "Epoch 7620/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0423 - accuracy: 0.9870 - val_loss: 0.7457 - val_accuracy: 0.8551\n",
      "Epoch 7621/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0396 - accuracy: 0.9876 - val_loss: 0.7155 - val_accuracy: 0.8628\n",
      "Epoch 7622/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0408 - accuracy: 0.9870 - val_loss: 0.7440 - val_accuracy: 0.8551\n",
      "Epoch 7623/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0406 - accuracy: 0.9873 - val_loss: 0.8000 - val_accuracy: 0.8519\n",
      "Epoch 7624/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0431 - accuracy: 0.9872 - val_loss: 0.7737 - val_accuracy: 0.8544\n",
      "Epoch 7625/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0408 - accuracy: 0.9872 - val_loss: 0.8098 - val_accuracy: 0.8440\n",
      "Epoch 7626/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0455 - accuracy: 0.9861 - val_loss: 0.7342 - val_accuracy: 0.8602\n",
      "Epoch 7627/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0391 - accuracy: 0.9880 - val_loss: 0.8321 - val_accuracy: 0.8496\n",
      "Epoch 7628/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0455 - accuracy: 0.9860 - val_loss: 0.7227 - val_accuracy: 0.8594\n",
      "Epoch 7629/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0413 - accuracy: 0.9870 - val_loss: 0.7756 - val_accuracy: 0.8552\n",
      "Epoch 7630/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0402 - accuracy: 0.9877 - val_loss: 0.7594 - val_accuracy: 0.8550\n",
      "Epoch 7631/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0412 - accuracy: 0.9866 - val_loss: 0.8851 - val_accuracy: 0.8420\n",
      "Epoch 7632/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0416 - accuracy: 0.9866 - val_loss: 0.8439 - val_accuracy: 0.8466\n",
      "Epoch 7633/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0477 - accuracy: 0.9853 - val_loss: 0.7698 - val_accuracy: 0.8559\n",
      "Epoch 7634/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0414 - accuracy: 0.9873 - val_loss: 0.7520 - val_accuracy: 0.8584\n",
      "Epoch 7635/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0431 - accuracy: 0.9865 - val_loss: 0.7141 - val_accuracy: 0.8587\n",
      "Epoch 7636/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0479 - accuracy: 0.9850 - val_loss: 0.7289 - val_accuracy: 0.8603\n",
      "Epoch 7637/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0447 - accuracy: 0.9863 - val_loss: 0.7720 - val_accuracy: 0.8507\n",
      "Epoch 7638/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0389 - accuracy: 0.9878 - val_loss: 0.7111 - val_accuracy: 0.8638\n",
      "Epoch 7639/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0476 - accuracy: 0.9860 - val_loss: 0.7131 - val_accuracy: 0.8614\n",
      "Epoch 7640/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0432 - accuracy: 0.9869 - val_loss: 0.7591 - val_accuracy: 0.8516\n",
      "Epoch 7641/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0417 - accuracy: 0.9870 - val_loss: 0.7180 - val_accuracy: 0.8618\n",
      "Epoch 7642/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0461 - accuracy: 0.9858 - val_loss: 0.8279 - val_accuracy: 0.8488\n",
      "Epoch 7643/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0424 - accuracy: 0.9868 - val_loss: 0.7263 - val_accuracy: 0.8628\n",
      "Epoch 7644/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0461 - accuracy: 0.9863 - val_loss: 0.8473 - val_accuracy: 0.8463\n",
      "Epoch 7645/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0467 - accuracy: 0.9863 - val_loss: 0.7145 - val_accuracy: 0.8637\n",
      "Epoch 7646/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0439 - accuracy: 0.9861 - val_loss: 0.7065 - val_accuracy: 0.8609\n",
      "Epoch 7647/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0429 - accuracy: 0.9864 - val_loss: 0.7786 - val_accuracy: 0.8529\n",
      "Epoch 7648/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0437 - accuracy: 0.9864 - val_loss: 0.7590 - val_accuracy: 0.8570\n",
      "Epoch 7649/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0454 - accuracy: 0.9868 - val_loss: 0.7486 - val_accuracy: 0.8572\n",
      "Epoch 7650/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0400 - accuracy: 0.9872 - val_loss: 0.7800 - val_accuracy: 0.8515\n",
      "Epoch 7651/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0450 - accuracy: 0.9866 - val_loss: 0.7187 - val_accuracy: 0.8620\n",
      "Epoch 7652/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0420 - accuracy: 0.9871 - val_loss: 0.7288 - val_accuracy: 0.8560\n",
      "Epoch 7653/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0443 - accuracy: 0.9861 - val_loss: 0.8021 - val_accuracy: 0.8462\n",
      "Epoch 7654/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0401 - accuracy: 0.9878 - val_loss: 0.7986 - val_accuracy: 0.8458\n",
      "Epoch 7655/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0454 - accuracy: 0.9857 - val_loss: 0.7550 - val_accuracy: 0.8547\n",
      "Epoch 7656/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0398 - accuracy: 0.9867 - val_loss: 0.7307 - val_accuracy: 0.8572\n",
      "Epoch 7657/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0403 - accuracy: 0.9870 - val_loss: 0.7442 - val_accuracy: 0.8568\n",
      "Epoch 7658/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0470 - accuracy: 0.9859 - val_loss: 0.7408 - val_accuracy: 0.8573\n",
      "Epoch 7659/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0407 - accuracy: 0.9871 - val_loss: 0.7635 - val_accuracy: 0.8561\n",
      "Epoch 7660/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0446 - accuracy: 0.9864 - val_loss: 0.8443 - val_accuracy: 0.8462\n",
      "Epoch 7661/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0444 - accuracy: 0.9862 - val_loss: 0.7977 - val_accuracy: 0.8504\n",
      "Epoch 7662/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0444 - accuracy: 0.9867 - val_loss: 0.7721 - val_accuracy: 0.8542\n",
      "Epoch 7663/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0416 - accuracy: 0.9867 - val_loss: 0.7790 - val_accuracy: 0.8551\n",
      "Epoch 7664/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0397 - accuracy: 0.9881 - val_loss: 0.7607 - val_accuracy: 0.8532\n",
      "Epoch 7665/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0397 - accuracy: 0.9876 - val_loss: 0.9016 - val_accuracy: 0.8444\n",
      "Epoch 7666/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0452 - accuracy: 0.9861 - val_loss: 0.7419 - val_accuracy: 0.8595\n",
      "Epoch 7667/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0436 - accuracy: 0.9862 - val_loss: 0.7786 - val_accuracy: 0.8465\n",
      "Epoch 7668/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0393 - accuracy: 0.9879 - val_loss: 0.7645 - val_accuracy: 0.8539\n",
      "Epoch 7669/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0454 - accuracy: 0.9863 - val_loss: 0.7622 - val_accuracy: 0.8531\n",
      "Epoch 7670/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0440 - accuracy: 0.9863 - val_loss: 0.8965 - val_accuracy: 0.8448\n",
      "Epoch 7671/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0424 - accuracy: 0.9869 - val_loss: 0.7806 - val_accuracy: 0.8559\n",
      "Epoch 7672/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0415 - accuracy: 0.9868 - val_loss: 0.7435 - val_accuracy: 0.8583\n",
      "Epoch 7673/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0438 - accuracy: 0.9866 - val_loss: 0.7769 - val_accuracy: 0.8507\n",
      "Epoch 7674/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0470 - accuracy: 0.9855 - val_loss: 0.7332 - val_accuracy: 0.8565\n",
      "Epoch 7675/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0399 - accuracy: 0.9871 - val_loss: 0.7810 - val_accuracy: 0.8550\n",
      "Epoch 7676/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0431 - accuracy: 0.9865 - val_loss: 0.7668 - val_accuracy: 0.8559\n",
      "Epoch 7677/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0458 - accuracy: 0.9862 - val_loss: 0.7889 - val_accuracy: 0.8553\n",
      "Epoch 7678/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0428 - accuracy: 0.9865 - val_loss: 0.7257 - val_accuracy: 0.8622\n",
      "Epoch 7679/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0415 - accuracy: 0.9870 - val_loss: 0.7689 - val_accuracy: 0.8496\n",
      "Epoch 7680/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0430 - accuracy: 0.9868 - val_loss: 0.7437 - val_accuracy: 0.8576\n",
      "Epoch 7681/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0416 - accuracy: 0.9875 - val_loss: 0.7809 - val_accuracy: 0.8576\n",
      "Epoch 7682/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0438 - accuracy: 0.9861 - val_loss: 0.7946 - val_accuracy: 0.8531\n",
      "Epoch 7683/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0417 - accuracy: 0.9871 - val_loss: 0.7916 - val_accuracy: 0.8558\n",
      "Epoch 7684/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0432 - accuracy: 0.9862 - val_loss: 0.7714 - val_accuracy: 0.8531\n",
      "Epoch 7685/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0426 - accuracy: 0.9865 - val_loss: 0.7304 - val_accuracy: 0.8616\n",
      "Epoch 7686/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0412 - accuracy: 0.9873 - val_loss: 0.7283 - val_accuracy: 0.8613\n",
      "Epoch 7687/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0416 - accuracy: 0.9875 - val_loss: 0.7734 - val_accuracy: 0.8503\n",
      "Epoch 7688/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0368 - accuracy: 0.9883 - val_loss: 0.7938 - val_accuracy: 0.8468\n",
      "Epoch 7689/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0449 - accuracy: 0.9859 - val_loss: 0.7243 - val_accuracy: 0.8597\n",
      "Epoch 7690/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0400 - accuracy: 0.9871 - val_loss: 0.7129 - val_accuracy: 0.8615\n",
      "Epoch 7691/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0412 - accuracy: 0.9867 - val_loss: 0.7550 - val_accuracy: 0.8557\n",
      "Epoch 7692/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0487 - accuracy: 0.9855 - val_loss: 0.7556 - val_accuracy: 0.8598\n",
      "Epoch 7693/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0460 - accuracy: 0.9857 - val_loss: 0.8409 - val_accuracy: 0.8530\n",
      "Epoch 7694/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0409 - accuracy: 0.9874 - val_loss: 0.7366 - val_accuracy: 0.8612\n",
      "Epoch 7695/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0469 - accuracy: 0.9858 - val_loss: 0.7943 - val_accuracy: 0.8446\n",
      "Epoch 7696/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0412 - accuracy: 0.9871 - val_loss: 0.7503 - val_accuracy: 0.8566\n",
      "Epoch 7697/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0464 - accuracy: 0.9854 - val_loss: 0.7399 - val_accuracy: 0.8535\n",
      "Epoch 7698/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0396 - accuracy: 0.9880 - val_loss: 0.6968 - val_accuracy: 0.8610\n",
      "Epoch 7699/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0434 - accuracy: 0.9866 - val_loss: 0.7415 - val_accuracy: 0.8631\n",
      "Epoch 7700/8000\n",
      "1460/1463 [============================>.] - ETA: 0s - loss: 0.0487 - accuracy: 0.9849\n",
      "Epoch 7700: saving model to ./training_ckpt_20240109205949_v8_240109_d10000_n4096_b64_e8000_c100_Adamax\\cp-000007700.ckpt\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0487 - accuracy: 0.9849 - val_loss: 0.7411 - val_accuracy: 0.8574\n",
      "Epoch 7701/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0415 - accuracy: 0.9867 - val_loss: 0.7954 - val_accuracy: 0.8539\n",
      "Epoch 7702/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0387 - accuracy: 0.9879 - val_loss: 0.7723 - val_accuracy: 0.8529\n",
      "Epoch 7703/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0395 - accuracy: 0.9881 - val_loss: 0.7670 - val_accuracy: 0.8535\n",
      "Epoch 7704/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0427 - accuracy: 0.9871 - val_loss: 0.8014 - val_accuracy: 0.8487\n",
      "Epoch 7705/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0453 - accuracy: 0.9862 - val_loss: 0.7601 - val_accuracy: 0.8559\n",
      "Epoch 7706/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0451 - accuracy: 0.9866 - val_loss: 0.7750 - val_accuracy: 0.8538\n",
      "Epoch 7707/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0418 - accuracy: 0.9866 - val_loss: 0.7217 - val_accuracy: 0.8590\n",
      "Epoch 7708/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0358 - accuracy: 0.9888 - val_loss: 0.6976 - val_accuracy: 0.8636\n",
      "Epoch 7709/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0396 - accuracy: 0.9881 - val_loss: 0.7651 - val_accuracy: 0.8561\n",
      "Epoch 7710/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0450 - accuracy: 0.9855 - val_loss: 0.7276 - val_accuracy: 0.8621\n",
      "Epoch 7711/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0397 - accuracy: 0.9876 - val_loss: 0.7076 - val_accuracy: 0.8650\n",
      "Epoch 7712/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0414 - accuracy: 0.9874 - val_loss: 0.7281 - val_accuracy: 0.8600\n",
      "Epoch 7713/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0390 - accuracy: 0.9877 - val_loss: 0.9263 - val_accuracy: 0.8314\n",
      "Epoch 7714/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0422 - accuracy: 0.9867 - val_loss: 0.7433 - val_accuracy: 0.8605\n",
      "Epoch 7715/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0426 - accuracy: 0.9873 - val_loss: 0.7558 - val_accuracy: 0.8531\n",
      "Epoch 7716/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0399 - accuracy: 0.9875 - val_loss: 0.7948 - val_accuracy: 0.8493\n",
      "Epoch 7717/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0400 - accuracy: 0.9876 - val_loss: 0.7346 - val_accuracy: 0.8598\n",
      "Epoch 7718/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0430 - accuracy: 0.9863 - val_loss: 0.7214 - val_accuracy: 0.8633\n",
      "Epoch 7719/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0402 - accuracy: 0.9875 - val_loss: 0.7824 - val_accuracy: 0.8582\n",
      "Epoch 7720/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0450 - accuracy: 0.9861 - val_loss: 0.7380 - val_accuracy: 0.8583\n",
      "Epoch 7721/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0409 - accuracy: 0.9873 - val_loss: 0.7179 - val_accuracy: 0.8594\n",
      "Epoch 7722/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0456 - accuracy: 0.9861 - val_loss: 0.8357 - val_accuracy: 0.8468\n",
      "Epoch 7723/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0410 - accuracy: 0.9872 - val_loss: 0.7018 - val_accuracy: 0.8647\n",
      "Epoch 7724/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0423 - accuracy: 0.9873 - val_loss: 0.7290 - val_accuracy: 0.8605\n",
      "Epoch 7725/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0440 - accuracy: 0.9862 - val_loss: 0.7525 - val_accuracy: 0.8590\n",
      "Epoch 7726/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0431 - accuracy: 0.9870 - val_loss: 0.7606 - val_accuracy: 0.8555\n",
      "Epoch 7727/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0444 - accuracy: 0.9859 - val_loss: 0.7912 - val_accuracy: 0.8538\n",
      "Epoch 7728/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0388 - accuracy: 0.9879 - val_loss: 0.7323 - val_accuracy: 0.8627\n",
      "Epoch 7729/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0438 - accuracy: 0.9866 - val_loss: 0.7329 - val_accuracy: 0.8606\n",
      "Epoch 7730/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0388 - accuracy: 0.9877 - val_loss: 0.7566 - val_accuracy: 0.8561\n",
      "Epoch 7731/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0420 - accuracy: 0.9872 - val_loss: 0.7865 - val_accuracy: 0.8537\n",
      "Epoch 7732/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0421 - accuracy: 0.9869 - val_loss: 0.7706 - val_accuracy: 0.8550\n",
      "Epoch 7733/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0499 - accuracy: 0.9846 - val_loss: 0.7251 - val_accuracy: 0.8587\n",
      "Epoch 7734/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0411 - accuracy: 0.9871 - val_loss: 0.7824 - val_accuracy: 0.8538\n",
      "Epoch 7735/8000\n",
      "1463/1463 [==============================] - 15s 10ms/step - loss: 0.0440 - accuracy: 0.9864 - val_loss: 0.7391 - val_accuracy: 0.8559\n",
      "Epoch 7736/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0438 - accuracy: 0.9863 - val_loss: 0.7837 - val_accuracy: 0.8545\n",
      "Epoch 7737/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0457 - accuracy: 0.9865 - val_loss: 0.8036 - val_accuracy: 0.8534\n",
      "Epoch 7738/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0424 - accuracy: 0.9870 - val_loss: 0.7299 - val_accuracy: 0.8582\n",
      "Epoch 7739/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0439 - accuracy: 0.9862 - val_loss: 0.8421 - val_accuracy: 0.8479\n",
      "Epoch 7740/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0437 - accuracy: 0.9859 - val_loss: 0.7407 - val_accuracy: 0.8587\n",
      "Epoch 7741/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0384 - accuracy: 0.9878 - val_loss: 0.7003 - val_accuracy: 0.8664\n",
      "Epoch 7742/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0457 - accuracy: 0.9857 - val_loss: 0.7374 - val_accuracy: 0.8601\n",
      "Epoch 7743/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0440 - accuracy: 0.9864 - val_loss: 0.7964 - val_accuracy: 0.8518\n",
      "Epoch 7744/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0414 - accuracy: 0.9868 - val_loss: 0.8780 - val_accuracy: 0.8447\n",
      "Epoch 7745/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0452 - accuracy: 0.9862 - val_loss: 0.7675 - val_accuracy: 0.8563\n",
      "Epoch 7746/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0438 - accuracy: 0.9864 - val_loss: 0.7387 - val_accuracy: 0.8599\n",
      "Epoch 7747/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0455 - accuracy: 0.9863 - val_loss: 0.7320 - val_accuracy: 0.8593\n",
      "Epoch 7748/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0397 - accuracy: 0.9879 - val_loss: 0.7790 - val_accuracy: 0.8535\n",
      "Epoch 7749/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0426 - accuracy: 0.9866 - val_loss: 0.7434 - val_accuracy: 0.8584\n",
      "Epoch 7750/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0358 - accuracy: 0.9884 - val_loss: 0.7250 - val_accuracy: 0.8610\n",
      "Epoch 7751/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0395 - accuracy: 0.9873 - val_loss: 0.7480 - val_accuracy: 0.8584\n",
      "Epoch 7752/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0404 - accuracy: 0.9874 - val_loss: 0.7873 - val_accuracy: 0.8537\n",
      "Epoch 7753/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0417 - accuracy: 0.9869 - val_loss: 0.7607 - val_accuracy: 0.8570\n",
      "Epoch 7754/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0467 - accuracy: 0.9861 - val_loss: 0.7618 - val_accuracy: 0.8573\n",
      "Epoch 7755/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0379 - accuracy: 0.9882 - val_loss: 0.7586 - val_accuracy: 0.8569\n",
      "Epoch 7756/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0420 - accuracy: 0.9874 - val_loss: 0.8156 - val_accuracy: 0.8453\n",
      "Epoch 7757/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0466 - accuracy: 0.9863 - val_loss: 0.7790 - val_accuracy: 0.8534\n",
      "Epoch 7758/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0416 - accuracy: 0.9869 - val_loss: 0.7874 - val_accuracy: 0.8562\n",
      "Epoch 7759/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0415 - accuracy: 0.9875 - val_loss: 0.7836 - val_accuracy: 0.8524\n",
      "Epoch 7760/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0424 - accuracy: 0.9868 - val_loss: 0.7308 - val_accuracy: 0.8613\n",
      "Epoch 7761/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0429 - accuracy: 0.9868 - val_loss: 0.8837 - val_accuracy: 0.8438\n",
      "Epoch 7762/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0437 - accuracy: 0.9865 - val_loss: 0.7407 - val_accuracy: 0.8558\n",
      "Epoch 7763/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0416 - accuracy: 0.9875 - val_loss: 0.7192 - val_accuracy: 0.8620\n",
      "Epoch 7764/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0467 - accuracy: 0.9857 - val_loss: 0.7668 - val_accuracy: 0.8513\n",
      "Epoch 7765/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0422 - accuracy: 0.9872 - val_loss: 0.7413 - val_accuracy: 0.8575\n",
      "Epoch 7766/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0402 - accuracy: 0.9876 - val_loss: 0.7874 - val_accuracy: 0.8510\n",
      "Epoch 7767/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0463 - accuracy: 0.9858 - val_loss: 0.8331 - val_accuracy: 0.8439\n",
      "Epoch 7768/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0418 - accuracy: 0.9874 - val_loss: 0.7865 - val_accuracy: 0.8532\n",
      "Epoch 7769/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0463 - accuracy: 0.9860 - val_loss: 0.7566 - val_accuracy: 0.8547\n",
      "Epoch 7770/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0411 - accuracy: 0.9869 - val_loss: 0.7368 - val_accuracy: 0.8624\n",
      "Epoch 7771/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0389 - accuracy: 0.9875 - val_loss: 0.7854 - val_accuracy: 0.8525\n",
      "Epoch 7772/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0400 - accuracy: 0.9878 - val_loss: 0.7110 - val_accuracy: 0.8637\n",
      "Epoch 7773/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0441 - accuracy: 0.9870 - val_loss: 0.9247 - val_accuracy: 0.8387\n",
      "Epoch 7774/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0429 - accuracy: 0.9870 - val_loss: 0.7139 - val_accuracy: 0.8632\n",
      "Epoch 7775/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0445 - accuracy: 0.9866 - val_loss: 0.7984 - val_accuracy: 0.8491\n",
      "Epoch 7776/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0413 - accuracy: 0.9874 - val_loss: 0.7505 - val_accuracy: 0.8583\n",
      "Epoch 7777/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0414 - accuracy: 0.9871 - val_loss: 0.7486 - val_accuracy: 0.8563\n",
      "Epoch 7778/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0422 - accuracy: 0.9871 - val_loss: 0.9939 - val_accuracy: 0.8387\n",
      "Epoch 7779/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0495 - accuracy: 0.9850 - val_loss: 0.7430 - val_accuracy: 0.8555\n",
      "Epoch 7780/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0438 - accuracy: 0.9864 - val_loss: 0.7361 - val_accuracy: 0.8604\n",
      "Epoch 7781/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0445 - accuracy: 0.9865 - val_loss: 0.7204 - val_accuracy: 0.8651\n",
      "Epoch 7782/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0435 - accuracy: 0.9875 - val_loss: 0.8440 - val_accuracy: 0.8460\n",
      "Epoch 7783/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0364 - accuracy: 0.9888 - val_loss: 0.7712 - val_accuracy: 0.8552\n",
      "Epoch 7784/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0413 - accuracy: 0.9872 - val_loss: 0.7776 - val_accuracy: 0.8567\n",
      "Epoch 7785/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0452 - accuracy: 0.9862 - val_loss: 0.7278 - val_accuracy: 0.8603\n",
      "Epoch 7786/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0411 - accuracy: 0.9873 - val_loss: 0.8139 - val_accuracy: 0.8485\n",
      "Epoch 7787/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0407 - accuracy: 0.9881 - val_loss: 0.7595 - val_accuracy: 0.8598\n",
      "Epoch 7788/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0365 - accuracy: 0.9888 - val_loss: 0.7152 - val_accuracy: 0.8641\n",
      "Epoch 7789/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0384 - accuracy: 0.9879 - val_loss: 0.7305 - val_accuracy: 0.8602\n",
      "Epoch 7790/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0419 - accuracy: 0.9875 - val_loss: 0.7284 - val_accuracy: 0.8641\n",
      "Epoch 7791/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0399 - accuracy: 0.9874 - val_loss: 0.7973 - val_accuracy: 0.8486\n",
      "Epoch 7792/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0410 - accuracy: 0.9875 - val_loss: 0.7804 - val_accuracy: 0.8531\n",
      "Epoch 7793/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0404 - accuracy: 0.9876 - val_loss: 0.8099 - val_accuracy: 0.8445\n",
      "Epoch 7794/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0462 - accuracy: 0.9857 - val_loss: 0.7563 - val_accuracy: 0.8571\n",
      "Epoch 7795/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0444 - accuracy: 0.9871 - val_loss: 0.7741 - val_accuracy: 0.8515\n",
      "Epoch 7796/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0373 - accuracy: 0.9883 - val_loss: 0.7156 - val_accuracy: 0.8653\n",
      "Epoch 7797/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0405 - accuracy: 0.9875 - val_loss: 0.7867 - val_accuracy: 0.8537\n",
      "Epoch 7798/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0418 - accuracy: 0.9866 - val_loss: 0.7048 - val_accuracy: 0.8673\n",
      "Epoch 7799/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0401 - accuracy: 0.9876 - val_loss: 0.7488 - val_accuracy: 0.8599\n",
      "Epoch 7800/8000\n",
      "1459/1463 [============================>.] - ETA: 0s - loss: 0.0378 - accuracy: 0.9887\n",
      "Epoch 7800: saving model to ./training_ckpt_20240109205949_v8_240109_d10000_n4096_b64_e8000_c100_Adamax\\cp-000007800.ckpt\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0378 - accuracy: 0.9887 - val_loss: 0.7117 - val_accuracy: 0.8655\n",
      "Epoch 7801/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0379 - accuracy: 0.9880 - val_loss: 0.7298 - val_accuracy: 0.8621\n",
      "Epoch 7802/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0425 - accuracy: 0.9866 - val_loss: 0.7641 - val_accuracy: 0.8568\n",
      "Epoch 7803/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0429 - accuracy: 0.9862 - val_loss: 0.7952 - val_accuracy: 0.8484\n",
      "Epoch 7804/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0406 - accuracy: 0.9869 - val_loss: 0.7755 - val_accuracy: 0.8550\n",
      "Epoch 7805/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0438 - accuracy: 0.9871 - val_loss: 0.7209 - val_accuracy: 0.8659\n",
      "Epoch 7806/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0417 - accuracy: 0.9874 - val_loss: 0.7858 - val_accuracy: 0.8554\n",
      "Epoch 7807/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0451 - accuracy: 0.9860 - val_loss: 0.7402 - val_accuracy: 0.8614\n",
      "Epoch 7808/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0446 - accuracy: 0.9860 - val_loss: 0.7562 - val_accuracy: 0.8560\n",
      "Epoch 7809/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0415 - accuracy: 0.9877 - val_loss: 0.7606 - val_accuracy: 0.8551\n",
      "Epoch 7810/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0407 - accuracy: 0.9873 - val_loss: 0.7523 - val_accuracy: 0.8586\n",
      "Epoch 7811/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0378 - accuracy: 0.9882 - val_loss: 0.7252 - val_accuracy: 0.8603\n",
      "Epoch 7812/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0421 - accuracy: 0.9870 - val_loss: 0.7865 - val_accuracy: 0.8502\n",
      "Epoch 7813/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0427 - accuracy: 0.9867 - val_loss: 0.8036 - val_accuracy: 0.8476\n",
      "Epoch 7814/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0387 - accuracy: 0.9878 - val_loss: 0.7306 - val_accuracy: 0.8597\n",
      "Epoch 7815/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0381 - accuracy: 0.9878 - val_loss: 0.7002 - val_accuracy: 0.8650\n",
      "Epoch 7816/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0407 - accuracy: 0.9879 - val_loss: 0.7488 - val_accuracy: 0.8537\n",
      "Epoch 7817/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0491 - accuracy: 0.9854 - val_loss: 0.7340 - val_accuracy: 0.8625\n",
      "Epoch 7818/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0459 - accuracy: 0.9860 - val_loss: 0.7179 - val_accuracy: 0.8632\n",
      "Epoch 7819/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0455 - accuracy: 0.9860 - val_loss: 0.7266 - val_accuracy: 0.8642\n",
      "Epoch 7820/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0355 - accuracy: 0.9888 - val_loss: 0.7898 - val_accuracy: 0.8523\n",
      "Epoch 7821/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0423 - accuracy: 0.9866 - val_loss: 0.7673 - val_accuracy: 0.8545\n",
      "Epoch 7822/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0384 - accuracy: 0.9882 - val_loss: 0.7716 - val_accuracy: 0.8550\n",
      "Epoch 7823/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0401 - accuracy: 0.9878 - val_loss: 0.7796 - val_accuracy: 0.8532\n",
      "Epoch 7824/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0478 - accuracy: 0.9855 - val_loss: 0.7271 - val_accuracy: 0.8623\n",
      "Epoch 7825/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0384 - accuracy: 0.9882 - val_loss: 0.7410 - val_accuracy: 0.8576\n",
      "Epoch 7826/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0442 - accuracy: 0.9863 - val_loss: 0.7708 - val_accuracy: 0.8553\n",
      "Epoch 7827/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0422 - accuracy: 0.9866 - val_loss: 0.8210 - val_accuracy: 0.8517\n",
      "Epoch 7828/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0426 - accuracy: 0.9871 - val_loss: 0.7126 - val_accuracy: 0.8614\n",
      "Epoch 7829/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0405 - accuracy: 0.9878 - val_loss: 0.8321 - val_accuracy: 0.8484\n",
      "Epoch 7830/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0481 - accuracy: 0.9851 - val_loss: 0.7957 - val_accuracy: 0.8543\n",
      "Epoch 7831/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0385 - accuracy: 0.9878 - val_loss: 0.7714 - val_accuracy: 0.8564\n",
      "Epoch 7832/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0372 - accuracy: 0.9885 - val_loss: 0.7293 - val_accuracy: 0.8608\n",
      "Epoch 7833/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0402 - accuracy: 0.9870 - val_loss: 0.7888 - val_accuracy: 0.8516\n",
      "Epoch 7834/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0373 - accuracy: 0.9880 - val_loss: 0.7368 - val_accuracy: 0.8590\n",
      "Epoch 7835/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0462 - accuracy: 0.9855 - val_loss: 0.7405 - val_accuracy: 0.8589\n",
      "Epoch 7836/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0399 - accuracy: 0.9876 - val_loss: 0.7346 - val_accuracy: 0.8560\n",
      "Epoch 7837/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0393 - accuracy: 0.9876 - val_loss: 0.8053 - val_accuracy: 0.8492\n",
      "Epoch 7838/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0450 - accuracy: 0.9861 - val_loss: 0.7142 - val_accuracy: 0.8623\n",
      "Epoch 7839/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0460 - accuracy: 0.9862 - val_loss: 0.7522 - val_accuracy: 0.8566\n",
      "Epoch 7840/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0442 - accuracy: 0.9860 - val_loss: 0.7751 - val_accuracy: 0.8572\n",
      "Epoch 7841/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0407 - accuracy: 0.9870 - val_loss: 0.7842 - val_accuracy: 0.8529\n",
      "Epoch 7842/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0405 - accuracy: 0.9874 - val_loss: 0.7115 - val_accuracy: 0.8621\n",
      "Epoch 7843/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0407 - accuracy: 0.9868 - val_loss: 0.7423 - val_accuracy: 0.8580\n",
      "Epoch 7844/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0495 - accuracy: 0.9854 - val_loss: 0.7088 - val_accuracy: 0.8639\n",
      "Epoch 7845/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0446 - accuracy: 0.9859 - val_loss: 0.7735 - val_accuracy: 0.8557\n",
      "Epoch 7846/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0407 - accuracy: 0.9871 - val_loss: 0.7562 - val_accuracy: 0.8584\n",
      "Epoch 7847/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0440 - accuracy: 0.9867 - val_loss: 0.7874 - val_accuracy: 0.8479\n",
      "Epoch 7848/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0461 - accuracy: 0.9862 - val_loss: 0.7508 - val_accuracy: 0.8591\n",
      "Epoch 7849/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0403 - accuracy: 0.9872 - val_loss: 0.8719 - val_accuracy: 0.8481\n",
      "Epoch 7850/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0476 - accuracy: 0.9857 - val_loss: 0.8353 - val_accuracy: 0.8482\n",
      "Epoch 7851/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0401 - accuracy: 0.9879 - val_loss: 0.7335 - val_accuracy: 0.8599\n",
      "Epoch 7852/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0398 - accuracy: 0.9881 - val_loss: 0.7157 - val_accuracy: 0.8634\n",
      "Epoch 7853/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0446 - accuracy: 0.9864 - val_loss: 0.8218 - val_accuracy: 0.8475\n",
      "Epoch 7854/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0434 - accuracy: 0.9865 - val_loss: 0.7810 - val_accuracy: 0.8525\n",
      "Epoch 7855/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0427 - accuracy: 0.9867 - val_loss: 0.8994 - val_accuracy: 0.8466\n",
      "Epoch 7856/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0431 - accuracy: 0.9868 - val_loss: 0.7831 - val_accuracy: 0.8516\n",
      "Epoch 7857/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0427 - accuracy: 0.9869 - val_loss: 0.7412 - val_accuracy: 0.8588\n",
      "Epoch 7858/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0418 - accuracy: 0.9873 - val_loss: 0.8322 - val_accuracy: 0.8451\n",
      "Epoch 7859/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0406 - accuracy: 0.9874 - val_loss: 0.7197 - val_accuracy: 0.8619\n",
      "Epoch 7860/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0431 - accuracy: 0.9867 - val_loss: 0.7410 - val_accuracy: 0.8577\n",
      "Epoch 7861/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0450 - accuracy: 0.9865 - val_loss: 0.7773 - val_accuracy: 0.8533\n",
      "Epoch 7862/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0458 - accuracy: 0.9863 - val_loss: 0.7784 - val_accuracy: 0.8540\n",
      "Epoch 7863/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0425 - accuracy: 0.9872 - val_loss: 0.6983 - val_accuracy: 0.8605\n",
      "Epoch 7864/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0378 - accuracy: 0.9887 - val_loss: 0.7082 - val_accuracy: 0.8640\n",
      "Epoch 7865/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0394 - accuracy: 0.9875 - val_loss: 0.7031 - val_accuracy: 0.8663\n",
      "Epoch 7866/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0396 - accuracy: 0.9875 - val_loss: 0.6816 - val_accuracy: 0.8680\n",
      "Epoch 7867/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0447 - accuracy: 0.9861 - val_loss: 0.7343 - val_accuracy: 0.8575\n",
      "Epoch 7868/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0389 - accuracy: 0.9875 - val_loss: 0.7674 - val_accuracy: 0.8517\n",
      "Epoch 7869/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0368 - accuracy: 0.9887 - val_loss: 0.7438 - val_accuracy: 0.8556\n",
      "Epoch 7870/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0429 - accuracy: 0.9866 - val_loss: 0.7273 - val_accuracy: 0.8600\n",
      "Epoch 7871/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0371 - accuracy: 0.9891 - val_loss: 0.7725 - val_accuracy: 0.8564\n",
      "Epoch 7872/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0425 - accuracy: 0.9867 - val_loss: 0.7323 - val_accuracy: 0.8594\n",
      "Epoch 7873/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0428 - accuracy: 0.9869 - val_loss: 0.8780 - val_accuracy: 0.8375\n",
      "Epoch 7874/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0451 - accuracy: 0.9859 - val_loss: 0.7570 - val_accuracy: 0.8540\n",
      "Epoch 7875/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0392 - accuracy: 0.9875 - val_loss: 0.7782 - val_accuracy: 0.8521\n",
      "Epoch 7876/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0485 - accuracy: 0.9855 - val_loss: 0.7791 - val_accuracy: 0.8532\n",
      "Epoch 7877/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0402 - accuracy: 0.9878 - val_loss: 0.7915 - val_accuracy: 0.8510\n",
      "Epoch 7878/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0428 - accuracy: 0.9872 - val_loss: 0.7293 - val_accuracy: 0.8601\n",
      "Epoch 7879/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0400 - accuracy: 0.9877 - val_loss: 0.7321 - val_accuracy: 0.8589\n",
      "Epoch 7880/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0416 - accuracy: 0.9877 - val_loss: 0.7333 - val_accuracy: 0.8635\n",
      "Epoch 7881/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0433 - accuracy: 0.9865 - val_loss: 0.7246 - val_accuracy: 0.8619\n",
      "Epoch 7882/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0391 - accuracy: 0.9884 - val_loss: 0.8075 - val_accuracy: 0.8505\n",
      "Epoch 7883/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0475 - accuracy: 0.9854 - val_loss: 0.7311 - val_accuracy: 0.8556\n",
      "Epoch 7884/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0378 - accuracy: 0.9884 - val_loss: 0.7346 - val_accuracy: 0.8630\n",
      "Epoch 7885/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0454 - accuracy: 0.9864 - val_loss: 0.8182 - val_accuracy: 0.8450\n",
      "Epoch 7886/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0431 - accuracy: 0.9870 - val_loss: 0.7937 - val_accuracy: 0.8491\n",
      "Epoch 7887/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0411 - accuracy: 0.9871 - val_loss: 0.7190 - val_accuracy: 0.8672\n",
      "Epoch 7888/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0382 - accuracy: 0.9879 - val_loss: 0.7629 - val_accuracy: 0.8537\n",
      "Epoch 7889/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0453 - accuracy: 0.9863 - val_loss: 0.7460 - val_accuracy: 0.8582\n",
      "Epoch 7890/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0398 - accuracy: 0.9879 - val_loss: 0.7658 - val_accuracy: 0.8548\n",
      "Epoch 7891/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0395 - accuracy: 0.9877 - val_loss: 0.7706 - val_accuracy: 0.8538\n",
      "Epoch 7892/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0432 - accuracy: 0.9871 - val_loss: 0.7503 - val_accuracy: 0.8589\n",
      "Epoch 7893/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0417 - accuracy: 0.9873 - val_loss: 0.7460 - val_accuracy: 0.8572\n",
      "Epoch 7894/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0409 - accuracy: 0.9874 - val_loss: 0.7506 - val_accuracy: 0.8588\n",
      "Epoch 7895/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0407 - accuracy: 0.9875 - val_loss: 0.7162 - val_accuracy: 0.8619\n",
      "Epoch 7896/8000\n",
      "1463/1463 [==============================] - 12s 9ms/step - loss: 0.0449 - accuracy: 0.9858 - val_loss: 0.8037 - val_accuracy: 0.8547\n",
      "Epoch 7897/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0371 - accuracy: 0.9886 - val_loss: 0.7758 - val_accuracy: 0.8534\n",
      "Epoch 7898/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0437 - accuracy: 0.9865 - val_loss: 0.7537 - val_accuracy: 0.8576\n",
      "Epoch 7899/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0450 - accuracy: 0.9860 - val_loss: 0.7516 - val_accuracy: 0.8594\n",
      "Epoch 7900/8000\n",
      "1461/1463 [============================>.] - ETA: 0s - loss: 0.0407 - accuracy: 0.9872\n",
      "Epoch 7900: saving model to ./training_ckpt_20240109205949_v8_240109_d10000_n4096_b64_e8000_c100_Adamax\\cp-000007900.ckpt\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0407 - accuracy: 0.9872 - val_loss: 0.7947 - val_accuracy: 0.8509\n",
      "Epoch 7901/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0428 - accuracy: 0.9869 - val_loss: 0.7271 - val_accuracy: 0.8619\n",
      "Epoch 7902/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0385 - accuracy: 0.9877 - val_loss: 0.7425 - val_accuracy: 0.8609\n",
      "Epoch 7903/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0432 - accuracy: 0.9870 - val_loss: 0.8116 - val_accuracy: 0.8483\n",
      "Epoch 7904/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0405 - accuracy: 0.9871 - val_loss: 0.7446 - val_accuracy: 0.8602\n",
      "Epoch 7905/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0417 - accuracy: 0.9874 - val_loss: 0.7711 - val_accuracy: 0.8564\n",
      "Epoch 7906/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0430 - accuracy: 0.9863 - val_loss: 0.7353 - val_accuracy: 0.8583\n",
      "Epoch 7907/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0413 - accuracy: 0.9872 - val_loss: 0.7634 - val_accuracy: 0.8515\n",
      "Epoch 7908/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0408 - accuracy: 0.9878 - val_loss: 0.8288 - val_accuracy: 0.8466\n",
      "Epoch 7909/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0421 - accuracy: 0.9868 - val_loss: 0.7557 - val_accuracy: 0.8580\n",
      "Epoch 7910/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0443 - accuracy: 0.9865 - val_loss: 0.7267 - val_accuracy: 0.8599\n",
      "Epoch 7911/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0376 - accuracy: 0.9881 - val_loss: 0.8338 - val_accuracy: 0.8495\n",
      "Epoch 7912/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0443 - accuracy: 0.9866 - val_loss: 0.7692 - val_accuracy: 0.8558\n",
      "Epoch 7913/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0466 - accuracy: 0.9862 - val_loss: 0.7575 - val_accuracy: 0.8574\n",
      "Epoch 7914/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0377 - accuracy: 0.9882 - val_loss: 0.7436 - val_accuracy: 0.8598\n",
      "Epoch 7915/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0399 - accuracy: 0.9881 - val_loss: 0.7057 - val_accuracy: 0.8644\n",
      "Epoch 7916/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0399 - accuracy: 0.9877 - val_loss: 0.8093 - val_accuracy: 0.8536\n",
      "Epoch 7917/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0390 - accuracy: 0.9879 - val_loss: 0.7571 - val_accuracy: 0.8617\n",
      "Epoch 7918/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0402 - accuracy: 0.9876 - val_loss: 0.8299 - val_accuracy: 0.8493\n",
      "Epoch 7919/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0424 - accuracy: 0.9872 - val_loss: 0.7206 - val_accuracy: 0.8675\n",
      "Epoch 7920/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0400 - accuracy: 0.9878 - val_loss: 0.7373 - val_accuracy: 0.8615\n",
      "Epoch 7921/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0464 - accuracy: 0.9859 - val_loss: 0.7193 - val_accuracy: 0.8637\n",
      "Epoch 7922/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0389 - accuracy: 0.9877 - val_loss: 0.7434 - val_accuracy: 0.8573\n",
      "Epoch 7923/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0392 - accuracy: 0.9877 - val_loss: 0.8203 - val_accuracy: 0.8466\n",
      "Epoch 7924/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0429 - accuracy: 0.9869 - val_loss: 0.7295 - val_accuracy: 0.8649\n",
      "Epoch 7925/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0448 - accuracy: 0.9863 - val_loss: 0.7378 - val_accuracy: 0.8569\n",
      "Epoch 7926/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0389 - accuracy: 0.9879 - val_loss: 0.7390 - val_accuracy: 0.8608\n",
      "Epoch 7927/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0392 - accuracy: 0.9879 - val_loss: 0.7555 - val_accuracy: 0.8569\n",
      "Epoch 7928/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0394 - accuracy: 0.9880 - val_loss: 0.7704 - val_accuracy: 0.8551\n",
      "Epoch 7929/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0457 - accuracy: 0.9856 - val_loss: 0.7256 - val_accuracy: 0.8609\n",
      "Epoch 7930/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0394 - accuracy: 0.9884 - val_loss: 0.7469 - val_accuracy: 0.8605\n",
      "Epoch 7931/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0437 - accuracy: 0.9864 - val_loss: 0.7178 - val_accuracy: 0.8630\n",
      "Epoch 7932/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0449 - accuracy: 0.9867 - val_loss: 0.7596 - val_accuracy: 0.8574\n",
      "Epoch 7933/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0399 - accuracy: 0.9873 - val_loss: 0.8603 - val_accuracy: 0.8431\n",
      "Epoch 7934/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0442 - accuracy: 0.9861 - val_loss: 0.7021 - val_accuracy: 0.8656\n",
      "Epoch 7935/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0374 - accuracy: 0.9887 - val_loss: 0.7423 - val_accuracy: 0.8587\n",
      "Epoch 7936/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0476 - accuracy: 0.9850 - val_loss: 0.7306 - val_accuracy: 0.8605\n",
      "Epoch 7937/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0403 - accuracy: 0.9882 - val_loss: 0.7563 - val_accuracy: 0.8604\n",
      "Epoch 7938/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0488 - accuracy: 0.9857 - val_loss: 0.7656 - val_accuracy: 0.8565\n",
      "Epoch 7939/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0441 - accuracy: 0.9868 - val_loss: 0.7229 - val_accuracy: 0.8629\n",
      "Epoch 7940/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0402 - accuracy: 0.9875 - val_loss: 0.7708 - val_accuracy: 0.8550\n",
      "Epoch 7941/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0401 - accuracy: 0.9875 - val_loss: 0.7920 - val_accuracy: 0.8504\n",
      "Epoch 7942/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0470 - accuracy: 0.9862 - val_loss: 0.8046 - val_accuracy: 0.8469\n",
      "Epoch 7943/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0404 - accuracy: 0.9870 - val_loss: 0.8042 - val_accuracy: 0.8513\n",
      "Epoch 7944/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0393 - accuracy: 0.9877 - val_loss: 0.7477 - val_accuracy: 0.8574\n",
      "Epoch 7945/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0409 - accuracy: 0.9875 - val_loss: 0.8064 - val_accuracy: 0.8501\n",
      "Epoch 7946/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0436 - accuracy: 0.9862 - val_loss: 0.7443 - val_accuracy: 0.8588\n",
      "Epoch 7947/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0371 - accuracy: 0.9886 - val_loss: 0.7532 - val_accuracy: 0.8580\n",
      "Epoch 7948/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0432 - accuracy: 0.9872 - val_loss: 0.7515 - val_accuracy: 0.8567\n",
      "Epoch 7949/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0387 - accuracy: 0.9876 - val_loss: 0.7262 - val_accuracy: 0.8604\n",
      "Epoch 7950/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0434 - accuracy: 0.9871 - val_loss: 0.7552 - val_accuracy: 0.8599\n",
      "Epoch 7951/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0397 - accuracy: 0.9881 - val_loss: 0.7297 - val_accuracy: 0.8635\n",
      "Epoch 7952/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0441 - accuracy: 0.9867 - val_loss: 0.7523 - val_accuracy: 0.8573\n",
      "Epoch 7953/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0393 - accuracy: 0.9877 - val_loss: 0.7445 - val_accuracy: 0.8564\n",
      "Epoch 7954/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0402 - accuracy: 0.9876 - val_loss: 0.7418 - val_accuracy: 0.8588\n",
      "Epoch 7955/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0419 - accuracy: 0.9873 - val_loss: 0.7975 - val_accuracy: 0.8522\n",
      "Epoch 7956/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0418 - accuracy: 0.9871 - val_loss: 0.7455 - val_accuracy: 0.8615\n",
      "Epoch 7957/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0466 - accuracy: 0.9856 - val_loss: 0.9658 - val_accuracy: 0.8398\n",
      "Epoch 7958/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0399 - accuracy: 0.9876 - val_loss: 0.7863 - val_accuracy: 0.8549\n",
      "Epoch 7959/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0405 - accuracy: 0.9877 - val_loss: 0.7198 - val_accuracy: 0.8611\n",
      "Epoch 7960/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0363 - accuracy: 0.9889 - val_loss: 0.7794 - val_accuracy: 0.8537\n",
      "Epoch 7961/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0428 - accuracy: 0.9869 - val_loss: 0.7085 - val_accuracy: 0.8606\n",
      "Epoch 7962/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0414 - accuracy: 0.9872 - val_loss: 0.7796 - val_accuracy: 0.8564\n",
      "Epoch 7963/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0425 - accuracy: 0.9870 - val_loss: 0.7573 - val_accuracy: 0.8584\n",
      "Epoch 7964/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0381 - accuracy: 0.9882 - val_loss: 0.7826 - val_accuracy: 0.8548\n",
      "Epoch 7965/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0457 - accuracy: 0.9858 - val_loss: 0.6942 - val_accuracy: 0.8659\n",
      "Epoch 7966/8000\n",
      "1463/1463 [==============================] - 12s 8ms/step - loss: 0.0402 - accuracy: 0.9881 - val_loss: 0.7618 - val_accuracy: 0.8553\n",
      "Epoch 7967/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0403 - accuracy: 0.9879 - val_loss: 0.7767 - val_accuracy: 0.8600\n",
      "Epoch 7968/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0455 - accuracy: 0.9860 - val_loss: 0.7801 - val_accuracy: 0.8583\n",
      "Epoch 7969/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0383 - accuracy: 0.9884 - val_loss: 0.7337 - val_accuracy: 0.8597\n",
      "Epoch 7970/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0420 - accuracy: 0.9868 - val_loss: 0.8180 - val_accuracy: 0.8523\n",
      "Epoch 7971/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0410 - accuracy: 0.9871 - val_loss: 0.8215 - val_accuracy: 0.8507\n",
      "Epoch 7972/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0412 - accuracy: 0.9867 - val_loss: 0.7284 - val_accuracy: 0.8608\n",
      "Epoch 7973/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0404 - accuracy: 0.9874 - val_loss: 0.8149 - val_accuracy: 0.8494\n",
      "Epoch 7974/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0441 - accuracy: 0.9870 - val_loss: 0.7506 - val_accuracy: 0.8616\n",
      "Epoch 7975/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0398 - accuracy: 0.9873 - val_loss: 0.7529 - val_accuracy: 0.8566\n",
      "Epoch 7976/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0465 - accuracy: 0.9861 - val_loss: 0.7461 - val_accuracy: 0.8580\n",
      "Epoch 7977/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0386 - accuracy: 0.9874 - val_loss: 0.7257 - val_accuracy: 0.8610\n",
      "Epoch 7978/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0402 - accuracy: 0.9875 - val_loss: 0.7347 - val_accuracy: 0.8582\n",
      "Epoch 7979/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0434 - accuracy: 0.9863 - val_loss: 0.7794 - val_accuracy: 0.8551\n",
      "Epoch 7980/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0420 - accuracy: 0.9869 - val_loss: 0.7884 - val_accuracy: 0.8542\n",
      "Epoch 7981/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0386 - accuracy: 0.9880 - val_loss: 0.7966 - val_accuracy: 0.8522\n",
      "Epoch 7982/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0408 - accuracy: 0.9876 - val_loss: 0.7737 - val_accuracy: 0.8513\n",
      "Epoch 7983/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0396 - accuracy: 0.9876 - val_loss: 0.7309 - val_accuracy: 0.8653\n",
      "Epoch 7984/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0413 - accuracy: 0.9869 - val_loss: 0.7163 - val_accuracy: 0.8674\n",
      "Epoch 7985/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0424 - accuracy: 0.9870 - val_loss: 0.7470 - val_accuracy: 0.8581\n",
      "Epoch 7986/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0448 - accuracy: 0.9862 - val_loss: 0.7571 - val_accuracy: 0.8581\n",
      "Epoch 7987/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0436 - accuracy: 0.9866 - val_loss: 0.7503 - val_accuracy: 0.8597\n",
      "Epoch 7988/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0436 - accuracy: 0.9874 - val_loss: 0.7235 - val_accuracy: 0.8607\n",
      "Epoch 7989/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0350 - accuracy: 0.9891 - val_loss: 0.7516 - val_accuracy: 0.8585\n",
      "Epoch 7990/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0390 - accuracy: 0.9878 - val_loss: 0.8427 - val_accuracy: 0.8480\n",
      "Epoch 7991/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0392 - accuracy: 0.9881 - val_loss: 0.7538 - val_accuracy: 0.8579\n",
      "Epoch 7992/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0524 - accuracy: 0.9843 - val_loss: 0.7453 - val_accuracy: 0.8612\n",
      "Epoch 7993/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0384 - accuracy: 0.9878 - val_loss: 0.7641 - val_accuracy: 0.8578\n",
      "Epoch 7994/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0457 - accuracy: 0.9860 - val_loss: 0.7477 - val_accuracy: 0.8594\n",
      "Epoch 7995/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0431 - accuracy: 0.9871 - val_loss: 0.8588 - val_accuracy: 0.8471\n",
      "Epoch 7996/8000\n",
      "1463/1463 [==============================] - 14s 9ms/step - loss: 0.0440 - accuracy: 0.9867 - val_loss: 0.7808 - val_accuracy: 0.8525\n",
      "Epoch 7997/8000\n",
      "1463/1463 [==============================] - 14s 10ms/step - loss: 0.0428 - accuracy: 0.9866 - val_loss: 0.7230 - val_accuracy: 0.8624\n",
      "Epoch 7998/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0415 - accuracy: 0.9876 - val_loss: 0.7567 - val_accuracy: 0.8576\n",
      "Epoch 7999/8000\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0419 - accuracy: 0.9875 - val_loss: 0.8543 - val_accuracy: 0.8428\n",
      "Epoch 8000/8000\n",
      "1459/1463 [============================>.] - ETA: 0s - loss: 0.0412 - accuracy: 0.9872\n",
      "Epoch 8000: saving model to ./training_ckpt_20240109205949_v8_240109_d10000_n4096_b64_e8000_c100_Adamax\\cp-000008000.ckpt\n",
      "1463/1463 [==============================] - 13s 9ms/step - loss: 0.0412 - accuracy: 0.9872 - val_loss: 0.9251 - val_accuracy: 0.8415\n",
      "INFO:tensorflow:Assets written to: ./TrainedModel/20240109205949_v8_240109_d10000_n4096_b64_e8000_Adamax\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./TrainedModel/20240109205949_v8_240109_d10000_n4096_b64_e8000_Adamax\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "813/813 [==============================] - 2s 2ms/step - loss: 0.8837 - accuracy: 0.8439\n",
      "正解率(Accuracy)= 0.8439230918884277 loss= 0.8837326765060425\n",
      "813/813 [==============================] - 2s 2ms/step\n",
      "[0 1 3 ... 9 3 6]\n",
      "              precision    recall  f1-score       support\n",
      "0              0.821616  0.782218  0.801433   2002.000000\n",
      "1              0.816066  0.815321  0.815693   2193.000000\n",
      "2              0.854580  0.831419  0.842841   2177.000000\n",
      "3              0.770345  0.803556  0.786600   2250.000000\n",
      "4              0.917052  0.908434  0.912722   4150.000000\n",
      "5              0.858788  0.883416  0.870928   3208.000000\n",
      "6              0.805957  0.811645  0.808791   2267.000000\n",
      "7              0.803426  0.818856  0.811068   2291.000000\n",
      "8              0.808631  0.835962  0.822070   2219.000000\n",
      "9              0.897271  0.861856  0.879207   3243.000000\n",
      "accuracy       0.843923  0.843923  0.843923      0.843923\n",
      "macro avg      0.835373  0.835268  0.835135  26000.000000\n",
      "weighted avg   0.844651  0.843923  0.844110  26000.000000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGzCAYAAAD9pBdvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABnIUlEQVR4nO3dd3hTZfsH8G+6Fx3QSemAslfZpSzhpTJFBVFElCX4A+GVoYLIUFHBFxFBRHGBCwVFQARkWDaydxlllU0Xpbt05fn9cWjaNEmbtElPk3w/15WrZzznnPs00Nx5zjMUQggBIiIiIpnYyB0AERERWTcmI0RERCQrJiNEREQkKyYjREREJCsmI0RERCQrJiNEREQkKyYjREREJCsmI0RERCQrJiNEREQkKyYjREREJCsmI0RW7IsvvoBCoUBERITcoRCRFVNwbhoi69W5c2fcvXsX169fx+XLl1G/fn25QyIiK8SaESIrFRcXh3///ReLFi2Cj48PVq1aJXdIWmVlZckdAhGZGJMRIiu1atUqeHl5oX///hg8eLDWZCQ1NRVTpkxBaGgoHB0dUadOHQwfPhzJycmqMg8fPsS7776Lhg0bwsnJCQEBARg0aBCuXr0KANi9ezcUCgV2796tdu7r169DoVDg+++/V20bOXIk3NzccPXqVfTr1w81atTAsGHDAAD79u3Ds88+i+DgYDg6OiIoKAhTpkxBTk6ORtwXL17Ec889Bx8fHzg7O6NRo0aYOXMmAGDXrl1QKBRYv369xnG//PILFAoFDh48aPDvk4gqzk7uAIhIHqtWrcKgQYPg4OCAoUOH4ssvv8TRo0fRvn17AEBmZia6du2KCxcuYPTo0WjTpg2Sk5OxceNG3L59G97e3igsLMQTTzyB6OhoPP/885g0aRIyMjKwY8cOxMTEICwszOC4CgoK0Lt3b3Tp0gULFy6Ei4sLAOD3339HdnY2xo8fj1q1auHIkSNYunQpbt++jd9//111/JkzZ9C1a1fY29vjlVdeQWhoKK5evYq//voLH374Ibp3746goCCsWrUKAwcO1PidhIWFITIyshK/WSIymCAiq3Ps2DEBQOzYsUMIIYRSqRR16tQRkyZNUpWZM2eOACDWrVuncbxSqRRCCLFixQoBQCxatEhnmV27dgkAYteuXWr74+LiBACxcuVK1bYRI0YIAOKtt97SOF92drbGtvnz5wuFQiFu3Lih2tatWzdRo0YNtW0l4xFCiBkzZghHR0eRmpqq2paYmCjs7OzEO++8o3EdIjItPqYhskKrVq2Cn58fevToAQBQKBQYMmQIVq9ejcLCQgDAH3/8gfDwcI3ag6LyRWW8vb3x3//+V2eZihg/frzGNmdnZ9VyVlYWkpOT0alTJwghcPLkSQBAUlIS9u7di9GjRyM4OFhnPMOHD0dubi7Wrl2r2rZmzRoUFBTgxRdfrHDcRFQxTEaIrExhYSFWr16NHj16IC4uDleuXMGVK1cQERGBhIQEREdHAwCuXr2K5s2bl3muq1evolGjRrCzM94TXzs7O9SpU0dj+82bNzFy5EjUrFkTbm5u8PHxwWOPPQYASEtLAwBcu3YNAMqNu3Hjxmjfvr1aO5lVq1ahY8eO7FFEJAO2GSGyMjt37sS9e/ewevVqrF69WmP/qlWr0KtXL6NdT1cNSVENTGmOjo6wsbHRKPv4448jJSUF06dPR+PGjeHq6oo7d+5g5MiRUCqVBsc1fPhwTJo0Cbdv30Zubi4OHTqEzz//3ODzEFHlMRkhsjKrVq2Cr68vli1bprFv3bp1WL9+PZYvX46wsDDExMSUea6wsDAcPnwY+fn5sLe311rGy8sLgNQzp6QbN27oHfPZs2dx6dIl/PDDDxg+fLhq+44dO9TK1atXDwDKjRsAnn/+eUydOhW//vorcnJyYG9vjyFDhugdExEZDx/TEFmRnJwcrFu3Dk888QQGDx6s8Zo4cSIyMjKwceNGPPPMMzh9+rTWLrDi0ViJzzzzDJKTk7XWKBSVCQkJga2tLfbu3au2/4svvtA7bltbW7VzFi0vWbJErZyPjw+6deuGFStW4ObNm1rjKeLt7Y2+ffvi559/xqpVq9CnTx94e3vrHRMRGQ9rRoisyMaNG5GRkYEnn3xS6/6OHTuqBkD75ZdfsHbtWjz77LMYPXo02rZti5SUFGzcuBHLly9HeHg4hg8fjh9//BFTp07FkSNH0LVrV2RlZeGff/7Bq6++iqeeegoeHh549tlnsXTpUigUCoSFhWHTpk1ITEzUO+7GjRsjLCwMb7zxBu7cuQN3d3f88ccfePDggUbZzz77DF26dEGbNm3wyiuvoG7durh+/To2b96MU6dOqZUdPnw4Bg8eDAB4//339f9FEpFxydmVh4iq1oABA4STk5PIysrSWWbkyJHC3t5eJCcni/v374uJEyeKwMBA4eDgIOrUqSNGjBghkpOTVeWzs7PFzJkzRd26dYW9vb3w9/cXgwcPFlevXlWVSUpKEs8884xwcXERXl5e4v/+7/9ETEyM1q69rq6uWuM6f/68iIqKEm5ubsLb21uMHTtWnD59WuMcQggRExMjBg4cKDw9PYWTk5No1KiRmD17tsY5c3NzhZeXl/Dw8BA5OTl6/haJyNg4Nw0RWa2CggLUrl0bAwYMwHfffSd3OERWi21GiMhqbdiwAUlJSWqNYomo6rFmhIiszuHDh3HmzBm8//778Pb2xokTJ+QOiciqsWaEiKzOl19+ifHjx8PX1xc//vij3OEQWT3WjBAREZGsWDNCREREsmIyQkRERLIyi0HPlEol7t69ixo1alRqJlAiIiKqOkIIZGRkoHbt2hpzTpVkFsnI3bt3ERQUJHcYREREVAG3bt3SOht3EbNIRmrUqAFAuhl3d3eZoyEiIiJ9pKenIygoSPU5rotZJCNFj2bc3d2ZjBAREZmZ8ppYsAErERERycrgZGTv3r0YMGAAateuDYVCgQ0bNpR7zO7du9GmTRs4Ojqifv36+P777ysQKhEREVkig5ORrKwshIeHY9myZXqVj4uLQ//+/dGjRw+cOnUKkydPxpgxY7Bt2zaDgyUiIiLLY3Cbkb59+6Jv3756l1++fDnq1q2LTz75BADQpEkT7N+/H59++il69+5t6OV1KiwsRH5+vtHOZ01sbW1hZ2fHbtNERCQLkzdgPXjwIKKiotS29e7dG5MnT9Z5TG5uLnJzc1Xr6enpZV4jMzMTt2/fBke2rzgXFxcEBATAwcFB7lCIiMjKmDwZiY+Ph5+fn9o2Pz8/pKenIycnB87OzhrHzJ8/H++9955e5y8sLMTt27fh4uICHx8ffrs3kBACeXl5SEpKQlxcHBo0aFDmwDRERETGVi279s6YMQNTp05VrRf1U9YmPz8fQgj4+PhoTWyofM7OzrC3t8eNGzeQl5cHJycnuUMiIiIrYvJkxN/fHwkJCWrbEhIS4O7urjN5cHR0hKOjo0HXYY1I5bA2hIiI5GLyT6DIyEhER0erbduxYwciIyNNfWkiIiIyAwYnI5mZmTh16hROnToFQOq6e+rUKdy8eROA9Ihl+PDhqvLjxo3DtWvXMG3aNFy8eBFffPEFfvvtN0yZMsU4d0BERERmzeBk5NixY2jdujVat24NAJg6dSpat26NOXPmAADu3bunSkwAoG7duti8eTN27NiB8PBwfPLJJ/j222+N2q3X2oWGhmLx4sVyh0FERFQhCmEG/WHT09Ph4eGBtLQ0jblpHj58iLi4ONStW9esGl52794drVq1MkoSkZSUBFdXV7i4uFT4HOb6eyQiouqrrM/vkthqsZoSQqCgoECvsj4+PpVKRIiISJ2pvqfn5BUCAJRKoVouL44riZn4eu9VPMzXXv5WSjbyCpSq9csJGdgaE4/4tIdIysiFEAIfbDqP/ZeTUVAolXuQlYfTt1Jx4V46fjt6CylZeUa4u4qzuJoRIQRydLxhpuZsb6tXr56RI0fihx9+UNu2cuVKjBo1Clu2bMGsWbNw9uxZbN++HUFBQZg6dSoOHTqErKwsNGnSBPPnz1cbSC40NBSTJ09WDSSnUCjwzTffYPPmzdi2bRsCAwPxySef4Mknn9QZE2tGiEgfqdl5UCgU8HC2N/q5E9If4npyFjaduYd/LiRg6+RucLK3QXZuIWo42cHWRoG45Cz855M98HZzxLbJXeHhbA87WxvEpz3EnkuJqOvthrN30nDgSjJ6NvFFm2AvJKQ/RLcGPhj383FsPy/17jw+KwoKhQL2tgrUcLJHfNpDnLqVCp8ajgAEnvnyIF7qGIIwH1c09KuBlkGeGPfTcey/kozPX2iNJ1rWRlZuAdadvINtMfE4cDUZbo5SB9UwHzcEejnDt4YjXB3s8ER4ABr61sDvx29h+h9ntd57vxb+eL1XI/x+7Db83B3x3l/ny/xdebnY40G2cUcdv/5Rf6OeD9C/ZsTikpHsvAI0nSPPvDfn5/aGi0P5vaXT0tLQt29fNG/eHHPnzgUAnDt3DlFRUWjZsiUWLlyIevXqwcvLC7du3cKhQ4fQuXNnODo64scff8TChQsRGxuL4OBgANqTkTp16mDBggVo3749li5dihUrVuDGjRuoWbOm1piYjBBZj/i0h3Cyt4GniwOUSgEbm+IvUZm5BbC3VcDRzla1TQiB9IcFyCtQov2H/wAA3uzdCFvO3sPv4yLx99l43EvLwaWETNgogLf6NsEHm89j05l7GN89DCE1XWBro8DG03cxOaohVhyIw+0HOTh9K7Wqb53K8O9b/0FtT+OO16VvMlItBz2zdB4eHnBwcICLiwv8/f0BABcvXgQAzJ07F48//riqbM2aNREeHq5af//997F+/Xps3LgREydO1HmNkSNHYujQoQCAefPm4bPPPsORI0fQp08fU9wSERlBbkEhbqVko75vDbXteQVKONhJT9XP302Hg50N6vu6qfYXKgWEEBAAjsaloEAp0CbEC0O+OoinWtVGXW832Nkq4OZoh2eXH9Q7nkZ+NdDQvwb+On1XY9/H22IBQOuXvw2nist/ufuq2r59l5P1vj5VrWM3HuBJIycj+rK4ZMTZ3hbn58rTU8fZ3rb8QuVo166d2npmZibeffddbN68Gffu3UNBQQFycnLUeixp07JlS9Wyq6sr3N3dkZiYWOn4iMhwWbkFcHW0Q36hEnY2CtXj3DupObjzIAdZeQWo7+OGrgt2AQCaBrjj/L109Grqp3qs0LWBd4U+yM/dLXtur7LEJmQgNiGjwseTeXkyvLZs17a4ZEShUOj1qKS6cnV1VVt/4403sGPHDixcuBD169eHs7MzBg8ejLy8shsb2durP89VKBRQKpU6ShORoaatPY3fj9/G5J4NMbhdHZy9nYpFOy5hUs+GuBifjqU7r6BnY19EXzT8S8D5e1ICUZSIAKxRIHUvd6mL9qFe+O+vJ5FfKODn7oiE9Fz8/HIEPtp6AT0a+SInrxDf7o9DHS9nfDqkFX48eAPTejdCYsZDPPPlQczq3wS2Ngq899d5eLsZNuq5sZnvp7aZc3BwQGFh+Q1tDxw4gJEjR2LgwIEApJqS69evmzg6IsuRlJELTxd72Ntqdh5My8lHoVJgd2wiNp6+i4GtA5GcmYeF22LRJsQTp2+l4Z+pj8HV0RZd/rcLaTmaDQY//ecSPv3nkmp9wi8nVMsVSURIP9P7NIZCAfx08AbupOYAAPzdnRCf/lCt3OpXOqJjvVpY/M8lLP7nMgCgf4sAbD57T6/r1PN2xbXkLNX6K93qYUj7IHy77xr+On0P7k52aBbogblPNUNBoUCPhbtRoBT4c0JnvL/pPI7deAAA2DetB2p7OsPWRoGH+YVYf/IOAjyc0CnMGw1n/Q0A+HtSVzQJcMetlGyMWHEEtjYKfPRMC/jWcIK/hxMOX0tBmxBPtS/clz8MAPCoB6ZSwN7WBpsadFXtn/VEU9Vy+1CpzWBQTRdVY1UhBJoEuKOhn/qjwarGZEQmoaGhOHz4MK5fvw43NzedtRYNGjTAunXrMGDAACgUCsyePZs1HGTVHuYX4uydNDQJcMf15CyM+/k4mgS4Y8ejWoS/J3WFq4Md9lxOwuWEDPx48Ibq2BUj22FJ9BWdDSd3xyaplg9cuQ8A6Dg/WmtZAta92gmTVp/ErZQcnWWWv9gW434+jo71amL1K9I0IAev3kd+oRKhtVyx9sRtjOwUiiNxKZj71znY29lgzSuRqOXmoHqkVVCoxNHrD9AqyBPODuqPw8c9FqZqhJudV4A/jt9GzyZ+Gg0xx3cPg7+7E7o08Ia7sz1cHGyRlVeAWf2boranM/ILlZi85hQ2n7mHet6u2D6lG+weJbAbTt7B3stJ+GhQS1XbnfmDWmL+oJYo7cq8fqrlz4a2xsLtsRjduS6CahYPv+Bkb4uhHYJV6/1bBuBBVh4aPUoIgmq6YOcb3TXO3aWBt87fc1HPIEMpFAp0rFfL4OOMjcmITN544w2MGDECTZs2RU5ODlauXKm13KJFizB69Gh06tQJ3t7emD59OtLTK/4MmKg6SMvOx3f7r+Gp1oEI85EaYq45ehPT/ziLpgHu+H1cJD7beRlf7bmm1/luPyj+MOy7ZJ/OcqO/P1a5wM2Uk70NXuvZAAu2xsLRzgZ/T+qKNUdvoUsDb9T3dUPk/J0AgDAfV+yY8hie++qg6hv9v2/9BzVdHeBkbys1khXA4ujLaBXkgTbBXtj1enecupWKpIxcTP3tNEZ0CsX4x8KQlJmLjIf5aB3spdFlNDKs+MNv6uMNAQB9mvujdzM/CAG13j0AYGdro3ZMaUXlXRzs8FJkqNYyjna2eL5EAvDxs+Fq++1tbTB/UAu0CfbCEy0DVIkIADzdOhBPtw7UeX1dans6Y9Fzrcott+yFNgaf29JYXNdeqhj+HqmyEtMfwt3ZHonpuXBysMGWM/fQr2UAEtNz8SA7D2/9cRY5+YV4rKEPTt1KRVyJqm9r1dDPDX2aB+CzaOnxwab/doGbox26L9ytKnPx/T5oPHsrAOCjQS3UPlAvxqejz2Ip+erdzA+v9WyA3bFJyHhYgAk9wnAzJRsPsvJVVfunb6UiqKYLaro6qMVxJTETu2MT8WLHEDjZ2+JWSjZmbYjBK93qoXN93d/GSytUCtjacAZ1Kma144xQxfD3SCXlFyqRX6jEoWv34efuhGa1PXDzfjY+2noBBYUCHwxsjs1n7qF5oAeCvFzw3l/n8HdMvNxhVxtv9GoIbzdHNA/0wHt/nUOvpv749ehNtA32UvtGLoTQOVDihpN3EFTTGW1DamLvpSQciUvBlMcbanzY/3jwOvzdndCrmb9J74moIpiMkEH4e7RsRc/U45KzkPEwH7XcHOHhbI+b97PRtLb0f+qz6Mv4as9VZOkxRLW5e2dAU6w6fBNXEjMBAME1XbDm/zri9K1UnLmdhi92X8WEHmFoVtsDr646gfefaoaXIkMhhMDVpCzU83ZFgVLgbmoO6ng5w0ahwJ7LSfj+wHV4udhj8fOtZb5DouqByQgZhL9HyyGEgFJA1Wr/k+2x+GZfnNxhmcT8QS3wZHht9PtsH27cz9ZZbs0rHXH7QQ6eaVunCqMjIo7ASmQFbqVkI/pCAo5cT0FyZh4+fLo5Fm6PxbZzCeUfXM0teb4VFu24hOaBHpgS1RBBNZ2hVAI5+YXwdLZXa+S4580eAIAFWy8iwNMZL3UMAQBEX0hAmI8bQr1dESHLXRCRPpiMEFVjiRkPcSQuBb2a+iMx4yFmb4jB7Qc5uPzo8UJpj3+6t4oj1M8LEcF4qWMIDlxJxtrjt3ExvnhUzwtz+6BAqUQNJ3ukZefDw6V4wL6nWmn2YCjdtbOkaX0aq633bOJnhOiJyNSYjBBVA/O3XMCha/exdnwnfLHrKnbFJuJUNZtE7PXHG+KnQzeQmJELAHiiZQA+f6ENjsSl4Oj1FNR0dcBz7YKw43wCYu6k4fNdVwAA7z/dXFVT0STAHWO61kP0hQTE3EnHaz3rP2rAKSUYJRMRIrIebDNCAPh7rCrZeQVwsrPFG2tPY92JO7CzUaB3M3+9R4OsCva2CmyY0BkHriTjr9P38Eq3eohq4ldmjYQupWeEJSLrwjYjRNXM7A0x+OnQDbVtBUpRpYnI7Cea4uUudfH32Xv4/t/rOByXgno+rvhxdAf41nBSjS4JAM1qe+CVbmGVuh4TESLSB5MRIiMrKFQiLjkLbk52yC8Q6Pbxriq7trebA5IzpUkUZ/VvgpGdQlGgFHiQnYcAj+Lhsfu2CECPxr74O+YeujbwkX2SLCKybkxGiCohr0CJmLtpWHfiNu5n5lXZwF9TH2+IDnVrYv7fF3E1MRMfDmyOVkGeCKnliuvJWVAKgXqPhlm3s4VaIlLEyd4WA1uzqysRyY/JiEy6d++OVq1aYfHixUY538iRI5GamooNGzYY5XxUtlsp2ei6oGpqPGb0bYzRXerC3tYGey4lYdu5eIztWg/ODrb4c0JnjfKh3q5VEhcRkbEwGSHSISevEK/8dAz/aeyLUZ3rApDm8IhatMck1wup5YLtU7rh/U3n8fOhmwCAXW90R90SycVjDX3wWEMfk1yfiEgulpeMCAHk6x6J0aTsXQAd80yUNHLkSOzZswd79uzBkiVLAABxcXHIzMzEm2++iX379sHV1RW9evXCp59+Cm9vaaKqtWvX4r333sOVK1fg4uKC1q1b488//8THH3+MH374AQBU81zs2rUL3bt3N819WomfDl3HvsvJ2Hc5GbHxGVh99JZRznt0ZhS2xtzD7D/PAQD2T++By4mZ6NHIFwAwpF0wfj50Ez41HNUSESIiS2V5XXvzsoB5teUJ9O27gEP5Hx5paWno27cvmjdvjrlz5wIA7O3t0aRJE4wZMwbDhw9HTk4Opk+fjoKCAuzcuRP37t1DcHAwFixYgIEDByIjIwP79u3D8OHDAQAvv/wy0tPTsXLlSgBAzZo14eDgoDOG0ti1t5gQAm0/+AcpWXlGP3fRVOpCCCzYFosgLxe8EBGsUe5aUib83J3g6mh53xeIyHqwa2815uHhAQcHB7i4uMDfX5pp84MPPkDr1q0xb948VbkVK1YgKCgIly5dQmZmJgoKCjBo0CCEhEgDSLVo0UJV1tnZGbm5uarzkaZbKdkoUAq8/P1RfPFiGzT2l/5j5BUokZyZiyNxKZi85pRRruVoZ4Ojs6Lg7mSPq0mZeP2305jYo75qv0KhwPRSo4WWVNT4lIjIGlheMmLvItVQyHXtCjp9+jR27doFNzfND6GrV6+iV69e6NmzJ1q0aIHevXujV69eGDx4MLy8vCoTsVWIvpCAl384pratz+J9uPJhX3y45QJWHrhulOuE1HLB1Mcb4omWtdWmeQ/zccMGLQ1NiYhIYnnJiEKh16OS6iYzMxMDBgzA//73P419AQEBsLW1xY4dO/Dvv/9i+/btWLp0KWbOnInDhw+jbt26MkRc/d28n13mGB/1Z/5d4XP/MjYCkfVqqdroFCoFbBTFbXaIiEh/lpeMmAkHBwcUFhaq1tu0aYM//vgDoaGhsLPT/rYoFAp07twZnTt3xpw5cxASEoL169dj6tSpGuezVpvO3MWSfy7rnEiuMhr6ueGNXo3QJMAdQTXVa8FsOdIoEVGFMRmRSWhoKA4fPozr16/Dzc0NEyZMwDfffIOhQ4di2rRpqFmzJq5cuYLVq1fj22+/xbFjxxAdHY1evXrB19cXhw8fRlJSEpo0aaI637Zt2xAbG4tatWrBw8MD9vbWNelYfNpDTPzlpFHO5eZoh+OzozB7Qwwa+NbA2G71jHJeIiLSxGREJm+88QZGjBiBpk2bIicnB3FxcThw4ACmT5+OXr16ITc3FyEhIejTpw9sbGzg7u6OvXv3YvHixUhPT0dISAg++eQT9O3bFwAwduxY7N69G+3atUNmZqbFd+29npyF3AIlnO1tEVzLBdeTs9B94e5KnXNMl7ro3dwfgZ7OqO0pjVi6YHC4EaIlIqKyWF7XXqoQc/o9JqQ/RMS8aNV6uxAvHLvxoNzjZj/RFADw/qbzGvuuzevHSd2IiIyMXXvJIhUUKtUSEQBlJiJPhtfGZ0Nbq9Yvxqer7T/8dk/41nBkw1MiIhkxGSGzEfrWZoOPKZmIAFCNLQIAf4yPhJ979a4FIiKyBkxGqNo7fuMBnvnyX4OPe759kNbtcfP7ISe/EC4O/OdPRFQd8K8xVTsnbj7A+bvpGBYRjJO3UvVORN57shmGPEpATt9KRdsQ7QPCKRQKJiJERNWIxfxFNoN2uNVadfn9fbI9Fkt3XgEAzNoQo/dxXwxrg34tAlTrEfVqGT02IiIyDbNPRmxtbQEAeXl5cHZ2ljka85WdLc10LNfYJNl5BRj6zWGcvpWqV3k/d0ckpOcCAMKDPNUSESIiMi9mn4zY2dnBxcUFSUlJsLe3h42NjdwhmRUhBLKzs5GYmAhPT09VcleVsvMK0HTONr3Lv9GrIUZ0CsWsDTH489RdTIlqYMLoiIjI1Mx+nBFAqhWJi4uDUqmUITrL4OnpCX9//yrt4ppbUIjXfj2JbecS9Cr/69iOCPNxhe+jHjBKpUByVi58a7BHDBFRdWRV44w4ODigQYMGyMvLkzsUs2Rvby9LjUijWVv1KufhbI/T7/TS2G5jo2AiQkRkASwiGQEAGxubaj9yKEmUSoF6b2/Ru7y2RISIiCyHxSQjVH1dTcrEG7+fxstd6mLL2XvYcjZe72N7NPIxYWRERFQdMBkhk7qSmIGoRXsBoNwZdd2d7HBs1uM4fTsVzy4/CAD46qV2Jo+RiIjkxWSETEIIgU1n7uG/v5adgADA9ind4Olsr2qY2j60Jna90R0BHk5wsGPvKCIiS8dkhIyu96d7EZuQoVfZmPd6w81R859hXW9XY4dFRETVFJMRMhohBGLupOudiJx9t5fWRISIiKwLPwnIaD7cfAHf7o/Tq2zc/H5VOqYJERFVX0xGqNKEEFi+55reicj2Kd2YiBARkQpbB1Kl/XMhEf/belHn/tLdcxv61TB1SEREZEZYM0JaZeUWoNk70nwxV+f1g62N9pqM68lZGPvjMa37RnYKhaO9DV7tXh8KBTBnQwyeah1ospiJiMg8WcTcNGRcF+6lo++Sfar1hn5u2D7lMdX6mqM3Mf2Ps/B3d0J8+kOd57n+UX+TxklERNWbvp/ffExDGkomIgBwKSETWbkFAICH+YWY/sdZACgzEenfIsB0ARIRkUVhMmLlZq4/i4h5/6CgUJrx+NzdNK3lih7ZNJ6t3+R23TmMOxER6YltRqzYnD9jsOrwTQDAB5svYNxjYej/2X6d5UPf2qxzn4OdDeY80RQNfN1wJC4Fg9rUMXq8RERkmdhmxEpdTsjA45/uNcq5/prYBS3qeBjlXEREZDnYZoR0yniYb7REpIGvGxMRIiKqFD6msTLZeQVo8e72Sp9n48TOcLa3RR0vFyNERURE1ow1IxZqV2wi3t14DvmPGqYWaTpnm17Hb/pvFwwIr611318Tu6BlHU808KsBZwfbSsdKRETWjcmIBcrJK8SolUfx/b/X0WDm36rtvx+7pdfxX73UFs0DPbB4SCuNfdc/6s/HMkREZFRMRizQsl1XNLZl5RbgzbVnyj22ga8bejX1AwDY2ihw+O2eqn2xH/QxXpBERESPsM2IBfpcSzIy8IsD5R7n7eaAHVMfU9vm5+6Eq/P6oVAp4GDH3JWIiIyPny4W5tStVI1tj328C5cSMjW2B9dUb3x6bNbjWs9pa6NgIkJERCbDTxgLsvJAHJ5eplkDcuN+tsa26x/1x95pPRBU07kqQiMiItKJyYgFee+v83qVG/dYmGp54eBw2NsqMPuJpqYKi4iIqExsM2IBhBCoO2OLXmU9Xewx8T/1VesR9Wrh3Ht9+BiGiIhkw2TEAjyxVPd8MiVtndwVjf01h+NlIkJERHLip5AFOHc3XWNbHS/NtiDaEhEiIiK5VSgZWbZsGUJDQ+Hk5ISIiAgcOXJEZ9n8/HzMnTsXYWFhcHJyQnh4OLZu1W8aeipfzJ00rdvtbBRq63+M71QV4RARERnM4GRkzZo1mDp1Kt555x2cOHEC4eHh6N27NxITE7WWnzVrFr766issXboU58+fx7hx4zBw4ECcPHmy0sFbOyGEzkc0CoV6MtI2xKsqQiIiIjKYwcnIokWLMHbsWIwaNQpNmzbF8uXL4eLighUrVmgt/9NPP+Htt99Gv379UK9ePYwfPx79+vXDJ598Uungrd3cTbp7zziWaAfiyDYhRERUjRn0KZWXl4fjx48jKiqq+AQ2NoiKisLBgwe1HpObmwsnJye1bc7Ozti/X3ejy9zcXKSnp6u9SN3D/EKsPHBd536XEhPY9WziWwURERERVYxByUhycjIKCwvh5+entt3Pzw/x8fFaj+nduzcWLVqEy5cvQ6lUYseOHVi3bh3u3bun8zrz58+Hh4eH6hUUFGRImFZhyFeayd9bfRurlm+m5GDXG93x3//Ux7yBLaoyNCIiIoOYvP5+yZIlaNCgARo3bgwHBwdMnDgRo0aNgo2N7kvPmDEDaWlpqtetW/rNNmstcvIKcfq2esPVgzP+ozaYmZujLep6u+L1Xo3g6eJQ1SESERHpzaBkxNvbG7a2tkhISFDbnpCQAH9/f63H+Pj4YMOGDcjKysKNGzdw8eJFuLm5oV69ejqv4+joCHd3d7UXFfvlyE319TERCPBQ78rbpYF3VYZERERUYQYlIw4ODmjbti2io6NV25RKJaKjoxEZGVnmsU5OTggMDERBQQH++OMPPPXUUxWLmPC/vy+qrUeG1VItT328IQI9nfHafxpUdVhEREQVYvAIrFOnTsWIESPQrl07dOjQAYsXL0ZWVhZGjRoFABg+fDgCAwMxf/58AMDhw4dx584dtGrVCnfu3MG7774LpVKJadOmGfdOrERi+kPkFSpV68teaKPWjfe1ng3w3//U1+jaS0REVF0ZnIwMGTIESUlJmDNnDuLj49GqVSts3bpV1aj15s2bau1BHj58iFmzZuHatWtwc3NDv3798NNPP8HT09NoN2FNIj/aqbbev2WARhkmIkREZE4UQgghdxDlSU9Ph4eHB9LS0qy+/UjoW5vV1q9/1F+mSIiIiMqm7+c3R8MyI/P/vqC23ruZn46SRERE5oPJiBn5as81tfXPX2gjUyRERETGw2TETNxKydbYZm/Lt4+IiMwfP83MRNcFu9TW/5rYRaZIiIiIjIvJiJlqUcdD7hCIiIiMgslINVbU0amgxLgiAPDH+LIHmCMiIjInBo8zQqb3ML8QjWdvBQBs+m8XTPzlhNp+RztbbYcRERGZJSYj1dB7f51TLT+xdL/G/qYB1j3WChERWRY+pqmGfj2ie5bis+/2go0NR1glIiLLwWSkmtly9p7aet/m6rMh13Cyr8pwiIiITI7JSDXz6ir19iF/x8Srlp9uVbuqwyEiIjI5JiPVSGLGwzL3f/RMyyqKhIiIqOowGalGPt1xSee+8DoecLJnLxoiIrI8TEaqkbIarm6Y0LkKIyEiIqo6TEaqiR3nE8rcr1CwBw0REVkmJiPVxNgfj8kdAhERkSyYjFRDy19sq7Ze09VBpkiIiIhMj8lINRD61ma19dbBnmrr3wxvV4XREBGR2ctJBZSF0nJWMrBpCnDrCKBUArePAfmPem8W5AEPbsgWZhEmIzI6dj1FIxEBAG83R/jWcFSttw3xqsqwiIiqnhBAXhawehiw+yPjnjtuH3D8e+OesySlEijILV7PL3uYhnJlJQPHfwByM/U/Ji9LOiYzEbh/FfhfCPB9f2nfpinAsRXAd48Dc72Ab3sCq4dK+1b2AZa0BK5rTj1SlTg3jUwe5hdi8PKDWvfZ2iiwfUo37LyYiD6lRmAlIqpWhAASzwO16gN2jtrLXN8PPEwHGvfTfZ73PIuXL24Cur+lvj8nFdizAGj5HFC7Vdkxpd4ErvwDhL8AJF0EfnhC2u4ZDOxdCDQZAHQcX/Y5Tq+WahD6LgBsyvne/vVjQPJlYNpV4O4p4Pt+QJepQNQ7ZR8HSInM7nlAnfZAw97Stp8GAvFngBsHgEFfl3+OuyeBLdOA20eAQ00AxaN4bx6UEpOEGM1jru4EfnwauHNcWj/xExDapfxrmQhrRmQghMCYH7Q3WF3waGAzTxcHDGpTBy4OzBeJyAQKcoHDX0sfVvoQAvj3c+BKNFCYX7z97O/Al52Anwaply9Z5vv+0jfxtDvSev5DYOsM4PKO4m3arnd2LRB/VlrfPhM4tEz64C+SlwWcXgNkp0jlAeDmYWBxC6k24EM/9fI/DZQ+4LeWSnS0XXv9/wFHvwFiS9ReF91T0bVO/AT8/IyUOBTkALePAttmSPv2LyouV+T2cWDDBODUr8XbLvwJ7P0Y+OU5af3iZul8AHBmDfBxfek9UhYCOQ+kcx5bCcT+LZVJiQO+7i4lIgCQdAFILJ5sFUvbACnXtN/ntV0l7llZ9u/ExPhJJ4Nzd9Ox/0qyxvb3n2qG59oHyRAREVmd/Yulb+QA8G5a+eVvHJASgiKjtgIhkcDf0x/t3y8lAnF7gNgtUhLR8nng6WXFxxz9FnDzlZKIQ19ILwB49ZDm9c6tA/54WVoef1BKTIq86wE8+Tlw5KviZAUA3r4LrOhV/r0AwPpxwMDl2vf9ObF4ec2LwONzgYz44nh1EUJKDoq85wmM3Az8OUGqObryj7T91M9Axj0gK0mq8SkStxdY/YL6ObOSpIRCm1d2S4mIMehKWKqIQojSqVv1k56eDg8PD6SlpcHd3V3ucCrt5M0HGPjFvxrbt7zWFU1rm//9EZEZ+OFJKXEAgPH/Ar5NAYVCaq9x5jdgzD+AYw3A1h7ISAA+aah+vHcjYNQW4OOwsq8z/Trwv9Cyy4R0lpKdqlYyCUu7A1zeDoQ/D3xopY/HZ8YD9s5GPaW+n9+sGZGBtkQEABMRIqo4IYCHqYCzlgbvKdeAnR8CnScBAUVzXJX4HvplJ+nbf+dJwO750rYFdaWfEeOAxAua50yOLT8RAcpPRAB5EhFAqvXoPBnY/6nUTgWQanWsVc4Doycj+mIyUsUKldW+IoqI5HTjICAK9W9MGB8jPf44v0H6MGn8BPD8quL9iReBLyKk5Zg/gBEbgR8GaJ5nxxyp62dph3U8yrAEF/6SXiVd3i5PLNWBjA9K2IC1Ct24n4UPNp9X2/bZ0NZoHuiOPW92lycoIjK+28eAe2fKL5efA/w+Suq5AUiNSlf2kRp8PkwvLpebAWx8TWroWLKNAQAs7wwcXyklIoD0DX/7LKntwtHvihMRAIDQnogUKaodIOskYyNW1oxUkdyCQjz28W6N7U+G18aT4bWrPiAiMo3sFGkcBwCY8wDITZMaXzYbBLjWApKvAHsXAIFtgb+nSeXOrZPaKuTnFJ/n0jag5bPS8p4FwIkfpOX9i6V2GLb2umP4d6n0IjIEkxHLt+tiktwhEFm2vCxpkKgafvLFIITU+0G1XgisfRm4Gg3ErJPGjPj80XQPZ9ZoO0Hx4roxQHBHICkW+Pez4u15mcD73sBLG7S35SAyQ0xGqoAQAuN+Pq6x/eq8MgYAIiLDLGwofVBPvQi4B+h3zK2jUluJ3h9Kj0CcPLR390y7DXzaDKgfBbz4h/ZzrXoOyE0HnlhcvE1ZKCUiAHDzX2Bxc92xvOsBtButvq2s8j89rXsfkZlhMlIF7qVpDg3cso4HbG0UMkRDZGEK86UxI/IeDZ198yDQfFDZxxT5Lkr6+U2P4m112ksjhga2AWq3BoI7SQNbAcXjRKRcA458C0ROADwCpfk9Lm+T9pVso2FoG4xjKwwrT2RMfExj2d5ef1Zj258TOssQCZEZE0KqabAt9WdrXiBQmKtZft8nQNZ9oM884Mg30oBSg1dIbS2E0P2Hd/NU6ee5ddr3H1wGRM8FCh4Cd44BrV4A/pqkvWzRoF1E5oDJiOVa8s9l7I7VbC+iULBWhEgvD65Ls4rung/cvwK8dgpwdCveXzoRWTsK2Pjf4pqSYyukoboBabI0z+DiobcrYtvbxcu3DksvIksgY9deJiMm9uk/lzS2rX+1kwyREFUz969KXVIjJwKuvronI1sSrr6+5U0g+RLQ7GnA1Uf7MUWJCFCciADAljcqFTKRRWPNiGUqKNT+xro7l9Elj8jSHPkGOPQlMHyDVCtRZEVvqefJyVXSqI8Ne0tzmVzYCPSYCTi4aJ/E7fQv0s872iebJKIKEoWyXZrJiAn9fOiG2vqbvRuhoFAgzMdNxxFEZixurzTjaEGulHSE/QcICC+ujdg2Exjyk1QVrFAUd4HNSQFyID1OKWrAGX8GuHNCvYaDiEyLNSOW6d2/1EdbndCjvkyREJnQgxvS45LSI3tGvwe0H1u8fv+qlGxsmgKEdi37nHF7jR8nkTWacRuYX0e/sjImIxwOnoik4cu3z5IGDiuz3HFgbi3goxBpwK34GGBJS+DzdtrLH/2meDnxnJSIAMD1fcaJm6g8to7A2/fkjqJ8I0wwFL9LLWnm5fLUeDQKOJMRyyNkbJVMZLBve0rDh+/5n+a+gjxpOPPMRGnOFGWBNDvsz4OBkz9LZdLvVGm4RHp7bJrU/qiquHhrbnsntexj3kkF6uqoLfQIBmbf131soxKDZ9ZqoL5v5KMZiKecK972f1pqHRWPUgGlfG1GmIyYyNgf1UdcXf1KR5kiIauVdlt9rpPcDGmMjNSbuo85sAT4e7o0kFiR/Yuk8TIWNlDvmZJ+Gzj8pfHjJsswuhKz306/IX2rN4amTxvnPLp4BgPPfFe8HjFOfX/dblIbqSItngPGRBev29ir7y/NxkZzbB0AaDIAeDdNfcTf0dvUy/g2ln46eRZvc64JDFureQ2As/Zaon8uJKiWYz/og471jPQfi0gfSbHS8OVL2xZv+/staYyMr7uXfezh5cD/QqWaksv/SON7kHnrPa9qr9d+LBAcUX65koZvBGzsgL4fA86egJ2zSUKrEPsyala6vg7UCiteL5lXDF0NDFlV6gAB1CnxWNPJQ/OcjfoBTy8H3Pykgfq0KZmEGKrB40D7McXrRTUjfExj2RztbOUOgSxd7FbgxI/F6xc3Sz9LPj65tkv6mV1GlW+RvEypDcmqZ4wXI8nDzlkatt5UppzX3GZo8uPXHKj3GDAzHoh4RdqmzwdjxHjDrgMA7oHFy++kAv0WFq+/tEH7MSPLaM/R4jn1GoUGvaSfDjWARn0BJ3f18kWPcV5aD/i3AF4sVUtRpNVQ4PVYaXbnklx9gclnAddH5ylZq6KzhkVLjUdol+LlMTuBN68BtVvpON702JvGBA5cSZY7BLIGD24ANrbSH7dfh0jbQjpL39JK/iH/e7pU5V0yMbn8D5CdDHiFSjPDElWURyAw8Zh6I2Y7B93l6z8OXNlRvD5iExDQUlq2LTEGU3nJiMIG6PuR/o8Kx/8LXNoKBEVIbZ8A6cO7w1igdhvgQRwQ1gPwDAFSHw3L8NJ6IKCVNPS/Nr7NNNuj+LUAJh4H3HzVtz/7PXB6DdB9urQe9h/ppf3miuMrrf9C9fF6Kqrp01KtTUBLwFX+mnsmIyYw7Nvi4aFXjmwvYyRksfKypF4sAGBb4g9/VtKjKuMS34QOa5mFtmSNR3mN60h+Pk2ApAvq21q9CJz6WY+DH/1bcPQActPUd9k5q7cDqijvEg0nmwzQXQ6QagJuHATWvAj0/Z/uhptuvkBmfOVjK7p/v2bSCwCe+1FKxIvUaSu9AGlW5qLEyjMEcKkp1XyEdJYeI90+BuSX7nVW4v+bQgF4axnGodlA6aWPojgrYsYdqRdbyRmgSz5mKhq1WKEAmjxR8esYGR/TmFiPxr7lFyIyVEaJP9KFecXLqbeAS9uk3i/6es/TaGGRCbQaBkw4VLw+4ahUm/D0Mv2OL3qEMOQnzX0lv723qMB8PW7+WjbqMe9WSCTw5hWgxWDdZQav1Nym1hi1EvN7NX1KGpBPG48gzW0KBTByMzD8TyC05CSnWh5/VGbesVd2A49NB7pOrfg5HN2ALlPU26LY2ALT4qRHMfZOFT+3CbFmxMgKlezSSzJaN6b8MmQ+Rm4GgiOl5Rm3pV5OLjUBn4bStmlxwIK6+p2rRkDZ+z0C1defWgb8WaqtSeMngIsl2k84uBYvN+gFXN6u3pvk1cNA2i0pYV79gvq5yvvQ9q4v3d/6cUD4EKBmmFRjcH7DowJ6/q21N7AhrK64VNtNOMlp7dbSyxRcaprmvEbCZMTI5m8prkptHuheRkmiEpRKqQrd2at4W+ot4J93pcaANfyAwgLpWXbJlvtkWfyaAwkx0nK3N9UbGWobvEqvDxhR6qeuYmXsH7kZcK8t1Rq8X3IcjRLHDF0NZCVL/1aL+DaWXkIAA7+SGmwawqUmMOw3w44pqcdMwEPP0Ucroyq+g3oESYldSJfyy5ohJiNG9u3+ONXyc+20VPcRFcnPAeycpG9cPw8Eru2WukS2HCJ1/VvcXCoXs1YqV7IRXZMnZQmZtHDxlhoDV0STAcCFv4rXXUt80P9nluHn678I2DxV6mXiWgvY+QEw4DNpX3ljSNiW0ei0KClSlmpUWvKcNrbqiUhJCgUQ/nzZ1zfYoxqKtiOB499rL/LYNMNPa1PiY1HbrNAB4cDlber7q6LW4b8npPY9Gl2BTVhTU4WYjJjQ4011/MckSr4sNZILHwq0fE5KRACp4dnRb4AXSn0bLN2a/8LGKgmT9NBhLHDoC+BhWvllS3v8ffVkpDJGbpaShubPSB9YCoWU3Dp7PiqgRzJiYw8o83WXsbEBot6Vauz0OWdVeGIxEPUe8L8Q45zPxlZ6vKTM1+yWC0jtOa7tBlKuAk99Lm2rWRcYsEQaUMxU7By091Jy9QbqRwFQqNesmhkmIyYU4FGNBu2hqlE0I21JaXeAvR8DV6Klb8J95gEHH/0RO/2r9CqtaD8VK107VJaWzwNnVhvv2hHjgfuXgSv/aNmpUP82rY8O/yc1NCz94dF5svRBV5FRQ4tqKVTJR6nlmmHS9Zy9gJRrj/Z7FXdjBaQPtUt/l32dLlOk0X2Pfgv0nGN4nMamUKjfpzEUjVyqjb0zMGaH5va2I40bg74UCqkHkJljMmJE15OLu3vVci2jypMs084PpcRi7E6pl8LDNODI11JVeZFDywDfJuXPAcFZazW5eEtD0Ouj5OMOY+j7kfRY7co/UpfU0p5eDvzyrP7n67dA+pmTqr49rAfwxhXjxw9I36pfvyR985/76Bt86xeBe6dKFCpR01FWQ8p+C6VeH6XH0iCqIHbtNaLuC3erlv3cq2f3KTKhvQukBmb7F0vjKPw2Qj0RKbJxInBSSzdLKlvE/+lfVlHqT1utBsCgb4vXS44xUcQ9UHNbSfbO2sfQUCiAhr2kCcimxQH1ugORE/WPtTQ3n4p1D9XnGDsHKRkpUnKQMUB63GHrCHR9Q+q5MmorMOm09msxESEjYjJiIrU9+YjGap3fAKzsUzz8OhlHu9H6d3ss/cEc8X/SmBb9F0mDhWmbrr1x/+JlLz27y5YUEC41ZBz+J9D7Q/V9XV8v//g61WCARN/GwNt3gZ6zpfWQSO2JG5GRMRkxohaBxa2cbfmbtV4lh10nTfV6aN8+7kDZxykU0tDceimVjLQb/ahB58vSYGGeWnq6lRzsavRWqd2JsXSeVH6Zp/QcxEwnI/Wq0DZDrDnS9e+MqiV+ZBrJ/svJOHunuDV93+blDDBE5i/tNrDxNeDUL7JOvV1tNdYy1PQTn0rjUTyppYGutgShdHfTko8YylJyOO1Ww/Q7LuL/pN4nw/4Aavgb0CCxnCSgdhv17piOJZZL1uBoG0eEKmZWojSvDJkNJiNGcCslGy9+d1ht21OtassUDRldQS4Qsw7ITgFuHy8eav3TZsCJH4AN4zmkujYNHtfc1m60NBx1o75aDij1of7mVemRgaO7NJ6DnbN6mfpazl+keYlhxvX5kH/mO8DOUZqErEGUtK0oobGx131cWQIfzW9SVCvi/WjUVK33bgQVaWdiyq6oVW3gV9LP3vOk97Iyw7JTlbOQ+jh5dV2g3jYgPMgTCv5HsAxCAB88aqjn2xRIfDRd+uZKzB1hjtqPkbpy6it8qGZtkWOJMRuca0rDk2fc032Ooh4lb16RGqTa2KjXMJT1f8zGRprY7MYBqceINkUDhD3znfY5UpzcpQapdo66r1OWkZulLrS+TaT1EZukodRblpgDxqEG4F5HGtPCrQrHJRr4NXDnmHrtlbn/yQp/XrofRze5I6EKYDJSSdrmoknOyJUhEjKJXSUaIhYlIkDFBrgyZ2WNzqlN73kl5hB5pORYHDY2wOQYYGEDICfl0baSj1JKfDKWTAY6vwbcPiIN7FU0UFxpRcNlj/gLyHmgu5ts+5elRzhlTRymbWTN/9sLnFsP7P9U93GAdF6/psXrNfyka5ZkY/Oot4rQ/xFUaa4+0mzNhgy1Hj5EelkaJiJmi8lIJW07pznFdURdC6r6tEbpd4EDn0lDsu/9WO5oqp6LN/DcD8D3JXqX1O8pjTIKSANdRc/VPC7qXeDeGaDX+9KHeP2oUgVKJe62duofwCUnXdPVjdfJQ0oyAOkxzf2r0uOg7BSg46vAg+tSDxBAOnd543VUZAbTgHDpVZSMaAzPbaDKNhidcl6aiK6yH8ShXSt3PFElMBmppI/+vqixbcHgljJEQgbJywYubpaq+v/9TJpSvOvrUvuQJa2AwlzgcLlnsUwBLaVhxVsOAc6sAV7eAQR1AEZuAbwbSEPZl9b8GaDTa+rJhWewehltjVYr0/DXIxAYt099W9FstlVhwBLg8g6gzfCqu6Y2uoYJ19frsVISF9zRaCERGYrJSCXdTMnW2GbHfr3V192TwM+DNSc2u3caiPwv8Pc0KRExV0UzexpEAURO0ByCftDX0qtIaGfpp7ZkZPCKsi/x9HKgiZbeNdVhbpOKajtSviHAjamGv/QikhE/NY1s5+uPyR0C6ZJ8Bfi6u+4ZVj/w0T37p7nQNstoaQOWAC9tKF5/4TfDaih8Ghkcls7HIaWvW9SuJOw/hl+DiMwWk5FKyCtQamyr58MGVNWSshD4vK3cUVSNumUkxG1HAa2HA7XCircFdwREiX/L5SUmrt7SdOaGKOrmWlrRiKpF3WenXpDahDToZdj5yfqwx6JF4WOaSrhwL11tfc+b3eUJhMp31VqGZhea87KUNGCx9NO9jjT8uK2jNA5H82eAw1/qf5mSyUxZDR+nX5cmg9M2oBkADFwuNQQtetzh5ss5T0g/HGjQorBmpBL2Xymu7u/awBshtVzLKE1VSgipHcjJVdJyQY7cEVWdVsOkn34tpFEotU1Hb2MjNUwduUn6hhlUcl4UA//IlzWnirMXULOMeV7cfIE+8yv26IeILAZrRirh422xquUlz+s5gReZ3s3DwIoS1fzZyUCahc0X88RiqSHpIS3zmbQYDHjXl0b8dHCV2l9kJAAOLurlSldzd38b2L8I6FVqkjei6oiPaSwKkxEjqelaia51ZLi0O9JQ7O1GF/cEEAJIvameiADAjjlVH5+x1GkP9F0AOHtK93dgMdBxgjS7KqCZjARFSH+kS89uW0OP0T27T5e6N1vKRGlk2fRprE1mg391KkjweaW8Vg2WRkS9Eg2MjZa2bXu7eGAuSzFsrZSIFHlyqfr+7m8Dx757VFMSC3R4pXLXYyJC1d2ITdKge08skjsSMiL+5amgzNwC1XKgp7OMkVipoqHZ7xyTagwUCvNLRPp/Amx+XX2bT2Pg1UPScPMFD9UTEW26Twcem/aoyrqfqSIlqj7qdgXG7JA7CjKyCjVgXbZsGUJDQ+Hk5ISIiAgcOXKkzPKLFy9Go0aN4OzsjKCgIEyZMgUPHz6sUMDVxYgVxff8yXPhMkZC+H0EkHZb7igM12xQ8bJnCPDiOuDl7VJi4eyp/0BUcj8754BZRFRJBteMrFmzBlOnTsXy5csRERGBxYsXo3fv3oiNjYWvr2aXvF9++QVvvfUWVqxYgU6dOuHSpUsYOXIkFAoFFi0yz2o2IQRO3ExVrXesV0u+YKxRXqlRb8//Kb3MRVAEoLCVepoUsbGT5n8xJ8/9BFz5Rxq7hIioEgyuGVm0aBHGjh2LUaNGoWnTpli+fDlcXFywYoX24aD//fdfdO7cGS+88AJCQ0PRq1cvDB06tNzalOpsV2yi3CFYF6USOLsW+HUokHhBqgkxZ6O3AaO2yF+jUVlNnwSe/Kxy86IQEcHAZCQvLw/Hjx9HVFTxbJw2NjaIiorCwYMHtR7TqVMnHD9+XJV8XLt2DVu2bEG/frqfb+fm5iI9PV3tVZ1MXn1K7hCsy7YZwB8vA7FbgC86Ape3yx1R5SgUmomIuScmRESVYNBjmuTkZBQWFsLPT72boJ+fHy5e1Jy9FgBeeOEFJCcno0uXLhBCoKCgAOPGjcPbb7+t8zrz58/He++9Z0hoVSr9YXHj1UFtAmWMxMLlZQNrRwOX/pY7ksppNQxIvwNc2y21DSEiIjUmH4F19+7dmDdvHr744gucOHEC69atw+bNm/H+++/rPGbGjBlIS0tTvW7dMnQW0qozJaoKpyy3Nl93r/6JSNS7wJwHZZfxaQwM/xOYFgdMPKajEGtGiMh6GVQz4u3tDVtbWyQkJKhtT0hIgL+/9hb1s2fPxksvvYQxY8YAAFq0aIGsrCy88sormDlzJmxsNPMhR0dHODo6GhJalbmTqj6seFBNFx0lqVIyE6VxM6q7tqOkodXLEvF/0k+XmqaPh4jIDBlUM+Lg4IC2bdsiOjpatU2pVCI6OhqRkZFaj8nOztZIOGxtbQGY58BhVxMz5Q7BOizrIHcE+ikaB6RuN91l7KpnYk1EVF0Y3LV36tSpGDFiBNq1a4cOHTpg8eLFyMrKwqhRUve+4cOHIzAwEPPnzwcADBgwAIsWLULr1q0RERGBK1euYPbs2RgwYIAqKTEn434+rlrmEPBGdOEvwM5JalOxrIyJ16qr8KFA3N6KH88GrERkxQxORoYMGYKkpCTMmTMH8fHxaNWqFbZu3apq1Hrz5k21mpBZs2ZBoVBg1qxZuHPnDnx8fDBgwAB8+KF5TsaVnVeoWu7RiFOdG8Xt48CaF+WOonLChwK16gO+TYD0e+aZUBERyUQhzOBZSXp6Ojw8PJCWlgZ3d3fZ4niYX4jGs7eq1k/NeRyeLqwdqbT3agKisPxyptZ9BrB7ftllarcB7p4oXn83TXu5dz3KL1OynHcjYKL5jr1DRKSNvp/fJu9NYykKCpVqiQgAJiIVlf9QGrkz/1Fj4OqQiABAvR5l728zHHhlV/G6ex3TxkNEZCU4UZ4e0nLy8d5f59S2/TImQqZozFzOA+B/odJycCfg5r9Ve/1a9YH7V7TvCy7jPX37LuDgKi2HvwCc/gXoMUN3eVcfICsJcPTQXaYkthkhIivGmpFy3ErJRvh727HuxB217ezSW0HrxxUvV3UiAgAdx5e9/+UdQJMngUlngJr1ircXJSIA8NTnwMTj0mBmuoz4C2gyABhdzjgpAY8mWWw5pOxyREQWjDUj5SidhBSp4+VcxZFYgIJc4NLW8suZkmM5bY6COgBDfpKW63YDUq5BY0AyG1vAu37Z5/FtAgz5ufx4RvwF3DkOhJbRNZiIyMIxGSmHna326nMFq9UNlyTDIGZPLwc2lKiN0dVeO3Ki5rZeHwAeQUDTp00SGgDAyQMI+4/pzk9EZAaYjJTj+I1yhvom/e37pOqvWT+q1AYdyUgNLSMIO9YAur1h9JCIiEgd24yUY+fFRLlDMF93TwL7FwO5GcCfE4HzG0x3LZdamtue/wVw8ylulwEAnsGmi4GIiCqEyUgFjOwUKncI1ZsQQE6qNNHdP+8A8+sAJ38y7TX7LdTc1ri/9PP5X4EWzwFjdwIhnYC+H2uWrf7D7RARWSwmI2W4lZKtdftTrWpXcSRmZvPrwP9CTH+dmmHFy16hust5BALPfAMEtpXWI14xaVhERGQYJiNl6Lpgl8a2BYNbonWwlwzRmJFj31XNdYLKGBfEv6WBJ2PNCBGRXJiM6JCUkaux7e1+jfFcuyAZojEjSmXVXMfGDhBlXGv0NsPO1/iJysVDREQVxmREh9sPNB/R2Nrw11UmIYDts6rmWsGRQO1Wuvc7lDMoXY+Z0s9hfwBvXAFqhZVdnoiITIZde3WYu+m8xjZ7HWOOEIADS4CDXwCZ8VVzPZdaQPsxUgJUtxtQmGfY8Y9NAzq9Btg7mSY+IiLSG5MRHU7eTNXYVtOVE+NpKMyX5pvZMafqr21rD0S+Ki3fOW748UxEiIiqBSYjehrUJhB9mwfIHUbVEqLsCdzuXwWWtqm6eMrCGXSJiMwWkxE97H2zB4JrWdnEeFtnSPPIvLIHcCoxn4uyEDi7VprDpbokIgBQww+wdQQKNRseExFR9cZkRA9Wl4gAwKEvpJ8nf5YehRRNcvfgujyPZErTVmMT1AG4vq/qYyEiokphMqKFUlk85sTsJ5rKGEk1sG0GcP5PaZ6WKzvkjoaIiCwQkxEt4tMfqpaHRXAuE9w6JHcE+nFwlTsCIiKqAA6coUX3hbtVy072tvIFIpdfnpc7Ak3txwAvbQCCOkrrbUdqlum7APBtCjy1rCojIyKiSmLNiBZ5BVU0imh1c+NfqeHqvVNyR6Kp+wzA1RsI7QJk3NM++65XCPDqwaqPjYiIKoU1I1o0D3Qvv1B1l5cFZCQYdszKvvIlIn0/Bvp/on2fq4+UiADS2CLaEhEiIjJbrBnRQgGpp0Zj/xoyR1IJH9cH8rOBNy4Dbr6a+5VKYNUzgIMbENwRCB9atfE16CU1io35Q1ovmknXp7GUfNw6DGz8r7Rt4tGqjY2IiKoUkxEtzt5JAwBcjM+QOZJKyH80t86tI0ATLZPAHVwKXN0pLV/YCGx7u+piA4BubwKHl2tuD+0i/fRpBLR8Hih4qD7OCRERWRwmI9ZGCGDfQmDnB/LGYeeoRxkH6UVERBaNyUgpuQWFquU2wZ7yBWI0Qn1143+Bkz/JE0ppniFyR0BERNUAk5FSjsSlqJZfiLDAD8vqkogAQLc3gIepQNOn5I6EiIhkxGSklD+O31Yt5+QVyBhJJTy4XrwsBPDgBnDoS6DjeNlC0srBFXjiU7mjICIimTEZKUEIgQ2n7qrWn2sfJGM0lbAkvHh57WjAMwhIuQZcjZYvJgDoPBk4sPjRShmzARMRkVVhMlJCjxIjrwKAo50FjL6qzJcSEQBIviRPDFHvAbXCgAa9SyQjREREEiYjj+y5lITr97NV687mOgz8zcNyR6DJ2RNoMkB9Ww1/WUIhIqLqh8nII/O3XFBb3zOtuzyBVNaPT8odgTR/jK7J9cbukkaH1TYQGxERWSUOB/9I6QHOarnqMQ5GdVKYD+RmSIOEyU3XsO4AENgGqNu16mIhIqJqjzUjOtjamFkDy6VtgdQbckcBzHkAFObJHQUREZkR1oxYgp0fVo9EBABsbKAx0Bp7zhARURmYjGix7tVOcodgmL0L5I5A8vhc6aeC/6yIiEh//NQAUKhU/yZvtj1p5FY086+dI9B7vryxEBGR2WAyAiC71Eir7s72MkVi5pw8ipcjX5UvDiIiMitMRgAs2lE8GJiXiz0CPZ1ljKYaevx97dvd6xQvd3tT90y8CrYZISIi3ZiMAFh54Lpq+cTsx+ULpCJSb5r+Gg6uxcs9Zha3CQlqX7zdPdD0cRARkUViMlKKwpy+xSuVwOIWpr+Om1/x8mPTgFcPAV2mAP0Xmf7aRERk8TjOSAn+7k5yh6A/IYATP5ju/IHtgDvHpOUGvYAuU4GARxPw+TQCot413bWJiMiqsGakhPj0ajB6qb4u/AVsmlz587QZrn17zbrFywoFEPUO0OzpCl7EjGqbiIioyjEZMUfZKcBvLxnpZDoShQa9yy9DRERkBHxMU8L0Po3lDkE/m6ca8WQlxlgZ9C1QK0ya46beY0DGXcDeBbCt5D8Tc2qHQ0REVY7JCAAnexs8zFfiiZYBcoein9vHjXcuoSxeDusBuHoXr3eeVLlzB0cCNw8CDftW7jxERGTRrD4ZeZhfiIf50geyp4sZDHaWlwWkGbE7ryg5+qyRazBGbgEKcwF7jttCRES6WX0ycuN+tmrZzdEMfh0nf5Y7Ah1KT44HadI8GyYiRERUNqtvwJqUkataNosxRgqM3OOn5GMaIiIiGVh9MpL+MB8A0CG0psyRVJGOE9TXhZYaDSIioipk9clISlYeAMDL1QzaiwBA9v3KHd9nHmDrULzuwWHciYhIXlafjDwoSkZcHMopWQ2sHQ0cWGLcc7YdVbnj3fyln2E9Kx8LERFZJTNosWlanzyasTc5M7ecktVAzB/GP6dtJZOwSaeBh2lADb/yyxIREWlh9TUjRQ5fS5E7BE0FecXLh7827Nj/zNbcZor5ZOydmIgQEVGlMBl55KNnWsodgrroucAHPsCdRwOcbZ+l/7E29kDnyZrbu0xR/9l8MLR2ySUiIqpCVp+MeDhLDVcb+rnJHEkp+z6Rfm6fI/0sNOAxUqM+ZQ/h/thbwNhdwMDl6tvNoWszERFZHKtORrLzCpCWI3Xt9XZzlDkaHW7sB+Z6l18OKG7/0W1a2eVsbIDANoCtmfQgIiIii2bVycjyPddUy0U1JNWSMl+/cv0+BmbGAwGPHjk9Prf8Yxzdi5ftXQyPjYiIqJKsujeNV4m5aGxsLOQRRcl5YDpPAhr1Az5vp7u8gwswbj8AhdQYlYiIqIpZdTKy82Ki3CGYnncDIOo9wM1Xdxn/FlUXDxERUSlWnYzsu5wsdwhVo8tkuSMgIiLSyarbjBTxrVHNGq+e3yh3BERERFXGqpORTmG1AABv9W0scyQl3L8K/PZSxY5t1N+4sRAREVUBq05GimbsrTbz0jy4Afw+ouLHu/kYLxYiIqIqYtVtRj59rhWSMnLRJMC9/MJVYWU/IP223FEQERFVKatORhr41UADvxpyh1GsoomIjR3Q5yPjxkJERFRFrDoZqRaUhcAfY6QRUStqZkLZw78TERFVYxVqM7Js2TKEhobCyckJEREROHLkiM6y3bt3h0Kh0Hj178/GlgCAS9uAc+sMmwivNCYiRERkxgxORtasWYOpU6finXfewYkTJxAeHo7evXsjMVH7AGLr1q3DvXv3VK+YmBjY2tri2WefrXTwFiE/W+4IiIiIZGVwMrJo0SKMHTsWo0aNQtOmTbF8+XK4uLhgxYoVWsvXrFkT/v7+qteOHTvg4uLCZKSIwqo7NBERERmWjOTl5eH48eOIiooqPoGNDaKionDw4EG9zvHdd9/h+eefh6urq84yubm5SE9PV3tZLCYjRERk5Qz6JExOTkZhYSH8/PzUtvv5+SE+Pr7c448cOYKYmBiMGTOmzHLz58+Hh4eH6hUUFGRImOalosmIX3Ng+EZgynnjxkNERFTFqvRr+XfffYcWLVqgQ4cOZZabMWMG0tLSVK9bt25VUYQyUFRwtuDxB4B6jwEegcaNh4iIqIoZ1A3D29sbtra2SEhIUNuekJAAf3//Mo/NysrC6tWrMXfu3HKv4+joCEfHajZfjDE9TAO2vAnU6wFsGGfYsW2GA/W6myQsIiIiORhUM+Lg4IC2bdsiOjpatU2pVCI6OhqRkZFlHvv7778jNzcXL774YsUitSS75gNn1hieiADAk0uB5s8YPyYiIiKZGDxAxdSpUzFixAi0a9cOHTp0wOLFi5GVlYVRo0YBAIYPH47AwEDMnz9f7bjvvvsOTz/9NGrVqmWcyM1VXjZw+Eu5oyAiIqo2DE5GhgwZgqSkJMyZMwfx8fFo1aoVtm7dqmrUevPmTdjYqFe4xMbGYv/+/di+fbtxojZXmYnAwgZyR0FERFStKIQQQu4gypOeng4PDw+kpaXB3b2aTGpXEev+DzizuuLHTzgC+DQyXjxEREQmpO/nNwe5qCoPblQuEQGYiBARkUViMlIV8rKAJS3ljoKIiKhaYjJSFVa/IHcERERE1RaTEVMTAri2u/LnacUu0UREZJk497ypXTZCD6JZiYCdBQ8CR0REVo01I6Z281Dlz8FEhIiILBiTEVOKjwH2L9K//KtGSFyIiIjMDJMRU1re2bDyvk1MEwcREVE1xmSEiIiIZMVkxFQ2v2FY+a4GliciIrIQTEZMITsFOPqNYcc4uJgmFiIiomqOyYgp5GXKHQEREZHZYDJiCnv+V4GDFEYPg4iIyBwwGTGFkz8bfoxCRzLSfHDlYiEiIqrmOAKrseWkVuy4Rv2ln6O3A/9+BvT+EHBwA1xqGS00IiKi6ojJiLEtblGx43waSj+DI4DgVcaLh4iIqJrjYxpjy02XOwIiIiKzwmSEiIiIZMVkhIiIiGTFZISIiIhkxWSkqjh5FC/3XSBfHERERNUMkxFjSr2pe9+wtcXLNQLU9/lXsAcOERGRBWAyYkz6dustPcDZiE3Gj4WIiMhMMBmRm40d4OwpdxRERESyYTJiLEIYUFihY5mIiMj6MBkxljO/yR0BERGRWWIyYgx5WcD6Vyp2rK4J8oiIiKwEkxFj2LvQsPIKPqYhIiIqwmTEGO5fMax8yZl4WTNCRERWjrP2GoNCz5xu0LfA/ctAUETJg00SEhERkblgMlJZa18Gzm/Qr2zLZ4uXQ7oAN/YDrYeZJCwiIiJzwcc0lRWzVve+EX/p3jf0F2DIz0CvD40fExERkRlhzYgp1e2me5+TB9BkQNXFQkREVE0xGamoC5uAo9/KHQUREZHZYzJSUWsMbOvhGWyaOIiIiMwckxFTe/UwkJsO1PCXOxIiIqJqicmIqfk2ljsCIiKiao29aYiIiEhWTEYqIjtF7giIiIgsBpORitg2s/wy4/81fRxEREQWgMmIIQoLpETk9C/ll/VrZvp4iIiILAAbsOrr36XA9llyR0FERGRxWDOiLyYiREREJsFkRB/3zhhWPqSLaeIgIiKyQExG9HHiB8PKd5pomjiIiIgsEJMRfeRmyh0BERGRxWIyUp68LODMarmjICIislhMRsqz8TX9yg3iDL5EREQVwWSkPDFryy/z8j9Ay2dNHwsREZEFYjJiDB511Nd9ODkeERGRvjjoWVmSYssvY+cMuAdIy6+dlOatqVnXtHERERFZECYjZVnWofwyTQYUL9esJ72IiIhIb3xMU2lC7gCIiIjMGpORymo7Su4IiIiIzBqTEV0OfKZfOTdf08ZBRERk4ZiM6LJjtn7lbB1MGwcREZGFYzJSWV4hckdARERk1piMEBERkayYjFSUnTMwaqvcURAREZk9JiOlKQuBb6PKLzdwORASafp4iIiILByTkdKu7wNuHy2/nEJh+liIiIisAJOR0goL9CvnEWTaOIiIiKwEh4MvLS+z7P0v/A6k3wEC21RNPERERBaOyUiRB9eBJeHll2vYy+ShEBERWRM+pimiTyJCRERERsdkhIiIiGTFZISIiIhkVaFkZNmyZQgNDYWTkxMiIiJw5MiRMsunpqZiwoQJCAgIgKOjIxo2bIgtW7ZUKGAiIiKyLAY3YF2zZg2mTp2K5cuXIyIiAosXL0bv3r0RGxsLX1/NGWzz8vLw+OOPw9fXF2vXrkVgYCBu3LgBT09PY8RvHDmpckdARERktQxORhYtWoSxY8di1KhRAIDly5dj8+bNWLFiBd566y2N8itWrEBKSgr+/fdf2NvbAwBCQ0MrF7Wxpd2WOwIiIiKrZdBjmry8PBw/fhxRUcXDpdvY2CAqKgoHDx7UeszGjRsRGRmJCRMmwM/PD82bN8e8efNQWFio8zq5ublIT09Xe5mMshBY3tl05yciIqIyGZSMJCcno7CwEH5+fmrb/fz8EB8fr/WYa9euYe3atSgsLMSWLVswe/ZsfPLJJ/jggw90Xmf+/Pnw8PBQvYKCTDjaaV6W6c5NRERE5TJ5bxqlUglfX198/fXXaNu2LYYMGYKZM2di+fLlOo+ZMWMG0tLSVK9bt26ZLkB95pjp8H/Sz5ZDTBcHERGRlTKozYi3tzdsbW2RkJCgtj0hIQH+/v5ajwkICIC9vT1sbW1V25o0aYL4+Hjk5eXBwcFB4xhHR0c4OjoaElol6JGM9P4QaDYQCGxr+nCIiIisjEE1Iw4ODmjbti2io6NV25RKJaKjoxEZGan1mM6dO+PKlStQKpWqbZcuXUJAQIDWRKTKFeaVX8bWHgiJBOyqQbxEREQWxuDHNFOnTsU333yDH374ARcuXMD48eORlZWl6l0zfPhwzJgxQ1V+/PjxSElJwaRJk3Dp0iVs3rwZ8+bNw4QJE4x3F5WxearcERAREVk1g7v2DhkyBElJSZgzZw7i4+PRqlUrbN26VdWo9ebNm7CxKc5xgoKCsG3bNkyZMgUtW7ZEYGAgJk2ahOnTpxvvLirj3Hq5IyAiIrJqCiGEkDuI8qSnp8PDwwNpaWlwd3c37snf9dCjTJpxr0lERGQF9P385tw0REREJCsmI0RERCQr605GOOAZERGR7Kw7GVn3iu59zQZKPzv9t2piISIislIG96axKBc36d434DOg82TAv0WVhUNERGSNrDsZ0ealDQAE4OQO1G4lczBERESWj8lIaWE95I6AiIjIqlh3mxEiIiKSHZMRIiIikhWTESIiIpIVkxEiIiKSFZMRIiIikhWTkZJ6viN3BERERFaHyUgRv+ZA16lyR0FERGR1rDsZqdWgeNnZS744iIiIrJh1JyOewcXLNQLki4OIiMiKWXcyAlG82HuefGEQERFZMetORoRS+jnoW8DNR95YiIiIrBSTEQBQKOSNg4iIyIpZeTLy6DENkxEiIiLZMBkBAIV1/xqIiIjkZN2fwqrHNNb9ayAiIpKTdX8KFyUj4GMaIiIiuVh3MgI+piEiIpKbdX8K8zENERGR7OzkDkBWrV4A6nYDaoXJHQkREZHVsu5kpN1ouSMgIiKyenw+QURERLJiMkJERESyYjJCREREsmIyQkRERLJiMkJERESyYjJCREREsmIyQkRERLJiMkJERESyYjJCREREsmIyQkRERLJiMkJERESyYjJCREREsmIyQkRERLIyi1l7hRAAgPT0dJkjISIiIn0VfW4XfY7rYhbJSEZGBgAgKChI5kiIiIjIUBkZGfDw8NC5XyHKS1eqAaVSibt376JGjRpQKBRGO296ejqCgoJw69YtuLu7G+281Yml3yPvz/xZ+j3y/syfpd+jKe9PCIGMjAzUrl0bNja6W4aYRc2IjY0N6tSpY7Lzu7u7W+Q/sJIs/R55f+bP0u+R92f+LP0eTXV/ZdWIFGEDViIiIpIVkxEiIiKSlVUnI46OjnjnnXfg6OgodygmY+n3yPszf5Z+j7w/82fp91gd7s8sGrASERGR5bLqmhEiIiKSH5MRIiIikhWTESIiIpIVkxEiIiKSFZMRIiIikpVVJyPLli1DaGgonJycEBERgSNHjsgdklZ79+7FgAEDULt2bSgUCmzYsEFtvxACc+bMQUBAAJydnREVFYXLly+rlUlJScGwYcPg7u4OT09PvPzyy8jMzFQrc+bMGXTt2hVOTk4ICgrCggULTH1rAID58+ejffv2qFGjBnx9ffH0008jNjZWrczDhw8xYcIE1KpVC25ubnjmmWeQkJCgVubmzZvo378/XFxc4OvrizfffBMFBQVqZXbv3o02bdrA0dER9evXx/fff2/q28OXX36Jli1bqkY3jIyMxN9//20R96bNRx99BIVCgcmTJ6u2mfs9vvvuu1AoFGqvxo0bq/ab+/0BwJ07d/Diiy+iVq1acHZ2RosWLXDs2DHVfnP+OxMaGqrx/ikUCkyYMAGAZbx/hYWFmD17NurWrQtnZ2eEhYXh/fffV5ugrlq/h8JKrV69Wjg4OIgVK1aIc+fOibFjxwpPT0+RkJAgd2gatmzZImbOnCnWrVsnAIj169er7f/oo4+Eh4eH2LBhgzh9+rR48sknRd26dUVOTo6qTJ8+fUR4eLg4dOiQ2Ldvn6hfv74YOnSoan9aWprw8/MTw4YNEzExMeLXX38Vzs7O4quvvjL5/fXu3VusXLlSxMTEiFOnTol+/fqJ4OBgkZmZqSozbtw4ERQUJKKjo8WxY8dEx44dRadOnVT7CwoKRPPmzUVUVJQ4efKk2LJli/D29hYzZsxQlbl27ZpwcXERU6dOFefPnxdLly4Vtra2YuvWrSa9v40bN4rNmzeLS5cuidjYWPH2228Le3t7ERMTY/b3VtqRI0dEaGioaNmypZg0aZJqu7nf4zvvvCOaNWsm7t27p3olJSVZzP2lpKSIkJAQMXLkSHH48GFx7do1sW3bNnHlyhVVGXP+O5OYmKj23u3YsUMAELt27RJCmP/7J4QQH374oahVq5bYtGmTiIuLE7///rtwc3MTS5YsUZWpzu+h1SYjHTp0EBMmTFCtFxYWitq1a4v58+fLGFX5SicjSqVS+Pv7i48//li1LTU1VTg6Oopff/1VCCHE+fPnBQBx9OhRVZm///5bKBQKcefOHSGEEF988YXw8vISubm5qjLTp08XjRo1MvEdaUpMTBQAxJ49e4QQ0v3Y29uL33//XVXmwoULAoA4ePCgEEJK2GxsbER8fLyqzJdffinc3d1V9zRt2jTRrFkztWsNGTJE9O7d29S3pMHLy0t8++23FnVvGRkZokGDBmLHjh3iscceUyUjlnCP77zzjggPD9e6zxLub/r06aJLly4691va35lJkyaJsLAwoVQqLeL9E0KI/v37i9GjR6ttGzRokBg2bJgQovq/h1b5mCYvLw/Hjx9HVFSUapuNjQ2ioqJw8OBBGSMzXFxcHOLj49XuxcPDAxEREap7OXjwIDw9PdGuXTtVmaioKNjY2ODw4cOqMt26dYODg4OqTO/evREbG4sHDx5U0d1I0tLSAAA1a9YEABw/fhz5+flq99i4cWMEBwer3WOLFi3g5+enKtO7d2+kp6fj3LlzqjIlz1FUpirf88LCQqxevRpZWVmIjIy0qHubMGEC+vfvrxGHpdzj5cuXUbt2bdSrVw/Dhg3DzZs3AVjG/W3cuBHt2rXDs88+C19fX7Ru3RrffPONar8l/Z3Jy8vDzz//jNGjR0OhUFjE+wcAnTp1QnR0NC5dugQAOH36NPbv34++ffsCqP7voVUmI8nJySgsLFT7hwUAfn5+iI+PlymqiimKt6x7iY+Ph6+vr9p+Ozs71KxZU62MtnOUvEZVUCqVmDx5Mjp37ozmzZurru/g4ABPT0+N+AyJX1eZ9PR05OTkmOJ2VM6ePQs3Nzc4Ojpi3LhxWL9+PZo2bWoR9wYAq1evxokTJzB//nyNfZZwjxEREfj++++xdetWfPnll4iLi0PXrl2RkZFhEfd37do1fPnll2jQoAG2bduG8ePH47XXXsMPP/ygFqMl/J3ZsGEDUlNTMXLkSNV1zf39A4C33noLzz//PBo3bgx7e3u0bt0akydPxrBhw9TirK7voV2FjyQygQkTJiAmJgb79++XOxSjatSoEU6dOoW0tDSsXbsWI0aMwJ49e+QOyyhu3bqFSZMmYceOHXBycpI7HJMo+nYJAC1btkRERARCQkLw22+/wdnZWcbIjEOpVKJdu3aYN28eAKB169aIiYnB8uXLMWLECJmjM67vvvsOffv2Re3ateUOxah+++03rFq1Cr/88guaNWuGU6dOYfLkyahdu7ZZvIdWWTPi7e0NW1tbjdbSCQkJ8Pf3lymqiimKt6x78ff3R2Jiotr+goICpKSkqJXRdo6S1zC1iRMnYtOmTdi1axfq1Kmj2u7v74+8vDykpqZqxGdI/LrKuLu7m/wDxcHBAfXr10fbtm0xf/58hIeHY8mSJRZxb8ePH0diYiLatGkDOzs72NnZYc+ePfjss89gZ2cHPz8/s7/H0jw9PdGwYUNcuXLFIt7DgIAANG3aVG1bkyZNVI+iLOXvzI0bN/DPP/9gzJgxqm2W8P4BwJtvvqmqHWnRogVeeuklTJkyRVVbWd3fQ6tMRhwcHNC2bVtER0ertimVSkRHRyMyMlLGyAxXt25d+Pv7q91Leno6Dh8+rLqXyMhIpKam4vjx46oyO3fuhFKpREREhKrM3r17kZ+fryqzY8cONGrUCF5eXia9ByEEJk6ciPXr12Pnzp2oW7eu2v62bdvC3t5e7R5jY2Nx8+ZNtXs8e/as2n+kHTt2wN3dXfVHNjIyUu0cRWXkeM+VSiVyc3Mt4t569uyJs2fP4tSpU6pXu3btMGzYMNWyud9jaZmZmbh69SoCAgIs4j3s3LmzRnf6S5cuISQkBIBl/J0BgJUrV8LX1xf9+/dXbbOE9w8AsrOzYWOj/pFua2sLpVIJwAzew0o1fzVjq1evFo6OjuL7778X58+fF6+88orw9PRUay1dXWRkZIiTJ0+KkydPCgBi0aJF4uTJk+LGjRtCCKm7lqenp/jzzz/FmTNnxFNPPaW1u1br1q3F4cOHxf79+0WDBg3UumulpqYKPz8/8dJLL4mYmBixevVq4eLiUiVde8ePHy88PDzE7t271brfZWdnq8qMGzdOBAcHi507d4pjx46JyMhIERkZqdpf1PWuV69e4tSpU2Lr1q3Cx8dHa9e7N998U1y4cEEsW7asSrrevfXWW2LPnj0iLi5OnDlzRrz11ltCoVCI7du3m/296VKyN40Q5n+Pr7/+uti9e7eIi4sTBw4cEFFRUcLb21skJiZaxP0dOXJE2NnZiQ8//FBcvnxZrFq1Sri4uIiff/5ZVcbc/84UFhaK4OBgMX36dI195v7+CSHEiBEjRGBgoKpr77p164S3t7eYNm2aqkx1fg+tNhkRQoilS5eK4OBg4eDgIDp06CAOHTokd0ha7dq1SwDQeI0YMUIIIXXZmj17tvDz8xOOjo6iZ8+eIjY2Vu0c9+/fF0OHDhVubm7C3d1djBo1SmRkZKiVOX36tOjSpYtwdHQUgYGB4qOPPqqS+9N2bwDEypUrVWVycnLEq6++Kry8vISLi4sYOHCguHfvntp5rl+/Lvr27SucnZ2Ft7e3eP3110V+fr5amV27dolWrVoJBwcHUa9ePbVrmMro0aNFSEiIcHBwED4+PqJnz56qRMTc702X0smIud/jkCFDREBAgHBwcBCBgYFiyJAhamNwmPv9CSHEX3/9JZo3by4cHR1F48aNxddff62239z/zmzbtk0A0IhZCMt4/9LT08WkSZNEcHCwcHJyEvXq1RMzZ85U64Jbnd9DhRAlhmcjIiIiqmJW2WaEiIiIqg8mI0RERCQrJiNEREQkKyYjREREJCsmI0RERCQrJiNEREQkKyYjREREJCsmI0RERCQrJiNEREQkKyYjREREJCsmI0RERCSr/wfDsyEmFj3o3wAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fit_epoch(中間層の数, バッチサイズ, 学習回数, チェックポイントの作成タイミング, 最適化関数)\n",
    "fit_epoch(     4096,          64,        8000,                  100,              \"Adamax\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
