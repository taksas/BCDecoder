{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\TAKUMI\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 機械学習のライブラリ関連をインポート\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ランダムにシャッフルして，学習・テストに分割するモジュール\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "# 深層学習のライブラリをインポート\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "#表示系のインポートと設定\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ファイル操作\n",
    "import os\n",
    "\n",
    "# 画像操作\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIRS\n",
    "DIRS_DATASET = \"../Training/Datasets10000/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = []\n",
    "    \n",
    "# フォルダ内のファイルを取得\n",
    "files = os.listdir(DIRS_DATASET)\n",
    "\n",
    "# ファイル名を配列に格納\n",
    "for file in files:\n",
    "    file_names.append(file)\n",
    "\n",
    "# Pythonリスト型をnumpy.ndarray型に変換\n",
    "file_names = np.array(file_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['4510033397528.jpeg', '4510050634699.jpeg', '4510072948944.jpeg',\n",
       "       ..., '4999988925606.jpeg', '4999998682512.jpeg',\n",
       "       '4999999421189.jpeg'], dtype='<U18')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 学習データとテストデータのインデックスを作成\n",
    "# train_index, test_index = next(ss.split(file_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_names_train, file_names_test = file_names[train_index], file_names[test_index] # 学習データ，テストデータ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 画像をnumpy配列にするための関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jpeg_to_numpy(image_path):\n",
    "    # JPEG画像を開く\n",
    "    image = Image.open(image_path)\n",
    "    # NumPy配列に変換\n",
    "    numpy_array = np.array(image)\n",
    "    \n",
    "    return numpy_array\n",
    "\n",
    "def convert_to_grayscale(numpy_array):\n",
    "    # グレーと言わず2値化\n",
    "    grayscale_array = np.where(numpy_array <= 128, 0, 255)\n",
    "    # plt.imshow(grayscale_array) # こいつらのせいで処理が重かった。出力系は要注意\n",
    "    # print(grayscale_array)\n",
    "    return grayscale_array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 画像を配列にしてよしなに"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_name in file_names:\n",
    "    numpy_array = jpeg_to_numpy(DIRS_DATASET + file_name)\n",
    "    grayscale_array = convert_to_grayscale(numpy_array)\n",
    "    for i in range(13):\n",
    "        X.append(np.where(grayscale_array == 255, i+1, 0))\n",
    "        y.append(file_name[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 0,  0,  0],\n",
       "         [ 1,  1,  1],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [ 1,  1,  1],\n",
       "         [ 1,  1,  1],\n",
       "         [ 0,  0,  0]]],\n",
       "\n",
       "\n",
       "       [[[ 0,  0,  0],\n",
       "         [ 2,  2,  2],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [ 2,  2,  2],\n",
       "         [ 2,  2,  2],\n",
       "         [ 0,  0,  0]]],\n",
       "\n",
       "\n",
       "       [[[ 0,  0,  0],\n",
       "         [ 3,  3,  3],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [ 3,  3,  3],\n",
       "         [ 3,  3,  3],\n",
       "         [ 0,  0,  0]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[ 0,  0,  0],\n",
       "         [11, 11, 11],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [11, 11, 11],\n",
       "         [11, 11, 11],\n",
       "         [ 0,  0,  0]]],\n",
       "\n",
       "\n",
       "       [[[ 0,  0,  0],\n",
       "         [12, 12, 12],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [12, 12, 12],\n",
       "         [12, 12, 12],\n",
       "         [ 0,  0,  0]]],\n",
       "\n",
       "\n",
       "       [[[ 0,  0,  0],\n",
       "         [13, 13, 13],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [13, 13, 13],\n",
       "         [13, 13, 13],\n",
       "         [ 0,  0,  0]]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 5, 1, ..., 1, 8, 9])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ラベルデータをone-hotベクトルに直す\n",
    "labels = {\n",
    "    0: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], \n",
    "    1: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], \n",
    "    2: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], \n",
    "    3: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], \n",
    "    4: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], \n",
    "    5: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], \n",
    "    6: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], \n",
    "    7: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], \n",
    "    8: [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], \n",
    "    9: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], \n",
    "}\n",
    "\n",
    "y = np.array(list(map(lambda v : labels[v] , y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 1, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 1]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データの分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = ShuffleSplit(n_splits=1,      # 分割を1個生成\n",
    "                  train_size=0.8,  # 学習\n",
    "                  test_size =0.2,  # テスト\n",
    "                  random_state=0)  # 乱数種（再現用）\n",
    "\n",
    "# 学習データとテストデータのインデックスを作成\n",
    "train_index, test_index = next(ss.split(X))\n",
    "\n",
    "X_train, X_test = X[train_index], X[test_index] # 学習データ，テストデータ\n",
    "y_train, y_test = y[train_index], y[test_index] # 学習データのラベル，テストデータのラベル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 0,  0,  0],\n",
       "         [ 1,  1,  1],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [ 1,  1,  1],\n",
       "         [ 1,  1,  1],\n",
       "         [ 0,  0,  0]]],\n",
       "\n",
       "\n",
       "       [[[ 0,  0,  0],\n",
       "         [ 2,  2,  2],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [ 2,  2,  2],\n",
       "         [ 2,  2,  2],\n",
       "         [ 0,  0,  0]]],\n",
       "\n",
       "\n",
       "       [[[ 0,  0,  0],\n",
       "         [ 3,  3,  3],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [ 3,  3,  3],\n",
       "         [ 3,  3,  3],\n",
       "         [ 0,  0,  0]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[ 0,  0,  0],\n",
       "         [11, 11, 11],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [11, 11, 11],\n",
       "         [11, 11, 11],\n",
       "         [ 0,  0,  0]]],\n",
       "\n",
       "\n",
       "       [[[ 0,  0,  0],\n",
       "         [12, 12, 12],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [12, 12, 12],\n",
       "         [12, 12, 12],\n",
       "         [ 0,  0,  0]]],\n",
       "\n",
       "\n",
       "       [[[ 0,  0,  0],\n",
       "         [13, 13, 13],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [13, 13, 13],\n",
       "         [13, 13, 13],\n",
       "         [ 0,  0,  0]]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 1, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 1]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104000, 1, 112, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[0], X_train.shape[1], X_train.shape[2], X_train.shape[3] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 0,  0,  0],\n",
       "         [ 3,  3,  3],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [ 3,  3,  3],\n",
       "         [ 3,  3,  3],\n",
       "         [ 0,  0,  0]]],\n",
       "\n",
       "\n",
       "       [[[ 0,  0,  0],\n",
       "         [ 1,  1,  1],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [ 1,  1,  1],\n",
       "         [ 1,  1,  1],\n",
       "         [ 0,  0,  0]]],\n",
       "\n",
       "\n",
       "       [[[ 0,  0,  0],\n",
       "         [ 2,  2,  2],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [ 2,  2,  2],\n",
       "         [ 2,  2,  2],\n",
       "         [ 0,  0,  0]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[ 0,  0,  0],\n",
       "         [13, 13, 13],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [13, 13, 13],\n",
       "         [13, 13, 13],\n",
       "         [ 0,  0,  0]]],\n",
       "\n",
       "\n",
       "       [[[ 0,  0,  0],\n",
       "         [ 5,  5,  5],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [ 5,  5,  5],\n",
       "         [ 5,  5,  5],\n",
       "         [ 0,  0,  0]]],\n",
       "\n",
       "\n",
       "       [[[ 0,  0,  0],\n",
       "         [ 6,  6,  6],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [ 6,  6,  6],\n",
       "         [ 6,  6,  6],\n",
       "         [ 0,  0,  0]]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ニューラルネットワークの構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 学習し、テストデータで評価し、スコアを表示する\n",
    "# 引数は、中間層の数、バッチサイズ、epoch数\n",
    "\n",
    "def fit_epoch(neuron, batch, epochs):\n",
    "    \n",
    "    # レイヤーのオブジェクトを作成\n",
    "    Dense = keras.layers.Dense\n",
    "\n",
    "    # モデルの構造を定義\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Flatten(input_shape=(1, 112, 3)))\n",
    "    model.add(Dense(neuron, activation='relu'))\n",
    "    \n",
    "    # 畳み込み層を追加\n",
    "    # model.add(tf.keras.layers.Flatten(tf.keras.layers.Conv2D(filters=neuron, kernel_size=(3, 3), activation='relu', input_shape=(1, 112, 3))))\n",
    "\n",
    "    model.add(Dense(10, activation='softmax')) # 10つのラベルがありsoftmaxで最後の層作る\n",
    "\n",
    "    # モデルを構築\n",
    "    model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='Adamax',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "    # 学習を実行\n",
    "    hist = model.fit(X_train, y_train,\n",
    "        batch_size=batch, # 誤差逆伝播法をするときの1回当たりのデータ数\n",
    "        epochs=epochs,\n",
    "        verbose=1,\n",
    "        validation_split=0.1)\n",
    "    \n",
    "   # モデルを評価\n",
    "    score = model.evaluate(X_test, y_test, verbose=1)\n",
    "    print('正解率=', score[1], 'loss=', score[0])\n",
    "    \n",
    "     # 学習の様子をグラフへ描画 \n",
    "    # 正解率の推移をプロット\n",
    "    plt.plot(hist.history['accuracy'])\n",
    "    plt.plot(hist.history['val_accuracy'])\n",
    "    plt.title('Accuracy')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    # ロスの推移をプロット\n",
    "    plt.plot(hist.history['loss'])\n",
    "    plt.plot(hist.history['val_loss'])\n",
    "    plt.title('Loss')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 2.7263 - accuracy: 0.1595 - val_loss: 2.2837 - val_accuracy: 0.2155\n",
      "Epoch 2/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 2.2042 - accuracy: 0.2462 - val_loss: 2.1526 - val_accuracy: 0.2695\n",
      "Epoch 3/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 2.1330 - accuracy: 0.2577 - val_loss: 2.1173 - val_accuracy: 0.2566\n",
      "Epoch 4/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 2.1079 - accuracy: 0.2540 - val_loss: 2.0981 - val_accuracy: 0.2543\n",
      "Epoch 5/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 2.0948 - accuracy: 0.2542 - val_loss: 2.1045 - val_accuracy: 0.2496\n",
      "Epoch 6/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 2.0851 - accuracy: 0.2510 - val_loss: 2.0908 - val_accuracy: 0.2454\n",
      "Epoch 7/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 2.0797 - accuracy: 0.2512 - val_loss: 2.0874 - val_accuracy: 0.2515\n",
      "Epoch 8/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 2.0778 - accuracy: 0.2506 - val_loss: 2.0778 - val_accuracy: 0.2494\n",
      "Epoch 9/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 2.0754 - accuracy: 0.2515 - val_loss: 2.0747 - val_accuracy: 0.2503\n",
      "Epoch 10/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 2.0744 - accuracy: 0.2520 - val_loss: 2.0819 - val_accuracy: 0.2439\n",
      "Epoch 11/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 2.0742 - accuracy: 0.2507 - val_loss: 2.0780 - val_accuracy: 0.2484\n",
      "Epoch 12/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 2.0697 - accuracy: 0.2511 - val_loss: 2.0746 - val_accuracy: 0.2509\n",
      "Epoch 13/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 2.0688 - accuracy: 0.2528 - val_loss: 2.0909 - val_accuracy: 0.2438\n",
      "Epoch 14/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 2.0650 - accuracy: 0.2532 - val_loss: 2.0671 - val_accuracy: 0.2516\n",
      "Epoch 15/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 2.0653 - accuracy: 0.2528 - val_loss: 2.0817 - val_accuracy: 0.2540\n",
      "Epoch 16/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 2.0649 - accuracy: 0.2530 - val_loss: 2.0677 - val_accuracy: 0.2546\n",
      "Epoch 17/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 2.0630 - accuracy: 0.2528 - val_loss: 2.0990 - val_accuracy: 0.2494\n",
      "Epoch 18/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 2.0620 - accuracy: 0.2547 - val_loss: 2.0801 - val_accuracy: 0.2505\n",
      "Epoch 19/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 2.0587 - accuracy: 0.2558 - val_loss: 2.0681 - val_accuracy: 0.2531\n",
      "Epoch 20/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 2.0566 - accuracy: 0.2557 - val_loss: 2.0664 - val_accuracy: 0.2484\n",
      "Epoch 21/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 2.0548 - accuracy: 0.2572 - val_loss: 2.0659 - val_accuracy: 0.2528\n",
      "Epoch 22/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 2.0502 - accuracy: 0.2574 - val_loss: 2.0674 - val_accuracy: 0.2528\n",
      "Epoch 23/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 2.0492 - accuracy: 0.2583 - val_loss: 2.0745 - val_accuracy: 0.2519\n",
      "Epoch 24/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 2.0478 - accuracy: 0.2592 - val_loss: 2.0591 - val_accuracy: 0.2568\n",
      "Epoch 25/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 2.0444 - accuracy: 0.2596 - val_loss: 2.0834 - val_accuracy: 0.2535\n",
      "Epoch 26/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 2.0398 - accuracy: 0.2604 - val_loss: 2.0644 - val_accuracy: 0.2532\n",
      "Epoch 27/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 2.0393 - accuracy: 0.2605 - val_loss: 2.0728 - val_accuracy: 0.2568\n",
      "Epoch 28/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 2.0370 - accuracy: 0.2613 - val_loss: 2.0698 - val_accuracy: 0.2546\n",
      "Epoch 29/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 2.0337 - accuracy: 0.2615 - val_loss: 2.0633 - val_accuracy: 0.2554\n",
      "Epoch 30/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 2.0317 - accuracy: 0.2616 - val_loss: 2.0469 - val_accuracy: 0.2561\n",
      "Epoch 31/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 2.0270 - accuracy: 0.2632 - val_loss: 2.0521 - val_accuracy: 0.2600\n",
      "Epoch 32/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 2.0234 - accuracy: 0.2649 - val_loss: 2.0383 - val_accuracy: 0.2596\n",
      "Epoch 33/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 2.0151 - accuracy: 0.2647 - val_loss: 2.0441 - val_accuracy: 0.2571\n",
      "Epoch 34/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 2.0054 - accuracy: 0.2651 - val_loss: 2.0375 - val_accuracy: 0.2560\n",
      "Epoch 35/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.9910 - accuracy: 0.2664 - val_loss: 2.0028 - val_accuracy: 0.2629\n",
      "Epoch 36/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.9770 - accuracy: 0.2681 - val_loss: 1.9961 - val_accuracy: 0.2612\n",
      "Epoch 37/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.9612 - accuracy: 0.2696 - val_loss: 1.9731 - val_accuracy: 0.2690\n",
      "Epoch 38/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.9404 - accuracy: 0.2761 - val_loss: 1.9525 - val_accuracy: 0.2804\n",
      "Epoch 39/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.9148 - accuracy: 0.2891 - val_loss: 1.9257 - val_accuracy: 0.2900\n",
      "Epoch 40/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.8911 - accuracy: 0.3110 - val_loss: 1.9114 - val_accuracy: 0.3188\n",
      "Epoch 41/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.8688 - accuracy: 0.3326 - val_loss: 1.8885 - val_accuracy: 0.3393\n",
      "Epoch 42/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.8489 - accuracy: 0.3455 - val_loss: 1.8644 - val_accuracy: 0.3419\n",
      "Epoch 43/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.8319 - accuracy: 0.3480 - val_loss: 1.8551 - val_accuracy: 0.3425\n",
      "Epoch 44/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.8199 - accuracy: 0.3483 - val_loss: 1.8443 - val_accuracy: 0.3431\n",
      "Epoch 45/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.8069 - accuracy: 0.3498 - val_loss: 1.8323 - val_accuracy: 0.3465\n",
      "Epoch 46/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.7982 - accuracy: 0.3507 - val_loss: 1.8258 - val_accuracy: 0.3396\n",
      "Epoch 47/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.7894 - accuracy: 0.3514 - val_loss: 1.8234 - val_accuracy: 0.3437\n",
      "Epoch 48/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.7821 - accuracy: 0.3519 - val_loss: 1.8115 - val_accuracy: 0.3491\n",
      "Epoch 49/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.7762 - accuracy: 0.3539 - val_loss: 1.8073 - val_accuracy: 0.3480\n",
      "Epoch 50/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.7694 - accuracy: 0.3537 - val_loss: 1.8004 - val_accuracy: 0.3501\n",
      "Epoch 51/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.7646 - accuracy: 0.3546 - val_loss: 1.8067 - val_accuracy: 0.3480\n",
      "Epoch 52/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.7624 - accuracy: 0.3536 - val_loss: 1.7931 - val_accuracy: 0.3484\n",
      "Epoch 53/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.7582 - accuracy: 0.3554 - val_loss: 1.7870 - val_accuracy: 0.3479\n",
      "Epoch 54/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.7528 - accuracy: 0.3537 - val_loss: 1.7828 - val_accuracy: 0.3498\n",
      "Epoch 55/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.7493 - accuracy: 0.3550 - val_loss: 1.7827 - val_accuracy: 0.3458\n",
      "Epoch 56/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.7441 - accuracy: 0.3558 - val_loss: 1.7877 - val_accuracy: 0.3494\n",
      "Epoch 57/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.7406 - accuracy: 0.3571 - val_loss: 1.7786 - val_accuracy: 0.3495\n",
      "Epoch 58/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.7381 - accuracy: 0.3562 - val_loss: 1.7736 - val_accuracy: 0.3516\n",
      "Epoch 59/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.7346 - accuracy: 0.3576 - val_loss: 1.7704 - val_accuracy: 0.3528\n",
      "Epoch 60/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.7327 - accuracy: 0.3571 - val_loss: 1.7781 - val_accuracy: 0.3468\n",
      "Epoch 61/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.7306 - accuracy: 0.3573 - val_loss: 1.7793 - val_accuracy: 0.3486\n",
      "Epoch 62/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.7281 - accuracy: 0.3577 - val_loss: 1.7670 - val_accuracy: 0.3495\n",
      "Epoch 63/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.7264 - accuracy: 0.3582 - val_loss: 1.7627 - val_accuracy: 0.3519\n",
      "Epoch 64/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.7242 - accuracy: 0.3580 - val_loss: 1.7649 - val_accuracy: 0.3526\n",
      "Epoch 65/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.7223 - accuracy: 0.3591 - val_loss: 1.7656 - val_accuracy: 0.3498\n",
      "Epoch 66/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.7207 - accuracy: 0.3602 - val_loss: 1.7553 - val_accuracy: 0.3557\n",
      "Epoch 67/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.7196 - accuracy: 0.3595 - val_loss: 1.7562 - val_accuracy: 0.3538\n",
      "Epoch 68/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.7160 - accuracy: 0.3601 - val_loss: 1.7633 - val_accuracy: 0.3507\n",
      "Epoch 69/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.7154 - accuracy: 0.3607 - val_loss: 1.7587 - val_accuracy: 0.3560\n",
      "Epoch 70/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.7140 - accuracy: 0.3607 - val_loss: 1.7582 - val_accuracy: 0.3518\n",
      "Epoch 71/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.7120 - accuracy: 0.3619 - val_loss: 1.7613 - val_accuracy: 0.3512\n",
      "Epoch 72/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.7118 - accuracy: 0.3611 - val_loss: 1.7601 - val_accuracy: 0.3497\n",
      "Epoch 73/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.7095 - accuracy: 0.3630 - val_loss: 1.7506 - val_accuracy: 0.3552\n",
      "Epoch 74/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.7075 - accuracy: 0.3624 - val_loss: 1.7556 - val_accuracy: 0.3534\n",
      "Epoch 75/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.7066 - accuracy: 0.3641 - val_loss: 1.7480 - val_accuracy: 0.3553\n",
      "Epoch 76/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.7057 - accuracy: 0.3644 - val_loss: 1.7456 - val_accuracy: 0.3571\n",
      "Epoch 77/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.7042 - accuracy: 0.3631 - val_loss: 1.7443 - val_accuracy: 0.3588\n",
      "Epoch 78/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.7015 - accuracy: 0.3639 - val_loss: 1.7450 - val_accuracy: 0.3543\n",
      "Epoch 79/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.7006 - accuracy: 0.3652 - val_loss: 1.7463 - val_accuracy: 0.3532\n",
      "Epoch 80/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.7002 - accuracy: 0.3652 - val_loss: 1.7462 - val_accuracy: 0.3531\n",
      "Epoch 81/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.6974 - accuracy: 0.3663 - val_loss: 1.7468 - val_accuracy: 0.3542\n",
      "Epoch 82/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.6963 - accuracy: 0.3660 - val_loss: 1.7455 - val_accuracy: 0.3513\n",
      "Epoch 83/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.6972 - accuracy: 0.3655 - val_loss: 1.7409 - val_accuracy: 0.3575\n",
      "Epoch 84/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.6943 - accuracy: 0.3656 - val_loss: 1.7387 - val_accuracy: 0.3597\n",
      "Epoch 85/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.6929 - accuracy: 0.3671 - val_loss: 1.7388 - val_accuracy: 0.3606\n",
      "Epoch 86/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.6911 - accuracy: 0.3664 - val_loss: 1.7342 - val_accuracy: 0.3601\n",
      "Epoch 87/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.6893 - accuracy: 0.3685 - val_loss: 1.7329 - val_accuracy: 0.3567\n",
      "Epoch 88/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.6890 - accuracy: 0.3682 - val_loss: 1.7341 - val_accuracy: 0.3566\n",
      "Epoch 89/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.6841 - accuracy: 0.3699 - val_loss: 1.7264 - val_accuracy: 0.3653\n",
      "Epoch 90/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.6822 - accuracy: 0.3698 - val_loss: 1.7294 - val_accuracy: 0.3605\n",
      "Epoch 91/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.6785 - accuracy: 0.3713 - val_loss: 1.7276 - val_accuracy: 0.3653\n",
      "Epoch 92/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.6742 - accuracy: 0.3733 - val_loss: 1.7237 - val_accuracy: 0.3672\n",
      "Epoch 93/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.6689 - accuracy: 0.3764 - val_loss: 1.7092 - val_accuracy: 0.3696\n",
      "Epoch 94/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.6619 - accuracy: 0.3773 - val_loss: 1.7018 - val_accuracy: 0.3656\n",
      "Epoch 95/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.6558 - accuracy: 0.3791 - val_loss: 1.6993 - val_accuracy: 0.3692\n",
      "Epoch 96/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.6471 - accuracy: 0.3829 - val_loss: 1.6901 - val_accuracy: 0.3726\n",
      "Epoch 97/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.6369 - accuracy: 0.3863 - val_loss: 1.6806 - val_accuracy: 0.3814\n",
      "Epoch 98/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.6262 - accuracy: 0.3895 - val_loss: 1.6710 - val_accuracy: 0.3761\n",
      "Epoch 99/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.6183 - accuracy: 0.3929 - val_loss: 1.6600 - val_accuracy: 0.3839\n",
      "Epoch 100/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.6108 - accuracy: 0.3961 - val_loss: 1.6520 - val_accuracy: 0.3856\n",
      "Epoch 101/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.6028 - accuracy: 0.3980 - val_loss: 1.6429 - val_accuracy: 0.3894\n",
      "Epoch 102/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.5983 - accuracy: 0.4006 - val_loss: 1.6498 - val_accuracy: 0.3904\n",
      "Epoch 103/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.5944 - accuracy: 0.4016 - val_loss: 1.6420 - val_accuracy: 0.3913\n",
      "Epoch 104/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.5906 - accuracy: 0.4038 - val_loss: 1.6410 - val_accuracy: 0.3947\n",
      "Epoch 105/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.5870 - accuracy: 0.4063 - val_loss: 1.6364 - val_accuracy: 0.3990\n",
      "Epoch 106/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.5824 - accuracy: 0.4065 - val_loss: 1.6334 - val_accuracy: 0.3917\n",
      "Epoch 107/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.5792 - accuracy: 0.4082 - val_loss: 1.6383 - val_accuracy: 0.3952\n",
      "Epoch 108/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.5765 - accuracy: 0.4092 - val_loss: 1.6226 - val_accuracy: 0.4010\n",
      "Epoch 109/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.5752 - accuracy: 0.4107 - val_loss: 1.6235 - val_accuracy: 0.4008\n",
      "Epoch 110/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.5721 - accuracy: 0.4117 - val_loss: 1.6257 - val_accuracy: 0.3975\n",
      "Epoch 111/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.5689 - accuracy: 0.4129 - val_loss: 1.6159 - val_accuracy: 0.4029\n",
      "Epoch 112/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.5675 - accuracy: 0.4126 - val_loss: 1.6147 - val_accuracy: 0.3981\n",
      "Epoch 113/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.5662 - accuracy: 0.4140 - val_loss: 1.6118 - val_accuracy: 0.4038\n",
      "Epoch 114/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.5645 - accuracy: 0.4147 - val_loss: 1.6201 - val_accuracy: 0.4016\n",
      "Epoch 115/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.5635 - accuracy: 0.4149 - val_loss: 1.6072 - val_accuracy: 0.4037\n",
      "Epoch 116/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.5625 - accuracy: 0.4150 - val_loss: 1.6201 - val_accuracy: 0.4009\n",
      "Epoch 117/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.5594 - accuracy: 0.4164 - val_loss: 1.6036 - val_accuracy: 0.4058\n",
      "Epoch 118/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.5578 - accuracy: 0.4164 - val_loss: 1.6074 - val_accuracy: 0.4037\n",
      "Epoch 119/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.5564 - accuracy: 0.4189 - val_loss: 1.6137 - val_accuracy: 0.4056\n",
      "Epoch 120/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.5568 - accuracy: 0.4164 - val_loss: 1.6191 - val_accuracy: 0.4025\n",
      "Epoch 121/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.5544 - accuracy: 0.4179 - val_loss: 1.5985 - val_accuracy: 0.4063\n",
      "Epoch 122/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.5539 - accuracy: 0.4187 - val_loss: 1.6041 - val_accuracy: 0.4030\n",
      "Epoch 123/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.5532 - accuracy: 0.4190 - val_loss: 1.6060 - val_accuracy: 0.4041\n",
      "Epoch 124/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.5495 - accuracy: 0.4200 - val_loss: 1.6026 - val_accuracy: 0.4038\n",
      "Epoch 125/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.5499 - accuracy: 0.4202 - val_loss: 1.6056 - val_accuracy: 0.4060\n",
      "Epoch 126/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.5492 - accuracy: 0.4218 - val_loss: 1.6040 - val_accuracy: 0.4056\n",
      "Epoch 127/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.5468 - accuracy: 0.4212 - val_loss: 1.5963 - val_accuracy: 0.4091\n",
      "Epoch 128/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.5450 - accuracy: 0.4232 - val_loss: 1.5951 - val_accuracy: 0.4142\n",
      "Epoch 129/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.5427 - accuracy: 0.4221 - val_loss: 1.5965 - val_accuracy: 0.4079\n",
      "Epoch 130/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.5416 - accuracy: 0.4241 - val_loss: 1.5935 - val_accuracy: 0.4081\n",
      "Epoch 131/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.5417 - accuracy: 0.4249 - val_loss: 1.5985 - val_accuracy: 0.4121\n",
      "Epoch 132/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.5372 - accuracy: 0.4247 - val_loss: 1.5870 - val_accuracy: 0.4114\n",
      "Epoch 133/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.5356 - accuracy: 0.4255 - val_loss: 1.5832 - val_accuracy: 0.4098\n",
      "Epoch 134/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.5312 - accuracy: 0.4264 - val_loss: 1.5781 - val_accuracy: 0.4179\n",
      "Epoch 135/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.5271 - accuracy: 0.4291 - val_loss: 1.5796 - val_accuracy: 0.4131\n",
      "Epoch 136/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.5248 - accuracy: 0.4297 - val_loss: 1.5794 - val_accuracy: 0.4162\n",
      "Epoch 137/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.5208 - accuracy: 0.4302 - val_loss: 1.5682 - val_accuracy: 0.4181\n",
      "Epoch 138/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.5177 - accuracy: 0.4338 - val_loss: 1.5681 - val_accuracy: 0.4207\n",
      "Epoch 139/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.5132 - accuracy: 0.4335 - val_loss: 1.5736 - val_accuracy: 0.4182\n",
      "Epoch 140/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.5088 - accuracy: 0.4353 - val_loss: 1.5626 - val_accuracy: 0.4245\n",
      "Epoch 141/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.5055 - accuracy: 0.4382 - val_loss: 1.5576 - val_accuracy: 0.4264\n",
      "Epoch 142/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.5014 - accuracy: 0.4387 - val_loss: 1.5538 - val_accuracy: 0.4226\n",
      "Epoch 143/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.4978 - accuracy: 0.4396 - val_loss: 1.5600 - val_accuracy: 0.4244\n",
      "Epoch 144/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.4940 - accuracy: 0.4415 - val_loss: 1.5496 - val_accuracy: 0.4254\n",
      "Epoch 145/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.4907 - accuracy: 0.4426 - val_loss: 1.5403 - val_accuracy: 0.4297\n",
      "Epoch 146/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.4887 - accuracy: 0.4421 - val_loss: 1.5301 - val_accuracy: 0.4330\n",
      "Epoch 147/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.4847 - accuracy: 0.4455 - val_loss: 1.5351 - val_accuracy: 0.4304\n",
      "Epoch 148/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.4830 - accuracy: 0.4454 - val_loss: 1.5342 - val_accuracy: 0.4329\n",
      "Epoch 149/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.4814 - accuracy: 0.4455 - val_loss: 1.5362 - val_accuracy: 0.4267\n",
      "Epoch 150/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.4774 - accuracy: 0.4472 - val_loss: 1.5292 - val_accuracy: 0.4286\n",
      "Epoch 151/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.4761 - accuracy: 0.4466 - val_loss: 1.5318 - val_accuracy: 0.4336\n",
      "Epoch 152/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.4763 - accuracy: 0.4466 - val_loss: 1.5216 - val_accuracy: 0.4336\n",
      "Epoch 153/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.4716 - accuracy: 0.4477 - val_loss: 1.5303 - val_accuracy: 0.4348\n",
      "Epoch 154/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.4711 - accuracy: 0.4477 - val_loss: 1.5209 - val_accuracy: 0.4334\n",
      "Epoch 155/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.4690 - accuracy: 0.4486 - val_loss: 1.5209 - val_accuracy: 0.4317\n",
      "Epoch 156/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.4671 - accuracy: 0.4507 - val_loss: 1.5228 - val_accuracy: 0.4344\n",
      "Epoch 157/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.4654 - accuracy: 0.4502 - val_loss: 1.5185 - val_accuracy: 0.4345\n",
      "Epoch 158/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.4644 - accuracy: 0.4496 - val_loss: 1.5131 - val_accuracy: 0.4380\n",
      "Epoch 159/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.4621 - accuracy: 0.4517 - val_loss: 1.5163 - val_accuracy: 0.4356\n",
      "Epoch 160/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.4626 - accuracy: 0.4505 - val_loss: 1.5175 - val_accuracy: 0.4396\n",
      "Epoch 161/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.4591 - accuracy: 0.4529 - val_loss: 1.5122 - val_accuracy: 0.4384\n",
      "Epoch 162/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.4589 - accuracy: 0.4519 - val_loss: 1.5057 - val_accuracy: 0.4409\n",
      "Epoch 163/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.4577 - accuracy: 0.4532 - val_loss: 1.5119 - val_accuracy: 0.4391\n",
      "Epoch 164/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.4575 - accuracy: 0.4528 - val_loss: 1.5080 - val_accuracy: 0.4421\n",
      "Epoch 165/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.4543 - accuracy: 0.4544 - val_loss: 1.5040 - val_accuracy: 0.4411\n",
      "Epoch 166/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.4530 - accuracy: 0.4549 - val_loss: 1.5058 - val_accuracy: 0.4423\n",
      "Epoch 167/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.4527 - accuracy: 0.4546 - val_loss: 1.5070 - val_accuracy: 0.4425\n",
      "Epoch 168/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.4530 - accuracy: 0.4543 - val_loss: 1.4934 - val_accuracy: 0.4421\n",
      "Epoch 169/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.4506 - accuracy: 0.4559 - val_loss: 1.4995 - val_accuracy: 0.4423\n",
      "Epoch 170/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.4500 - accuracy: 0.4547 - val_loss: 1.5025 - val_accuracy: 0.4433\n",
      "Epoch 171/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.4486 - accuracy: 0.4563 - val_loss: 1.5026 - val_accuracy: 0.4440\n",
      "Epoch 172/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.4463 - accuracy: 0.4571 - val_loss: 1.4896 - val_accuracy: 0.4481\n",
      "Epoch 173/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.4459 - accuracy: 0.4571 - val_loss: 1.5003 - val_accuracy: 0.4474\n",
      "Epoch 174/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.4453 - accuracy: 0.4584 - val_loss: 1.5124 - val_accuracy: 0.4405\n",
      "Epoch 175/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.4446 - accuracy: 0.4594 - val_loss: 1.5072 - val_accuracy: 0.4399\n",
      "Epoch 176/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.4430 - accuracy: 0.4601 - val_loss: 1.5001 - val_accuracy: 0.4446\n",
      "Epoch 177/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.4414 - accuracy: 0.4624 - val_loss: 1.4960 - val_accuracy: 0.4478\n",
      "Epoch 178/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.4380 - accuracy: 0.4618 - val_loss: 1.4875 - val_accuracy: 0.4504\n",
      "Epoch 179/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.4356 - accuracy: 0.4639 - val_loss: 1.4815 - val_accuracy: 0.4524\n",
      "Epoch 180/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.4289 - accuracy: 0.4672 - val_loss: 1.4775 - val_accuracy: 0.4564\n",
      "Epoch 181/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.4238 - accuracy: 0.4676 - val_loss: 1.4738 - val_accuracy: 0.4570\n",
      "Epoch 182/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.4198 - accuracy: 0.4692 - val_loss: 1.4622 - val_accuracy: 0.4625\n",
      "Epoch 183/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.4131 - accuracy: 0.4711 - val_loss: 1.4531 - val_accuracy: 0.4650\n",
      "Epoch 184/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.4081 - accuracy: 0.4751 - val_loss: 1.4655 - val_accuracy: 0.4654\n",
      "Epoch 185/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.4050 - accuracy: 0.4732 - val_loss: 1.4475 - val_accuracy: 0.4644\n",
      "Epoch 186/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.3996 - accuracy: 0.4769 - val_loss: 1.4514 - val_accuracy: 0.4649\n",
      "Epoch 187/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.3962 - accuracy: 0.4772 - val_loss: 1.4531 - val_accuracy: 0.4623\n",
      "Epoch 188/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.3944 - accuracy: 0.4779 - val_loss: 1.4529 - val_accuracy: 0.4648\n",
      "Epoch 189/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.3920 - accuracy: 0.4802 - val_loss: 1.4311 - val_accuracy: 0.4741\n",
      "Epoch 190/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.3891 - accuracy: 0.4805 - val_loss: 1.4343 - val_accuracy: 0.4753\n",
      "Epoch 191/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.3865 - accuracy: 0.4822 - val_loss: 1.4357 - val_accuracy: 0.4714\n",
      "Epoch 192/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.3854 - accuracy: 0.4816 - val_loss: 1.4471 - val_accuracy: 0.4703\n",
      "Epoch 193/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.3814 - accuracy: 0.4832 - val_loss: 1.4227 - val_accuracy: 0.4755\n",
      "Epoch 194/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.3770 - accuracy: 0.4845 - val_loss: 1.4182 - val_accuracy: 0.4773\n",
      "Epoch 195/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.3739 - accuracy: 0.4856 - val_loss: 1.4278 - val_accuracy: 0.4748\n",
      "Epoch 196/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.3695 - accuracy: 0.4877 - val_loss: 1.4154 - val_accuracy: 0.4752\n",
      "Epoch 197/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.3668 - accuracy: 0.4891 - val_loss: 1.4157 - val_accuracy: 0.4809\n",
      "Epoch 198/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.3643 - accuracy: 0.4892 - val_loss: 1.4126 - val_accuracy: 0.4796\n",
      "Epoch 199/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.3607 - accuracy: 0.4914 - val_loss: 1.4018 - val_accuracy: 0.4823\n",
      "Epoch 200/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.3578 - accuracy: 0.4938 - val_loss: 1.4195 - val_accuracy: 0.4712\n",
      "Epoch 201/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.3564 - accuracy: 0.4935 - val_loss: 1.3998 - val_accuracy: 0.4848\n",
      "Epoch 202/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.3539 - accuracy: 0.4932 - val_loss: 1.4014 - val_accuracy: 0.4824\n",
      "Epoch 203/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.3526 - accuracy: 0.4936 - val_loss: 1.4024 - val_accuracy: 0.4889\n",
      "Epoch 204/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.3523 - accuracy: 0.4945 - val_loss: 1.3947 - val_accuracy: 0.4885\n",
      "Epoch 205/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.3497 - accuracy: 0.4953 - val_loss: 1.4195 - val_accuracy: 0.4809\n",
      "Epoch 206/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.3492 - accuracy: 0.4956 - val_loss: 1.3908 - val_accuracy: 0.4874\n",
      "Epoch 207/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.3461 - accuracy: 0.4967 - val_loss: 1.3872 - val_accuracy: 0.4873\n",
      "Epoch 208/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.3453 - accuracy: 0.4977 - val_loss: 1.3947 - val_accuracy: 0.4842\n",
      "Epoch 209/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.3419 - accuracy: 0.5000 - val_loss: 1.3903 - val_accuracy: 0.4854\n",
      "Epoch 210/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.3414 - accuracy: 0.4981 - val_loss: 1.3887 - val_accuracy: 0.4922\n",
      "Epoch 211/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.3387 - accuracy: 0.4998 - val_loss: 1.3747 - val_accuracy: 0.4933\n",
      "Epoch 212/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.3354 - accuracy: 0.5021 - val_loss: 1.3812 - val_accuracy: 0.4919\n",
      "Epoch 213/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.3360 - accuracy: 0.5021 - val_loss: 1.3922 - val_accuracy: 0.4849\n",
      "Epoch 214/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.3344 - accuracy: 0.5019 - val_loss: 1.3848 - val_accuracy: 0.4863\n",
      "Epoch 215/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.3311 - accuracy: 0.5036 - val_loss: 1.3912 - val_accuracy: 0.4910\n",
      "Epoch 216/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.3311 - accuracy: 0.5022 - val_loss: 1.3703 - val_accuracy: 0.4922\n",
      "Epoch 217/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.3303 - accuracy: 0.5040 - val_loss: 1.3850 - val_accuracy: 0.4889\n",
      "Epoch 218/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.3292 - accuracy: 0.5040 - val_loss: 1.3724 - val_accuracy: 0.4927\n",
      "Epoch 219/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.3267 - accuracy: 0.5052 - val_loss: 1.3732 - val_accuracy: 0.4947\n",
      "Epoch 220/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.3258 - accuracy: 0.5050 - val_loss: 1.3775 - val_accuracy: 0.4935\n",
      "Epoch 221/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.3231 - accuracy: 0.5061 - val_loss: 1.3722 - val_accuracy: 0.4936\n",
      "Epoch 222/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.3249 - accuracy: 0.5048 - val_loss: 1.3678 - val_accuracy: 0.4942\n",
      "Epoch 223/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.3233 - accuracy: 0.5067 - val_loss: 1.3835 - val_accuracy: 0.4913\n",
      "Epoch 224/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.3214 - accuracy: 0.5073 - val_loss: 1.3759 - val_accuracy: 0.4911\n",
      "Epoch 225/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.3216 - accuracy: 0.5079 - val_loss: 1.3737 - val_accuracy: 0.4963\n",
      "Epoch 226/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.3203 - accuracy: 0.5077 - val_loss: 1.3665 - val_accuracy: 0.4943\n",
      "Epoch 227/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.3181 - accuracy: 0.5082 - val_loss: 1.3667 - val_accuracy: 0.5000\n",
      "Epoch 228/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.3160 - accuracy: 0.5096 - val_loss: 1.3664 - val_accuracy: 0.4960\n",
      "Epoch 229/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.3174 - accuracy: 0.5096 - val_loss: 1.3720 - val_accuracy: 0.5005\n",
      "Epoch 230/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.3154 - accuracy: 0.5092 - val_loss: 1.3621 - val_accuracy: 0.4988\n",
      "Epoch 231/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.3147 - accuracy: 0.5109 - val_loss: 1.3566 - val_accuracy: 0.4997\n",
      "Epoch 232/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.3146 - accuracy: 0.5099 - val_loss: 1.3626 - val_accuracy: 0.4994\n",
      "Epoch 233/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.3132 - accuracy: 0.5102 - val_loss: 1.3721 - val_accuracy: 0.4937\n",
      "Epoch 234/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.3102 - accuracy: 0.5122 - val_loss: 1.3742 - val_accuracy: 0.4940\n",
      "Epoch 235/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.3116 - accuracy: 0.5109 - val_loss: 1.3547 - val_accuracy: 0.5037\n",
      "Epoch 236/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.3106 - accuracy: 0.5114 - val_loss: 1.3593 - val_accuracy: 0.4973\n",
      "Epoch 237/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.3096 - accuracy: 0.5122 - val_loss: 1.3596 - val_accuracy: 0.5019\n",
      "Epoch 238/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.3100 - accuracy: 0.5119 - val_loss: 1.3612 - val_accuracy: 0.5011\n",
      "Epoch 239/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.3074 - accuracy: 0.5114 - val_loss: 1.3637 - val_accuracy: 0.4937\n",
      "Epoch 240/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.3084 - accuracy: 0.5127 - val_loss: 1.3720 - val_accuracy: 0.4943\n",
      "Epoch 241/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.3092 - accuracy: 0.5113 - val_loss: 1.3577 - val_accuracy: 0.5005\n",
      "Epoch 242/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.3062 - accuracy: 0.5129 - val_loss: 1.3531 - val_accuracy: 0.5039\n",
      "Epoch 243/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.3052 - accuracy: 0.5129 - val_loss: 1.3543 - val_accuracy: 0.5011\n",
      "Epoch 244/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.3056 - accuracy: 0.5125 - val_loss: 1.3559 - val_accuracy: 0.5029\n",
      "Epoch 245/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.3074 - accuracy: 0.5124 - val_loss: 1.3643 - val_accuracy: 0.4967\n",
      "Epoch 246/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.3041 - accuracy: 0.5136 - val_loss: 1.3521 - val_accuracy: 0.5044\n",
      "Epoch 247/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.3042 - accuracy: 0.5132 - val_loss: 1.3623 - val_accuracy: 0.4993\n",
      "Epoch 248/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.3030 - accuracy: 0.5143 - val_loss: 1.3528 - val_accuracy: 0.5024\n",
      "Epoch 249/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.3035 - accuracy: 0.5135 - val_loss: 1.3595 - val_accuracy: 0.4987\n",
      "Epoch 250/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.3002 - accuracy: 0.5157 - val_loss: 1.3591 - val_accuracy: 0.5024\n",
      "Epoch 251/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.3022 - accuracy: 0.5143 - val_loss: 1.3553 - val_accuracy: 0.5000\n",
      "Epoch 252/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.3007 - accuracy: 0.5146 - val_loss: 1.3532 - val_accuracy: 0.5007\n",
      "Epoch 253/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.2995 - accuracy: 0.5141 - val_loss: 1.3505 - val_accuracy: 0.5012\n",
      "Epoch 254/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.3006 - accuracy: 0.5150 - val_loss: 1.3554 - val_accuracy: 0.4997\n",
      "Epoch 255/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2986 - accuracy: 0.5157 - val_loss: 1.3595 - val_accuracy: 0.4971\n",
      "Epoch 256/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.2986 - accuracy: 0.5155 - val_loss: 1.3600 - val_accuracy: 0.4969\n",
      "Epoch 257/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.3007 - accuracy: 0.5160 - val_loss: 1.3641 - val_accuracy: 0.5003\n",
      "Epoch 258/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.2983 - accuracy: 0.5152 - val_loss: 1.3539 - val_accuracy: 0.5018\n",
      "Epoch 259/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2991 - accuracy: 0.5157 - val_loss: 1.3501 - val_accuracy: 0.5020\n",
      "Epoch 260/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.2962 - accuracy: 0.5173 - val_loss: 1.3533 - val_accuracy: 0.5034\n",
      "Epoch 261/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.2968 - accuracy: 0.5170 - val_loss: 1.3455 - val_accuracy: 0.5072\n",
      "Epoch 262/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.2965 - accuracy: 0.5163 - val_loss: 1.3423 - val_accuracy: 0.5072\n",
      "Epoch 263/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.2969 - accuracy: 0.5161 - val_loss: 1.3461 - val_accuracy: 0.5063\n",
      "Epoch 264/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2960 - accuracy: 0.5164 - val_loss: 1.3539 - val_accuracy: 0.4998\n",
      "Epoch 265/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2957 - accuracy: 0.5180 - val_loss: 1.3476 - val_accuracy: 0.5050\n",
      "Epoch 266/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2930 - accuracy: 0.5174 - val_loss: 1.3502 - val_accuracy: 0.5030\n",
      "Epoch 267/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2947 - accuracy: 0.5174 - val_loss: 1.3531 - val_accuracy: 0.5034\n",
      "Epoch 268/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2945 - accuracy: 0.5182 - val_loss: 1.3431 - val_accuracy: 0.5081\n",
      "Epoch 269/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2934 - accuracy: 0.5191 - val_loss: 1.3396 - val_accuracy: 0.5081\n",
      "Epoch 270/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2914 - accuracy: 0.5178 - val_loss: 1.3427 - val_accuracy: 0.5014\n",
      "Epoch 271/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2937 - accuracy: 0.5167 - val_loss: 1.3425 - val_accuracy: 0.5070\n",
      "Epoch 272/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2911 - accuracy: 0.5188 - val_loss: 1.3414 - val_accuracy: 0.5061\n",
      "Epoch 273/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2917 - accuracy: 0.5186 - val_loss: 1.3471 - val_accuracy: 0.5060\n",
      "Epoch 274/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2913 - accuracy: 0.5191 - val_loss: 1.3429 - val_accuracy: 0.5044\n",
      "Epoch 275/2000\n",
      "366/366 [==============================] - 1s 4ms/step - loss: 1.2910 - accuracy: 0.5191 - val_loss: 1.3463 - val_accuracy: 0.5044\n",
      "Epoch 276/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2913 - accuracy: 0.5184 - val_loss: 1.3404 - val_accuracy: 0.5038\n",
      "Epoch 277/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2909 - accuracy: 0.5188 - val_loss: 1.3454 - val_accuracy: 0.5063\n",
      "Epoch 278/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2919 - accuracy: 0.5176 - val_loss: 1.3486 - val_accuracy: 0.5071\n",
      "Epoch 279/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2887 - accuracy: 0.5190 - val_loss: 1.3391 - val_accuracy: 0.5063\n",
      "Epoch 280/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2899 - accuracy: 0.5207 - val_loss: 1.3374 - val_accuracy: 0.5063\n",
      "Epoch 281/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2871 - accuracy: 0.5208 - val_loss: 1.3461 - val_accuracy: 0.5035\n",
      "Epoch 282/2000\n",
      "366/366 [==============================] - 1s 4ms/step - loss: 1.2879 - accuracy: 0.5195 - val_loss: 1.3360 - val_accuracy: 0.5030\n",
      "Epoch 283/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2879 - accuracy: 0.5192 - val_loss: 1.3468 - val_accuracy: 0.5038\n",
      "Epoch 284/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2869 - accuracy: 0.5197 - val_loss: 1.3496 - val_accuracy: 0.5045\n",
      "Epoch 285/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2885 - accuracy: 0.5203 - val_loss: 1.3368 - val_accuracy: 0.5036\n",
      "Epoch 286/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2866 - accuracy: 0.5192 - val_loss: 1.3335 - val_accuracy: 0.5073\n",
      "Epoch 287/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2870 - accuracy: 0.5201 - val_loss: 1.3364 - val_accuracy: 0.5051\n",
      "Epoch 288/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2839 - accuracy: 0.5207 - val_loss: 1.3543 - val_accuracy: 0.4965\n",
      "Epoch 289/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2864 - accuracy: 0.5206 - val_loss: 1.3365 - val_accuracy: 0.5071\n",
      "Epoch 290/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2843 - accuracy: 0.5203 - val_loss: 1.3512 - val_accuracy: 0.5020\n",
      "Epoch 291/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2869 - accuracy: 0.5208 - val_loss: 1.3349 - val_accuracy: 0.5093\n",
      "Epoch 292/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2825 - accuracy: 0.5214 - val_loss: 1.3469 - val_accuracy: 0.5031\n",
      "Epoch 293/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2833 - accuracy: 0.5208 - val_loss: 1.3317 - val_accuracy: 0.5110\n",
      "Epoch 294/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2838 - accuracy: 0.5225 - val_loss: 1.3382 - val_accuracy: 0.5060\n",
      "Epoch 295/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2831 - accuracy: 0.5207 - val_loss: 1.3367 - val_accuracy: 0.5100\n",
      "Epoch 296/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2804 - accuracy: 0.5232 - val_loss: 1.3326 - val_accuracy: 0.5094\n",
      "Epoch 297/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2837 - accuracy: 0.5214 - val_loss: 1.3459 - val_accuracy: 0.5017\n",
      "Epoch 298/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2854 - accuracy: 0.5212 - val_loss: 1.3316 - val_accuracy: 0.5119\n",
      "Epoch 299/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2814 - accuracy: 0.5238 - val_loss: 1.3348 - val_accuracy: 0.5063\n",
      "Epoch 300/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2827 - accuracy: 0.5215 - val_loss: 1.3511 - val_accuracy: 0.5018\n",
      "Epoch 301/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2809 - accuracy: 0.5227 - val_loss: 1.3304 - val_accuracy: 0.5114\n",
      "Epoch 302/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2807 - accuracy: 0.5234 - val_loss: 1.3413 - val_accuracy: 0.5085\n",
      "Epoch 303/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2816 - accuracy: 0.5226 - val_loss: 1.3425 - val_accuracy: 0.5087\n",
      "Epoch 304/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2800 - accuracy: 0.5235 - val_loss: 1.3377 - val_accuracy: 0.5127\n",
      "Epoch 305/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2805 - accuracy: 0.5229 - val_loss: 1.3343 - val_accuracy: 0.5124\n",
      "Epoch 306/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2791 - accuracy: 0.5238 - val_loss: 1.3235 - val_accuracy: 0.5163\n",
      "Epoch 307/2000\n",
      "366/366 [==============================] - 1s 4ms/step - loss: 1.2796 - accuracy: 0.5248 - val_loss: 1.3383 - val_accuracy: 0.5076\n",
      "Epoch 308/2000\n",
      "366/366 [==============================] - 1s 4ms/step - loss: 1.2787 - accuracy: 0.5238 - val_loss: 1.3271 - val_accuracy: 0.5141\n",
      "Epoch 309/2000\n",
      "366/366 [==============================] - 1s 4ms/step - loss: 1.2766 - accuracy: 0.5243 - val_loss: 1.3339 - val_accuracy: 0.5096\n",
      "Epoch 310/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2755 - accuracy: 0.5252 - val_loss: 1.3320 - val_accuracy: 0.5133\n",
      "Epoch 311/2000\n",
      "366/366 [==============================] - 1s 4ms/step - loss: 1.2760 - accuracy: 0.5246 - val_loss: 1.3263 - val_accuracy: 0.5148\n",
      "Epoch 312/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2738 - accuracy: 0.5268 - val_loss: 1.3228 - val_accuracy: 0.5138\n",
      "Epoch 313/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2756 - accuracy: 0.5259 - val_loss: 1.3289 - val_accuracy: 0.5100\n",
      "Epoch 314/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2724 - accuracy: 0.5280 - val_loss: 1.3384 - val_accuracy: 0.5054\n",
      "Epoch 315/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2722 - accuracy: 0.5264 - val_loss: 1.3343 - val_accuracy: 0.5122\n",
      "Epoch 316/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2720 - accuracy: 0.5276 - val_loss: 1.3373 - val_accuracy: 0.5083\n",
      "Epoch 317/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2709 - accuracy: 0.5278 - val_loss: 1.3263 - val_accuracy: 0.5114\n",
      "Epoch 318/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2699 - accuracy: 0.5276 - val_loss: 1.3429 - val_accuracy: 0.5088\n",
      "Epoch 319/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2690 - accuracy: 0.5284 - val_loss: 1.3233 - val_accuracy: 0.5155\n",
      "Epoch 320/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.2660 - accuracy: 0.5291 - val_loss: 1.3215 - val_accuracy: 0.5167\n",
      "Epoch 321/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.2669 - accuracy: 0.5279 - val_loss: 1.3288 - val_accuracy: 0.5127\n",
      "Epoch 322/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2652 - accuracy: 0.5307 - val_loss: 1.3238 - val_accuracy: 0.5150\n",
      "Epoch 323/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2626 - accuracy: 0.5319 - val_loss: 1.3149 - val_accuracy: 0.5169\n",
      "Epoch 324/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2635 - accuracy: 0.5306 - val_loss: 1.3139 - val_accuracy: 0.5151\n",
      "Epoch 325/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.2620 - accuracy: 0.5317 - val_loss: 1.3051 - val_accuracy: 0.5212\n",
      "Epoch 326/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2605 - accuracy: 0.5315 - val_loss: 1.3115 - val_accuracy: 0.5252\n",
      "Epoch 327/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2622 - accuracy: 0.5319 - val_loss: 1.3177 - val_accuracy: 0.5184\n",
      "Epoch 328/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2579 - accuracy: 0.5342 - val_loss: 1.3162 - val_accuracy: 0.5175\n",
      "Epoch 329/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2562 - accuracy: 0.5346 - val_loss: 1.3123 - val_accuracy: 0.5182\n",
      "Epoch 330/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2548 - accuracy: 0.5357 - val_loss: 1.3203 - val_accuracy: 0.5162\n",
      "Epoch 331/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.2536 - accuracy: 0.5363 - val_loss: 1.3121 - val_accuracy: 0.5196\n",
      "Epoch 332/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.2534 - accuracy: 0.5351 - val_loss: 1.3017 - val_accuracy: 0.5251\n",
      "Epoch 333/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.2514 - accuracy: 0.5367 - val_loss: 1.3079 - val_accuracy: 0.5241\n",
      "Epoch 334/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2525 - accuracy: 0.5363 - val_loss: 1.2997 - val_accuracy: 0.5267\n",
      "Epoch 335/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.2512 - accuracy: 0.5376 - val_loss: 1.2995 - val_accuracy: 0.5242\n",
      "Epoch 336/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2482 - accuracy: 0.5375 - val_loss: 1.3035 - val_accuracy: 0.5243\n",
      "Epoch 337/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.2474 - accuracy: 0.5391 - val_loss: 1.3137 - val_accuracy: 0.5156\n",
      "Epoch 338/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2447 - accuracy: 0.5396 - val_loss: 1.3079 - val_accuracy: 0.5203\n",
      "Epoch 339/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.2474 - accuracy: 0.5382 - val_loss: 1.3028 - val_accuracy: 0.5272\n",
      "Epoch 340/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.2464 - accuracy: 0.5392 - val_loss: 1.2972 - val_accuracy: 0.5265\n",
      "Epoch 341/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.2447 - accuracy: 0.5381 - val_loss: 1.3102 - val_accuracy: 0.5211\n",
      "Epoch 342/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2446 - accuracy: 0.5395 - val_loss: 1.3109 - val_accuracy: 0.5241\n",
      "Epoch 343/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.2421 - accuracy: 0.5404 - val_loss: 1.2933 - val_accuracy: 0.5321\n",
      "Epoch 344/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.2416 - accuracy: 0.5400 - val_loss: 1.2953 - val_accuracy: 0.5266\n",
      "Epoch 345/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.2412 - accuracy: 0.5410 - val_loss: 1.3006 - val_accuracy: 0.5274\n",
      "Epoch 346/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2412 - accuracy: 0.5424 - val_loss: 1.2891 - val_accuracy: 0.5306\n",
      "Epoch 347/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2401 - accuracy: 0.5413 - val_loss: 1.2945 - val_accuracy: 0.5287\n",
      "Epoch 348/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.2384 - accuracy: 0.5435 - val_loss: 1.3007 - val_accuracy: 0.5233\n",
      "Epoch 349/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.2364 - accuracy: 0.5435 - val_loss: 1.2868 - val_accuracy: 0.5289\n",
      "Epoch 350/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2386 - accuracy: 0.5430 - val_loss: 1.2984 - val_accuracy: 0.5275\n",
      "Epoch 351/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2395 - accuracy: 0.5418 - val_loss: 1.2867 - val_accuracy: 0.5309\n",
      "Epoch 352/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.2355 - accuracy: 0.5451 - val_loss: 1.2965 - val_accuracy: 0.5235\n",
      "Epoch 353/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.2366 - accuracy: 0.5431 - val_loss: 1.2886 - val_accuracy: 0.5313\n",
      "Epoch 354/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.2356 - accuracy: 0.5433 - val_loss: 1.2870 - val_accuracy: 0.5329\n",
      "Epoch 355/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.2331 - accuracy: 0.5453 - val_loss: 1.2949 - val_accuracy: 0.5271\n",
      "Epoch 356/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.2318 - accuracy: 0.5463 - val_loss: 1.2962 - val_accuracy: 0.5322\n",
      "Epoch 357/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.2323 - accuracy: 0.5467 - val_loss: 1.2810 - val_accuracy: 0.5360\n",
      "Epoch 358/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2300 - accuracy: 0.5468 - val_loss: 1.2843 - val_accuracy: 0.5416\n",
      "Epoch 359/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.2297 - accuracy: 0.5468 - val_loss: 1.2865 - val_accuracy: 0.5314\n",
      "Epoch 360/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.2311 - accuracy: 0.5472 - val_loss: 1.2861 - val_accuracy: 0.5353\n",
      "Epoch 361/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2296 - accuracy: 0.5469 - val_loss: 1.2916 - val_accuracy: 0.5255\n",
      "Epoch 362/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.2294 - accuracy: 0.5489 - val_loss: 1.2959 - val_accuracy: 0.5318\n",
      "Epoch 363/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.2305 - accuracy: 0.5473 - val_loss: 1.2829 - val_accuracy: 0.5364\n",
      "Epoch 364/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.2272 - accuracy: 0.5493 - val_loss: 1.2932 - val_accuracy: 0.5303\n",
      "Epoch 365/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.2264 - accuracy: 0.5492 - val_loss: 1.2902 - val_accuracy: 0.5328\n",
      "Epoch 366/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.2251 - accuracy: 0.5494 - val_loss: 1.2743 - val_accuracy: 0.5423\n",
      "Epoch 367/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.2271 - accuracy: 0.5487 - val_loss: 1.2710 - val_accuracy: 0.5380\n",
      "Epoch 368/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2268 - accuracy: 0.5486 - val_loss: 1.2788 - val_accuracy: 0.5393\n",
      "Epoch 369/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2248 - accuracy: 0.5505 - val_loss: 1.2918 - val_accuracy: 0.5332\n",
      "Epoch 370/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.2223 - accuracy: 0.5493 - val_loss: 1.2777 - val_accuracy: 0.5379\n",
      "Epoch 371/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.2243 - accuracy: 0.5502 - val_loss: 1.2912 - val_accuracy: 0.5294\n",
      "Epoch 372/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.2227 - accuracy: 0.5494 - val_loss: 1.2699 - val_accuracy: 0.5404\n",
      "Epoch 373/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2225 - accuracy: 0.5510 - val_loss: 1.2723 - val_accuracy: 0.5365\n",
      "Epoch 374/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.2241 - accuracy: 0.5495 - val_loss: 1.2817 - val_accuracy: 0.5337\n",
      "Epoch 375/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.2216 - accuracy: 0.5511 - val_loss: 1.2782 - val_accuracy: 0.5357\n",
      "Epoch 376/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.2215 - accuracy: 0.5502 - val_loss: 1.2649 - val_accuracy: 0.5405\n",
      "Epoch 377/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2199 - accuracy: 0.5515 - val_loss: 1.2752 - val_accuracy: 0.5331\n",
      "Epoch 378/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.2195 - accuracy: 0.5528 - val_loss: 1.2773 - val_accuracy: 0.5330\n",
      "Epoch 379/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.2223 - accuracy: 0.5511 - val_loss: 1.2783 - val_accuracy: 0.5327\n",
      "Epoch 380/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2194 - accuracy: 0.5525 - val_loss: 1.2680 - val_accuracy: 0.5417\n",
      "Epoch 381/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.2181 - accuracy: 0.5530 - val_loss: 1.2713 - val_accuracy: 0.5412\n",
      "Epoch 382/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.2200 - accuracy: 0.5522 - val_loss: 1.2660 - val_accuracy: 0.5433\n",
      "Epoch 383/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.2166 - accuracy: 0.5543 - val_loss: 1.2753 - val_accuracy: 0.5394\n",
      "Epoch 384/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2164 - accuracy: 0.5527 - val_loss: 1.2688 - val_accuracy: 0.5402\n",
      "Epoch 385/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.2194 - accuracy: 0.5524 - val_loss: 1.2687 - val_accuracy: 0.5376\n",
      "Epoch 386/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2152 - accuracy: 0.5542 - val_loss: 1.2750 - val_accuracy: 0.5387\n",
      "Epoch 387/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2168 - accuracy: 0.5537 - val_loss: 1.2661 - val_accuracy: 0.5434\n",
      "Epoch 388/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2158 - accuracy: 0.5546 - val_loss: 1.2794 - val_accuracy: 0.5377\n",
      "Epoch 389/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2173 - accuracy: 0.5533 - val_loss: 1.2782 - val_accuracy: 0.5359\n",
      "Epoch 390/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2131 - accuracy: 0.5548 - val_loss: 1.2888 - val_accuracy: 0.5359\n",
      "Epoch 391/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.2147 - accuracy: 0.5557 - val_loss: 1.2737 - val_accuracy: 0.5367\n",
      "Epoch 392/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.2111 - accuracy: 0.5559 - val_loss: 1.2582 - val_accuracy: 0.5467\n",
      "Epoch 393/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2111 - accuracy: 0.5567 - val_loss: 1.2665 - val_accuracy: 0.5393\n",
      "Epoch 394/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.2144 - accuracy: 0.5547 - val_loss: 1.2817 - val_accuracy: 0.5356\n",
      "Epoch 395/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.2132 - accuracy: 0.5548 - val_loss: 1.2718 - val_accuracy: 0.5423\n",
      "Epoch 396/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.2121 - accuracy: 0.5550 - val_loss: 1.2768 - val_accuracy: 0.5382\n",
      "Epoch 397/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.2115 - accuracy: 0.5567 - val_loss: 1.2673 - val_accuracy: 0.5431\n",
      "Epoch 398/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.2120 - accuracy: 0.5544 - val_loss: 1.2701 - val_accuracy: 0.5401\n",
      "Epoch 399/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.2089 - accuracy: 0.5568 - val_loss: 1.2817 - val_accuracy: 0.5403\n",
      "Epoch 400/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2095 - accuracy: 0.5569 - val_loss: 1.2570 - val_accuracy: 0.5453\n",
      "Epoch 401/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.2100 - accuracy: 0.5564 - val_loss: 1.2584 - val_accuracy: 0.5437\n",
      "Epoch 402/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.2101 - accuracy: 0.5560 - val_loss: 1.2573 - val_accuracy: 0.5442\n",
      "Epoch 403/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.2084 - accuracy: 0.5570 - val_loss: 1.2728 - val_accuracy: 0.5407\n",
      "Epoch 404/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2091 - accuracy: 0.5577 - val_loss: 1.2660 - val_accuracy: 0.5437\n",
      "Epoch 405/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.2071 - accuracy: 0.5576 - val_loss: 1.2624 - val_accuracy: 0.5456\n",
      "Epoch 406/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2092 - accuracy: 0.5562 - val_loss: 1.2658 - val_accuracy: 0.5467\n",
      "Epoch 407/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2067 - accuracy: 0.5571 - val_loss: 1.2578 - val_accuracy: 0.5412\n",
      "Epoch 408/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2071 - accuracy: 0.5579 - val_loss: 1.2584 - val_accuracy: 0.5482\n",
      "Epoch 409/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.2072 - accuracy: 0.5577 - val_loss: 1.2565 - val_accuracy: 0.5498\n",
      "Epoch 410/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2049 - accuracy: 0.5597 - val_loss: 1.2656 - val_accuracy: 0.5468\n",
      "Epoch 411/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.2042 - accuracy: 0.5595 - val_loss: 1.2688 - val_accuracy: 0.5407\n",
      "Epoch 412/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.2032 - accuracy: 0.5610 - val_loss: 1.2756 - val_accuracy: 0.5391\n",
      "Epoch 413/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.2044 - accuracy: 0.5589 - val_loss: 1.2552 - val_accuracy: 0.5482\n",
      "Epoch 414/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.2033 - accuracy: 0.5599 - val_loss: 1.2579 - val_accuracy: 0.5474\n",
      "Epoch 415/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.2047 - accuracy: 0.5599 - val_loss: 1.2511 - val_accuracy: 0.5505\n",
      "Epoch 416/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.2014 - accuracy: 0.5600 - val_loss: 1.2595 - val_accuracy: 0.5470\n",
      "Epoch 417/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.1998 - accuracy: 0.5615 - val_loss: 1.2607 - val_accuracy: 0.5477\n",
      "Epoch 418/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.1999 - accuracy: 0.5616 - val_loss: 1.2546 - val_accuracy: 0.5514\n",
      "Epoch 419/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.2013 - accuracy: 0.5607 - val_loss: 1.2557 - val_accuracy: 0.5487\n",
      "Epoch 420/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.1990 - accuracy: 0.5615 - val_loss: 1.2583 - val_accuracy: 0.5468\n",
      "Epoch 421/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.1989 - accuracy: 0.5612 - val_loss: 1.2573 - val_accuracy: 0.5460\n",
      "Epoch 422/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.1990 - accuracy: 0.5614 - val_loss: 1.2509 - val_accuracy: 0.5470\n",
      "Epoch 423/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.1995 - accuracy: 0.5616 - val_loss: 1.2512 - val_accuracy: 0.5464\n",
      "Epoch 424/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.1956 - accuracy: 0.5616 - val_loss: 1.2540 - val_accuracy: 0.5483\n",
      "Epoch 425/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.1958 - accuracy: 0.5640 - val_loss: 1.2467 - val_accuracy: 0.5551\n",
      "Epoch 426/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.1984 - accuracy: 0.5625 - val_loss: 1.2490 - val_accuracy: 0.5533\n",
      "Epoch 427/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.1972 - accuracy: 0.5616 - val_loss: 1.2452 - val_accuracy: 0.5521\n",
      "Epoch 428/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.1956 - accuracy: 0.5627 - val_loss: 1.2492 - val_accuracy: 0.5516\n",
      "Epoch 429/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.1948 - accuracy: 0.5633 - val_loss: 1.2483 - val_accuracy: 0.5453\n",
      "Epoch 430/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.1952 - accuracy: 0.5613 - val_loss: 1.2472 - val_accuracy: 0.5532\n",
      "Epoch 431/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.1942 - accuracy: 0.5626 - val_loss: 1.2393 - val_accuracy: 0.5528\n",
      "Epoch 432/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.1935 - accuracy: 0.5641 - val_loss: 1.2567 - val_accuracy: 0.5468\n",
      "Epoch 433/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.1947 - accuracy: 0.5636 - val_loss: 1.2524 - val_accuracy: 0.5523\n",
      "Epoch 434/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.1931 - accuracy: 0.5619 - val_loss: 1.2569 - val_accuracy: 0.5491\n",
      "Epoch 435/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.1942 - accuracy: 0.5626 - val_loss: 1.2463 - val_accuracy: 0.5516\n",
      "Epoch 436/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.1910 - accuracy: 0.5636 - val_loss: 1.2500 - val_accuracy: 0.5511\n",
      "Epoch 437/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.1940 - accuracy: 0.5627 - val_loss: 1.2458 - val_accuracy: 0.5506\n",
      "Epoch 438/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.1929 - accuracy: 0.5650 - val_loss: 1.2646 - val_accuracy: 0.5488\n",
      "Epoch 439/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.1904 - accuracy: 0.5650 - val_loss: 1.2468 - val_accuracy: 0.5480\n",
      "Epoch 440/2000\n",
      "366/366 [==============================] - 2s 4ms/step - loss: 1.1915 - accuracy: 0.5628 - val_loss: 1.2443 - val_accuracy: 0.5560\n",
      "Epoch 441/2000\n",
      "366/366 [==============================] - 1s 4ms/step - loss: 1.1914 - accuracy: 0.5633 - val_loss: 1.2433 - val_accuracy: 0.5562\n",
      "Epoch 442/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.1899 - accuracy: 0.5644 - val_loss: 1.2463 - val_accuracy: 0.5545\n",
      "Epoch 443/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.1900 - accuracy: 0.5641 - val_loss: 1.2702 - val_accuracy: 0.5466\n",
      "Epoch 444/2000\n",
      "366/366 [==============================] - 2s 4ms/step - loss: 1.1905 - accuracy: 0.5642 - val_loss: 1.2518 - val_accuracy: 0.5484\n",
      "Epoch 445/2000\n",
      "366/366 [==============================] - 1s 4ms/step - loss: 1.1892 - accuracy: 0.5661 - val_loss: 1.2443 - val_accuracy: 0.5545\n",
      "Epoch 446/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.1879 - accuracy: 0.5656 - val_loss: 1.2465 - val_accuracy: 0.5549\n",
      "Epoch 447/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.1874 - accuracy: 0.5652 - val_loss: 1.2424 - val_accuracy: 0.5553\n",
      "Epoch 448/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.1886 - accuracy: 0.5649 - val_loss: 1.2614 - val_accuracy: 0.5458\n",
      "Epoch 449/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.1867 - accuracy: 0.5661 - val_loss: 1.2377 - val_accuracy: 0.5563\n",
      "Epoch 450/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.1859 - accuracy: 0.5651 - val_loss: 1.2526 - val_accuracy: 0.5457\n",
      "Epoch 451/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.1856 - accuracy: 0.5651 - val_loss: 1.2478 - val_accuracy: 0.5531\n",
      "Epoch 452/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.1857 - accuracy: 0.5655 - val_loss: 1.2334 - val_accuracy: 0.5557\n",
      "Epoch 453/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.1851 - accuracy: 0.5650 - val_loss: 1.2473 - val_accuracy: 0.5550\n",
      "Epoch 454/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.1839 - accuracy: 0.5669 - val_loss: 1.2465 - val_accuracy: 0.5502\n",
      "Epoch 455/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.1840 - accuracy: 0.5661 - val_loss: 1.2552 - val_accuracy: 0.5468\n",
      "Epoch 456/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.1834 - accuracy: 0.5674 - val_loss: 1.2420 - val_accuracy: 0.5544\n",
      "Epoch 457/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.1819 - accuracy: 0.5670 - val_loss: 1.2554 - val_accuracy: 0.5498\n",
      "Epoch 458/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.1837 - accuracy: 0.5657 - val_loss: 1.2395 - val_accuracy: 0.5594\n",
      "Epoch 459/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.1804 - accuracy: 0.5683 - val_loss: 1.2414 - val_accuracy: 0.5503\n",
      "Epoch 460/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.1808 - accuracy: 0.5683 - val_loss: 1.2517 - val_accuracy: 0.5527\n",
      "Epoch 461/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.1817 - accuracy: 0.5669 - val_loss: 1.2356 - val_accuracy: 0.5552\n",
      "Epoch 462/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.1805 - accuracy: 0.5678 - val_loss: 1.2541 - val_accuracy: 0.5564\n",
      "Epoch 463/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.1806 - accuracy: 0.5667 - val_loss: 1.2295 - val_accuracy: 0.5608\n",
      "Epoch 464/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.1771 - accuracy: 0.5689 - val_loss: 1.2376 - val_accuracy: 0.5597\n",
      "Epoch 465/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.1794 - accuracy: 0.5682 - val_loss: 1.2338 - val_accuracy: 0.5568\n",
      "Epoch 466/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.1793 - accuracy: 0.5684 - val_loss: 1.2505 - val_accuracy: 0.5492\n",
      "Epoch 467/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.1775 - accuracy: 0.5689 - val_loss: 1.2319 - val_accuracy: 0.5560\n",
      "Epoch 468/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.1776 - accuracy: 0.5690 - val_loss: 1.2313 - val_accuracy: 0.5604\n",
      "Epoch 469/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.1763 - accuracy: 0.5676 - val_loss: 1.2476 - val_accuracy: 0.5560\n",
      "Epoch 470/2000\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 1.1739 - accuracy: 0.5706 - val_loss: 1.2322 - val_accuracy: 0.5616\n",
      "Epoch 471/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.1746 - accuracy: 0.5694 - val_loss: 1.2381 - val_accuracy: 0.5581\n",
      "Epoch 472/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.1725 - accuracy: 0.5708 - val_loss: 1.2380 - val_accuracy: 0.5535\n",
      "Epoch 473/2000\n",
      "366/366 [==============================] - 1s 4ms/step - loss: 1.1739 - accuracy: 0.5698 - val_loss: 1.2297 - val_accuracy: 0.5592\n",
      "Epoch 474/2000\n",
      "366/366 [==============================] - 1s 4ms/step - loss: 1.1749 - accuracy: 0.5686 - val_loss: 1.2271 - val_accuracy: 0.5565\n",
      "Epoch 475/2000\n",
      "366/366 [==============================] - 2s 5ms/step - loss: 1.1738 - accuracy: 0.5699 - val_loss: 1.2296 - val_accuracy: 0.5567\n",
      "Epoch 476/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.1766 - accuracy: 0.5695 - val_loss: 1.2282 - val_accuracy: 0.5578\n",
      "Epoch 477/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.1720 - accuracy: 0.5712 - val_loss: 1.2370 - val_accuracy: 0.5544\n",
      "Epoch 478/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.1726 - accuracy: 0.5698 - val_loss: 1.2286 - val_accuracy: 0.5598\n",
      "Epoch 479/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.1730 - accuracy: 0.5709 - val_loss: 1.2247 - val_accuracy: 0.5571\n",
      "Epoch 480/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.1721 - accuracy: 0.5701 - val_loss: 1.2369 - val_accuracy: 0.5566\n",
      "Epoch 481/2000\n",
      "366/366 [==============================] - 1s 4ms/step - loss: 1.1711 - accuracy: 0.5708 - val_loss: 1.2408 - val_accuracy: 0.5509\n",
      "Epoch 482/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.1697 - accuracy: 0.5706 - val_loss: 1.2318 - val_accuracy: 0.5588\n",
      "Epoch 483/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.1708 - accuracy: 0.5712 - val_loss: 1.2268 - val_accuracy: 0.5572\n",
      "Epoch 484/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.1706 - accuracy: 0.5706 - val_loss: 1.2209 - val_accuracy: 0.5609\n",
      "Epoch 485/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.1671 - accuracy: 0.5727 - val_loss: 1.2194 - val_accuracy: 0.5576\n",
      "Epoch 486/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.1689 - accuracy: 0.5715 - val_loss: 1.2310 - val_accuracy: 0.5510\n",
      "Epoch 487/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.1667 - accuracy: 0.5720 - val_loss: 1.2210 - val_accuracy: 0.5612\n",
      "Epoch 488/2000\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 1.1656 - accuracy: 0.5727 - val_loss: 1.2615 - val_accuracy: 0.5438\n",
      "Epoch 489/2000\n",
      "366/366 [==============================] - 1s 4ms/step - loss: 1.1658 - accuracy: 0.5724 - val_loss: 1.2100 - val_accuracy: 0.5664\n",
      "Epoch 490/2000\n",
      " 43/366 [==>...........................] - ETA: 1s - loss: 1.1612 - accuracy: 0.5768"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fit_epoch(128, 256, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
